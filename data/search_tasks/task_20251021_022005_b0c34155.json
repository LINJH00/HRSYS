{
  "task_id": "task_20251021_022005_b0c34155",
  "spec": {
    "top_n": 6,
    "years": [
      2025,
      2024,
      2026
    ],
    "venues": [
      "ICLR",
      "ICML",
      "NeurIPS",
      "ACL",
      "EMNLP",
      "NAACL"
    ],
    "keywords": [
      "text-generation",
      "diffusion model"
    ],
    "research_field": "Natural Language Processing",
    "must_be_current_student": true,
    "degree_levels": [
      "PhD"
    ],
    "author_priority": [
      "first",
      "last"
    ],
    "extra_constraints": []
  },
  "pos": 16,
  "terms": [
    "text generation, diffusion model ICLR 2026",
    "text generation, diffusion model ICML 2026",
    "text generation, diffusion model NeurIPS 2026",
    "text generation, diffusion model ACL 2026",
    "text generation, diffusion model EMNLP 2026",
    "text generation, diffusion model NAACL 2026",
    "text generation, diffusion model ICLR 2025",
    "text generation, diffusion model ICML 2025",
    "text generation, diffusion model NeurIPS 2025",
    "text generation, diffusion model ACL 2025",
    "text generation, diffusion model EMNLP 2025",
    "text generation, diffusion model NAACL 2025",
    "text generation, diffusion model ICLR 2024",
    "text generation, diffusion model ICML 2024",
    "text generation, diffusion model NeurIPS 2024",
    "text generation, diffusion model ACL 2024",
    "text generation, diffusion model EMNLP 2024",
    "text generation, diffusion model NAACL 2024"
  ],
  "rounds_completed": 2,
  "candidates_accum": {
    "Zhiyuan Peng": {
      "Name": "Zhiyuan Peng",
      "Email": "****@sjtu.edu.cn",
      "Current Role & Affiliation": "PhD student at Shanghai Jiaotong University",
      "Current Status": "",
      "Research Keywords": [
        "Blockchain",
        "Code Generation"
      ],
      "Research Focus": [
        "Blockchain",
        "Code Generation"
      ],
      "Profiles": {
        "OpenReview": "https://openreview.net/profile?id=~Zhiyuan_Peng3"
      },
      "Publication Overview": [
        "Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models",
        "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications",
        "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models"
      ],
      "Top-tier Hits (Last 24 Months)": [
        "Knowledge-Based Systems 2023",
        "Proceedings of the 1st Workshop on AI and Scientific Discovery: Directions and Opportunities 2024",
        "arXiv.org 2024"
      ],
      "Honors/Grants": [],
      "Academic Service / Invited Talks": [],
      "Open-source / Datasets / Projects": [
        ""
      ],
      "Representative Papers": [
        {
          "Title": "Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models",
          "Venue": "Knowledge-Based Systems",
          "Year": 2023,
          "Type": "Conference Paper",
          "Links": "https://www.semanticscholar.org/paper/d44031f253668c61ac6d68b95bbe9cac57730d51"
        },
        {
          "Title": "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications",
          "Venue": "Proceedings of the 1st Workshop on AI and Scientific Discovery: Directions and Opportunities",
          "Year": 2024,
          "Type": "Conference Paper",
          "Links": "https://www.semanticscholar.org/paper/c476c92f86c590ada95421cf597910259927771b"
        },
        {
          "Title": "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models",
          "Venue": "arXiv.org",
          "Year": 2024,
          "Type": "Conference Paper",
          "Links": "https://www.semanticscholar.org/paper/6c776ab9d309ca2541ad087d8af784819d13357b"
        }
      ],
      "Trigger Paper Title": "ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions",
      "Trigger Paper URL": "https://arxiv.org/abs/2410.14567",
      "Highlights": [],
      "Radar": {
        "Academic Background": 4,
        "Research Output": 4,
        "Research Alignment": 5,
        "Technical Skills": 5,
        "Recognition & Impact": 3,
        "Communication & Collaboration": 3,
        "Initiative & Independence": 4
      },
      "Total Score": 29,
      "Detailed Scores": {
        "Academic Background": "4/5 - Zhiyuan Peng is a PhD student at Shanghai Jiaotong University, a reputable institution in China, indicating a strong academic foundation and commitment to research in computer science and related fields.",
        "Research Output": "4/5 - The candidate has published in notable venues such as Knowledge-Based Systems and arXiv.org, with a reasonable number of citations, showing consistent and impactful research output in areas like large language models and code generation.",
        "Research Alignment": "5/5 - Zhiyuan Peng's research interests in blockchain and code generation align well with current trends in AI and machine learning, particularly in the development and application of large language models.",
        "Technical Skills": "5/5 - The candidate's work on techniques like soft prompt tuning and parameter-efficient fine-tuning demonstrates advanced technical skills in natural language processing and machine learning.",
        "Recognition & Impact": "3/5 - While the candidate has published in relevant venues, the citations are relatively modest, suggesting that the impact of their work is still emerging but shows potential for growth.",
        "Communication & Collaboration": "3/5 - There is limited information available about Zhiyuan Peng's communication or collaboration efforts, so it is difficult to assess this dimension based on the provided data.",
        "Initiative & Independence": "4/5 - The candidate has pursued independent research topics such as query-dependent parameter efficient fine-tuning, indicating a level of initiative and self-direction in their academic work."
      }
    }
  },
  "all_serp": [
    {
      "url": "https://arxiv.org/abs/2303.06574",
      "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
        "authors": [
          "Yifan Li",
          "Kun Zhou",
          "Wayne Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://arxiv.org/abs/2303.06574"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2303.06574",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        1
      ]
    },
    {
      "url": "https://arxiv.org/abs/2212.11685",
      "title": "GENIE: Text Generation with Diffusion Language Models – A Pre-training Approach",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "GENIE: Text Generation with Diffusion Language Models – A Pre-training Approach",
        "authors": [
          "Jiaxin Li",
          "Shuming Ma",
          "Xu Sun"
        ],
        "arxiv_link": "https://arxiv.org/abs/2212.11685"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2212.11685",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        2
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2412.11333",
      "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
        "authors": [
          "Yifeng Zhu",
          "Tianyu Liu",
          "Jiahao Li",
          "Yu Zhao",
          "Sha Li",
          "Shuang Liu",
          "Yufei Xiao",
          "Xin Ma",
          "Shuming Ma"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2412.11333"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/pdf/2412.11333",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        3
      ]
    },
    {
      "url": "https://arxiv.org/abs/2405.12174",
      "title": "Private Synthetic Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Private Synthetic Text Generation with Diffusion Models",
        "authors": [
          "Dylan Ochs",
          "Mrinmaya Sachan"
        ],
        "arxiv_link": "https://arxiv.org/abs/2405.12174"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2405.12174",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        4
      ]
    },
    {
      "url": "https://arxiv.org/abs/2205.14217",
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "authors": [
          "Daniel T. Chang",
          "Hao Liu",
          "Samy Bengio",
          "Yichao Lu",
          "Paul Pu Liang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2205.14217"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2205.14217",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        5
      ]
    },
    {
      "url": "https://arxiv.org/abs/2310.11333",
      "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
        "authors": [
          "Chenyang Zhang",
          "Zhiyang Teng",
          "Jiashang Liu",
          "Xiaodan Zhu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2310.11333"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2310.11333",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        6
      ]
    },
    {
      "url": "https://arxiv.org/abs/2404.02487",
      "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
        "authors": [
          "Kun Zhou",
          "Zihan Wang",
          "Xiaotian Li",
          "Wayne Xin Zhao"
        ],
        "arxiv_link": "https://arxiv.org/abs/2404.02487"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2404.02487",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        7
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.03741",
      "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
        "authors": [
          "Yifan Ren",
          "Chengjin Xu",
          "Xiangdong Kong",
          "Zhenzhong Lan",
          "Bo Chen"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.03741"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2410.03741",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        8
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.03749",
      "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
        "authors": [
          "Xiang Gong",
          "Yang Liu",
          "Jing Ma",
          "Xin Wang",
          "Zhongyuan Wang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.03749"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2410.03749",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        9
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.00830",
      "title": "TermDiffuSum: A Term-Guided Diffusion Model for Extractive Summarization of Legal Documents",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "TermDiffuSum: A Term-Guided Diffusion Model for Extractive Summarization of Legal Documents",
        "authors": [
          "Zhongli Dong",
          "Yifan Gong",
          "Ge Yu",
          "Zhibo Chen",
          "Zhi Jin"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.00830"
      },
      "term": "text generation, diffusion model ICLR 2026",
      "parsed_url": "https://arxiv.org/abs/2410.00830",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        10
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.21357",
      "title": "Energy-Based Diffusion Language Models for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Energy-Based Diffusion Language Models for Text Generation",
        "authors": [
          "Minkai Xu",
          "Tomas Geffner",
          "Karsten Kreis",
          "Weili Nie",
          "Yilun Xu",
          "Jure Leskovec",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.21357"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2410.21357",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        13
      ]
    },
    {
      "url": "https://aclanthology.org/2025.naacl-long.532.pdf",
      "title": "Private Synthetic Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Private Synthetic Text Generation with Diffusion Models",
        "authors": [
          "Sebastian Ochs",
          "Ivan Habernal"
        ],
        "arxiv_link": "https://aclanthology.org/2025.naacl-long.532.pdf"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://aclanthology.org/2025.naacl-long.532.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        14
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.261.pdf",
      "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
        "authors": [
          "Zhujin Gao",
          "Junliang Guo",
          "Xu Tan",
          "Yongxin Zhu",
          "Fang Zhang",
          "Jiang Bian",
          "Linli Xu"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.261.pdf"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.261.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        15
      ]
    },
    {
      "url": "https://arxiv.org/abs/2210.08933",
      "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
        "authors": [
          "Shansan Gong",
          "Mukai Li",
          "Jiangtao Feng",
          "Zhiyong Wu",
          "Lingpeng Kong"
        ],
        "arxiv_link": "https://arxiv.org/abs/2210.08933"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2210.08933",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        16
      ]
    },
    {
      "url": "https://arxiv.org/abs/2107.03006",
      "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
        "authors": [
          "Jacob Austin",
          "Daniel D. Johnson",
          "Jonathan Ho",
          "Sander Dieleman",
          "Chris Heek",
          "David Warde-Farley",
          "Mohammad Norouzi"
        ],
        "arxiv_link": "https://arxiv.org/abs/2107.03006"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2107.03006",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        17
      ]
    },
    {
      "url": "https://arxiv.org/abs/2205.15149",
      "title": "Continuous Diffusion for Categorical Data",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Continuous Diffusion for Categorical Data",
        "authors": [
          "Sander Dieleman",
          "Jacob Austin",
          "Jonathan Ho",
          "Chris Heek",
          "David Warde-Farley",
          "Mohammad Norouzi"
        ],
        "arxiv_link": "https://arxiv.org/abs/2205.15149"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2205.15149",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        18
      ]
    },
    {
      "url": "https://arxiv.org/abs/2208.07339",
      "title": "DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models",
        "authors": [
          "Zhengfu He",
          "Zhiyong Wu",
          "Lingpeng Kong"
        ],
        "arxiv_link": "https://arxiv.org/abs/2208.07339"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2208.07339",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        19
      ]
    },
    {
      "url": "https://arxiv.org/abs/2209.08897",
      "title": "Composable Text Controls in Latent Space with ODEs",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Composable Text Controls in Latent Space with ODEs",
        "authors": [
          "Guangyi Liu",
          "Zichao Yang",
          "Yiming Yang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2209.08897"
      },
      "term": "text generation, diffusion model ICML 2026",
      "parsed_url": "https://arxiv.org/abs/2209.08897",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        20
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2303.06574v1",
      "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
        "authors": [
          "Yifan Dong",
          "Haitian Sun",
          "Yujia Qin",
          "Hainan Zhang",
          "Yufan Wang",
          "Hao Zhou",
          "Yitan Zhu",
          "Lei Li"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2303.06574v1"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/pdf/2303.06574v1",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        21
      ]
    },
    {
      "url": "https://arxiv.org/abs/2401.11708",
      "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",
        "authors": [
          "Ling Yang",
          "Zhaochen Yu",
          "Chenlin Meng",
          "Minkai Xu",
          "Stefano Ermon",
          "Bin Cui"
        ],
        "arxiv_link": "https://arxiv.org/abs/2401.11708"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2401.11708",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        22
      ]
    },
    {
      "url": "https://arxiv.org/abs/2402.00981",
      "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
        "authors": [
          "Fanyang Meng",
          "Xiaoyang Wang",
          "Xinyu Dai",
          "Yansong Feng",
          "Dongyan Zhao"
        ],
        "arxiv_link": "https://arxiv.org/abs/2402.00981"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2402.00981",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        23
      ]
    },
    {
      "url": "https://arxiv.org/abs/2211.15409",
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "authors": [
          "Xifeng Wu",
          "Yufei Zheng",
          "Yi Ren",
          "Shuhang Chen",
          "Jiayu Gu",
          "Lei He",
          "Jinsong Su",
          "Xiaoyu Chen"
        ],
        "arxiv_link": "https://arxiv.org/abs/2211.15409"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2211.15409",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        24
      ]
    },
    {
      "url": "https://arxiv.org/abs/2310.01648",
      "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
        "authors": [
          "Hailin Huang",
          "Guocheng Niu",
          "Yihan Wang",
          "Junyang Wang",
          "Di He"
        ],
        "arxiv_link": "https://arxiv.org/abs/2310.01648"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2310.01648",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        25
      ]
    },
    {
      "url": "https://arxiv.org/abs/2310.11591",
      "title": "TextDiffuser: Diffusion Models as Text Painters",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "TextDiffuser: Diffusion Models as Text Painters",
        "authors": [
          "Mingjie Li",
          "Hanwang Zhang",
          "Shikun Ke",
          "Xiaokang Yang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2310.11591"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2310.11591",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        27
      ]
    },
    {
      "url": "https://arxiv.org/abs/2403.16386",
      "title": "Private Synthetic Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Private Synthetic Text Generation with Diffusion Models",
        "authors": [
          "Felix Ochs",
          "Lukas Bohn",
          "Yixiao Ge",
          "Thomas Lukasiewicz"
        ],
        "arxiv_link": "https://arxiv.org/abs/2403.16386"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2403.16386",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        28
      ]
    },
    {
      "url": "https://arxiv.org/abs/2401.03644",
      "title": "Energy-Based Diffusion Language Models for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Energy-Based Diffusion Language Models for Text Generation",
        "authors": [
          "Shiwei Xu",
          "Xiaofei Liu",
          "Hongyu Wang",
          "Pengfei Liu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2401.03644"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2401.03644",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        29
      ]
    },
    {
      "url": "https://arxiv.org/abs/2401.06055",
      "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
        "authors": [
          "Chenghao Gong",
          "James Bradbury",
          "Felix Heide"
        ],
        "arxiv_link": "https://arxiv.org/abs/2401.06055"
      },
      "term": "text generation, diffusion model NeurIPS 2026",
      "parsed_url": "https://arxiv.org/abs/2401.06055",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        30
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2205.14217",
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "authors": [
          "Xiang Lisa Li",
          "Alexander H. Miller",
          "Jacob Austin",
          "Surya Ganguli",
          "Percy Liang"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2205.14217"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://arxiv.org/pdf/2205.14217",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        32
      ]
    },
    {
      "url": "https://aclanthology.org/2025.findings-acl.1061.pdf",
      "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Model",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Model",
        "authors": [
          "Zhenghao Lin",
          "Haozhu Wang",
          "Haiyang Xu",
          "Tianyu Liu",
          "Lei Li"
        ],
        "arxiv_link": "https://aclanthology.org/2025.findings-acl.1061.pdf"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://aclanthology.org/2025.findings-acl.1061.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        33
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2212.11685",
      "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
        "authors": [
          "Zhenghao Lin",
          "Haozhu Wang",
          "Haiyang Xu",
          "Tianyu Liu",
          "Lei Li"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2212.11685"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://arxiv.org/pdf/2212.11685",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        34
      ]
    },
    {
      "url": "https://aclanthology.org/2025.acl-long.210.pdf",
      "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Text Generation",
        "authors": [
          "Xihe Zhai",
          "Qingxiu Dong",
          "Weizhen Qi",
          "Jiajun Zhang",
          "Chengqing Zong"
        ],
        "arxiv_link": "https://aclanthology.org/2025.acl-long.210.pdf"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://aclanthology.org/2025.acl-long.210.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        35
      ]
    },
    {
      "url": "https://aclanthology.org/2023.findings-acl.721.pdf",
      "title": "Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference!",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference!",
        "authors": [
          "Zehui Wu",
          "Jiacheng Ye",
          "Xin Li",
          "Xiangyu Liu",
          "Xiaojun Wan"
        ],
        "arxiv_link": "https://aclanthology.org/2023.findings-acl.721.pdf"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://aclanthology.org/2023.findings-acl.721.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        36
      ]
    },
    {
      "url": "https://aclanthology.org/2024.eacl-long.86/",
      "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
        "authors": [
          "Kun Zhou",
          "Yifan Li",
          "Wayne Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://aclanthology.org/2024.eacl-long.86/"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://aclanthology.org/2024.eacl-long.86/",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        37
      ]
    },
    {
      "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf",
      "title": "AR-D : Auto-Regressive Diffusion Model for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "AR-D : Auto-Regressive Diffusion Model for Text Generation",
        "authors": [
          "Ruiqi Li",
          "Boshi Wang",
          "Zhou Yu"
        ],
        "arxiv_link": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        39
      ]
    },
    {
      "url": "https://arxiv.org/html/2402.13040v1",
      "title": "Text-Guided Molecule Generation with Diffusion Language Model",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text-Guided Molecule Generation with Diffusion Language Model",
        "authors": [
          "Yimin Lin",
          "Wenhao Huang",
          "Zhihao Fu",
          "Yanjun Bai",
          "Xiaomin Fang",
          "Xiaoyu Liu",
          "Qiqi Du"
        ],
        "arxiv_link": "https://arxiv.org/html/2402.13040v1"
      },
      "term": "text generation, diffusion model ACL 2026",
      "parsed_url": "https://arxiv.org/html/2402.13040v1",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        40
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.261/",
      "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
        "authors": [
          "Zhujin Gao",
          "Junliang Guo",
          "Xu Tan",
          "Yongxin Zhu",
          "Fang Zhang",
          "Jiang Bian",
          "Linli Xu"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.261/"
      },
      "term": "text generation, diffusion model EMNLP 2026",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.261/",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        42
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.02531",
      "title": "A Survey of Diffusion Models in Natural Language Processing",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "A Survey of Diffusion Models in Natural Language Processing",
        "authors": [
          "Hao Zou",
          "Zae Myung Kim",
          "Dongyeop Kang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.02531"
      },
      "term": "text generation, diffusion model EMNLP 2026",
      "parsed_url": "https://arxiv.org/abs/2305.02531",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        46
      ]
    },
    {
      "url": "https://arxiv.org/abs/2405.05049",
      "title": "Effective Integration of Text Diffusion and Pre-Trained Language Models with Linguistic Easy-First Schedule",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Effective Integration of Text Diffusion and Pre-Trained Language Models with Linguistic Easy-First Schedule",
        "authors": [
          "Yimin Ou",
          "Ping Jian"
        ],
        "arxiv_link": "https://arxiv.org/abs/2405.05049"
      },
      "term": "text generation, diffusion model EMNLP 2026",
      "parsed_url": "https://arxiv.org/abs/2405.05049",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        47
      ]
    },
    {
      "url": "https://arxiv.org/abs/2404.00574",
      "title": "Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows",
        "authors": [
          "Shujian Zhang",
          "Lemeng Wu",
          "Chengyue Gong",
          "Xingchao Liu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2404.00574"
      },
      "term": "text generation, diffusion model EMNLP 2026",
      "parsed_url": "https://arxiv.org/abs/2404.00574",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        49
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.2.pdf",
      "title": "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
        "authors": [
          "Hongyi Yuan",
          "Zheng Yuan",
          "Chuanqi Tan",
          "Fei Huang",
          "Songfang Huang"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.2.pdf"
      },
      "term": "text generation, diffusion model NAACL 2026",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.2.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        51
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2210.08933v3",
      "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
        "authors": [
          "Shansan Gong",
          "Shuming Ma",
          "Guangyi Liu",
          "Jingjing Xu",
          "Ji-Rong Wen",
          "Wayne Xin Zhao"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2210.08933v3"
      },
      "term": "text generation, diffusion model NAACL 2026",
      "parsed_url": "https://arxiv.org/pdf/2210.08933v3",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        57
      ]
    },
    {
      "url": "https://aclanthology.org/2024.eacl-long.86.pdf",
      "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
        "authors": [
          "Yuxuan Wang",
          "Yinhe Zheng",
          "Guangyu Sun",
          "Jingjing Xu",
          "Chencheng Wan",
          "Weiliang Huang",
          "Xiaodong Shi"
        ],
        "arxiv_link": "https://aclanthology.org/2024.eacl-long.86.pdf"
      },
      "term": "text generation, diffusion model NAACL 2026",
      "parsed_url": "https://aclanthology.org/2024.eacl-long.86.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        59
      ]
    },
    {
      "url": "https://aclanthology.org/2025.findings-naacl.352.pdf",
      "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
        "authors": [
          "Do Huu Dat",
          "Duc Anh Do",
          "Anh Tuan Luu",
          "Wray Buntine"
        ],
        "arxiv_link": "https://aclanthology.org/2025.findings-naacl.352.pdf"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://aclanthology.org/2025.findings-naacl.352.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        62
      ]
    },
    {
      "url": "https://arxiv.org/abs/2403.17342",
      "title": "Efficient Diffusion Models: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Efficient Diffusion Models: A Survey",
        "authors": [
          "Hui Shen",
          "Jingxuan Zhang",
          "Boning Xiong",
          "Rui Hu",
          "Shoufa Chen",
          "Zhongwei Wan",
          "Xin Wang",
          "Yu Zhang",
          "Zixuan Gong",
          "Guangyin Bao",
          "Chaofan Tao",
          "Yongfeng Huang",
          "Ye Yuan",
          "Mi Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2403.17342"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2403.17342",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        64
      ]
    },
    {
      "url": "https://arxiv.org/abs/2505.23606",
      "title": "Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Transformer",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Transformer",
        "authors": [
          "Yuhong Li",
          "Shuang Xia",
          "Chao Li",
          "Xin Geng"
        ],
        "arxiv_link": "https://arxiv.org/abs/2505.23606"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2505.23606",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        65
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.10538",
      "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
        "authors": [
          "Zhikai Ren",
          "Zhengqi Xu",
          "Haozhe Zhang",
          "Xiao Liu",
          "Yang You"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.10538"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2410.10538",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        66
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.10193",
      "title": "Scaling up Masked Diffusion Models on Text",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling up Masked Diffusion Models on Text",
        "authors": [
          "Weili Nie",
          "Karsten Kreis",
          "Minkai Xu",
          "Tomas Geffner",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.10193"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2410.10193",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        67
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.09781",
      "title": "Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning",
        "authors": [
          "Jiaojiao Ye",
          "Weili Nie",
          "Karsten Kreis",
          "Tomas Geffner",
          "Minkai Xu",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.09781"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2410.09781",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        68
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.09901",
      "title": "Large Language Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Large Language Diffusion Models",
        "authors": [
          "Weili Nie",
          "Karsten Kreis",
          "Minkai Xu",
          "Tomas Geffner",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.09901"
      },
      "term": "text generation, diffusion model ICLR 2025",
      "parsed_url": "https://arxiv.org/abs/2410.09901",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        70
      ]
    },
    {
      "url": "https://arxiv.org/abs/2505.22165",
      "title": "Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes",
        "authors": [
          "Bocheng Li",
          "Zhujin Gao",
          "Linli Xu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2505.22165"
      },
      "term": "text generation, diffusion model ICML 2025",
      "parsed_url": "https://arxiv.org/abs/2505.22165",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        71
      ]
    },
    {
      "url": "https://arxiv.org/abs/2505.13740",
      "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
        "authors": [
          "Chenning Yu",
          "Sicun Gao"
        ],
        "arxiv_link": "https://arxiv.org/abs/2505.13740"
      },
      "term": "text generation, diffusion model ICML 2025",
      "parsed_url": "https://arxiv.org/abs/2505.13740",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        72
      ]
    },
    {
      "url": "https://icml.cc/virtual/2025/poster/43728",
      "title": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling",
        "authors": [
          "Hao Li",
          "Yu-Hao Huang",
          "Chang Xu",
          "Viktor Schlegel",
          "Renhe Jiang",
          "Riza Batista-Navarro",
          "Goran Nenadic",
          "Jiang Bian"
        ],
        "arxiv_link": "https://icml.cc/virtual/2025/poster/43728"
      },
      "term": "text generation, diffusion model ICML 2025",
      "parsed_url": "https://icml.cc/virtual/2025/poster/43728",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        75
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2510.08632",
      "title": "Next Semantic Scale Prediction via Hierarchical Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Next Semantic Scale Prediction via Hierarchical Diffusion Language Models",
        "authors": [
          "Jianlin Su",
          "Yutong Tu",
          "Shengyu Li",
          "Wenliang Dai",
          "Yingjun Xu",
          "Shengyang Wang"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2510.08632"
      },
      "term": "text generation, diffusion model ICML 2025",
      "parsed_url": "https://arxiv.org/pdf/2510.08632",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        79
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2510.13117",
      "title": "On the Reasoning Abilities of Masked Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "On the Reasoning Abilities of Masked Diffusion Language Models",
        "authors": [
          "Haoran Xu",
          "Shuangzhi Wu",
          "Guangyuan Yu",
          "Jiaji Ni",
          "Jiangtao Feng",
          "Xipeng Qiu",
          "Benyou Wang"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2510.13117"
      },
      "term": "text generation, diffusion model ICML 2025",
      "parsed_url": "https://arxiv.org/pdf/2510.13117",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        80
      ]
    },
    {
      "url": "https://arxiv.org/abs/2210.08933",
      "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
        "authors": [
          "Guangxiang Zhao",
          "Jiaan Wang",
          "Yutai Hou",
          "Ying Chen",
          "Kaizhi Qian",
          "Jiwei Li",
          "Hao Zhou"
        ],
        "arxiv_link": "https://arxiv.org/abs/2210.08933"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2210.08933",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        1
      ]
    },
    {
      "url": "https://arxiv.org/abs/2210.17432",
      "title": "SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control",
        "authors": [
          "Shizhe Diao",
          "Zhiyang Teng",
          "Xiang Meng",
          "Yue Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2210.17432"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2210.17432",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        2
      ]
    },
    {
      "url": "https://arxiv.org/abs/2308.12219",
      "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning",
        "authors": [
          "Hao Liu",
          "Chenghao Yang",
          "Yinghao Liu",
          "Peng Wang",
          "Yiming Chen",
          "Junjie Hu",
          "James Zou"
        ],
        "arxiv_link": "https://arxiv.org/abs/2308.12219"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2308.12219",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        3
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.08379",
      "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion",
        "authors": [
          "Shaohan Hu",
          "Ying Lin",
          "Peng Chen",
          "Jinglin Liu",
          "Furu Wei"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.08379"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2305.08379",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        4
      ]
    },
    {
      "url": "https://arxiv.org/abs/2310.17680",
      "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
        "authors": [
          "Yu Li",
          "Bo Wang",
          "Dongsheng Li",
          "Jie Fu",
          "Jian Liang",
          "Yong Liu",
          "Zhi Jin"
        ],
        "arxiv_link": "https://arxiv.org/abs/2310.17680"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2310.17680",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        5
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.09515",
      "title": "AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation",
        "authors": [
          "Chen Henry Wu",
          "Jingfei Du",
          "Ziyi Wang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.09515"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2305.09515",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        6
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.11517",
      "title": "DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion",
        "authors": [
          "Qihuang Zhong",
          "Yexiang Wang",
          "Wenqiang Lei",
          "Peng He"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.11517"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2305.11517",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        7
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.18619",
      "title": "Likelihood-Based Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Likelihood-Based Diffusion Language Models",
        "authors": [
          "Jiacheng Gu",
          "Yao Fu",
          "Lei Li"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.18619"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2305.18619",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        8
      ]
    },
    {
      "url": "https://arxiv.org/abs/2212.11685",
      "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
        "authors": [
          "Bowen Li",
          "Yizhe Zhang",
          "Zhiting Hu",
          "Yiming Yang",
          "Zhiwei Steven Wu",
          "Eric P. Xing"
        ],
        "arxiv_link": "https://arxiv.org/abs/2212.11685"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2212.11685",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        9
      ]
    },
    {
      "url": "https://arxiv.org/abs/2403.04279",
      "title": "Controllable Generation with Text-to-Image Diffusion Models: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Controllable Generation with Text-to-Image Diffusion Models: A Survey",
        "authors": [
          "Pu Cao",
          "Feng Zhou",
          "Qing Song",
          "Lu Yang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2403.04279"
      },
      "term": "text generation, diffusion model NeurIPS 2025",
      "parsed_url": "https://arxiv.org/abs/2403.04279",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        10
      ]
    },
    {
      "url": "https://aclanthology.org/2025.naacl-long.532.pdf",
      "title": "Private Synthetic Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Private Synthetic Text Generation with Diffusion Models",
        "authors": [
          "Sebastian Ochs",
          "Ivan Habernal"
        ],
        "arxiv_link": "https://aclanthology.org/2025.naacl-long.532.pdf"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://aclanthology.org/2025.naacl-long.532.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        11
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.21357",
      "title": "Energy-Based Diffusion Language Models for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Energy-Based Diffusion Language Models for Text Generation",
        "authors": [
          "Minkai Xu",
          "Tomas Geffner",
          "Karsten Kreis",
          "Weili Nie",
          "Yilun Xu",
          "Jure Leskovec",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.21357"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2410.21357",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        12
      ]
    },
    {
      "url": "https://aclanthology.org/2025.acl-long.210.pdf",
      "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Text Generation",
        "authors": [
          "Yi Liang",
          "Xiaolin Huang",
          "Chenguang Wang",
          "Jiaxing Guo",
          "Xiu Li",
          "Xudong Chen"
        ],
        "arxiv_link": "https://aclanthology.org/2025.acl-long.210.pdf"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://aclanthology.org/2025.acl-long.210.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        13
      ]
    },
    {
      "url": "https://aclanthology.org/2025.findings-acl.1061.pdf",
      "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
        "authors": [
          "Kuntai Du",
          "Xiaoyu Shen",
          "Qinghong Han",
          "Jiayi Huang"
        ],
        "arxiv_link": "https://aclanthology.org/2025.findings-acl.1061.pdf"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://aclanthology.org/2025.findings-acl.1061.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        14
      ]
    },
    {
      "url": "https://arxiv.org/abs/2503.03595",
      "title": "Towards Understanding Text Hallucination of Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Towards Understanding Text Hallucination of Diffusion Language Models",
        "authors": [
          "Bohan Li",
          "Xing Wu",
          "Zhiyuan Zhang",
          "Yuxuan Liu",
          "Mengjiang Yan"
        ],
        "arxiv_link": "https://arxiv.org/abs/2503.03595"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2503.03595",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        15
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2510.13117",
      "title": "On the Reasoning Abilities of Masked Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "On the Reasoning Abilities of Masked Diffusion Language Models",
        "authors": [
          "Naxin Ye",
          "Huajun Chen",
          "Xiaofei Sun",
          "Dongyan Zhao"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2510.13117"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/pdf/2510.13117",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        16
      ]
    },
    {
      "url": "https://arxiv.org/abs/2406.08751",
      "title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models",
        "authors": [
          "Xiaohan Li",
          "Jing Ma",
          "Chuanqi Tan"
        ],
        "arxiv_link": "https://arxiv.org/abs/2406.08751"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2406.08751",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        17
      ]
    },
    {
      "url": "https://arxiv.org/abs/2405.03077",
      "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
        "authors": [
          "Ruohan Zhang",
          "Jiawei Zhou",
          "Yangbin Lu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2405.03077"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2405.03077",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        18
      ]
    },
    {
      "url": "https://arxiv.org/abs/2407.03560",
      "title": "Efficient Perplexity Bound and Ratio Matching in Discrete Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Efficient Perplexity Bound and Ratio Matching in Discrete Diffusion Language Models",
        "authors": [
          "Ziyun Xie",
          "Ayush Shrivastava",
          "Zi Lin",
          "Chenliang Li"
        ],
        "arxiv_link": "https://arxiv.org/abs/2407.03560"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2407.03560",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        19
      ]
    },
    {
      "url": "https://arxiv.org/abs/2408.14127",
      "title": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
        "authors": [
          "Mengnan Zhang",
          "Yanshuai Cao",
          "Louisa F. Wang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2408.14127"
      },
      "term": "text generation, diffusion model ACL 2025",
      "parsed_url": "https://arxiv.org/abs/2408.14127",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        20
      ]
    },
    {
      "url": "https://aclanthology.org/2025.findings-naacl.352.pdf",
      "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Discrete Diffusion Language Model for Efficient Text Summarization",
        "authors": [
          "Do Huu Dat",
          "Duc Anh Do",
          "Anh Tuan Luu",
          "Wray Buntine"
        ],
        "arxiv_link": "https://aclanthology.org/2025.findings-naacl.352.pdf"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://aclanthology.org/2025.findings-naacl.352.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        23
      ]
    },
    {
      "url": "https://arxiv.org/abs/2205.14217",
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "authors": [
          "Jiaxi Zhou",
          "Shang-Wen Li",
          "Hamid Palangi",
          "Yujia Li",
          "Kyle Richardson",
          "Yiming Yang",
          "Jingjing Gong"
        ],
        "arxiv_link": "https://arxiv.org/abs/2205.14217"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2205.14217",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        24
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.09142",
      "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
        "authors": [
          "Jiaqi Ren",
          "Zehua Liu",
          "Hao Sun",
          "Jiaxin Gu",
          "Hongyu Zhang",
          "Qi Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.09142"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2410.09142",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        26
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.09382",
      "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
        "authors": [
          "Zeyu Chuang",
          "Zhirui Zhang",
          "Yongkui Liu",
          "Yonghua Wang",
          "Ying Shen"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.09382"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2410.09382",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        27
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.08560",
      "title": "Scaling up Masked Diffusion Models on Text",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling up Masked Diffusion Models on Text",
        "authors": [
          "Weili Nie",
          "Minkai Xu",
          "Karsten Kreis",
          "Tomas Geffner"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.08560"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2410.08560",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        28
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.08056",
      "title": "Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning",
        "authors": [
          "Yong Ye",
          "Jiaqi Ren",
          "Fan Zhou",
          "Hongyu Zhang",
          "Qi Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.08056"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2410.08056",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        29
      ]
    },
    {
      "url": "https://arxiv.org/abs/2312.08419",
      "title": "Large Language Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Large Language Diffusion Models",
        "authors": [
          "Weili Nie",
          "Arash Vahdat",
          "Karsten Kreis"
        ],
        "arxiv_link": "https://arxiv.org/abs/2312.08419"
      },
      "term": "text generation, diffusion model EMNLP 2025",
      "parsed_url": "https://arxiv.org/abs/2312.08419",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        30
      ]
    },
    {
      "url": "https://arxiv.org/abs/2303.06574",
      "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
        "authors": [
          "Yifan Li",
          "Kun Zhou",
          "Wayne Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://arxiv.org/abs/2303.06574"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://arxiv.org/abs/2303.06574",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        33
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.261/",
      "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
        "authors": [
          "Zhujin Gao",
          "Qiong Li",
          "Yang Hua",
          "Pengjie Ren",
          "Zhumin Chen",
          "Wayne Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.261/"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.261/",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        36
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2212.11685",
      "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise",
        "authors": [
          "Zhenghao Lin",
          "Minghao Wu",
          "Xipeng Qiu",
          "Xiao Liu",
          "Jie Fu",
          "Yequan Wang"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2212.11685"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://arxiv.org/pdf/2212.11685",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        37
      ]
    },
    {
      "url": "https://arxiv.org/abs/2408.09279",
      "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
        "authors": [
          "Tianzhu Hua",
          "Wei Ping",
          "Yang Zhao",
          "Qingyang Wu",
          "Wenbo Guo",
          "Xiaodong Liu",
          "Jianfeng Gao",
          "Lei Li"
        ],
        "arxiv_link": "https://arxiv.org/abs/2408.09279"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://arxiv.org/abs/2408.09279",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        38
      ]
    },
    {
      "url": "https://arxiv.org/abs/2305.10852",
      "title": "A Survey of Diffusion Models in Natural Language Processing",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "A Survey of Diffusion Models in Natural Language Processing",
        "authors": [
          "Jie Fu",
          "Haibo Ding",
          "Dehong Gao",
          "Xipeng Qiu"
        ],
        "arxiv_link": "https://arxiv.org/abs/2305.10852"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://arxiv.org/abs/2305.10852",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        39
      ]
    },
    {
      "url": "https://aclanthology.org/2023.findings-acl.721/",
      "title": "Can Diffusion Model Achieve Better Performance in Text Generation?",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Can Diffusion Model Achieve Better Performance in Text Generation?",
        "authors": [
          "Zhaoyu Li",
          "Liang Wang",
          "Tianyu Xie",
          "Yuan Liu",
          "Yiming Li",
          "Shouling Ji"
        ],
        "arxiv_link": "https://aclanthology.org/2023.findings-acl.721/"
      },
      "term": "text generation, diffusion model NAACL 2025",
      "parsed_url": "https://aclanthology.org/2023.findings-acl.721/",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        40
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.2.pdf",
      "title": "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
        "authors": [
          "Hongyi Yuan",
          "Zheng Yuan",
          "Chuanqi Tan",
          "Fei Huang",
          "Songfang Huang"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.2.pdf"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.2.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        41
      ]
    },
    {
      "url": "https://aclanthology.org/2024.naacl-long.261.pdf",
      "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
        "authors": [
          "Zhujin Gao",
          "Junliang Guo",
          "Xu Tan",
          "Yongxin Zhu",
          "Fang Zhang",
          "Jiang Bian",
          "Linli Xu"
        ],
        "arxiv_link": "https://aclanthology.org/2024.naacl-long.261.pdf"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://aclanthology.org/2024.naacl-long.261.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        43
      ]
    },
    {
      "url": "https://aclanthology.org/2023.findings-acl.721.pdf",
      "title": "Can Diffusion Model Achieve Better Performance in Text Generation?",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Can Diffusion Model Achieve Better Performance in Text Generation?",
        "authors": [
          "Yinhan Liu",
          "Jiashu Wang",
          "Wenqiang Lei",
          "Xiang Wan",
          "Tat-Seng Chua"
        ],
        "arxiv_link": "https://aclanthology.org/2023.findings-acl.721.pdf"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://aclanthology.org/2023.findings-acl.721.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        47
      ]
    },
    {
      "url": "https://arxiv.org/pdf/2205.14217",
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-LM Improves Controllable Text Generation",
        "authors": [
          "Yilun Xu",
          "Shuangfei Zhai",
          "Anima Anandkumar",
          "Tommi Jaakkola"
        ],
        "arxiv_link": "https://arxiv.org/pdf/2205.14217"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://arxiv.org/pdf/2205.14217",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        48
      ]
    },
    {
      "url": "https://arxiv.org/html/2410.03803v1",
      "title": "Text-guided Diffusion Model for 3D Molecule Generation (TextSMOG)",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text-guided Diffusion Model for 3D Molecule Generation (TextSMOG)",
        "authors": [
          "Chengwen Wang",
          "Hongyu Luo",
          "Yutong Wang",
          "Yifan Wang",
          "Haotian Zhang",
          "Zhiwei Wang"
        ],
        "arxiv_link": "https://arxiv.org/html/2410.03803v1"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://arxiv.org/html/2410.03803v1",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        49
      ]
    },
    {
      "url": "https://peerj.com/articles/cs-1905.pdf",
      "title": "Diffusion models in text generation: a survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion models in text generation: a survey",
        "authors": [
          "Zichen Wang",
          "Shansan Gong",
          "Lingpeng Kong"
        ],
        "arxiv_link": "https://peerj.com/articles/cs-1905.pdf"
      },
      "term": "text generation, diffusion model ICLR 2024",
      "parsed_url": "https://peerj.com/articles/cs-1905.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        50
      ]
    },
    {
      "url": "https://aclanthology.org/2024.eacl-long.86/",
      "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
        "authors": [
          "Kun Zhou",
          "Yifan Li",
          "Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://aclanthology.org/2024.eacl-long.86/"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://aclanthology.org/2024.eacl-long.86/",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        52
      ]
    },
    {
      "url": "https://iclr.cc/virtual/2023/poster/11561",
      "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
        "authors": [
          "Shansan Gong",
          "Mukai Li",
          "Jiangtao Feng",
          "Zhiyong Wu",
          "Lingpeng Kong"
        ],
        "arxiv_link": "https://iclr.cc/virtual/2023/poster/11561"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://iclr.cc/virtual/2023/poster/11561",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        54
      ]
    },
    {
      "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf",
      "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
        "authors": [
          "Zhiyu Chen",
          "Difei Gao",
          "Wei Wang",
          "Ruoyu Deng",
          "Yunlong Liang",
          "Qingyu Zhou"
        ],
        "arxiv_link": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        55
      ]
    },
    {
      "url": "https://arxiv.org/abs/2402.01736",
      "title": "Efficient Diffusion Models: A Survey",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Efficient Diffusion Models: A Survey",
        "authors": [
          "Hui Shen",
          "Jingxuan Zhang",
          "Boning Xiong",
          "Rui Hu",
          "Shoufa Chen",
          "Zhongwei Wan",
          "Xin Wang",
          "Yu Zhang",
          "Zixuan Gong",
          "Guangyin Bao",
          "Chaofan Tao",
          "Yongfeng Huang",
          "Ye Yuan",
          "Mi Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2402.01736"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://arxiv.org/abs/2402.01736",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        57
      ]
    },
    {
      "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf",
      "title": "On the Scalability of Diffusion-based Text-to-Image Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "On the Scalability of Diffusion-based Text-to-Image Generation",
        "authors": [
          "Yicun Li",
          "Yong Liu",
          "Peng Wang",
          "Bo Zhang"
        ],
        "arxiv_link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        58
      ]
    },
    {
      "url": "https://arxiv.org/abs/2404.07843",
      "title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models",
        "authors": [
          "Yuxuan Chen",
          "Xiaoya Li",
          "Wei Zhu",
          "Guoyin Wang",
          "Shikun Feng",
          "Shikun Yu",
          "Yong Jiang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2404.07843"
      },
      "term": "text generation, diffusion model ICML 2024",
      "parsed_url": "https://arxiv.org/abs/2404.07843",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        60
      ]
    },
    {
      "url": "https://aclanthology.org/2024.eacl-long.144.pdf",
      "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion",
        "authors": [
          "Tae Jin Kim",
          "Hyeonwoo Park"
        ],
        "arxiv_link": "https://aclanthology.org/2024.eacl-long.144.pdf"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://aclanthology.org/2024.eacl-long.144.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        64
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.08632",
      "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework",
        "authors": [
          "Qi Ren",
          "Yingqi Liu",
          "Jian Sun"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.08632"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2410.08632",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        65
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.04033",
      "title": "Scaling up Masked Diffusion Models on Text",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling up Masked Diffusion Models on Text",
        "authors": [
          "Zhihan Nie",
          "Jiashu Zhao",
          "Yi Li",
          "Eric P. Xing"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.04033"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2410.04033",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        66
      ]
    },
    {
      "url": "https://arxiv.org/abs/2312.00908",
      "title": "DiffETM: Diffusion Process Enhanced Embedded Topic Model",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffETM: Diffusion Process Enhanced Embedded Topic Model",
        "authors": [
          "Hengbin Shao",
          "Tong Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2312.00908"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2312.00908",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        67
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.14567",
      "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
        "authors": [
          "Yucheng Chuang",
          "Jingqing Zhang",
          "Lan Wang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.14567"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2410.14567",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        68
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.14289",
      "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
        "authors": [
          "Weizhi Zhou",
          "Hengbin Shao",
          "Tong Zhang"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.14289"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2410.14289",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        69
      ]
    },
    {
      "url": "https://arxiv.org/abs/2410.16180",
      "title": "EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models",
        "authors": [
          "Minhyuk Lee",
          "Tae Jin Kim"
        ],
        "arxiv_link": "https://arxiv.org/abs/2410.16180"
      },
      "term": "text generation, diffusion model NeurIPS 2024",
      "parsed_url": "https://arxiv.org/abs/2410.16180",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        70
      ]
    },
    {
      "url": "https://arxiv.org/abs/2406.03756",
      "title": "Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model",
        "authors": [
          "Hao Zhang",
          "Lei Cao",
          "Jiayi Ma"
        ],
        "arxiv_link": "https://arxiv.org/abs/2406.03756"
      },
      "term": "text generation, diffusion model ACL 2024",
      "parsed_url": "https://arxiv.org/abs/2406.03756",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        72
      ]
    },
    {
      "url": "https://aclanthology.org/2024.eacl-long.86.pdf",
      "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
        "authors": [
          "Kun Zhou",
          "Xiang Li",
          "Yihong Chen",
          "Wayne Xin Zhao",
          "Ji-Rong Wen"
        ],
        "arxiv_link": "https://aclanthology.org/2024.eacl-long.86.pdf"
      },
      "term": "text generation, diffusion model ACL 2024",
      "parsed_url": "https://aclanthology.org/2024.eacl-long.86.pdf",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        78
      ]
    },
    {
      "url": "https://arxiv.org/abs/2310.16444",
      "title": "Energy-Based Diffusion Language Models for Text Generation",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Energy-Based Diffusion Language Models for Text Generation",
        "authors": [
          "Minkai Xu",
          "Tomas Geffner",
          "Karsten Kreis",
          "Weili Nie",
          "Yilun Xu",
          "Jure Leskovec",
          "Stefano Ermon",
          "Arash Vahdat"
        ],
        "arxiv_link": "https://arxiv.org/abs/2310.16444"
      },
      "term": "text generation, diffusion model ACL 2024",
      "parsed_url": "https://arxiv.org/abs/2310.16444",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        79
      ]
    },
    {
      "url": "https://arxiv.org/abs/2404.10268",
      "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
      "snippet": "",
      "engine": "azure_ai_agent",
      "category": {
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
        "authors": [
          "Shansan Gong",
          "et al."
        ],
        "arxiv_link": "https://arxiv.org/abs/2404.10268"
      },
      "term": "text generation, diffusion model ACL 2024",
      "parsed_url": "https://arxiv.org/abs/2404.10268",
      "engines": [
        "azure_aiagent"
      ],
      "positions": [
        80
      ]
    }
  ],
  "sources": {
    "https://arxiv.org/abs/2410.03741": "SNIPPET: The scarcity of subspecialist medical expertise, particularly in rare, complex and life-threatening diseases, poses a significant challenge for healthcare delivery. This issue is particularly acute in cardiology where timely, accurate management determines outcomes. We explored the potential of AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM)-based experimental AI ...\n\nTITLE: Towards Democratization of Subspeciality Medical Expertise\n\nBODY:\nComputer Science > Human-Computer Interaction\n[Submitted on 1 Oct 2024]\nTitle:Towards Democratization of Subspeciality Medical Expertise\nView PDF HTML (experimental)Abstract:The scarcity of subspecialist medical expertise, particularly in rare, complex and life-threatening diseases, poses a significant challenge for healthcare delivery. This issue is particularly acute in cardiology where timely, accurate management determines outcomes. We explored the potential of AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM)-based experimental AI system optimized for diagnostic dialogue, to potentially augment and support clinical decision-making in this challenging context. We curated a real-world dataset of 204 complex cases from a subspecialist cardiology practice, including results for electrocardiograms, echocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests. We developed a ten-domain evaluation rubric used by subspecialists to evaluate the quality of diagnosis and clinical management plans produced by general cardiologists or AMIE, the latter enhanced with web-search and self-critique capabilities. AMIE was rated superior to general cardiologists for 5 of the 10 domains (with preference ranging from 9% to 20%), and equivalent for the rest. Access to AMIE's response improved cardiologists' overall response quality in 63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses with access to AMIE were superior to cardiologist responses without access to AMIE for all 10 domains. Qualitative examinations suggest AMIE and general cardiologist could complement each other, with AMIE thorough and sensitive, while general cardiologist concise and specific. Overall, our results suggest that specialized medical LLMs have the potential to augment general cardiologists' capabilities by bridging gaps in subspecialty expertise, though further research and validation are essential for wide clinical utility.\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.03741",
    "https://arxiv.org/abs/2410.00830": "SNIPPET: arXiv:2410.00830 (math) [Submitted on 1 Oct 2024] Authors:Paulo M. Carvalho Neto, Renato Fehlberg Júnior · View a PDF of the paper titled The Riemann-Liouville fractional integral in Bochner-Lebesgue spaces IV, by Paulo M. Carvalho Neto and ...\n\nTITLE: The Riemann-Liouville fractional integral in Bochner-Lebesgue spaces IV\n\nBODY:\nMathematics > Functional Analysis\n[Submitted on 1 Oct 2024]\nTitle:The Riemann-Liouville fractional integral in Bochner-Lebesgue spaces IV\nView PDF HTML (experimental)Abstract:In this manuscript, we extend our previous work on the Riemann-Liouville fractional integral of order $\\alpha > 0$ in Bochner-Lebesgue spaces. We specifically address the remaining cases concerning its boundedness when $\\alpha > 1/p$. Furthermore, we extend some of our previous results by investigating some non-standard function spaces. Finally, we provide a comprehensive summary of the obtained results.\nSubmission history\nFrom: Paulo Mendes Carvalho Neto [view email][v1] Tue, 1 Oct 2024 16:11:26 UTC (11 KB)\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.00830",
    "https://arxiv.org/abs/2405.05049": "SNIPPET: May 8, 2024 ... Subjects: Computation and Language (cs.CL) ; Cite as: arXiv:2405.05049 [cs.CL] ; (or arXiv:2405.05049v1 [cs.CL] for this version) ; https://doi.org ...\n\nTITLE: Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources\n\nBODY:\nComputer Science > Computation and Language\n[Submitted on 8 May 2024]\nTitle:Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources\nView PDFAbstract:Background Advancements in Large Language Models (LLMs) hold transformative potential in healthcare, however, recent work has raised concern about the tendency of these models to produce outputs that display racial or gender biases. Although training data is a likely source of such biases, exploration of disease and demographic associations in text data at scale has been limited.\nMethods We conducted a large-scale textual analysis using a dataset comprising diverse web sources, including Arxiv, Wikipedia, and Common Crawl. The study analyzed the context in which various diseases are discussed alongside markers of race and gender. Given that LLMs are pre-trained on similar datasets, this approach allowed us to examine the potential biases that LLMs may learn and internalize. We compared these findings with actual demographic disease prevalence as well as GPT-4 outputs in order to evaluate the extent of bias representation.\nResults Our findings indicate that demographic terms are disproportionately associated with specific disease concepts in online texts. gender terms are prominently associated with disease concepts, while racial terms are much less frequently associated. We find widespread disparities in the associations of specific racial and gender terms with the 18 diseases analyzed. Most prominently, we see an overall significant overrepresentation of Black race mentions in comparison to population proportions.\nConclusions Our results highlight the need for critical examination and transparent reporting of biases in LLM pretraining datasets. Our study suggests the need to develop mitigation strategies to counteract the influence of biased training data in LLMs, particularly in sensitive domains such as healthcare.\nSubmission history\nFrom: Lasse Hyldig Hansen [view email][v1] Wed, 8 May 2024 13:38:56 UTC (2,102 KB)\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2405.05049",
    "https://arxiv.org/abs/2410.10538": "SNIPPET: Oct 14, 2024 ... arXiv:2410.10538 [stat.ML]. (or arXiv:2410.10538v1 [stat.ML] for this version). https://doi.org/10.48550/arXiv.2410.10538. Focus to learn more.\n\nTITLE: Data-Driven Approaches for Modelling Target Behaviour\n\nBODY:\nStatistics > Machine Learning\n[Submitted on 14 Oct 2024]\nTitle:Data-Driven Approaches for Modelling Target Behaviour\nView PDFAbstract:The performance of tracking algorithms strongly depends on the chosen model assumptions regarding the target dynamics. If there is a strong mismatch between the chosen model and the true object motion, the track quality may be poor or the track is easily lost. Still, the true dynamics might not be known a priori or it is too complex to be expressed in a tractable mathematical formulation. This paper provides a comparative study between three different methods that use machine learning to describe the underlying object motion based on training data. The first method builds on Gaussian Processes (GPs) for predicting the object motion, the second learns the parameters of an Interacting Multiple Model (IMM) filter and the third uses a Long Short-Term Memory (LSTM) network as a motion model. All methods are compared against an Extended Kalman Filter (EKF) with an analytic motion model as a benchmark and their respective strengths are highlighted in one simulated and two real-world scenarios.\nSubmission history\nFrom: Isabel Schlangen [view email][v1] Mon, 14 Oct 2024 14:18:27 UTC (2,996 KB)\nCurrent browse context:\nstat.ML\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.10538",
    "https://icml.cc/virtual/2025/poster/43728": "SNIPPET: ICML 2025 virtual content is now free. An account is required. Beware of ... Beware of Unofficial Events: Unless an event is listed on icml.cc, it is not ...\n\nTITLE: Main Navigation\n\nBODY:\nPoster\nBRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling\nHao Li · Yu-Hao Huang · Chang Xu · Viktor Schlegel · Renhe Jiang · Riza Batista-Navarro · Goran Nenadic · Jiang Bian\nWest Exhibition Hall B2-B3 #W-510\nTime-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions.To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce Bridge, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.\nTime series data—such as electricity usage, stock prices, or patient heart rates—are essential in fields like finance, energy, and healthcare. However, creating realistic synthetic time series that meet specific needs is a major challenge. Our research introduces a new method, called BRIDGE, that allows users to control time series generation using plain-language descriptions. Think of it as describing a pattern in words and receiving a matching time series in return. To do this, we designed a system where multiple AI agents work together to generate, evaluate, and refine these descriptions. We also developed a powerful model that learns both from text and from common time series patterns to generate high-quality, tailored outputs. BRIDGE not only outperforms existing methods on 11 of 12 benchmark datasets but also works well in new, unseen domains.\n\nSOURCE: https://icml.cc/virtual/2025/poster/43728",
    "https://aclanthology.org/2025.naacl-long.532.pdf": "SNIPPET: BibTeX. Markdown MODS XML Endnote More options… PDF: https://aclanthology.org/2025.naacl-long.532.pdf · PDF Cite Search Fix data. Export citation. ×. BibTeX ...\n\nTITLE: (from PDF)\n\nBODY:\n10612\nProceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies\n(Volume 1: Long Papers), pages 10612–10626\nApril 29 - May 4, 2025 ©2025 Association for Computational Linguistics\n\nPrivateSyntheticTextGenerationwithDiffusionModelsSebastianOchs1andIvanHabernal2TrustworthyHumanLanguageTechnologies1DepartmentofComputerScience,TechnicalUniversityofDarmstadt2ResearchCenterTrustworthyDataScienceandSecurityoftheUniversityAllianceRuhr,FacultyofComputerScience,RuhrUniversityBochumsebastian.ochs@tu-darmstadt.de,ivan.habernal@ruhr-uni-bochum.dewww.trusthlt.orgAbstractHowcapablearediffusionmodelsofgenerat-ingsyntheticstexts?Recentresearchshowstheirstrengths,withperformancereachingthatofauto-regressiveLLMs.Butaretheyalsogoodingeneratingsyntheticdataifthetrain-ingwasunderdifferentialprivacy?Heretheevidenceismissing,yetthepromisesfrompri-vateimagegenerationlookstrong.Inthispa-perweaddressthisopenquestionbyextensiveexperiments.Atthesametime,wecriticallyassess(andreimplement)previousworksonsyntheticprivatetextgenerationwithLLMsandrevealsomeunmetassumptionsthatmighthaveledtoviolatingthedifferentialprivacyguarantees.Ourresultspartlycontradictpre-viousnon-privatefindingsandshowthatfullyopen-sourceLLMsoutperformdiffusionmod-elsintheprivacyregime.Ourcompletesourcecodes,datasets,andexperimentalsetuparepub-liclyavailabletofosterfutureresearch1.1IntroductionHowcanwesharesensitivetextualdataandprotectprivacyofindividualsinthereatthesametime?Ago-tomethodtocircumventthisissueissyntheticdatageneration,usedmainlyfortabulardata(Her-nandezetal.,2022),orimages(Bissotoetal.,2018)inthemedicaldomain.However,syntheticdatagenerationaloneisnotsufficienttoprotectprivacyoftheunderlyingdata.Forexample,Stadleretal.(2022)showthatoutliersinsyntheticdatasufferfrommembershipinferenceattacks.Achievingformalprivacyguaranteesfortheun-derlyingdataispossiblebycombiningagenerativemodelwithdifferentialprivacy(DP,Dworketal.(2006))wherewetradeoffprivacyforreducedutilityofthesyntheticdata.Yueetal.(2023)andMatternetal.(2022)demonstratedfeasibilityofsyntheticdatagenerationwithDPinNLP.However,1https://github.com/trusthlt/private-synthetic-text-generationbothYueetal.(2023)andMatternetal.(2022)vio-lateseveralassumptionsabouttheunderlyingdatawhichcastsdoubtsonthevalidityoftheirfindings.Recentadvancesalsoshowthesuccessofdif-fusionmodelsinprivatesyntheticdatagenerationinimages(Ghalebikesabietal.,2023).Despiterecentachievementsinconditionaltextgenerationusingdiffusionmodels(Lietal.,2022;Gongetal.,2023a;Linetal.,2023),thecapabilitiesofprivatesynthetictextgenerationwithdiffusionmodelsre-mainunexplored.Wethusasktworesearchquestions.First,whatperformanceondownstreamtaskscanweachieveusingdiffusionmodelsforsynthetictextgenerationwithvaryingstrengthsofdifferentialprivacy?Sec-ond,whichfactorsmighthaveartificiallyinflatedperformanceinpreviousworksandcanwemitigateinvalidassumptionsinempiricalexperiments?Weaddressthesequestionsasfollows.Ourfirsthypothesisisthatdiffusionmodelsfortextgener-ationmightnotsufferfromnoiseaddedinDP,astheyinherentlyworkwithade-noisingobjective.Weaddressthisquestionempiricallybyconduct-ingextensive(andexpensive)experimentswiththreestate-of-the-artdiffusionmodels.Weaddressthesecondresearchquestionbytwoarguments.Ourfirstargumentisthatpreviousexperimentsmostlyfocusedon‘old’publicdatasets,suchastheIMDbmoviereviews(Maasetal.,2011).Asthesedatasetsmayverylikelyhavebeenseenduringpre-trainingoftheutilizedLLMs(GPT-2),thereportedeffectivenessoftheprivacy-preservingsynthetictextsmaybeoverestimated.Wefactoroutthepo-tentialdataleakingbyintroducingfivenew‘fresh’unseendatasetsintotheexperiments.OursecondargumentistheviolationofDPbyignoringgroupprivacyinthedatasets.Weprovideevidencein§4.Westrivefortransparency,reproducibility,andaccountability—threekeyingredientsofprivacy-relatedresearch.Thereforeweexperimentwithfullyopen-sourceandtransparentmodels,suchas\f10613\n\nBLOOM(LeScaoetal.,2023).Alloursourcecodesanddatasetsarealsopubliclyavailableforfurtherscrutiny.Ourmaincontributionsare(1)ev-idenceofsevereunderestimationofDPguaranteesinpreviousworks,(2)empiricalevidenceshowingthat,unlikeinimagedomain,diffusionmodelsforsynthetictextgenerationsufferseverelyunderDPtraining,and(3)completere-implementationsofunpublishedpreviousworksenablingtransparencyandpotentiallyincreasingtrustinprivacy-orientedresearch.2Theoreticalbackground2.1Differentialprivacy(DP)DP,introducedbyDwork(2006),isamathemati-calframeworkaimedatprotectingtheprivacyofindividualsinadataset.Throughaddingacalcu-latedamountofnoisetodataorstatisticalqueries,itprovidesformalguaranteesthatdatacontributorscannotbesingledouteasily,whilestillenablingmeaningfulanalysis.Abadietal.(2016)applyDPtostochasticgradientdescent,calledDP-SGD,whichallowsustoputformalprivacyguaranteesontrainedneuralnetworks.AsthetheoryofDPisconsiderablyextensive,werefertoWoodetal.’s(2018)workasaneas-ilyaccessibleintroductionfortheinterestedreader.Furthermore,Habernaletal.(2023)presentatuto-rialabouthowDPcanbeharnessedforNLPap-plications,whileCummingsetal.(2024)provideacomprehensivereviewaboutthecurrentstateoftheartinDPresearch.2.2DiffusionmodelsfortextDiffusionmodelshaveriseninpopularityasgen-erativemodelsrecently,especiallyinthedomainofimagesynthesis(Yangetal.,2023).Diffusionmodelscanbedescribedas\"MarkovianHierarchi-calVariationalAutoencoders\"(Luo,2022),thatareabletogeneratedatafromGaussiannoise.Thisisachievedbyutilizingtwotransitionsduringtrain-ing,calledforwardandreverseprocess.GivenTsteps,theforwardprocessincrementallyaddsasmallamountofGaussiannoisetoadatapointx0,creatingachainx0,x1,x2,...,xT,wherexTresemblesaGaussiandistribution.Duringthere-verseprocess,thediffusionmodellearnshowtotransitionfromxitoxi−1,∀i∈{0,1,2,...,T},es-sentiallylearninghowto‘undo’thecorruptionoftheforwardchain,called‘denoising’.Foramoremathematicallyfoundeddescriptionofdiffusionmodels,wepointtoBishopandBishop(2024,chap.20)andthebackgroundchapterofHoetal.(2020).Thereverseprocesscanbeguidedbyaddinginformationthatrelatestotheoriginaldata.Forexample,intext-to-imagegeneration,thelatentrepresentationofanimagedescription,usingatextencoder,steersthedenoisingofthediffusionmodel(Rameshetal.,2022).Duringinference,thediffusionmodelisthenabletogenerateimagesfromGaussiannoisethatcorrespondtotheinputtext.TextdiffusionmodelvariantsLikeinimagesynthesis,diffusionmodelsarealsobeingex-ploredintextgeneration.Lietal.(2022)proposeDiffusion-LM,adiffusionmodelcapableofgen-eratingtextsnon-autoregressively.Incontrasttotypicallanguagemodels,wheretextsequencesarecreatedtoken-by-token,Diffusion-LMgeneratesatextbygraduallydenoisingalistofGaussiannoisevectorsintowordembeddings.Thegenera-tionprocesscanbedirectlycontrolledbyprovidingconditionsthattheresultingtextshouldfulfill,forexamplesyntacticfeaturessuchasapredeterminedsequenceofparts-of-speechtags.Diffusion-LM’scodebasealsoservedasabasisforothertextdiffusionmodels,suchasDiffuSeq(Gongetal.,2023a),asequence-to-sequencetextdiffusionmodel.UnlikeDiffusion-LM,DiffuSeqconditionsthegeneratedoutputontheinputtext.Thisisaccomplishedthroughconcatenatingthewordvectorsequencesoftheinputandoutput,andapplyingthediffusionprocessonlytotheoutputvectors.Gongetal.(2023a)reportthatDiffuSeqachievessimilartext-to-textgenerationcapabilitiesasfine-tunedGPT2-baseand-large(Radfordetal.,2019)models,despiteofbeingnon-autoregressive.Therefore,weincludedDiffuSeqinourexperi-ments.Interestingly,whilethetrainingandinferencemethodoftextdiffusionmodelsdifferfundamen-tallyfromLLMs,theirarchitectureisstillbasedontheTransformer(Vaswanietal.,2017).3RelatedworkToenabletheprivacy-preservingsharingoflabeledtextdata,Matternetal.(2022)proposeamethodcalledprompt-basedDPfine-tuning,whichtheyutilizetotrainaGPT2-largemodel(Radfordetal.,2019).Theprocesscanbedescribedasa‘reverse’classificationtaskwhereinsteadoflearningtopre-dictthelabelforatext,thegenerativemodelis\f10614\n\ntrainedongeneratingtextssuitableforagivenla-bel.TheprivacyofeachauthorinthedatasetisprotectedbyapplyingDP-SGDtothefine-tuningprocedure.Additionally,amismatchlossisappliedduringtrainingbymaximizingthenegativelog-likelihoodofpurposelymislabeledtexts.Matternetal.(2022)experimentontwopubliclyavailabledatasetstovalidatetheirapproach.Thereportedresultsclaimthattextclassifierstrainedonthepri-vatized,syntheticdataandevaluatedonoriginaldataexperiencenosignificantperformancelosscomparedtoaclassifierdirectlytrainedontheorig-inaltexts.Yueetal.(2023)usethesamemethodologyintheirapproach,apartfromthemismatchloss.IncontrasttoMatternetal.(2022),theyincludeaprivatecustomerfeedbackdatasetintheirexper-iments,wherethesynthetictextsalsoprovedtobeusefulfordownstreamtaskclassificationper-formance.Furthermore,theyempiricallyevaluatetheprivacy-preservationoftheDPgenerationmod-elsbyinjecting‘canaries’intothetrainingdata,assuggestedbyCarlinietal.(2019).Afterthosemodelsgenerateasyntheticdataset,itisthenpos-sibletotrackifanycanarieshavebeenreplicated,whichwasnotthecaseformodelstrainedwithDPguarantees.Althoughnotinthetextdomain,diffusionmod-elshavealsobeenexploredforDPsyntheticdatageneration.Ghalebikesabietal.(2023)traindiffusionmodelswithDP-SGDonseverallow-resolutionimagedatasets,suchastheMNISTdatasetofhandwrittendigits(LeCunetal.,2010)andgeneratesyntheticimagesforthedownstreamclassificationtask.Classifierstrainedonthesyn-theticdatareportedlyreachperformancesclosetothestateoftheart.Notably,inmostexperi-ments,beforethediffusionmodelsweretrainedwithDP-SGDonsmallerdatasets,theywerepre-trainedwithoutDPonthelarge-scaleImageNet32(Chrabaszczetal.,2017)dataset.Sofar,pretraininglargemodelsonpublicdataandfine-tuningthosewithDP-SGDonsmaller,pri-vatedatasetsseemstobeanefficientmethodtopro-duceprivacy-preservingandusefulsyntheticdata.However,neitherDiffusion-LM,norDiffuSeq,normostothercurrentdiffusionmodelincludepretrain-ingintheirmethodology.OneexceptionisGENIE,introducedbyLinetal.(2023),whichistheonlyavailablediffusionmodelfortext-to-textgenera-tionthatispretrained.GENIEispretrainedonalargecorporaoftextsbyusinganobjectivesimilartospan-basedmaskedlanguagemodeling,How-ever,insteadofpredictingthecorrecttextspan,Gaussiannoiseiscontinuouslyaddedtothese-lectedtokenspan,whichGENIElearnstodenoise.Whenfine-tuned,themodeloutperformsthebaseversionsofT5(Raffeletal.,2020)andBART(Lewisetal.,2020)inseveralnaturallanguagegeneration(NLG)tasks.4CriticalanalysisofexistingworksInthefollowing,weexplainindetailhowDPsyn-thetictextgenerationhasbeenaccomplishedinpriorwork.Wealsocriticallyassesstheirunderly-ingassumptionsandevaluatetheirrespectivevalid-ityinregardstoprivacyprotection.PromptingLLMstrainedwithDP-SGDiscor-rect.BothYueetal.(2023)andMatternetal.(2022)describeascenario,whereadataholderwishestobenefitfrompublicresearchontheirin-housesensitivetextresources(suchasmedicalre-portsorcustomerdata),butcannotreleasethemduetoprivacyconcerns.Thefirstassumptionisthatthesensitivedocumentsarelabeled(catego-rized)andthetasktobesolvedisclassification.Theauthorsaddressthisproblemasfollows.First,theycreatepromptsforeachoriginaltextbasedonthecategorytowhichitbelongs.Sec-ond,apretrainedlanguagemodelisfine-tunedontheprompt:textpairs(e.g.,<writeapositivereview:originalreviewtext>)fromthetrainingpartofthesensitivedataset,learningtocreatetextsresemblingthedatafromtheinstructedcategory.Sincesyntheticdatagenerationaloneisnotenoughtoprotectprivacy(recallthediscussioninSection1),bothauthorstraintheirmodelswithDP-SGD.Afterwards,synthetictextsaresampledfromtheresultingmodelsusingthepromptsfor-mulatedearlier.ItisworthmentioningthattheDPguaranteeremainsthesameregardlessoftheamountofsyntheticgeneratedtexts.Theutilityoftheresultingsamplesisthenevaluatedonadown-streamclassificationtask,namelybyfine-tuningBERTonthegeneratedtextsandtestingitontheoriginalsensitivetestdata.Multipletextsfromthesamepersonviolatesdif-ferentialprivacy.ThemainrequirementinDPisthatintheunderlyingdataset,thereisaone-to-onecorrespondenceofapersonanditsdatapoint.FromtheMLperspective,thismeansthateachex-\f10615\n\namplefortrainingorfine-tuningbelongsexactlytoauniqueperson.ThisallowsustospelloutthenecessarynotionofneighboringdatasetsandtheveryguaranteeofDP,suchthatthedifferenceofaprivateanalysiswillbe‘roughlythesame’(gov-ernedbyεandδ)ontwodatasetsofsizenandn−1,respectively.Thisassumptionisviolatedwhenatextualdatasetcontainsmultipleexamplesfromthesameauthor.Duetouniquewritingstyle,vocabularyorotherimplicitfeatures,thosetextsmaycorre-latewitheachothereventhoughtheydonotsharethesameexplicitinformation.Aworkaroundforthisissueisgroupprivacy(DworkandRoth,2014,Theorem2.2),whichtranslatestothefollowing:Whenassumingthateachauthorprovidesatmostkcontributionstoadatasetandtextsofdifferentauthorsdonotcorrelatewitheachother,thepri-vacyboundsofany(ε,δ)-DPmechanismincreaseto(kε,kexp((k−1)ε),δ)-DP.However,tothebestofourknowledge,noworksutilizingDP-SGDhaveeverusedgroupprivacy,anditisactuallyunclearwhethertheDP-SGDiscompatiblewithit.2Weofferadditionalperspectivesonthismatterinthe“Limitationsandethicsstatement”sectionbelow.OuranalysisofthedatasetsusedinpreviousworksrevealsthatthereisaclearviolationofthisDPassumption.InthebookreviewsfromtheAmazonMultiDomaindata(Blitzeretal.,2007),usedinMatternetal.’s(2022)experiments,users‘ShalomFreedman’,‘PrairiePal’and52morecon-tributedatleastmorethanonereview.Similarly,theYelpOpenDataset3providesconcreteproofinitsdocumentationthatsomeusershavewrittenmorethanonereview.Nonetheless,thedatasetwaspartoftheexperimentscarriedoutbyYueetal.(2023).Giventheseviolatedassumptions,wecannotreallytellwhetherornotpreviousworkstrulyguar-anteethereportedprivacystrength.Wesuspectthatunderfairconditionstheprotectionwouldbemuchlower.NoevidencethatthesensitivedatawerenotpartofLMpretraining.AnotherassumptioninMat-ternetal.’s(2022)andYueetal.’s(2023)workisthatthe‘sensitive’data(inthiscaseIMDb,Yelp,2MostDP-SGDimplementationsrelyontheamplificationtheorembysubsampling,socalledPoissonsampling,whichwasonlyprovenfornon-groupprivacybyLietal.(2012).3https://www.yelp.com/dataset/documentation/mainetc.)havenotbeen‘seen’duringpretrainingofthegenerativelanguagemodel.Weidentifytwopotentialissueshere.First,anydatapointaccessedduringLLMpre-trainingcanbepotentiallyleakedbyadversarialprompting(Carlinietal.,2021;Nasretal.,2023).Ifthesensitivedatawereusedbothin(1)LLMpretrainingandin(2)privatefine-tuning,privacyhadbeenbreachedin(1)alreadyandnoclaimsaboutprotectionin(2)arevalid.Second,pre-trainingandfine-tuningonthesamedatawillmostlikelyboosttheeffectivenessofthesynthesizedtexts,asopposedtosynthesizingout-of-domain‘fresh’data.ThishasbeendemonstratedinpreviousworkbyIgamberdievetal.(2022)whofoundthatsuchleakingledtounrealisticallygoodresultsinotherworks.SinceYueetal.(2023)andMatternetal.(2022)useGPT2(Radfordetal.,2019)intheirmethod,andthepretrainingdataofthatmodelisnotdis-closed,wedoubtthattheperformancereportedontheYELPandI\n...[truncated]",
    "https://aclanthology.org/2024.naacl-long.2.pdf": "SNIPPET: https://aclanthology.org/2024.naacl-long/; DOI: Bib Export formats: BibTeX MODS XML EndNote; PDF: https://aclanthology.org/2024.naacl-long.pdf · PDF (full) Bib ...\n\nTITLE: (from PDF)\n\nBODY:\n22\nProceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies (Volume 1: Long Papers), pages 22–39\nJune 16-21, 2024 ©2024 Association for Computational Linguistics\n\nTextDiffusionModelwithEncoder-DecoderTransformersforSequence-to-SequenceGenerationHongyiYuan12∗,ZhengYuan2,ChuanqiTan2,FeiHuang2,SongfangHuang21TsinghuaUniversity,2AlibabaGroupyuanhy20@mails.tsinghua.edu.cn{yuanzheng.yuanzhen,chuanqi.tcq,f.huang,songfang.hsf}@alibaba-inc.comAbstractThediffusionmodel,anewgenerativemod-elingparadigm,hasachievedgreatsuccessinimage,audio,andvideogeneration.However,consideringthediscretecategoricalnatureofthetext,itisnottrivialtoextendcontinuousdiffusionmodelstonaturallanguage.Inthiswork,weproposeSeqDiffuSeq,atextdiffu-sionmodel,toapproachsequence-to-sequencetextgenerationwithanencoder-decoderTrans-formerarchitecture.Toimprovethegenerationperformance,SeqDiffuSeqisequippedwiththeself-conditioningtechniqueandournewlyproposedadaptivenoisescheduletechnique.Self-conditioningenablesSeqDiffuSeqtobet-terusethepredictedsequenceinformationdur-ingthegenerationprocess.Theadaptivenoiseschedulebalancesthedifficultyofdenoisingacrosstimestepsatthetokenlevel.Exper-imentresultsillustratetheimprovedperfor-manceonfivesequence-to-sequencegenerationtaskscomparedtootherdiffusion-basedmodelsregardingtextqualityandinferencetime.1IntroductionGenerativemodelingisdrawingmoreattentioninrecentyearsofmachinelearningresearchduetothedevelopmentofdiffusionmodels(Hoetal.,2020).Diffusionmodelsdefinetheforwardpro-cessandthereverseprocesswheretheformergrad-uallydiffusesdatatorandomnoisewhilethelatterrecoversdatafromrandomnoiseiteratively,whichhaveshownsuperiorperformanceonsynthesiz-ingimages(Rombachetal.,2021),audios(Kongetal.,2020),andvideos(Hoetal.,2022)overothergenerativemethods,suchasgenerativeadversar-ialnetwork(GAN)(Goodfellowetal.,2014)andnormalizingflow(Kobyzevetal.,2021).Itisnottrivialtoextenddiffusionmodelstothegenerationofnaturallanguages.Mostoftheex-istingdiffusionmodelsareappliedtocontinuous∗WorkdoneatAlibabaDAMOAcademy.Codesarere-leasedinhttps://github.com/Yuanhy1997/SeqDiffuSeqfeaturespace(Hoetal.,2020;NicholandDhari-wal,2021)whiletextsaresequencesofdiscretecategoricaltokens.Recently,researchhasexploredcategoricaldiffusionmodelsindiscretespacefortextgeneration(Hoogeboometal.,2021;Austinetal.,2022).TherealsoexistsresearchsuchasDif-fusionLM(Lietal.,2022)thatappliescontinuousdiffusionmodelstowordembedding.However,theseworksonlyfocusonunconditionalandcon-trolledtextgeneration.Sequence-to-sequencetextgenerationisafun-damentalnaturallanguageprocessingsettingandcoversvariouspracticaldownstreamtasks,suchasdialogue(Nietal.,2021)andmachinetranslation(Liuetal.,2020).Inrecentpractice,researchersresorttoauto-regressive(AR)(Daietal.,2019)ornon-auto-regressive(NAR)(Guetal.,2019)Transformersforthetasks,andachievegoodgen-erationperformance.Usingdiffusionmodels,arecentworknamedDiffuSeq(Gongetal.,2022)appliesthediffusion-basedmethodforsequence-to-sequencetextgeneration.Theydeployencoder-onlyTransformersandpartiallydefinediffusionanddenoisingprocessesonoutputsequences.Inthiswork,weexplorediffusionmodelswithencoder-decoderTransformerarchitectureforsequence-to-sequencegeneration.WeproposeSe-qDiffuSeqwhichextendsthecontinuousdiffusionframeworkproposedinDiffusionLM(Lietal.,2022)tosequence-to-sequencesettings.WeequipSeqDiffuSeqwiththeself-conditioningtechnique(Chenetal.,2022)andournewlyproposedadap-tivenoiseschedule.Self-conditioninghelpsthemodelbettercapturetheinformationfromformerit-erationsduringthegeneration.Theproposedadap-tivenoiseschedulelearnsatoken-levelnoisesched-uletobettercontroltheamountofnoiseinjectedandinformationrecoveredduringtheforwardandreverseprocess(NicholandDhariwal,2021).Weconductexperimentsonfivegenerationtasks.ResultsshowthatSeqDiffuSeqachievescompet-\f23\n\nitiveperformancecomparedwithARandNARbaselinesintermsofgenerationqualityanddiver-sity.SeqDiffuSeqalsoshowsimprovedgenera-tionperformanceandinferencespeedcomparedtotextdiffisonmodelDiffuSeq.Ablationstud-iesdemonstratethatourmodelcanbenefitfromself-conditioningandadaptivenoisescheduletech-niques,andbotharecomplementarytoeachotherinsequence-to-sequencesettings.Tosummarize,themaincontributionsofthisworkareasfollows:1.WeproposeSeqDiffuSeqthatextendsthecontinuoustextdiffusionmodeltosequence-to-sequencetextgenerationwithencoder-decoderTransformerarchitecture.2.Theself-conditioningandnewlyproposedadaptivenoisescheduletechniquecaneffec-tivelyimprovethegenerationqualityofthetextdiffusionmodel.3.ExperimentsshowSeqDiffuSeqachievespromisingperformancewiththepreviousdiffusion-basedmethodDiffuSeqaswellasARandNARmodelsonfivegenerationtasks.2RelatedWorkSincethegreatsuccessofdiffusionmodelsinvi-sion(Hoetal.,2020;Rombachetal.,2021;Songetal.,2021b),researchershaveexploredextend-ingdiffusionmodelstotextgeneration.Consid-eringthediscreteandcategoricalnatureoftexts,MultinomialDiffusion(Hoogeboometal.,2021)andD3PM(Austinetal.,2021)areproposedformodelingcategoricaldata.Theydefinediscretediffusionmodelsusingdiscretecategoricaltransi-tionsdirectlyontexts.DiffusionBERT(Heetal.,2022)followsD3PMandintroducespre-trainedmodelsforlanguagemodeling.Besides,recentresearchalsoexploresconvertingtextsintocon-tinuousfeaturestoadapttodiffusionmodels.BitDiffusion(Chenetal.,2022)encodesdiscretedataasbinarybitsandtreatsthesebinarybitsasrealnumberfeatures.Yuetal.(2022)isproposedtobuildtextdiffusionmodelsincontinuouslatentspace.DiffusionLM(Lietal.,2022)usesthewordembeddingspaceforcontinuousdiffusionmod-elsandintroducesauxiliarylossestoenablejointlearningofembeddingandnetworkparameters.FollowingDiffusionLM,recentresearchexploresimprovingtextgenerationquality(Strudeletal.,2022),andDiffuSeq(Gongetal.,2022)extendsittosequence-to-sequencesettings.ComparedtoDif-fuSeq,weproposeadifferentmodelarchitectureandself-conditioningandadaptivenoisescheduletechniquestoimprovesequence-to-sequencegen-erationperformance.Noiseschedulesindiffusionmodelscontrolthelevelofnoiseinjectedandthelevelofinformationrecoveredintheforwardandreverseprocessre-spectively.Previousresearchinvisionandtextsdemonstratesthatappropriatenoiseschedulede-signcanimprovethegenerationqualityperfor-manceofdiffusionmodels(NicholandDhariwal,2021;Lietal.,2022).Concurrently,Diffusion-BERT(Heetal.,2022)proposesaspindlesched-uleforlanguagemodeling,andCDCD(Dielemanetal.,2022)designsalearnednoisescheduleforlanguagemodelingandmachinetranslation.Dif-ferentfrombothconcurrentworks,SeqDiffuSeqisproposedwithatoken-levelnoiseschedulethatbalancesthedifficultyofdenoisingacrosstimesteps.Gaoetal.(2023)proposesDifformerandisorthogonaltoourwork.3PreliminaryDiffusionmodelisgenerallyformulatedbyade-signedforwarddiffusionprocessandalearntre-versedenoisingprocess.Intheforwarddiffusionprocess,samplesgraduallymixwithrandomnoise,whileinthereversedenoisingprocess,therandomnoiseisgraduallydenoisedtogeneratesyntheticsamples.Weadopttheforwardandreversepro-cessesproposedinDDPM(Hoetal.,2020).Fortheforwardprocess,givenasamplez0fromareal-worlddatadistributionq(z0).Ateachtimestept∈{1,2,···,T},anoisesampleztissam-pledfromzt∼q(zt|zt−1)=N(zt;√αtzt−1,(1−αt)I),whereαtcontrolthenoiseaddedattimestept.Inthisregard,whenTislargeenough,areal-worldsamplewillgraduallyandultimatelydiffusetoastandardGaussiannoisedistribution.Forthereverseprocess,thediffusionmodelusesalearntparameterizeddenoisingdistributionzt−1∼pθ(zt−1|zt)tograduallyrecoversamplesfromnoise.Thedenoisingdistributionisparame-terizedbyθandistofittheposteriordistributionq(zt−1|zt,z0)oftheforwardprocess.q(zt−1|zt,z0)=N(zt−1;˜µ(z0,zt),˜βtI).(1)\f24\n\nInthisequation,˜µ(z0,zt)=√¯αt−1βt1−¯αtz0+√αt(1−¯αt−1)1−¯αtzt,(2)¯αt=tYs=1αs,βt=1−αt,˜βt=1−¯αt−11−¯αtβt.(3)Withlearntdenoisingdistributionpθ,asyntheticreal-worldsamplez0canbegeneratedfrompurerandomnoisezTstep-by-step.4ApproachInthissection,wepresentthemaindesignofourproposedSeqDiffuSeqforsequence-to-sequencelanguagegeneration.TheoverviewofSeqDiffuSeqisdepictedinFigure1.Inthefollowingsections,theinputandoutputsequencesaredenotedaswxandwyrespectively.Forthei-thtokeninwy,thetokenisdenotedaswiy,where0<i≤nandnrepresentsthemaximumoutputsequencewordlength.Inordertoavoidlengthynotations,weomittheindicesreferringtodifferentdatasamples.4.1DiffusionModelForwardProcessTofitdiffusionmodelstosequence-to-sequencesettings,weextendthetextdiffusionmodel,DiffusionLM(Lietal.,2022).Inthesequence-to-sequencesetting,theforwardprocessgraduallychangesthetargetoutputse-quencewytorandomnoise.Diffusingwytopurerandomnoiseisindependentoftheinputsequencewx.Forthesequencewy,weuseanembeddingfunctiongϕtomapthewordtokenswiytocon-tinuouswordembeddinggϕ(wiy)∈Rd,wheredrepresentsthedimensionofembeddingandϕrepresentstheparametersofthewordembeddingfunction.Theembeddingforthesequencewyisdefinedbystackingthetokens’embeddingandisdenotedasgϕ(wy)∈Rn×d.Atthebeginningoftheforwardprocess,aMarkoviantransitionpa-rameterizedbyqϕ(z0|wy)=N(z0;gϕ(wy),β0I)isadded.Extendedbyqϕ(z0|wy),theforwardpro-cesscancontinuetodiffusecontinuousfeaturesofz0iteratively.Foreachtimestept,weapplythediffusiondistributionq(zt|zt−1)togetnoisiersam-ples.Ultimately,theoutputsequencewybecomeszTwhichisnearlypurerandomnoisefollowingstandardGaussiandistribution.ReverseProcessDiffusionmodelsgeneratethesyntheticsamplesbysuccessivelysamplingthede-noisingdistributioninthereverseprocess.Foreachtimesteptinthereverseprocess,alearntdenoisingdistributionpθparameterizedbyθgeneratessam-pleszt−1conditionedontheformernoisiersam-pleszt.Inthesequence-to-sequencesetting,thegeneratedsequencescorrelatetoinputsequences.Therefore,thedenoisingdistributionisaddition-allyconditionedontheinputsequencewx,andpθ=pθ(zt−1|zt,wx).AfterthereversedenoisingprocessreachesT=0,weroundeachcolumnofthegeneratedˆz0toitsnearestwordintheembed-dingspacebytheroundingdistribution˜pϕ(wy|ˆz0)togeneratethefinalwordsequences.TrainingObjectiveWeoptimizeθandembed-dingparametersbyminimizingthevariationalboundofthedatalog-likelihood:LVB=Eqϕ(z0:T,wx,wy)[logq(zT|z0)p(zT)+TXt=2logq(zt−1|z0,zt)pθ(zt−1|zt,wx)−logpθ(z0|z1,wx)+logqϕ(z0|wy)−log˜pϕ(wy|z0)],(4)Thetrainingobjectiveistonarrowdownthedis-crepancybetweenpθ(zt−1|zt,wx)andtheposte-riorq(zt−1|zt,z0)intheforwardprocess.Sinceq(zt−1|zt,z0)followstheformofGaussiandis-tribution,weparameterizethedenoisingdistribu-tionfollowingGaussiandistributionfamilyandpθ(zt−1|zt,wx)=N(zt−1;˜µθ(zt,wx,t),˜βtI),where˜µθ(zt,wx,t)=√¯αt−1βt1−¯αtz0θ(zt,wx,t)+√αt(1−¯αt−1)1−¯αtzt.(5)z0θ(zt,wx,t)isnamedthedenoisingfunctionandpredictstheestimatedoutputembeddingsequencesateachreversestept.ThenaccordingtodensityfunctionsqandpθfollowingGaussiandistribution,theobjectivecanbefurthersimplifiedas:Lsimple=Eqϕ(z0,wx,wy)[TXt=2Eq(zt|z0)∥z0θ(zt,wx,t)−z0∥2+∥˜µ(zT,z0)∥2+∥z0θ(z1,wx,1)−gϕ(wy)∥2−log˜pϕ(wy|z0)],(6)whereq(zt|z0)=N(zt;√¯αtz0,(1−¯αt)I)foreffi-cientsamplingofztduringtraining,andµT(z0)=√¯αTz0.WeleavethedetailedderivationtoAp-pendixB.Thetrainingobjectivebecomestofit\f25\n\nFigure1:TheoverviewofSeqDiffuSeqwithanencoder-decoderTransformersarchitecture.gϕ(wy)andthedenoisingfunctionz0θ(zt,wx,t),whichwecanmodelwithencoder-decoderTrans-formersarchitectures.Duringtraining,thesam-plingdistributionqϕcontainstrainableparame-tersofwordembedding.Wecanbackpropagatethroughthiswithreparameterizationtrick(KingmaandWelling,2013).DenoisingwithEncoder-DecoderFrameworkUnlikeDiffuSeq(Gongetal.,2022)usingencoder-onlyTransformerarchitecture,weproposeusinganencoder-decoderTransformersarchitecturetomodeltheinputandoutputtextsequences.Forz0θ(zt,wx,t),weusetheencodertoprocessthein-putsequenceswxandusethedecodertomodelthenoisyoutputsequencezt.Followingthepre-viouswork(Lietal.,2022),weinjecttimestepinformationtbyaddingtimestepembeddingtozt.Usingtheencoder-decoderarchitecturehascom-putationalconvenienceduringgenerationbecausetheinputsequenceswxonlyrequireoneforwardcomputationthroughtheencodernetworkduringthewholereverseprocess.Consideringthereverseprocessrequiresthousandsofiterationstogeneratetheoutputsequencesofhighquality,thesavingofcomputationalresourcescanbesignificant.Duringtrainingandgeneration,thefunctionz0θgeneratesdenoisedsamplesatthesequencelevel.Thereforemakingpredictionsfromthedenoisingfunctionz0θresemblesthenon-autoregressivenatu-rallanguagegeneration.Inthisregard,weuseade-coderwithfullattentionmatricesinsteadofcausalattentionmatricestomodelztatthesequencelevel.4.2Self-ConditioningAteachtimesteptinthereverseprocess,thedenoisingfunctionz0θ(zt,wx,t)makesoutputse-quencepredictionsbasedonthenoisiersamplezt.ztissampledfromtheformerdenoisingdis-tributionbymixingformersequencepredictionˆzt0=z0θ(zt+1,wx,t+1),zt+1andrandomnoise.Inthisregard,partoftheinformationcontainedintheformerpredictionˆzt0isdiscarded.Bit-Diffusion(Chenetal.,2022)proposedtheself-conditioningtechniquemitigatingthiswasteofinformationbyadditionallytakingformersequencepredictionsasinputs.Thedenoisingfunctionisformulatedasz0θ(zt,ˆzt0,wx,t).Self-conditioningmayenablethedenoisingfunctiontorefinetheformersequencepredictionsratherthanmakenewpredictionsfromscratch.Itisempiricallyverifiedthattheself-conditioningtechniquecanboosttheperformanceoftextdiffusionmodels(Strudeletal.,2022).TofitthetechniqueintotheTransformersmodel-ingofz0θinoursequence-to-sequencesetting,thesequencefeaturesˆzt0fromtheformerpredictionsareconcatenatedwithnoisiersequencefeaturesztontheembeddingdimension.Hence,thedi-mensionofinputfeaturesofTransformerdecoderbecomesn×2d.SincetheformersequencesattimesteptaresampledsuccessivelyfromTtotwhichiscomputational-tediousduringtrain-ing,wetakeanefficienttrainingscheme.Withhalfprobability,z0θ(zt,ˆzt0,wx,t)istrainedbyset-tingtheinputˆzt0to0.Otherwise,ˆzt0isfirstesti-matedbyz0θ(zt,0,wx,t)andthenisusedforself-conditioningtraining.Underthesecondcircum-stance,wedonotbackpropagatethroughthefirstforwardpropagateestimatedˆzt0.4.3AdaptiveNoiseScheduleInthedomainofvisionandaudio,thegeneratedsamplequality(NicholandDhariwal,2021)andlikelihoodestimation(Kingmaetal.,2021)maypotentiallybenefitfromdifferentappropriatetimeschedules.Previousresearchusesdifferentsimplefunctionssuchaslinearfunction(Hoetal.,2020)\f26\n\norcosinefunction(NicholandDhariwal,2021)ofαagainsttimestepttodesignnoiseschedules.Suchdesignsmayresultsinunbalanceddenoisingdifficultiesforeachstepandleadtounsatisfyinggenerationquality.Someworksproposedtoallevi-atethisproblembyimportancesampling(Lietal.,2022)orlossreweighing(Gongetal.,2022).Weproposeanoveladaptivenoisescheduleatthetoken-level.Firstly,weproposetoadaptivelyadjustthetimeschedulesduringtrainingtomakethedenoisingdifficultiesofz0θpredictingoutputsequenceincreaselinearlywithrespecttothetimestep.Secondly,weseparatelysetadaptivenoiseschedulefordifferenttokenpositions,unlikeprevi-oustextdiffusionresearchthatonlydesignsnoiseschedulesonthewholesequencelevel.Sincetheintrinsicfeaturesforembeddingsequencesaredif-ferentacrosstokenpositionswithin,w\n...[truncated]",
    "https://aclanthology.org/2024.naacl-long.261.pdf": "SNIPPET: Human Language Technologies (Volume 1: Long Papers), pages 4664–4683. June 16-21, 2024 ©2024 Association for Computational Linguistics.\n\nTITLE: (from PDF)\n\nBODY:\n4664\nProceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies (Volume 1: Long Papers), pages 4664–4683\nJune 16-21, 2024 ©2024 Association for Computational Linguistics\n\nEmpoweringDiffusionModelsontheEmbeddingSpaceforTextGenerationZhujinGao1,2*,JunliangGuo3*,XuTan3,YongxinZhu1,2,FangZhang1,2,JiangBian3,LinliXu1,2†1SchoolofComputerScienceandTechnology,UniversityofScienceandTechnologyofChina2StateKeyLaboratoryofCognitiveIntelligence3MicrosoftResearchAsiagaozhujin@mail.ustc.edu.cn,{junliangguo,xuta}@microsoft.com{zyx2016,fangzhang}@mail.ustc.edu.cn,jiabia@microsoft.comlinlixu@ustc.edu.cnAbstractDiffusionmodelshaveachievedstate-of-the-artsynthesisqualityonbothvisualandaudiotasks,andrecentworksfurtheradaptthemtotextualdatabydiffusingontheembeddingspace.Inthispaper,weconductsystematicstudiesoftheoptimizationchallengesencounteredwithboththeembeddingspaceandthedenoisingmodel,whichhavenotbeencarefullyexplored.Firstly,thedatadistributionislearnableforem-beddings,whichmayleadtothecollapseoftheembeddingspaceandunstabletraining.Toalle-viatethisproblem,weproposeanewobjectivecalledtheanchorlosswhichismoreefficientthanpreviousmethods.Secondly,wefindthenoiselevelsofconventionalschedulesareinsuf-ficientfortrainingadesirabledenoisingmodelwhileintroducingvaryingdegreesofdegenera-tioninconsequence.Toaddressthischallenge,weproposeanovelframeworkcallednoiserescaling.Basedontheaboveanalysis,wepro-poseDifformer,anembeddingdiffusionmodelbasedonTransformer.Experimentsonvari-etiesofseminaltextgenerationtasksshowtheeffectivenessoftheproposedmethodsandthesuperiorityofDifformeroverpreviousstate-of-the-artembeddingdiffusionbaselines.11IntroductionAwaveofdiffusionmodels(Sohl-Dicksteinetal.,2015;Hoetal.,2020;Songetal.,2020b)issweep-ingthegenerationtasks(e.g.,imageandaudiosyn-thesis)recently,showingtheirgreatcapacityforhigh-qualitydatageneration.Diffusionmodelsareafamilyofiterativegenerativemodels,whicharetrainedtorecovercorrupteddataandthengener-atedatabygraduallyrefiningsamplesfromthepurenoise.Thisprocedureenablesthemodeltomakesubtlerefinementsofoutputsamplesina*Equalcontribution.†Correspondingauthor.1Codeisavailableathttps://github.com/zhjgao/difformermulti-stepdenoisingprocess,andthusgeneratehigh-fidelityanddiversesamples(DhariwalandNichol,2021;NicholandDhariwal,2021;HoandSalimans,2021;Rombachetal.,2022;Chenetal.,2020;Kongetal.,2020).Theboomingachievementsinvisionandaudiodomainsinspireresearcherstodelveintotherealmoftextgeneration.Diffusionmodelsintroduceanovelnoisingparadigmandatrainingobjectiveotherthantokenprediction,establishinganalterna-tiveformoflanguagemodels,whichexhibitsthepotentialtofosteranenhancedcomprehensionoflanguagemodeling.Fromahigherperspective,thisinvestigationgeneralizesthediffusionmodelacrossmodalities,andfurthercontributestoaunifiedmul-timodalframework(Baoetal.,2023;Tangetal.,2024).Nonetheless,theexplorationisstillatanini-tialstage.Recentworks(Lietal.,2022;Gongetal.,2022;Strudeletal.,2022)basicallyconvertthediscretetokenstoembeddingsandthenutilizecon-tinuousdiffusionmodelstogeneratethem,whichcanbetermedembeddingdiffusionmodels.Thesepreliminaryattemptsfollowtheoriginalmodeltodealwiththeembeddings,withlittleconsiderationoftheuniquepropertiesandtheoptimizationchal-lengesoftheembeddingspaceandthedenoisingmodel.Inthispaper,weexploretheembeddingdiffu-sionmodelfromtwoperspectivesseparately,i.e.,theembeddingspaceandthedenoisingmodel,basedonwhichweconductathoroughstudyre-spectively.Firstly,fordiffusionmodelsonimageandaudiogeneration,thegroundtruthdataissta-tionaryduringtraining.Incontrast,itislearnableforthetextualdata(i.e.,embeddings),whichmaycausethecollapseoftheembeddingspaceandin-troduceinstabilitytothetrainingofthemodel.Toavoidthecollapsecausedbydynamicallyshiftingembeddingparameters,weproposeananchorlossfunctiontoattainwell-distributedembeddingsandstabilizethetrainingprocess.Thedetailedanalysis\f4665\n\nispresentedinSection3.1.Secondly,inSection3.2,wefindthatinthehighdimensionalembeddingspace,theinsuffi-cientnoiseresultsinasimpledenoisingtask,whichcausesthedegenerationofthemodel.Totacklethischallenge,weproposeanovelframeworknamednoiserescaling,whichisorthogonaltothechoiceofthenoisescheduleandapplicabletoanyexistingschedules.Specifically,wedefineanindextermeddegenerationscoreasameasurementofthedegreeofdegeneration.Guidedbythedegenerationscore,wecanapplyanoiserescalingproceduretopreventthemodelfromdegenerating.Basedontheabovediscussion,weproposeanin-tegratedframeworkofDifformer,adenoisingdiffu-sionTransformermodel.Weconductexperimentsonavarietyofimportanttextgenerationtasksin-cludingmachinetranslation,textsummarization,paraphrasing,textsimplification,andquestiongen-eration.Onthesebenchmarkdatasets,Difformeroutperformsdiffusion-basedanditeration-basednon-autoregressivebaselinesandachievesstate-of-the-artperformanceamongembeddingdiffusionmodels.Furtherexperimentsdemonstratethesupe-riorityofDifformeroverbaselinesincludingLLMsinquality,diversity,andefficiency,emphasizingthepotentialofdiffusionmodelsfortextgenerationintheeraofLLMs.2BackgroundDiffusionModelsDenoisingdiffusionproba-bilisticmodels(Sohl-Dicksteinetal.,2015;Hoetal.,2020)utilizeaforwardprocesstoperturbthedatawithGaussiannoise,andareversepro-cesstorestorethedatasymmetrically.Hoetal.(2020)developtheapproachbyspecificparam-eterizations,achievingcomparablesamplequal-itywithstate-of-the-artgenerativemodelssuchasGANs(GoodfellowIanetal.,2014).Afterthat,greatimprovementshavebeenmadebymanyfol-lowingworks(Songetal.,2020a;DhariwalandNichol,2021;NicholandDhariwal,2021;Rom-bachetal.,2022)bothinqualityandefficiency.Givenadatasamplez0∈Rd,thedenoisingdiffu-sionprobabilisticmodelgraduallyperturbsitintoapureGaussiannoisezT∼N(0,I)throughaseriesoflatentvariablesz1,···,zTintheforwardprocess:q(zt|z0)=N(cid:0)zt;√¯αtz0,¯βtI(cid:1),where¯αt,¯βtarehyper-parameterscontrollingthenoiseleveladdedattimestept,whichformthenoiseschedule.Usually,thesehyper-parametersaresettosatisfy¯αt:=Qti=0αi,αt+βt=1,and¯αt+¯βt=1.Thereverseprocessisparameterizedas:pθ(zt−1|zt)=N(zt−1;µθ(zt,t),Σθ(zt,t)),whereµθ(·)andΣθ(·)arethepredictedmeanandcovarianceofq(zt−1|zt),andθdenotesthemodelparameters.Afterparameterization,weutilizeasimplifiedvariationallower-boundastheobjectivefunctionLvlb=Ez0,zt,t(cid:2)∥ˆz0(zt,t)−z0∥2(cid:3),(1)whereˆz0(zt,t)isthemodelpredictionoftheorig-inaldataz0givenzt.ThedetailedderivationcanbefoundinAppendixB.DiffusionModelsforTextGenerationThebreakthroughofdiffusionmodelsoncontinuousdataencouragespeopletoexploretheirpotentialondiscretetextualdata.Thedefinitionofforwardandreverseprocessesisthekeyquestionfordif-fusionmodels.Recentworksmainlyfollowtwodirections.Firstly,discretediffusionmodelsoncategori-caldistributionsareproposed(Hoogeboometal.,2021;Austinetal.,2021;Savinovetal.,2021;Reidetal.,2022),bywhichsentencesarecorruptedandrefinedatthetokenlevel.However,thesekindsofcorruptionarecoarse-grained.Attemptshavebeenmadetoexploremodelingonsurrogaterepresen-tationsofdiscretedatasuchasanalogbits(Chenetal.,2022)andsimplex(Hanetal.,2023).Never-theless,theserepresentationscarrylittlesemanticinformationabouttokens,whichimpliesthatthedistancesinthisspacecannotaccuratelyreflectsemanticcorrelationsbetweentokens.Incontrast,embeddingdiffusionmodels(Lietal.,2022;Strudeletal.,2022;Gongetal.,2022;Yeetal.,2023)introduceanadditionalembed-dingstepandroundingstepintheforwardandreverseprocessesrespectively.Theembeddingstepconvertstokensintolearnableorpre-trainedem-beddings,whichcarrysemanticinformation,andthenacontinuousdiffusionprocessisabletoaddGaussiannoisetotheseembeddings,achievingafine-grainednoisingprocedure.Mathematically,givenasequenceoftokensy=[y1,y2,···,yn],theembeddingstepcanbedenotedasz0∼N(eϕ(y),β0I)whereeϕ(·)denotestheembed-dinglookupfunction.Theroundingstepturnspre-dictedembeddingsbacktodiscretetokens,which\f4666\n\nContinuousDiscreteEmbeddingSpace𝐳𝑇𝐳𝑡𝐳𝑡−1⋯𝐳0𝒚𝑝𝜃(𝐳𝑡−1|𝐳𝑡,𝐱)Reverse𝑞𝐳𝑡𝐳𝑡−1=𝒩(𝐳𝑡;𝛼𝑡𝐳𝑡−1,𝑭𝟐𝛽𝑡𝐈)ForwardAnchor Loss𝒙⋯Noise Rescaling𝒩(𝟎,𝑭𝟐𝐈)𝑝𝜙(𝒚|ො𝐳𝟎)Figure1:AnoverviewoftheDifformer,includingtheproposedtechniques,i.e.,theanchorloss,andthenoiserescaling.canbeexpressedasasoftmaxdistributionoverthevocabularypϕ(y|z0),andistrainedbyanextralossfunctionLround=Ey,z0[−logpϕ(y|z0)].Thepa-rametersofthisstepandtheembeddingsteparetied.Thefinallossfunctioniswrittenas:Ltext=Lvlb+Lround.Nevertheless,theseworksdirectlyadaptcon-tinuousdiffusionmodelstoembeddings,withoutconsideringthegapbetweenthelearnableembed-dingspaceandthestationaryimageoraudiodata,aswellasthedistinctiverequirementsofthede-noisingmodelestablishedontheembeddingspace.3MethodologyThissectionelucidatesthechallengesinher-entinoptimizingembeddingdiffusionmodelsandpresentsourcorrespondingsolutions.Westartwithanintroductiontothemodelarchitec-ture.ThemodelarchitectureisbasedonTrans-former(Vaswanietal.,2017),whichconsistsofanencoderandadecoder.Thedecoder,asthemainstemcomponent,isconsideredastwoseparatepartsinthispaper,namelytheembed-dingseϕ=[e1,e2,···,eV]∈Rd×V,eϕ(y)=[ey1,ey2,···,eyn]andthedenoisingmodelfθ(·),whichdenotesthestackeddecoderlayers.Notably,thispaperdefinez0=eϕ(y).Theencoderpro-videstherepresentationx=Encoder(x)oftheconditionsentencex=[x1,x2,···,xm].3.1CollapseoftheEmbeddingSpaceAnalysisoftheCollapseProblemThedataspaceisusuallyfixedforcontinuousdata(e.g.,im-ageandaudio),whileitislearnedfromscratchfordiscretetextualdata(i.e.,embeddings),whichthereforeshiftsdynamicallyduringtraining.Orig-inaldiffusionmodelsrelyonthelossfunctionEq.(1)tolearntoestimatethecleandatasam-plez0.Nevertheless,whendirectlyadaptingthisobjectivetotheembeddingdiffusionmodel,theembeddingspacewillcollapse.Asaresult,theembeddingsofdifferenttokenswillbelessdis-tinguishableandnon-uniformlydistributedinthespace,whichconsiderablylimitstherepresenta-tioncapacityandqualityoftheembeddings.Onthecontrary,themodelcouldachievebetterperfor-mancewithmoreisotropicembeddings(Gaoetal.,2018;Lietal.,2020).Recentworksofdiffusiononembeddings(Lietal.,2022;Gongetal.,2022)introducetheround-inglossLroundfromthederivationofthevaria-tionallowerbound,whichdiscriminatesthecor-rectembeddingsfromothersgiventheirnoisedcounterparts,thereforeenforcestheembeddingsaredistinguishableandinformative,alleviatingthecollapseobjectively.Wecouldregardthisaddi-tionallossfunctionasaregularizationtermfortheembeddings.Nonetheless,onlyaminorlevelofperturbationisinvolvedfromytoz0,therebytheroundinglossisonlyabletoapplyarelativelyweakconstraintontheembeddings.Ourempiricalevidencealsocorroboratesthelim-itationoftheroundingloss.Weobservethattheroundinglossundergoesasteepdescentandfallstonearzerointheinitialstagesoftraining,whichim-pliestheroundinglosscanbeeffortlesslyaddressedandfailstoconductstrongenoughregularizationtotheembeddings.Therefore,theembeddingspaceisundesirableandeventuallyleadstounsatisfac-\f4667\n\ntoryperformance.Concurrently,theinstabilityintrainingalsoemergesasaproblemduringtraining.Evenifcarefultuningofthehyper-parametersisperformedtorelieveanisotropy,theperformanceisstillinferior.AnchorLossToemphasizetheeffectofthereg-ularizationterm,weproposeatrainingobjectivenamedtheanchorlossLanchor=E(x,y),zt,t[−logpϕ(y|ˆz0(zt,x,t))].ComparedwithLround,Lanchorutilizesthemodelpredictionofz0astheinput,whichinvolvesalargediscrepancywithz0duetothepredictionerrorofthedenoisingmodel.Consequently,toensurethesehighlynoisyrepresentationsareidentifiedasthecorrecttokens,theanchorlossemploysastrongerregularizationtotheembeddingstopre-ventcollapse.Additionally,besidesLvlb,thean-chorlosscreatesanotherpathwaybetweenthede-noisingmodelandthetargetsentences,throughwhichthemodelcouldreceivefeedbackfromthegroundtruth,maintainingthetrainingstability.Fi-nally,ourtrainingobjectiveiswrittenasL=Lvlb+Lanchor.(2)Empirically,weuseselfsimilarity(Ethayarajh,2019)astheanisotropyscoretomeasurethesever-ityofcollapse:ANI=1V(V−1)VXi=1VXj=1,j̸=icos(ei,ej).Essentially,thehighertheanisotropyscoreis,themoreseverethecollapseis.TheanisotropyscoreaswellastheperformanceobtainedbyeachlossfunctioncanbefoundinTable1.WithonlyLvlborLtext,theanisotropyscoredemonstratesthattheembeddingsarenon-uniformlydistributed,re-sultinginunsatisfactoryresults.Onthecontrary,theembeddingsarewell-distributedacrosstheen-tirespacewiththeanchorloss,andthusthemodelreachescompetitiveperformance(inBLEU(Pa-pinenietal.,2002)).Alternatively,utilizingpre-trainedembeddingsandfreezingthemduringtrain-ingcouldalsoavoidcollapse.Asshownintheexperimentalresults,thefrozenembeddingsalle-viatethecollapseremarkably,however,theyaresuboptimalfortheproblem.DetaileddiscussioncanbefoundinAppendixC.3.LossANIBLEULvlb0.990.07Ltext0.3227.89L0.0334.48Table1:TheanisotropyscoreandperformanceofeachlossfunctionontheIWSLT14De-Endatasetwithlinearschedule.3.2DegenerationoftheDenoisingModelAnalysisoftheDegenerationProblemThede-signofthenoiseschedule,whichdeterminestheamountofnoiseaddedtothedataateachstep,hassignificantinfluencesonbothforwardandreverseprocesses.Intuitively,denoisingisamorechalleng-ingtaskforthemodelwithhigherlevelsofnoise,andbecomeseasierwheninsufficientcorruptionisapplied,wherethemodelcangeneratethecorrectembeddingswithoutdependingontheconditionandcontext.Asaconsequence,themodeltendstodegeneratetoatrivialsolution.Here,wepro-videin-depthanalysesofthisproblem.Westartbydefiningthedegeneratedmodel,whichdiscardstheconditioninginformationandgenerateseachembeddingbychoosingthenearestonesindepen-dently:Definition1.Foranoisedinputzt=[zt,1,zt,2,···,zt,n],theDegeneratedModelisde-finedasfdg(zt;x)=\"argminey∈eϕL(zt,i,ey)#ni,whereL(zt,i,ey)=∥zt,i−ey∥2−logpϕ(y|zt,i).Itcanbeprovedthatwheninsufficientnoiseisin-troducedduringtraining,thedenoisingmodeltendstofallasthedegeneratedmodeldefinedabove.Theorem1.Givenembeddingseϕ∼Nd×V(0,σeI),theprobabilityofthedegen-eratedmodelbeingaglobalminimumoftheobjectivefunctionLforθconvergesto1as¯β→0andd→∞.Weleavetheproofandillustrationsofthistheo-reminAppendixA.Thisphenomenoncouldbeverifiedquantita-tively.Toanalyzethecapacityofthedenoisingmodelateachnoiselevel,weevaluatetheBLEUscoreofˆz0generatedbythemodelatdifferenttimesteps.Toeliminatetheimpactofthenoise\f4668\n\n0.00.20.40.60.81.0t08162432BLEUOriginalW/ Noise Rescaling(a)0.00.20.40.60.81.0t0.00.20.40.60.81.0DGStLinearCosineSqrt(b)0.00.20.40.60.81.0t0.00.20.40.60.81.0tF=1F=2F=3F=4F=5F=6(c)Figure2:(a)BLEUscoreofmodelsfedwithpureGaussiannoisezTontheIWSLT14De-Endataset.Thevalueoftisnormalizedto[0,1].(b)DGStwithdifferentwidelyusedschedules.(c)Thesqrtschedulerescaledwithdifferentvaluesoftherescalingfactor.schedule,wefeedthemodelwithzT,i.e.,thepurenoise,ratherthanzt.AsillustratedinFig.2a,theBLEUscoredropsdramaticallyattswithlownoiselevels,andtherangewithlowscoresoccu-piesnearlyhalfoftheaxis.Inotherwords,themodeldegeneratessignificantlyandextensively,implyingthenoiselevelsbroughtbytheschedulearefarfrombeingsufficient.NoiseRescalingInmosttextgenerationtasks,adegeneratedmodelisundesirable,asitfailstomaintaincontextualcoh\n...[truncated]",
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf": "SNIPPET: (2023). Available online at: https://proceedings.neurips.cc/paper_files/paper/2023/hash/7d866abba506e5a56335e4644ebe18f9-Abstract-Conference.html; 34. Parikh ...\n\nTITLE: (from PDF)\n\nBODY:\nAR-DIFFUSION: Auto-Regressive Diffusion Model for\nText Generation\n\nTong Wu1∗ † , Zhihao Fan2∗†, Xiao Liu3, Hai-Tao Zheng1,8‡, Yeyun Gong3‡, Yelong Shen4,\nJian Jiao5, Juntao Li6, Zhongyu Wei2, Jian Guo7‡, Nan Duan3‡, Weizhu Chen4‡\n1Shezhen International Graduate School, Tsinghua University, 2 Fudan University,\n3Microsoft Research Asia, 4Microsoft Azure AI, 5Microsoft,\n6Soochow University, 7IDEA Research, 8Pengcheng Laboratory\n{yegong, yeshe, nanduan, wzchen}@microsoft.com,\nzheng.haitao@sz.tsinghua.edu.cn, guojian@idea.edu.cn\n\nAbstract\n\nDiffusion models have gained significant attention in the realm of image generation\ndue to their exceptional performance. Their success has been recently expanded\nto text generation via generating all tokens within a sequence concurrently. How-\never, natural language exhibits a far more pronounced sequential dependency in\ncomparison to images, and the majority of existing language models are trained\nwith a left-to-right auto-regressive approach. To account for the inherent sequen-\ntial characteristic of natural language, we introduce Auto-Regressive Diffusion\n(AR-DIFFUSION). AR-DIFFUSION ensures that the generation of tokens on the\nright depends on the generated ones on the left, a mechanism achieved through\nemploying a dynamic number of denoising steps that vary based on token position.\nThis results in tokens on the left undergoing fewer denoising steps than those on\nthe right, thereby enabling them to generate earlier and subsequently influence\nthe generation of tokens on the right. In a series of experiments on various text\ngeneration tasks, including text summarization, machine translation, and common\nsense generation, AR-DIFFUSION clearly demonstrated its superiority over existing\ndiffusion language models and that it can be 100× ∼ 600× faster when achieving\ncomparable results. Our code is available at this https URL.\n\n1\n\nIntroduction\n\nText generation is a fundamental task within the field of natural language processing (NLP). Pre-\ntrained language models like GPT-4 [OpenAI, 2023], LLaMA [Touvron et al., 2023], and Alpaca\n[Taori et al., 2023] have garnered significant attention with their ability to generate fluent and human-\nlike textual content. These models utilize the auto-regressive (AR) Transformer decoders [Vaswani\net al., 2017] to emit generated tokens one-by-one in sequential order from left to right. By leveraging\nthe power of position dependency, AR models are able to enhance the naturalness, coherence, and\nadherence to human language conventions in the generated text [Brown et al., 2020].\n\nRecent studies have shown the remarkable performance of diffusion models in image generation [Ho\net al., 2020], motivating researchers to extend diffusion to text generation [Li et al., 2022a, Gong\net al., 2022, Dieleman et al., 2022, Yuan et al., 2022, Ye et al., 2023]. By introducing timestep, these\nmethods progressively regulate the interpolation between the original tokens and Gaussian noise, then\niteratively denoise for text generation. At each timestep, the diffusion-based text generator predicts\n\n∗Work done during an internship at Microsoft Research Asia.\n†These authors contributed equally to this work.\n‡Corresponding author.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n\fFigure 1: Model behaviors illustrated on a two-dimensional coordinate system, where the horizontal\naxis stands for the position and the vertical axis represents the diffusion timestep. In the inference\nstage, different models will behave differently. (a) For the typical Diffusion-LM [Li et al., 2022a],\neach token share the identical movement speed v(n1, ti, ti+1) = v(n2, ti, ti+1) = |ti+1 − ti|. (b) For\nAR from the perspective of diffusion models, the tokens have two states based on the degree of interpo-\nlation between the original tokens and Gaussian noise: to be decoded (at timestep t = T ) and already\ndecoded (at timestep t = 0). Specifically, we have v(n1, ti, ti+1) = 0 and v(n2, ti, ti+1) = T . (c)\nIn AR-DIFFUSION, (ne, te) is the coordinate of anchor point. Tokens in different positions exhibit\nvarying movement speeds, such as v(n1, ti, ti+1) > v(n2, ti, ti+1) when n1 < n2.\n\nall tokens simultaneously following Non-Auto-Regression (NAR) [Lewis et al., 2020, Qi et al., 2020,\n2021, Li et al., 2022b], leading to faster decoding speed compared to AR. However, it also inherits\nthe drawback of NAR, namely the sacrifice of inter-token position dependency [Li et al., 2022c] and\nthe drop of generation performance [Bao et al., 2021].\n\nTo conduct a comprehensive analysis, we introduce a two-dimensional coordinate system to track the\ndiffusion timestep of tokens f (·) positioned at various locations. As illustrated in Figure 1, the system\nassigns the token position n ∈ [1, N ] to the horizontal axis and the diffusion timestep t ∈ [0, T ] to\nthe vertical axis. Diffusion-LM [Li et al., 2022a], which is followed by existing diffusion-based text\ngeneration models, is shown in Figure 1(a). It assigns a uniform timestep t to all tokens. In contrast,\ntokens in the AR model depicted in Figure 1(b) exhibit distinct timesteps within a generation step (ti).\nFor instance, the already decoded token at position n1 has a timestep of 0, while the to-be-decoded\ntoken at position n2 has a timestep of T . This approach effectively captures the sequential dependency.\nMotivated by this observation, we introduce AR-DIFFUSION, an auto-regressive diffusion method,\nfor the disparity in token positions and the principle of sequential token identification.\n\nIn AR-DIFFUSION, we propose a multi-level diffusion strategy that includes both sentence-level\nand token-level diffusion. We randomly choose a sentence-level timestep t, and assign dynamic\nmovement speeds v(·) by determining position-sensitive token-level timestep f (n, t) for each token.\nThis enables tokens at the left of a sentence to undergo faster movement from random Gaussian noise\nto token embedding, while those at the right of the sentence experience slower movement to better\nutilize information from previously denoised tokens. During inference, to reduce the significant\nnumber of inference steps (e.g., 2,000) required in Diffusion-LM [Li et al., 2022a], SeqDiffSeq [Yuan\net al., 2022] and GENIE [Lin et al., 2023], we introduce a skipping mechanism that collaborates with\nthe multi-level diffusion strategy to accelerate the process.\n\nExperimental results across various text generation tasks, such as text summarization, machine\ntranslation, and common sense generation, have consistently demonstrated that AR-DIFFUSION\nsurpasses existing text diffusion models, including AR methods in terms of both quality and diversity.\nMoreover, our verification reveals that AR-DIFFUSION requires fewer resources during decoding\nwhile maintaining superior performance. It achieves 100× faster than SeqDiffSeq [Yuan et al., 2022]\nin machine translation and 600× faster than GENIE [Lin et al., 2023] in text summarization while\ndelivering comparable results. Furthermore, it demonstrates promising results even in a challenging\nscenario where decoding is limited to only two steps.\n\n2\n\n𝑡𝑖+1TT𝑡𝑖+1𝑡𝑖𝑡𝑖TimestepTimestepPositionPosition𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)(a) Diffusion-LM(c) AR-DiffusionToken-Level Diffusion Timestep FunctionForward Diffusion ProcessReverse Diffusion Process(𝑛𝑒,𝑡𝑒)𝑛1𝑛2NN𝑛2T𝑡𝑖+1𝑡𝑖TimestepPosition(b) ARN𝑛2𝑛1𝒗𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏=|𝒕𝒊+𝟏−𝒕𝒊|𝒗𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏=|𝒕𝒊+𝟏−𝒕𝒊|𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛1,𝑡𝑖)𝑛1𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)𝒗𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏=𝑻𝒗𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏=𝟎𝑓𝑛1,𝑡𝑖=𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)𝒗(𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏)𝒗(𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏)𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛1,𝑡𝑖)\f2 Preliminary\n\n2.1 Conditional Generative Language Models\n\nIn the field of natural language generation, conditional generative models are commonly implemented\nusing either auto-regressive (AR) or non-auto-regressive (NAR) methods. In AR [Vaswani et al.,\n2017], tokens on the right are predicted based on visible left tokens. The likelihood is given by\npAR(y|x) = (cid:81)N\ni=1 p(yi|y1:i−1; x), where yi denotes the i-th token of y. On the other hand, NAR [Gu\net al., 2017] assumes conditional independence among tokens and generates them uniformly without\ndistinction during decoding, resulting in the likelihood pNAR(y|x) = (cid:81)N\ni=1 p(yi|x). This parallel gen-\neration approach is of lower quality compared to AR, although it offers a substantial speed advantage.\n\n2.2 Diffusion Models for Text Generation\n\nRecently, Li et al. [2022a] propose a natural language generation model based on the diffusion\nprocess, which is typically divided into a forward noising process and a reverse denoising process.\n\nSpecifically, the forward process is a fixed linear Gaussian model, which gradually perturbs the\nrandom variable z0 until it becomes the standard Gaussian distribution. This can be formalized as:\n(1)\ni=1 αi, and αi is a coefficient that monotonically decreases with timestep t, zt is the\n\nq(zt | z0; x) = N (zt;\n\n¯αtz0, (1 − ¯αt)I),\n\n√\n\nwhere, ¯αt = (cid:81)t\nlatent state at timestep t.\n\nThe reverse process is to initiate from standard Gaussian noise and progressively utilize the denoising\ntransition pθ(zt−1|zt; x) for generation.\n\npθ(zt−1 | zt; x) = N (cid:0)zt−1; µθ(zt, t; x), Σθ(zt, t; x)(cid:1),\n(2)\nwhere the mean µθ and variance Σθ are learned from the model. In particular, we follow Li et al.\n[2022a]’s approach of using predefined variance without trainable parameters.\n\nTo extend the continuous diffusion process to discrete text generation, Li et al. [2022a] introduce\nan additional Markov transition from the discrete tokens y to the latent variable z0. In practice, we\nadd an embedding step qϕ(z0|y) = N (z0; Emb(y), (1 − α0)I) in the forward process, and use a\ntrainable rounding step which is parametrized by pθ(y|z0; x) = (cid:81)N\n0; x) in the reverse\nprocess. In each timestep, we utilize an encoder-decoder model gθ(zt, t; x) to approximate z0 [Lin\net al., 2023] in a NAR manner and then estimate µθ(zt, t; x).\n\ni=1 pθ(yi|zi\n\nIn consequence, combined with maximizing the evidence lower bound (ELBO) of log pθ(y|x), our\ntraining objective of the conditional diffusion language model is:\n\n(cid:34)\n\nL = Eqϕ(z0:T |y)\n\n− log pθ(y | z0; x) +\n\nT\n(cid:88)\n\nt=1\n\n∥z0 − gθ(zt, t; x)∥2\n\n.\n\n(3)\n\n(cid:35)\n\n3 Methodology\n\n3.1 Multi-Level Diffusion\n\nIn the typical diffusion process, every token in the text sequence has the same diffusion timestep.\nIn order to leverage the sequential nature of language, we enable tokens to have different diffusion\ntimesteps during the forward and reverse pass. To accomplish this, we propose a multi-level diffusion\nstrategy that includes both sentence-level and token-level diffusion. Firstly, at the sentence-level, we\nfollow Diffusion-LM [Li et al., 2022a] to randomly select a timestep t. Secondly, at the token-level,\nwe incorporate positional information n ∈ [1, N ] based on the sentence-level timestep to regulate\nthe diffusion timestep for the current token. The procedure is illustrated as:\nzt = (cid:0)z1\n\nf (2,t), · · · , zN\n\nf (1,t), z2\n\nf (N,t)\n\n(4)\n\n(cid:1),\n\nwhere N is the given target sentence length, zt is the sentence representation at timestep4 t, zn\nf (n,t)\nis the latent representation for the n-th token at sentence-level timestep t, and f (n, t) is a token-level\n\n4Please note that if we talk about a “timestep” without explicitly indicating that it is for token-level, it should\n\nbe for sentence-level.\n\n3\n\n\ftimestep function that denotes the token-level diffusion timestep determined by token position n\nand sentence-level timestep t.\nWe visualize the token-level timestep (cid:0)n, f (n, t)(cid:1) onto a two-dimensional coordinate system as Fig-\nure 1 , which takes the token position as the horizontal axis and the sentence-level timestep as the\nvertical axis. Furthermore, to provide a more profound description of the characteristics of movement,\nwe define the speed of movement as the following equation.\n\nv(n, ti, ti+1) = f (n, ti+1) − f (n, ti),\n\n(5)\n\nwhere ti and ti+1 are the start and end sentence-level diffusion timesteps. It can be observed that\ntokens in Diffusion-LM share the same movement speed, while those in AR exhibit different speeds.\n\n3.2 Token-Level Diffusion with Dynamic Movement Speed\n\nBased on the speed of movement, we propose a fundamental principle, dynamic movement speed,\nfor designing the token-level diffusion timestep function f (n, t) to take advantage of AR in diffusion.\nSpecifically, elements on the left side of a sentence undergo higher movement speed from random\nGaussian noise to token embedding, while those on the right side experience lower movement speed,\nthereby they can be generated in the later sentence-level timestep and utilize information from\npreviously generated tokens more effectively.\n\nAlgorithm 1 Training Process of AR-DIFFUSION.\n\nInput: Dataset {(x, y)}, maximum timestep number T and maximum target length N .\nOutput: Optimized model parameters θ.\n\n1: Define an anchor point (ne, te)5.\n2: repeat\n3:\n4:\n\nSample (x, y) from the dataset and embed y into z0.\nSample a sentence-level timestep t from the interval [0, N + T ], then the start point is determined by the\nfollowing equation:\n\n(ns, ts) = (cid:0)clip(N − t, 0, N ), clip(t − N, 0, T )(cid:1)\n\n5:\n\nUse the point-slope linear function to determine the token-level timestep f (n, t) in position n:\n\nf (n, t) = clip(cid:0) te − ts\nne − ns\n\n(n − ns) + ts, 0, T (cid:1)\n\n6:\n7:\n\nSample zn\nf (n,t) for each n in different positions with Gaussian reparameterization.\nAccording to equation (3) and equation (9), employ gradient descent to optimize the objective:\n\n(cid:104)\n\nmin\nθ\n\n− log pθ(y | z0; x) +\n\nN\n(cid:88)\n\nn=1\n\n(cid:13)\n(cid:13)gθ(zn\n\nf (n,t), f (n, t); x) − z0\n\n2(cid:105)\n\n(cid:13)\n(cid:13)\n\n8: until converged\n\n(6)\n\n(7)\n\n(8)\n\nFollowing the guidance of the principle, we develop a token-level diffusion strategy with the\nlinear function, which is shown in Figure 1(c).\nIn particular, the procedure is illustrated in\nAlgorithm 1, where clip(x, min, max) function is to clamp all elements in x into the range\n[min, max]. Specifically, in the forward process of diffusion, the start point goes to the left from\n(N, 0) to (0, 0) along the horizontal axis and then moves up to (0, T ) along the vertical axis.\nTherefore, the entire range of sentence-level timestep is extended to [0, N + T ].\n\nIn the reverse diffusion process, the multi-level diffusion follows the formula:\n\n(cid:0)zt, t; x(cid:1) = gθ\n\ngθ\n\n(cid:16)(cid:0)z1\n\nf (1,t), f (1, t)(cid:1), (cid:0)z2\n\nf (2,t), f (2, t)(cid:1), · · · , (cid:0)zN\n\nf (N,t), f (N, t)(cid:1); x\n\n(cid:17)\n\n,\n\n(9)\n\nwhere gθ(zn\n\nf (n,t), f (n, t); x) denotes the n-th element.\n\n5In particular, the anchor point is set as (2 × N, T ) in our implementation. The impact of different choices\n\nof the anchor point is discussed in supplementary material E.\n\n4\n\n\f3.3\n\nInference with Skippin\n...[truncated]",
    "https://aclanthology.org/2023.findings-acl.721.pdf": "SNIPPET: (Tang et al., Findings 2023); Copy Citation: BibTeX. Markdown MODS XML Endnote More options… PDF: https://aclanthology.org/2023.findings-acl.721.pdf · PDF Cite ...\n\nTITLE: (from PDF)\n\nBODY:\n11359\nFindings of the Association for Computational Linguistics: ACL 2023, pages 11359–11386\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\n\nCanDiffusionModelAchieveBetterPerformanceinTextGeneration?BridgingtheGapbetweenTrainingandInference!ZechengTang∗PinzhengWang∗KeyanZhouJuntaoLi†ZiqiangCaoMinZhangInstituteofComputerScienceandTechnology,SoochowUniversity,China{zctang,pzwang,kyzhou123}@stu.suda.edu.cn;{ljt,zqcao,minzhang}@suda.edu.cnAbstractDiffusionmodelshavebeensuccessfullyadaptedtotextgenerationtasksbymappingthediscretetextintothecontinuousspace.How-ever,thereexistnonnegligiblegapsbetweentrainingandinference,owingtotheabsenceoftheforwardprocessduringinference.Thus,themodelonlypredictsbasedonthepreviouslygeneratedreversenoiseratherthanthenoisecomputedbytheforwardprocess.Besides,thewidely-useddownsamplingstrategyinspeed-inguptheinferencewillcausethemismatchofdiffusiontrajectoriesbetweentrainingandin-ference.Tounderstandandmitigatetheabovetwotypesoftraining-inferencediscrepancies,welaunchathoroughpreliminarystudy.Basedonourobservations,weproposetwosimpleyeteffectivemethodstobridgethegapsmentionedabove,namedDistancePenaltyandAdaptiveDecaySampling.Extensiveexperimentson6generationtasksconfirmthesuperiorityofourmethods,whichcanachieve100×→200×speedupwithbetterperformance.Ourcodeisavailableathttps://github.com/CODINNLG/Bridge_Gap_Diffusion.1IntroductionWiththeprevalenceofAIGC(ArtificialIntelli-genceGeneratedContent)inrecentyears,genera-tivemodels(KingmaandWelling,2013;Goodfel-lowetal.,2020)havebeenreceivingmoreattention.Asoneoftherepresentativegenerativemodels,dif-fusionmodels(Sohl-Dicksteinetal.,2015;Songetal.,2020)haveachievedgreatsuccessonmyri-adsofgenerationtaskswithcontinuousdata,suchasimage(Songetal.,2020;Rameshetal.,2022;Rombachetal.,2022),audiogeneration(Kongetal.,2020),andmoleculegeneration(Hoogeboometal.,2022),byiterativelyrefiningtheinputnoisetomatchadatadistribution.Morerecently,diffu-sionmodelshavebeensuccessfullyadaptedtotext∗Equalcontribution.†CorrespondingAuthor.Figure1:Overviewofdiffusionmodelfortextgenera-tion,whereztdenotestheintermediatenoiseatstept.generation(Lietal.,2022;Gongetal.,2022;Linetal.,2022)byfirstleveraginganextraembeddingmodulethatmapsthediscretedataintothecontin-uousspaceandthenrecoveringthetextfromthecontinuousspacewithroundingstrategy(Lietal.,2022)orlogitsprojection(Strudeletal.,2022).Atypicaldiffusion-basedtextgenerationmodelcontainsonereverseprocess(fromnoisetodata)andoneforwardprocess(fromdatatonoise),whichisshowninFigure1.Moreconcretely,bothofthetwoprocessescanbeviewedasMarkovchains,wheretheforwardprocessgraduallyper-turbsthedataintoGaussianNoisewhilethere-verseprocessrecoverstheoriginaldatastepbystepconditionedonthecorrelatednoisefromthefor-wardprocess.Thetrainingstageinvolvesbothoftheabovetwoprocesses,whiletheinferencestageonlyconsistsofthereverseprocess,i.e.,themodelpredictsbasedonthepreviousnoiseoutputtedbythemodelitselfratherthanthecorrelatedforwardnoise.Suchdiscrepancybetweentrainingandin-ference,alsocalledexposurebias(Ranzatoetal.,2015),leadstoerroraccumulationasthedenois-ingstepsgrowduringtheinferencestage(Huszár,2015;WisemanandRush,2016).Anotherdrawbackofthediffusionmodelisthatitrequiresmultipleiterativedenoisingstepstopro-ducethefinalresultssincethereverseprocessshouldapproximatetheforwardprocess(Hoetal.,2020),whichusuallyinvolvesthousandsofsteps.Numerousiterativereversestepsofdiffusionmod-elsareinevitablytime-consumingfortextgenera-\f11360\n\ntion.Forinstance,adiffusionmodeltakesaround12hoursononesingleNVIDIAA100GPUtofin-ishtheinferenceof10Ksentenceswithalengthof128whiletheCMLM-basednon-autoregressivemodel(Ghazvininejadetal.,2019)onlytakesafewminutes1.Toacceleratetheinferencespeedintextgeneration,downsampling(NicholandDhari-wal,2021)isleveraged(Lietal.,2022;Gaoetal.,2022;Gongetal.,2022),thoughmuchfasterbutatthecostofperformanceowingtothegapbetweenthedownsampledstepsininferenceandthefulldiffusiontrajectoryinthetrainingstage.Toexploretheinsightsandthepotentialimprove-mentoftheaforementionedtraining-inferencegaps,weconductapreliminarystudywithadiffusionmodel(Gongetal.,2022)onthestorygenera-tiontaskandmainlyobservethat:(1)injectingthenoisegeneratedbythemodelitselfintothetrainingstagecanimprovethemodelperformance,and(2)theuniformdownsamplingstrategyintheinferencethattreatseachstepequallyimpairsthemodelperformance,andadaptivesamplingstrategyshouldbeappliedfordifferentgenerationstages.Accordingly,weproposetwosimpleyeteffectivestrategies:DistancePenaltyandAdaptiveDecaySampling,tobridgethetraining-inferencegapsandacceleratetheinferenceprocess.Experimentson6generationtasksof3differentsettings(directed,open-ended,andcontrollable)showthesuperior-ityofourmethodswithoutchangingtheoriginalarchitectureofthediffusionmodeloraddingmoreparameters.Surprisingly,ourmethodscanachieve100×speedupwithperformanceimprovementor200×accelerationwithcompetitiveresults.2Background2.1DiffusionModelDiffusionmodelsareoneoftheprevalentgener-ativemodels(Sohl-Dicksteinetal.,2015;Songetal.,2020;NicholandDhariwal,2021),whichcantransferanarbitrarydatadistributionintotheGaussiannoisewiththeforwardprocessandre-coverthedatafromthepurenoisewiththereverseprocessandbothtwoprocessescanberegardedasaMarkovchain.Specifically,giventhetimestepsT={0,1,···,T}andtheoriginaldatadis-tributionz0attimestept=0,theforwardpro-cessgraduallyperturbsitintotheGaussiannoise1BothdiffusionmodelandCMLMmodelsharethesamebackbonemodel,i.e.,Transformer(Vaswanietal.,2017).zT∼N(0,I)attimestept=T:q(zt|zt−1)=N(zt;p1−βtzt−1,βtI),(1)whereztrepresentstheintermediatenoiseattimesteptandβt∈(0,1)isthescalingfactor,control-lingtheamountofaddednoiseattimestept.Thereversediffusionprocessrecoverstheinitialdatadistributionz0fromtheGaussiannoisezTbypredictingthenoiseofcurrenttimesteptanddenoisingitintothenextreversestatezt−1:pθ(zt−1|zt)=N(zt−1;µθ(zt,t),Σθ(zt,t)),(2)whereµθandΣθcanbeimplementedbyneuralnetworksfθ,e.g.,Transformer2:µθ(zt,t)=1√αt(zt−βt√1−¯αtfθ(zt,t)),(3)whereαt=1−βtand¯αt=Qti=1αi.TrainingThetrainingobjectiveofthediffusionmodelistomaximizethemarginallikelihoodofdatalogpθ(z0),andthesimplifiedtrainingobjec-tivecanbewrittenas(Hoetal.,2020):Lsimple=TXt=1Eq(zt|z0)||µθ(zt,t)−ˆµ(zt,z0)||2,(4)whereˆµ(zt,z0)isthemeanofq(zt−1|z0,zt),anditisworthnotingthateachintermediatenoiseztcanbeobtaineddirectlywithouttheprevioushistoryduringthetrainingstage(Equation12).InferenceTheinferencestageonlyconsistsofthereverseprocess.Tosamplezt−1∼pθ(zt−1|zt)inEquation2,reparameterizationstrategy(KingmaandWelling,2013)isleveraged:zt−1=µθ(zt,t)+σtϵ,(5)whereϵ∼N(0,I),σ2t=βt,andztisinitializedwithpureGaussiannoiseinthebeginning.MoredetailsaboutthetrainingandinferencestagesaswellasthederivationsareshowninAppendixA.2.2DiffusionModelforTextGenerationThecoreofapplyingdiffusionmodelsfortextgen-erationtaskisthetransitionbetweendiscretespaceandcontinuousspace.Existingworksmainlyintro-ducetheembeddingfunction(Lietal.,2022)E(·)tomapthediscretetextw={w1,w2,···,wL}2Σθisoftensetasσ2tI(Hoetal.,2020),whereσ2t=βt.\f11361\n\noflengthLintothecontinuousspaceE(w)={E(w1),E(w2),···,E(wL)}∈RLd.Thus,thediffusionmodelcanhandlediscretetextgenera-tionbyaddinganextraforwardstepbeforet=0,denotedasq(z0|w)=N(E(w),σ0I),andan-otherstepattheendofthereverseprocess,i.e.,pθ(w|z0).MoredetailsaregiveninAppendixB.2.3InferenceSpeedupOnecriticalpointthatpreventstheusabilityofdiffusionmodelsintextgenerationistheirslowsamplingspeedduringinferenceduetothelongreversetrajectory,whichmakeseachdiffusionstepsimpleandeasytoestimate(Sohl-Dicksteinetal.,2015).Toacceleratetheinferencespeedintextgenerationtasks,currentworks(Lietal.,2022;Gaoetal.,2022)applythedownsamplingstrat-egy(NicholandDhariwal,2021)thatpicksthesubsetT′={t′1,t′2,···,t′k}fromthefulldiffu-siontrajectoryandeachintermediatereversestepcanbeobtainedby:z′t−1=µθ(z′t,t′)+σ′tϵ.3GapsbetweenTrainingandInferenceFromtheabovedescriptionofdiffusionmodels,wecansummarizetwogaps:(1)thereverseprocessattimesteptininferenceisconditionedonthepre-dictednoisezt+1bythemodelitselfwhilezt+1canbeobtaineddirectlywiththeforwardcomputationq(zt+1|z0)duringtraining,and(2)thedown-sampledtimesubsetT′ininferenceisinconsistentwiththefulldiffusiontrajectoryTintrainingstagewhenapplyingthedownsamplingmethodforinfer-encespeedup.Tocalibratetheeffectsofthesetwotypesoftraining-inferencegaps,welaunchastudyonthestorygenerationtaskinthissection.3.1StudySettingsWeimplementthediffusionmodelwiththetrans-formermodelandselecttheROCStories(ROC)corpus(Mostafazadehetal.,2016)forthestorygenerationtask.Specifically,giventhepromptorthesourcesentencewxandthereferencewy,weapplythepartiallynoisingstrategy(Gongetal.,2022)fortraining(AppendixA).WeutilizeBLEU(B-2)score(Papinenietal.,2002)toreflectthegenerationprecision(thehigher,thebetter),Lexi-calRepetition(LR-2)score(Shaoetal.,2019)toshowthediversityoftext(thelower,thebetter),ROUGE(R-2)torepresenttherecallofgenerationresult(thehigher,thebetter)andPerplexity(PPL)toreflectsthefluency(thelower,thebetter).More(a)B-2scores.(b)LR-2scores.(c)PPLscores.Figure2:Evaluationresultsofnoiseinjection,wherethenumberinabscissarepresentsγ2andγ1=1−γ2.implementationdetailsareinAppendixC.3.2AnalysisTrainingwithPredictedNoiseTomitigatethetraining-inferencegap,itisnaturaltoinjectpartofthepredictednoisesintothetrainingstagebyreplacingtheforwardnoisezt+1inpθ(zt|zt+1)withthepredictednoisez′t+1fromthe(t+1)-thstepofthereverseprocessorinjectingthepredictednoiseintoztbyreplacing||µθ(zt,t)−ˆµ(zt,z0)||2inEquation4withγ1||µθ(zt,t)−ˆµ(zt,z0)||2+γ2||µθ(zt,t)−ˆµ(z′t,t)||2,wherezt∼q(zt|z0)andz′t∼pθ(zt|z′t+1).Wereporttheevaluationre-sultsinFigure2withdifferentsettingsofγ1andγ2andcanmainlyobservethatreplacingtheforwardnoisewiththepredictednoise(γ2=1,γ1=0)doesmitigatethetraining-inferencegapbyachiev-ingabetterperformancethanthevanillatrainingscheme(γ2=0,γ1=1),andtheinjectingstrat-egyperformsbetterthanthereplacingone.Moredetailsaboutnoisereplacementoperationandeval-uationresultsareshowninAppendixD.1.SamplingStrategyDownsamplingcanacceler-atetheinferencebyuniformlyselectingthesubsetsT′fromthefulldiffusiontrajectoryTbutatthecostofperformance.Suchauniformsamplingstrategytreatseachreversestepequallywhilene-glectingthediscrepanciesamongthemincontri-butiontothefinalresult.Toexplorewhethersuchanequal-stepsamplingstrategybringstheperfor-mancedecrease,wesimplycomparedifferentnon-uniformsamplingschemes.Alongwiththereversesteps,wesplitthereverseprocessintothreestages[κ1,κ2,κ3]anddownsampledifferentnumbersofstepsforeachstagebutkeepthetotaldownsam-pledstepsthesame3.AsshowninFigure3,wecanobservethatwhendownsamplingmorestepsfromκ1(orangecurve),themodelcanachieve3Fortotalnumberofdownsampledsteps20,wecansample{[12,4,4],[4,12,4],[4,4,12],[8,4,8]}stepsas[κ1,κ2,κ3].\f11362\n\n(a)B-2ofnon-uniformsampling.(b)R-2ofnon-uniformsampling.Figure3:Comparisonbetweennon-uniformstepsof[κ1,κ2,κ3]andtheoriginaluniformscheme,wherethex-axisrepresentsthedenoisingsteps,andy-axisillus-tratestheevaluationresultsforeachmetric.Thedotsoneachcurveindicatethenumberofdown-sampledsteps.abetterperformancethanotherdownsamplingschemes(greencurve,redcurve,andpurplecurve)andevenexceedtheoriginalfullreversesteps(bluecurve).Inotherwords,theequal-stepuniformdownsamplingschemedoeslimitthemodelcapa-bility,andthesimplenon-uniformdownsamplingstrategycanmitigatesuchissueandmeanwhileacceleratetheinferencespeed.ExtensiveTrialsAsmentionedabove,thegapbroughtbythedifferentdiffusiontrajectoriesintheinferencestage,i.e.,downsampledreversestepsv.s.thefullreversesteps,furtheraggravatesthetraining-inferencediscrepancy.Inviewthatsim-plyinjectingthepredictedreversenoiseintrainingcaneffectivelynarrowthegapsbetweentrainingandinference,itisalsoappealingtomakesuchastrategyadapttothedownsampleddiffusiontra-jectories,i.e.,introducingthedownsampledre-versenoisesinthetrainingstage.Forinstance,wecaninjectthepredictedreversenoisedownsam-pledfromthereversestepsof(t,t+δ]intothed-th(d∼(t,t+δ])forwardnoisetocomputethet-thstepreversenoise,i.e.,replacingtheforwardnoisezt+1inpθ(zt|zt+1)withzd∼(t,t+δ].Intuitively,addingaperturbationwithareason-ablerangeofvaluesintrainingcanmakethemodelmorerobusttowardstheperturbationduringinfer-ence,whileanunconstrainedperturbationvaluemightriskthemodeltraining,e.g.,thetrainingcollapseinauto-regressivetextgenerationmod-Figure4:Euclideandistancebetweenthepredictedre-versenoiseandtheforwardnoiseofaconvergedmodel.els(Zhangetal.,2019b).Forourpurposes,thediscrepancybeforeandafterinjectingthedown-sampledreversenoiseineachtrainingstepshouldfallinarationalrange,whichmainlydependsonthetimesteptandthechoiceofδ.Toexploremoreinsights,wedepictthediscrepancybetweenpre-dictedreversenoisesandforwardnoisesalongwith200randomlyselectedcontinuoustimestepswiththeEuclideandistance,whichisconsistentwiththetrainingobjectiveinEquation4.Tosimplifythestudyexperiment,wedownsampleatimestepforeverytwentysteps4.AsshowninFigure4,wecanobservethat(1)thediscrepancybetweenpre-dictedreversenoisesandforwardnoisesisgettinglargeralongwiththeincreaseoftimestept(reddiagonalarrow),and(2)thedifferencesbetweentheforwardnoiseattimesteptandthepredictedreversenoisefromttot+δarebecominglargeralongwiththeincreaseoftimestep(yellowhor-izontalarrow).Thus,therangeofdownsampledreversenoisestepsshouldbegraduallynarrowedalongwiththeincreaseoftimestep.3.3PotentialImprovementBasedontheanalysismentionedabove,wecanconcludethat:(1)injectingthepredictedreversenoiseintothetrainingstagecanmitigatethetraining-inferencegaps,(2)theschemeofuniformdownsamplingininferencewhichtreatseachstepequallyharmsthemodelperformance,andanon-uniformadaptivemethodshouldbedesigned,and(3)inspiredby(1)and(2),wecaninjectthedown-sampledreversenoisesintothetrainingstagewhiletherangeofdownsampledstepsshouldbegradu-4Weutilizethediffusionmodeltrainedwith240Ksteps.MoreimplementationdetailsareshowninAppendixD.2\f11363\n\nallynarrowedasthetimestepincreases.4MethodWeproposetwosimpleyeteffectivemethods:Dis-tancePenaltyinthepost-trainingstageandAdap-tiveSparseSamplingininferencetobridgethegapswithoutintroducinganyarchitecturemodifi-cationtodiffusionmodels.Thus,itcanbeflexiblyadaptedtodifferentdiffusionmodelvariants.4.1DistancePenaltyWefirstintroducetheDistancePenaltystrategy,whichinjectstheDownsampledpredictedreversenoiseintothepost-trainingstageofdiffusionmod-elsthatconsistsofTtimesteps.5Forbetterillustra-tion,weutilizenewsymbolsK={0,1,···,K}forthetimestepsinthepost-trainingstagetodis-tinguishfromtheoriginaldiffusiontrajectoryTinthetrainingstage.TheoverviewoftheDistancePenaltystrategyisshowninFigure5.DownsamplingRangeinTrainingToobtainarationalpredictedreversenoiseforeachstepk,i.e.,conductthedownsamplingoperationintherangeRk={k−1,···,k−h},andmitigatethetraining-inferencegaps,weconstrainthetotalamountofnoisesinRkwiththethresholdωkadj:ωkadj=√1−¯αKk′,(6)where√1−¯αKdenotesthescalingfactorthatcontrolsthevarianceofnoiseaccumulatedatstepK(AppendixA),andk′isthenumberofthepre\n...[truncated]",
    "https://arxiv.org/abs/2410.14567": "SNIPPET: Oct 18, 2024 ... arXiv:2410.14567 [cs.CL]. (or arXiv:2410.14567v4 [cs.CL] for this version). https://doi.org/10.48550/arXiv.2410.14567. Focus to learn more.\n\nTITLE: ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions\n\nBODY:\nComputer Science > Computation and Language\n[Submitted on 18 Oct 2024 (v1), last revised 4 May 2025 (this version, v4)]\nTitle:ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions\nView PDF HTML (experimental)Abstract:Retrieval-augmented generation (RAG) has become integral to large language models (LLMs), particularly for conversational AI systems where user questions may reference knowledge beyond the LLMs' training cutoff. However, many natural user questions lack well-defined answers, either due to limited domain knowledge or because the retrieval system returns documents that are relevant in appearance but uninformative in content. In such cases, LLMs often produce hallucinated answers without flagging them. While recent work has largely focused on questions with false premises, we study out-of-scope questions, where the retrieved document appears semantically similar to the question but lacks the necessary information to answer it. In this paper, we propose a guided hallucination-based approach ELOQ to automatically generate a diverse set of out-of-scope questions from post-cutoff documents, followed by human verification to ensure quality. We use this dataset to evaluate several LLMs on their ability to detect out-of-scope questions and generate appropriate responses. Finally, we introduce an improved detection method that enhances the reliability of LLM-based question-answering systems in handling out-of-scope questions.\nSubmission history\nFrom: Zhiyuan Peng [view email][v1] Fri, 18 Oct 2024 16:11:29 UTC (48 KB)\n[v2] Thu, 19 Dec 2024 19:49:04 UTC (88 KB)\n[v3] Tue, 8 Apr 2025 22:24:08 UTC (136 KB)\n[v4] Sun, 4 May 2025 04:28:02 UTC (138 KB)\nCurrent browse context:\ncs.CL\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.14567",
    "https://arxiv.org/abs/2410.09142": "SNIPPET: Oct 11, 2024 ... arXiv:2410.09142 [astro-ph.HE]. (or arXiv:2410.09142v1 [astro-ph.HE] for this version). https://doi.org/10.48550/arXiv.2410.09142. Focus to ...\n\nTITLE: JWST/MIRI Observations of Newly Formed Dust in the Cold, Dense Shell of the Type IIn SN 2005ip\n\nBODY:\nAstrophysics > High Energy Astrophysical Phenomena\n[Submitted on 11 Oct 2024]\nTitle:JWST/MIRI Observations of Newly Formed Dust in the Cold, Dense Shell of the Type IIn SN 2005ip\nView PDF HTML (experimental)Abstract:Dust from core-collapse supernovae (CCSNe), specifically Type IIP SNe, has been suggested to be a significant source of the dust observed in high-redshift galaxies. CCSNe eject large amounts of newly formed heavy elements, which can condense into dust grains in the cooling ejecta. However, infrared (IR) observations of typical CCSNe generally measure dust masses that are too small to account for the dust production needed at high redshifts. Type IIn SNe, classified by their dense circumstellar medium (CSM), are also known to exhibit strong IR emission from warm dust, but the dust origin and heating mechanism have generally remained unconstrained because of limited observational capabilities in the mid-IR. Here, we present a JWST/MIRI Medium Resolution Spectrograph (MRS) spectrum of the Type IIn SN 2005ip nearly 17 years post-explosion. The Type IIn SN 2005ip is one of the longest-lasting and most well-studied SNe observed to date. Combined with a Spitzer mid-IR spectrum of SN 2005ip obtained in 2008, this data set provides a rare 15-year baseline, allowing for a unique investigation of the evolution of dust. The JWST spectrum shows a new high-mass dust component ($\\gtrsim0.08$ M$_{\\odot}$) that is not present in the earlier Spitzer spectrum. Our analysis shows dust likely formed over the past 15 years in the cold, dense shell (CDS), between the forward and reverse shocks. There is also a smaller mass of carbonaceous dust ($\\gtrsim0.005$ M$_{\\odot}$) in the ejecta. These observations provide new insights into the role of SN dust production, particularly within the CDS, and its potential contribution to the rapid dust enrichment of the early Universe.\nSubmission history\nFrom: Melissa Shahbandeh [view email][v1] Fri, 11 Oct 2024 18:00:00 UTC (7,204 KB)\nCurrent browse context:\nastro-ph.HE\nChange to browse by:\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\nIArxiv Recommender\n(What is IArxiv?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.09142",
    "https://arxiv.org/abs/2410.08632": "SNIPPET: Oct 11, 2024 ... arXiv:2410.08632 [cs.AI]. (or arXiv:2410.08632v1 [cs.AI] for this version). https://doi.org/10.48550/arXiv.2410.08632. Focus to learn more.\n\nTITLE: Words as Beacons: Guiding RL Agents with High-Level Language Prompts\n\nBODY:\nComputer Science > Artificial Intelligence\n[Submitted on 11 Oct 2024]\nTitle:Words as Beacons: Guiding RL Agents with High-Level Language Prompts\nView PDF HTML (experimental)Abstract:Sparse reward environments in reinforcement learning (RL) pose significant challenges for exploration, often leading to inefficient or incomplete learning processes. To tackle this issue, this work proposes a teacher-student RL framework that leverages Large Language Models (LLMs) as \"teachers\" to guide the agent's learning process by decomposing complex tasks into subgoals. Due to their inherent capability to understand RL environments based on a textual description of structure and purpose, LLMs can provide subgoals to accomplish the task defined for the environment in a similar fashion to how a human would do. In doing so, three types of subgoals are proposed: positional targets relative to the agent, object representations, and language-based instructions generated directly by the LLM. More importantly, we show that it is possible to query the LLM only during the training phase, enabling agents to operate within the environment without any LLM intervention. We assess the performance of this proposed framework by evaluating three state-of-the-art open-source LLMs (Llama, DeepSeek, Qwen) eliciting subgoals across various procedurally generated environment of the MiniGrid benchmark. Experimental results demonstrate that this curriculum-based approach accelerates learning and enhances exploration in complex tasks, achieving up to 30 to 200 times faster convergence in training steps compared to recent baselines designed for sparse reward environments.\nCurrent browse context:\ncs.AI\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.08632",
    "https://arxiv.org/abs/2410.09382": "SNIPPET: Oct 12, 2024 ... arXiv:2410.09382 [cs.CV]. (or arXiv:2410.09382v1 [cs.CV] for this version). https://doi.org/10.48550/arXiv.2410.09382. Focus to learn more.\n\nTITLE: CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification\n\nBODY:\nComputer Science > Computer Vision and Pattern Recognition\n[Submitted on 12 Oct 2024]\nTitle:CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification\nView PDF HTML (experimental)Abstract:Person re-identification (ReID) has recently benefited from large pretrained vision-language models such as Contrastive Language-Image Pre-Training (CLIP). However, the absence of concrete descriptions necessitates the use of implicit text embeddings, which demand complicated and inefficient training strategies. To address this issue, we first propose one straightforward solution by leveraging existing image captioning models to generate pseudo captions for person images, and thereby boost person re-identification with large vision language models. Using models like the Large Language and Vision Assistant (LLAVA), we generate high-quality captions based on fixed templates that capture key semantic attributes such as gender, clothing, and age. By augmenting ReID training sets from uni-modality (image) to bi-modality (image and text), we introduce CLIP-SCGI, a simple yet effective framework that leverages synthesized captions to guide the learning of discriminative and robust representations. Built on CLIP, CLIP-SCGI fuses image and text embeddings through two modules to enhance the training process. To address quality issues in generated captions, we introduce a caption-guided inversion module that captures semantic attributes from images by converting relevant visual information into pseudo-word tokens based on the descriptions. This approach helps the model better capture key information and focus on relevant regions. The extracted features are then utilized in a cross-modal fusion module, guiding the model to focus on regions semantically consistent with the caption, thereby facilitating the optimization of the visual encoder to extract discriminative and robust representations. Extensive experiments on four popular ReID benchmarks demonstrate that CLIP-SCGI outperforms the state-of-the-art by a significant margin.\nReferences & Citations\nexport BibTeX citation\nLoading...\nBibliographic and Citation Tools\nBibliographic Explorer (What is the Explorer?)\nConnected Papers (What is Connected Papers?)\nLitmaps (What is Litmaps?)\nscite Smart Citations (What are Smart Citations?)\nCode, Data and Media Associated with this Article\nalphaXiv (What is alphaXiv?)\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub (What is DagsHub?)\nGotit.pub (What is GotitPub?)\nHugging Face (What is Huggingface?)\nPapers with Code (What is Papers with Code?)\nScienceCast (What is ScienceCast?)\nDemos\nRecommenders and Search Tools\nInfluence Flower (What are Influence Flowers?)\nCORE Recommender (What is CORE?)\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\nSOURCE: https://arxiv.org/abs/2410.09382",
    "https://iclr.cc/virtual/2023/poster/11561": "SNIPPET: 2023 Virtual presentation / poster accept. Abstract: Recently, diffusion ... Code is available at https://github.com/Shark-NLP/DiffuSeq. It appears you ...\n\nTITLE: Main Navigation\n\nBODY:\nVirtual presentation / poster accept\nDiffuSeq: Sequence to Sequence Text Generation with Diffusion Models\nShansan Gong · Mukai Li · Jiangtao Feng · Zhiyong Wu · Lingpeng Kong\nKeywords: [ diveristy ] [ text generation ] [ diffusion model ] [ sequence to sequence ] [ Generative models ]\nRecently, diffusion models have emerged as a new paradigm for generative models. Despite the success in domains using continuous signals such as vision and audio, adapting diffusion models to natural language is under-explored due to the discrete nature of texts, especially for conditional generation. We tackle this challenge by proposing DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models. Apart from quality, an intriguing property of DiffuSeq is its high diversity during generation, which is desired in many Seq2Seq tasks. We further include a theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive models. Bringing together theoretical analysis and empirical evidence, we demonstrate the great potential of diffusion models in complex conditional language generation tasks. Code is available at https://github.com/Shark-NLP/DiffuSeq\n\nSOURCE: https://iclr.cc/virtual/2023/poster/11561",
    "https://peerj.com/articles/cs-1905.pdf": "SNIPPET: Feb 23, 2024 ... ... PeerJ Computer Science 10:e1905 https://doi.org/10.7717/peerj-cs.1905. Main article text. Introduction. Diffusion-based generation. With the ...\n\n[FetchError] HTTP 400 for https://peerj.com/articles/cs-1905.pdf\n\nSOURCE: https://peerj.com/articles/cs-1905.pdf",
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf": "SNIPPET: (2023). Available online at: https://proceedings.neurips.cc/paper_files/paper/2023/hash/7d866abba506e5a56335e4644ebe18f9-Abstract-Conference.html; 34. Parikh ...\n\nTITLE: (from PDF)\n\nBODY:\nAR-DIFFUSION: Auto-Regressive Diffusion Model for\nText Generation\n\nAnonymous Author(s)\nAffiliation\nAddress\nemail\n\nAbstract\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\n17\n\n18\n\n19\n\n20\n\n21\n\n22\n\n23\n\n24\n\n25\n\n26\n\n27\n\n28\n\n29\n\n30\n\n31\n\n32\n\n33\n\n34\n\n35\n\n36\n\nDiffusion models have gained significant attention in the realm of image generation\ndue to their exceptional performance. Their success has been recently expanded\nto text generation via generating all tokens within a sequence concurrently. How-\never, natural language exhibits a far more pronounced sequential dependency in\ncomparison to images, and the majority of existing language models are trained\nwith a left-to-right auto-regressive approach. To account for the inherent sequen-\ntial characteristic of natural language, we introduce Auto-Regressive Diffusion\n(AR-DIFFUSION). AR-DIFFUSION ensures that the generation of tokens on the\nright depends on the generated ones on the left, a mechanism achieved through\nemploying a dynamic number of denoising steps that vary based on token position.\nThis results in tokens on the left undergoing fewer denoising steps than those on\nthe right, thereby enabling them to generate earlier and subsequently influence\nthe generation of tokens on the right. In a series of experiments on various text\ngeneration tasks, including text summarization, machine translation, and common\nsense generation, AR-DIFFUSION clearly demonstrated its superiority over existing\ndiffusion language models and that it can be 100× ∼ 600× faster when achieving\ncomparable results. Our code will be publicly available.\n\n1\n\nIntroduction\n\nText generation is a fundamental task within the field of natural language processing (NLP). Pre-\ntrained language models like GPT-4 [OpenAI, 2023], LLaMA [Touvron et al., 2023], and Alpaca\n[Taori et al., 2023] have garnered significant attention with their ability to generate fluent and human-\nlike textual content. These models utilize the auto-regressive (AR) Transformer decoders [Vaswani\net al., 2017] to emit generated tokens one-by-one in sequential order from left to right. By leveraging\nthe power of position dependency, AR models are able to enhance the naturalness, coherence, and\nadherence to human language conventions in the generated text [Brown et al., 2020].\n\nRecent studies have shown the remarkable performance of diffusion models in image generation [Ho\net al., 2020], motivating researchers to extend diffusion to text generation [Li et al., 2022a, Gong\net al., 2022, Dieleman et al., 2022, Yuan et al., 2022, Ye et al., 2023]. By introducing timestep, these\nmethods progressively regulate the interpolation between the original tokens and Gaussian noise, then\niteratively denoise for text generation. At each timestep, the diffusion-based text generator predicts\nall tokens simultaneously following Non-Auto-Regression (NAR) [Lewis et al., 2020, Qi et al., 2020,\n2021, Li et al., 2022b], leading to faster decoding speed compared to AR. However, it also inherits\nthe drawback of NAR, namely the sacrifice of inter-token position dependency [Li et al., 2022c] and\nthe drop of generation performance [Bao et al., 2021].\n\nTo conduct a comprehensive analysis, we introduce a two-dimensional coordinate system to track the\ndiffusion timestep of tokens f (·) positioned at various locations. As illustrated in Figure 1, the system\n\nSubmitted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023). Do not distribute.\n\n\fFigure 1: Model behaviors illustrated on a two-dimensional coordinate system, where the horizontal\naxis stands for the position and the vertical axis represents the diffusion timestep. In the inference\nstage, different models will behave differently. (a) For the typical Diffusion-LM [Li et al., 2022a],\neach token share the identical movement speed v(n1, ti, ti+1) = v(n2, ti, ti+1) = |ti+1 − ti|. (b) For\nAR from the perspective of diffusion models, the tokens have two states based on the degree of interpo-\nlation between the original tokens and Gaussian noise: to be decoded (at timestep t = T ) and already\ndecoded (at timestep t = 0). Specifically, we have v(n1, ti, ti+1) = 0 and v(n2, ti, ti+1) = T . (c)\nIn AR-DIFFUSION, (ne, te) is the coordinate of anchor point. Tokens in different positions exhibit\nvarying movement speeds, such as v(n1, ti, ti+1) > v(n2, ti, ti+1) when n1 < n2.\n\nassigns the token position n ∈ [1, N ] to the horizontal axis and the diffusion timestep t ∈ [0, T ] to\nthe vertical axis. Diffusion-LM [Li et al., 2022a], which is followed by existing diffusion-based text\ngeneration models, is shown in Figure 1(a). It assigns a uniform timestep t to all tokens. In contrast,\ntokens in the AR model depicted in Figure 1(b) exhibit distinct timesteps within a generation step (ti).\nFor instance, the already decoded token at position n1 has a timestep of 0, while the to-be-decoded\ntoken at position n2 has a timestep of T . This approach effectively captures the sequential dependency.\nMotivated by this observation, we introduce AR-DIFFUSION, an auto-regressive diffusion method,\nfor the disparity in token positions and the principle of sequential token identification.\n\nIn AR-DIFFUSION, we propose a multi-level diffusion strategy that includes both sentence-level\nand token-level diffusion. We randomly choose a sentence-level timestep t, and assign dynamic\nmovement speeds v(·) by determining position-sensitive token-level timestep f (n, t) for each token.\nThis enables tokens at the left of a sentence to undergo faster movement from random Gaussian noise\nto token embedding, while those at the right of the sentence experience slower movement to better\nutilize information from previously denoised tokens. During inference, to reduce the significant\nnumber of inference steps (e.g., 2,000) required in Diffusion-LM [Li et al., 2022a], SeqDiffSeq [Yuan\net al., 2022] and GENIE [Lin et al., 2023], we introduce a skipping mechanism that collaborates with\nthe multi-level diffusion strategy to accelerate the process.\n\nExperimental results across various text generation tasks, such as text summarization, machine\ntranslation, and common sense generation, have consistently demonstrated that AR-DIFFUSION\nsurpasses existing text diffusion models, including AR methods in terms of both quality and diversity.\nMoreover, our verification reveals that AR-DIFFUSION requires fewer resources during decoding\nwhile maintaining superior performance. It achieves 100× faster than SeqDiffSeq [Yuan et al., 2022]\nin machine translation and 600× faster than GENIE [Lin et al., 2023] in text summarization while\ndelivering comparable results. Furthermore, it demonstrates promising results even in a challenging\nscenario where decoding is limited to only two steps.\n\n2 Preliminary\n\n2.1 Conditional Generative Language Models\n\nIn the field of natural language generation, conditional generative models are commonly implemented\nusing either auto-regressive (AR) or non-auto-regressive (NAR) methods. In AR [Vaswani et al.,\n\n37\n\n38\n\n39\n\n40\n\n41\n\n42\n\n43\n\n44\n\n45\n\n46\n\n47\n\n48\n\n49\n\n50\n\n51\n\n52\n\n53\n\n54\n\n55\n\n56\n\n57\n\n58\n\n59\n\n60\n\n61\n\n62\n\n63\n\n64\n\n65\n\n2\n\n𝑡𝑖+1TT𝑡𝑖+1𝑡𝑖𝑡𝑖TimestepTimestepPositionPosition𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)(a) Diffusion-LM(c) AR-DiffusionToken-Level Diffusion Timestep FunctionForward Diffusion ProcessReverse Diffusion Process(𝑛𝑒,𝑡𝑒)𝑛1𝑛2NN𝑛2T𝑡𝑖+1𝑡𝑖TimestepPosition(b) ARN𝑛2𝑛1𝒗𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏=|𝒕𝒊+𝟏−𝒕𝒊|𝒗𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏=|𝒕𝒊+𝟏−𝒕𝒊|𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛1,𝑡𝑖)𝑛1𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)𝒗𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏=𝑻𝒗𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏=𝟎𝑓𝑛1,𝑡𝑖=𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖+1)𝑓(𝑛2,𝑡𝑖)𝒗(𝒏𝟐,𝒕𝒊,𝒕𝒊+𝟏)𝒗(𝒏𝟏,𝒕𝒊,𝒕𝒊+𝟏)𝑓(𝑛1,𝑡𝑖+1)𝑓(𝑛1,𝑡𝑖)\f66\n\n67\n\n68\n\n69\n\n70\n\n71\n\n72\n\n73\n\n74\n\n75\n\n76\n\n77\n\n78\n\n79\n\n80\n\n81\n\n82\n\n83\n\n84\n\n85\n\n86\n\n87\n\n88\n\n89\n\n90\n\n91\n\n92\n\n93\n\n94\n\n95\n\n96\n\n97\n\n98\n\n2017], tokens on the right are predicted based on visible left tokens. The likelihood is given by\npAR(y|x) = (cid:81)N\ni=1 p(yi|y1:i−1; x), where yi denotes the i-th token of y. On the other hand, NAR [Gu\net al., 2017] assumes conditional independence among tokens and generates them uniformly without\ndistinction during decoding, resulting in the likelihood pNAR(y|x) = (cid:81)N\ni=1 p(yi|x). This parallel gen-\neration approach is of lower quality compared to AR, although it offers a substantial speed advantage.\n\n2.2 Diffusion Models for Text Generation\n\nRecently, Li et al. [2022a] propose a natural language generation model based on the diffusion\nprocess, which is typically divided into a forward noising process and a reverse denoising process.\n\nSpecifically, the forward process is a fixed linear Gaussian model, which gradually perturbs the\nrandom variable z0 until it becomes the standard Gaussian distribution. This can be formalized as:\n(1)\n\nq(zt | z0; x) = N (zt;\n\n¯αtz0, (1 − ¯αt)I),\n\n√\n\nwhere, ¯αt = (cid:81)t\nlatent state at timestep t.\n\ni=1 αi, and αi is a coefficient that monotonically decreases with timestep t, zt is the\n\nThe reverse process is to initiate from standard Gaussian noise and progressively utilize the denoising\ntransition pθ(zt−1|zt; x) for generation.\n\npθ(zt−1 | zt; x) = N (cid:0)zt−1; µθ(zt, t; x), Σθ(zt, t; x)(cid:1),\nwhere the mean µθ and variance Σθ are learned from the model. In particular, we follow Li et al.\n[2022a]’s approach of using predefined variance without trainable parameters.\n\n(2)\n\nTo extend the continuous diffusion process to discrete text generation, Li et al. [2022a] introduce\nan additional Markov transition from the discrete tokens y to the latent variable z0. In practice, we\nadd an embedding step qϕ(z0|y) = N (z0; Emb(y), (1 − α0)I) in the forward process, and use a\ntrainable rounding step which is parametrized by pθ(y|z0; x) = (cid:81)N\n0; x) in the reverse\nprocess. In each timestep, we utilize an encoder-decoder model gθ(zt, t; x) to approximate z0 [Lin\net al., 2023] in a NAR manner and then estimate µθ(zt, t; x).\n\ni=1 pθ(yi|zi\n\nIn consequence, combined with maximizing the evidence lower bound (ELBO) of log pθ(y|x), our\ntraining objective of the conditional diffusion language model is:\n\n(cid:34)\n\nL = Eqϕ(z0:T |y)\n\n− log pθ(y | z0; x) +\n\nT\n(cid:88)\n\nt=1\n\n∥z0 − gθ(zt, t; x)∥2\n\n.\n\n(3)\n\n(cid:35)\n\n3 Methodology\n\n3.1 Multi-Level Diffusion\n\nIn the typical diffusion process, every token in the text sequence has the same diffusion timestep.\nIn order to leverage the sequential nature of language, we enable tokens to have different diffusion\ntimesteps during the forward and reverse pass. To accomplish this, we propose a multi-level diffusion\nstrategy that includes both sentence-level and token-level diffusion. Firstly, at the sentence-level, we\nfollow Diffusion-LM [Li et al., 2022a] to randomly select a timestep t. Secondly, at the token-level,\nwe incorporate positional information n ∈ [1, N ] based on the sentence-level timestep to regulate\nthe diffusion timestep for the current token. The procedure is illustrated as:\nzt = (cid:0)z1\n\nf (2,t), · · · , zN\n\nf (1,t), z2\n\nf (N,t)\n\n(4)\n\n(cid:1),\n\n99\n\n100\n\n101\n\n102\n\n103\n\n104\n\nwhere N is the given target sentence length, zt is the sentence representation at timestep1 t, zn\nf (n,t)\nis the latent representation for the n-th token at sentence-level timestep t, and f (n, t) is a token-level\ntimestep function that denotes the token-level diffusion timestep determined by token position n\nand sentence-level timestep t.\nWe visualize the token-level timestep (cid:0)n, f (n, t)(cid:1) onto a two-dimensional coordinate system as Fig-\nure 1 , which takes the token position as the horizontal axis and the sentence-level timestep as the\n\n1Please note that if we talk about a “timestep” without explicitly indicating that it is for token-level, it should\n\nbe for sentence-level.\n\n3\n\n\f105\n\n106\n\nvertical axis. Furthermore, to provide a more profound description of the characteristics of movement,\nwe define the speed of movement as the following equation.\n\nv(n, ti, ti+1) = f (n, ti+1) − f (n, ti),\n\n(5)\n\n107\n\n108\n\nwhere ti and ti+1 are the start and end sentence-level diffusion timesteps. It can be observed that\ntokens in Diffusion-LM share the same movement speed, while those in AR exhibit different speeds.\n\n109\n\n3.2 Token-Level Diffusion with Dynamic Movement Speed\n\n110\n\n111\n\n112\n\n113\n\n114\n\n115\n\nBased on the speed of movement, we propose a fundamental principle, dynamic movement speed,\nfor designing the token-level diffusion timestep function f (n, t) to take advantage of AR in diffusion.\nSpecifically, elements on the left side of a sentence undergo higher movement speed from random\nGaussian noise to token embedding, while those on the right side experience lower movement speed,\nthereby they can be generated in the later sentence-level timestep and utilize information from\npreviously generated tokens more effectively.\n\nAlgorithm 1 Training Process of AR-DIFFUSION.\n\nInput: Dataset {(x, y)}, maximum timestep number T and maximum target length N .\nOutput: Optimized model parameters θ.\n\n1: Define an anchor point (ne, te)2.\n2: repeat\n3:\n4:\n\nSample (x, y) from the dataset and embed y into z0.\nSample a sentence-level timestep t from the interval [0, N + T ], then the start point is determined by the\nfollowing equation:\n\n(ns, ts) = (cid:0)clip(N − t, 0, N ), clip(t − N, 0, T )(cid:1)\n\n5:\n\nUse the point-slope linear function to determine the token-level timestep f (n, t) in position n:\n\nf (n, t) = clip(cid:0) te − ts\nne − ns\n\n(n − ns) + ts, 0, T (cid:1)\n\n6:\n7:\n\nSample zn\nf (n,t) for each n in different positions with Gaussian reparameterization.\nAccording to equation (3) and equation (9), employ gradient descent to optimize the objective:\n\n(cid:104)\n\nmin\nθ\n\n− log pθ(y | z0; x) +\n\nN\n(cid:88)\n\nn=1\n\n(cid:13)\n(cid:13)gθ(zn\n\nf (n,t), f (n, t); x) − z0\n\n2(cid:105)\n\n(cid:13)\n(cid:13)\n\n8: until converged\n\n(6)\n\n(7)\n\n(8)\n\n116\n\n117\n\n118\n\n119\n\n120\n\n121\n\n122\n\nFollowing the guidance of the principle, we develop a token-level diffusion strategy with the\nlinear function, which is shown in Figure 1(c).\nIn particular, the procedure is illustrated in\nAlgorithm 1, where clip(x, min, max) function is to clamp all elements in x into the range\n[min, max]. Specifically, in the forward process of diffusion, the start point goes to the left from\n(N, 0) to (0, 0) along the horizontal axis and then moves up to (0, T ) along the vertical axis.\nTherefore, the entire range of sentence-level timestep is extended to [0, N + T ].\n\nIn the reverse diffusion process, the multi-level diffusion follows the formula:\n\n(cid:0)zt, t; x(cid:1) = gθ\n\ngθ\n\n(cid:16)(cid:0)z1\n\nf (1,t), f (1, t)(cid:1), (cid:0)z2\n\nf (2,t), f (2, t)(cid:1), · · · , (cid:0)zN\n\nf (N,t), f (N, t)(cid:1); x\n\n(cid:17)\n\n,\n\n(9)\n\n123\n\nwhere gθ(zn\n\nf (n,t), f (n, t); x) denotes the n-th element.\n\n124\n\n3.3\n\nInference with Skipping\n\n125\n\n126\n\n127\n\nTypically, the generation process needs to go through all the sentence-level timesteps from T + N\nto 0. To reduce the decoding time, we introduce a skipping mechanism \n...[truncated]",
    "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf": "SNIPPET: In this paper, we investigate the scaling properties for training diffusion models, especially on the denoising back- bone and dataset. The goal is to ...\n\nTITLE: (from PDF)\n\nBODY:\nOn the Scalability of Diffusion-based Text-to-Image Generation\n\nHao Li1,2, Yang Zou1,2, Ying Wang1,2, Orchid Majumder1,2, Yusheng Xie1,2, R. Manmatha1,\nAshwin Swaminathan1,2, Zhuowen Tu1, Stefano Ermon1, Stefano Soatto1\n1AWS AI Labs, 2Amazon AGI\n{haolimax, yanzo, lyiwang, orchid, yushx, manmatha, swashwin, ztu, ermons, soattos}@amazon.com\n\nAbstract\n\nScaling up model and data size has been quite successful\nfor the evolution of LLMs. However, the scaling law for\nthe diffusion based text-to-image (T2I) models is not fully\nexplored. It is also unclear how to efﬁciently scale the model\nfor better performance at reduced cost. The different train-\ning settings and expensive training cost make a fair model\ncomparison extremely difﬁcult. In this work, we empirically\nstudy the scaling properties of diffusion based T2I models by\nperforming extensive and rigours ablations on scaling both\ndenoising backbones and training set, including training\nscaled UNet and Transformer variants ranging from 0.4B to\n4B parameters on datasets upto 600M images. For model\nscaling, we ﬁnd the location and amount of cross attention\ndistinguishes the performance of existing UNet designs. And\nincreasing the transformer blocks is more parameter-efﬁcient\nfor improving text-image alignment than increasing channel\nnumbers. We then identify an efﬁcient UNet variant, which is\n45% smaller and 28% faster than SDXL’s UNet. On the data\nscaling side, we show the quality and diversity of the train-\ning set matters more than simply dataset size. Increasing\ncaption density and diversity improves text-image alignment\nperformance and the learning efﬁciency. Finally, we provide\nscaling functions to predict the text-image alignment perfor-\nmance as functions of the scale of model size, compute and\ndataset size.\n\n1. Introduction\n\nScaling up model and dataset size has been the key enabling\nfactor for the success of LLMs [17, 21] and VLMs [6, 32].\nThe scaling law [4, 21] governs the expectation of perfor-\nmance as a function of dataset, model size and compute\nbudget. However, the scaling properties for recent diffusion\nbased Text-to-Image (T2I) models [31, 33–35] are not well\nstudied. Though there is emerging trend that T2I models can\nbe improved with larger denoising backbones [9, 31] and\nstronger text-encoders [1, 31, 35], it is still not clear how\nto effectively and efﬁciently scale up diffusion models, e.g.,\n\nFigure 1. Pushing the Pareto frontier of the text-image alignment\nlearning curve by efﬁciently scaling up both denoising backbones\nand training data. Comparing with the baseline SD2 UNet [34], the\ncombined scaling with both SDXL UNet and enlarged dataset sig-\nniﬁcantly increases the performance and speeds up the convergence\nof TIFA score by 6\n\n.\n\n⇥\n\nhow does the design of denoising backbone inﬂuence the\nimage generation and which components are more effective\nto scale? How should diffusion model scale when the train-\ning data increases? To answer the questions, it is essential\nto understand how exactly each new model improves over\nprevious ones. However, existing diffusion based T2I mod-\nels are mostly trained with different datasets, input space\n(latent space or pixel space) and training settings. Moreover,\nthe expensive training cost of high resolution models makes\nthe fair comparison extremely hard, not to mention explor-\ning new ones. Therefore, a fair and controlled comparison\nof different denoising backbones is greatly desired, which\ncan enable seeking of more efﬁcient models with reduced\ntraining and inference cost.\n\nIn this paper, we investigate the scaling properties for\ntraining diffusion models, especially on the denoising back-\nbone and dataset. The goal is to understand which dimension\n\nThisCVPRpaperistheOpenAccessversion,providedbytheComputerVisionFoundation.Exceptforthiswatermark,itisidenticaltotheacceptedversion;thefinalpublishedversionoftheproceedingsisavailableonIEEEXplore.9400\fof the model is more effective and efﬁcient to scale, how to\nproperly scale the dataset, and the scaling law among mod-\nels, dataset and compute. Fig.1 gives an illustration of how\nthe Pareto frontier of the text-image alignment performance\ncurve can be pushed via proper scaling.\n\n1.1. What we have done\n\n• Comparing existing UNets in a controlled environment:\nwe ﬁrst compare existing UNet designs from SD2 [34],\nDeepFloyd [9] and SDXL [31], to understand why cer-\ntain UNet design is signiﬁcantly better than others. To\nallow a fair comparison, we train all models with the same\ndataset, latent space, text encoder and training settings.\nWe monitor multiple evaluation metrics during training, in-\ncluding composition scores and image quality scores. We\nveriﬁed SDXL’s UNet achieves superior performance over\nothers with similar amount of parameters, which justiﬁes\nthe importance of architecture design.\n\n• Scaling UNet and comparing with Transformers: To\nunderstand why SDXL works so well, we conduct ex-\ntensive ablation studies on the design sapce of UNet by\ninvestigating 15 variations ranging from 0.4B to 4B pa-\nrameters, especially on the choice of channel numbers\nand transformer depth. We show how each architecture\nhyperparameter affects the performance and convergence\nspeed. Similarly, we ablate and scale the Transformer\nbackbones [5, 30] and compare with UNet.\n\n• Ablating the effect of dataset scaling and caption en-\nhancement: We study how different dataset properties\naffect the training performance, including dataset size, im-\nage quality and caption quality. We curate two large-scale\ndatasets with 250M and 350M images, both are augmented\nby synthetic captions. We train both small and large mod-\nels to see how they can beneﬁt from dataset scaling.\n\n1.2. Contributions\n\n• We conduct large-scale controlled experiments to allow\nfair comparison across various denoising backbones for\nT2I synthesis, including both UNets and Transformers.\nOur work veriﬁes the importance of the denoising back-\nbone design. We ﬁnd composition ability is mainly devel-\noped at low resolution, which enables fast model ablations\nwithout training in high resolution. To our best knowledge,\nour work is the ﬁrst large-scale controlled study allowing\nfair comparison across different denoising backbones for\nT2I syntheis.\n\n• We ablate the key design factors for UNet and Transform-\ners and compared their scaled versions. We show scalling\nthe transformer depth in UNet is more parameter efﬁcient\nin improving the alignment performance in comparison\nwith channel number. We identify an efﬁcient UNet vari-\nant that is 45% smaller and 28% faster than SDXL while\nachieving similar performance. We conﬁrm scaling trans-\n\nformer backbone improves performance, but also identify\nthe difﬁculty of training from scratch due to lack of induc-\ntive bias in comparison with UNets.\n\n• We show that properly scaling training data with synthetic\ncaptions improves image quality and speeds up the con-\nvergence. We see data scaling can improve small model’s\nperformance signiﬁcantly, a better designed model can\nhave a higher performance upper bound.\n\n2. Related Work\n\nDiffusion Models Diffusion models [15, 16, 28, 29, 36]\nsynthesize samples via an iterative denoising process and\nhave shown superior performance over GAN [13] based\nmethods for image generation [10]. Recent diffusion based\nT2I models such as Imagen [35], LDM/SD2 [34], Deep-\nFloyd [9], SDXL [31], and DALL\nE [3, 33] have shown\n·\nconsistently improved performance in terms of sample diver-\nsity, text-image alignment and image ﬁdelity. Pixel-based\nmodels [9, 33, 35] usually require cascaded super-resolution\n(SR) models to upscale images generated in low resolution,\nwhile LDMs [3, 31, 34] reduce training cost by utilizing a\ncompressed latent space and upsampling with via an autoen-\ncoder [22]. The low resolution latent space may not represent\nsmall objects (e.g., faces) well. SDXL mitigates this issue\nvia a better VAE and training models in higher resolution\nlatent space (128\n128). Emu [8] shows that increasing the\nlatent channels improves image quality.\n\n⇥\n\nScaling UNets UNet architecture was ﬁrst introduced for\ndiffusion models in [16]. [10, 28] ablated UNet with several\ndesign choices and investigated how FID scales as a function\nof training compute. The UNet in LDM or SD2 [34] has\n320 initial channels and 850M parameters. DeepFloyd [9]\ntrains a pixel based model with a UNet of 4B parameter size\nand 704 channels, which shows better performance than its\nsmaller versions. SDXL [31] employs a 3\nlarger UNet than\nSD2 with mutiple improvements. On the other hand, there\nare also works on improving UNet’s efﬁciency by scaling it\ndown, e.g., SnapFusion [25] studies the redundancy of UNet\nand identiﬁes an efﬁcient version by employing the change of\nCLIP/Latency to measure the impact of architecture change.\n\n⇥\n\nTransformer Backbones Recently there is surge inter-\nest in using Transformer [38] to replace UNet for its gen-\neral architecture design and increased scalability [2, 30,\n41]. DiT [30] replaces UNet with Transformers for class-\nconditioned image generation and ﬁnd there is a strong cor-\nrelation between the network complexity and sample quality.\nU-ViT [2] shows comparable performance can be achieved\nby ViTs with long skip connection. MDT [12] introduces a\nmask latent modeling scheme to improve the training efﬁ-\nciency of transformer-based diffusion models. Those works\n\n9401\f4\n\nC\n\nC\n\n!0 !0\n\n2C\n\n2C 2C\n\n!1\n\n!1\n\n2\n3\nx\n2\n3\n\n4C\n\n!2\n\n6\n1\nx\n6\n1\n\n!2\n\n8\nx\n8\n\n8C\n\n!2\n\n8\nx\n8\n\n\"0, \"1, \"2 = 1, 1, 1\n\n!!\n\n4\n6\nx\n4\n6\n\ni\n\ng\nn\nd\nd\ne\nb\nm\ne\n\nt\nx\ne\nT\n\n!0 !0\n\n!!\"#\n\n2C\n\n!1\n\n!1\n\n!2\n\n!2\n\n4\n\nC\n\nC\n\n2C\n\n2C 2C\n\n!1\n\n!1\n\n2\n3\nx\n2\n3\n\n4C\n\n!2\n\n6\n1\nx\n6\n1\n\n!!\n\n4\n6\nx\n4\n6\n\ni\n\ng\nn\nd\nd\ne\nb\nm\ne\n\nt\nx\ne\nT\n\n!2\n\n!2\n\n!2\n\n6\n1\nx\n6\n1\n\n4C\n\n!2\n\n\"0, \"1, \"2 = 0, 2, 10\n\n3x3 conv\n\nResidual Block\n\nDown/Up Sampling\n\n!\n\n\"\tTransformer Blocks \nwith Cross Attention\n\nIdentity Mapping\n\n! Channel number\n\n!!\"#\n\n2C\n\n!1\n\n!1\n\nFigure 2. Comparison of the UNet design between SD2 (left) and SDXL (right). SD2 applies cross-attention at all down-sampling levels,\nincluding 1\n\n, while SDXL adopts cross-attention only at 2\n\ndown-sampling levels.\n\nand 8\n\nand 4\n\n, 2\n\n, 4\n\n⇥\n\n⇥\n\n⇥\n\n⇥\n\n⇥\n\n⇥\n\nare mostly class conditioned models and only the effect of\nmodel architecture on image ﬁdelity is studied. PixArt-↵ [5]\nextends DiTs [30] for text-conditioned image generation.\nMore recently, SD3 [11] propose MM-DiT design and ﬁnd\nit scales well.\n\n3. Scaling Denoising Backbone\n\n3.1. Existing UNet Design\n\nThe UNet in diffusion models adopts a stack of residual\nblocks and a sequence of downsampling and upsampling\nconvolutions, along with additional spatial attention lay-\ners at multiple resolutions [10, 16]. Recent T2I frame-\nworks [9, 31, 34] mostly employ the ideas in simple dif-\nfusion [18] to improve the efﬁciency of UNet, i.e., tweaking\nmore parameters and computation at smaller resolutions.\nFig. 2 gives a comparison of the UNets for SD2 and SDXL.\nSDXL improves over SD2 in multiple dimensions: a) Less\ndownsampling rates. SD2 uses [1, 2, 4, 4] as the multipli-\ncation rates to increase channels at different downsampling\nlevels. DeepFloyd adopts [1, 2, 3, 4] to reduce computa-\ntion, while SDXL uses [1, 2, 4], which completely removes\nthe 4th downsampling level. b) Cross-attention only at\nlower resolution. Cross-attention is only computed at cer-\ntain downsampling rates, e.g., SD2 applies cross-attention at\n), while SDXL\n, 2\nﬁrst three downsampling rates (1\n⇥\nonly integrates text embedding at the 2\ndownsam-\n⇥\npling levels. c) More compute at lower resolution. SDXL\napplies more transformer blocks at the 2\ndownsam-\npling levels, while SD2 applies uniform single transformer\nblock at all three downsampling levels.\n\n⇥\nand 4\n\nand 4\n\n, 4\n\n⇥\n\n⇥\n\n⇥\n\n⇥\n\n3.2. Controlled Comparison of UNets\n\nTo allow fair comparison of different UNets, we train all\nbackbone variants in the same controlled settings, including\nthe same dataset, latent space, text-encoder and training\n\nsettings. Below we introduce the training conﬁgurations and\nevaluation metrics, based on which we compare all different\nbackbones variants.\n\nTraining We train models on our curated dataset LensArt,\nwhich contains 250M text-image pairs (details in Sec 4). We\nuse SDXL’s VAE and the OpenCLIP-H [20] text encoder\n(1024 dim), without adding extra embedding layer or other\n256 resolution\nconditioning. We train all models at 256\nwith batch size 2048 upto 600K steps. We follow the setup\nof LDM [34] for DDPM schedules. We use AdamW [27]\noptimizer with 10K steps warmup and then constant learning\nrate 8e-5. We employ mixed precision training with BF16\nand enables FSDP for large models.\n\n⇥\n\nInference and Evaluation We use DDIM sampler [37]\nwith 50 steps and ﬁxed seed and CFG scale for inference. To\nunderstand the training dynamics, we monitor the evolution\nof ﬁve metrics during training. We ﬁnd the the metrics at\nearly stage of training can help predict ﬁnal model perfor-\nmance. Speciﬁcally, we measure composition ability and\nimage quality with metrics including: 1) TIFA [19], which\nmeasures the faithfulness of a generated image to its text\ninput via visual question answering (VQA). It contains 4K\ncollected prompts and corresponding question-answer pairs\ngenerated by a language model. Image faithfulness is calcu-\nlated by checking whether existing VQA models can answer\nthese questions using the generated image. TIFA allows\nfor ﬁne-grained and interpretable evaluations of generated\nimages. 2) ImageReward [40] which was learned to ap-\nproximates human preference. We calculate the average\nImageReward score over images generated with MSCOCO-\n10K prompts. Though ImageReward is not a normalized\nscore, its scores are in the range of [-2, 2] and the average\nscore over the number of images gives meaningful statis-\ntics to allow comparision across models. Due to space\n\n9402 \n \n\f3.3. Ablation of UNet Design\n\nNow we have veriﬁed SDXL has a much better UNet design\nthan SD2 and DeepFloyd variants. The question is why it\nexcels and how to further improve it effectively and efﬁ-\nciently. Here we investigate how to improve SDXL’s UNet\nby exploring its design space.\n\nSearch Space Table 1 shows different UNet conﬁgura-\ntions, and their corresponding compute complexity at 256\nresolution. We mainly vary the initial channels and trans-\nformer depth. To understand the impact of each dimension\nof the design space, we select a subset of the variant models\nand train them with the same conﬁgurations. This forms\nour main “search space” for the UNet architecture. More\nablations on the impact of VAE, training iterations and batch\nsize can be found in Appendix.\n\nThe Effect of Initial Channels We train the following\nSDXL UNet variants with different channel numbers: 128,\n192, and 384, with parameters 0.4B, 0.9B and 3.4B, respec-\ntively. Fig. 4 (a) shows that UNet with reduced channel\n...[truncated]"
  },
  "all_scored_papers": {},
  "search_candidate_set": [
    [
      "Unai Ruiz-Gonzalez",
      "2325728468",
      "Words as Beacons: Guiding RL Agents with High-Level Language Prompts",
      "https://arxiv.org/abs/2410.08632"
    ],
    [
      "Qianru Han",
      "2326119521",
      "CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification",
      "https://www.semanticscholar.org/paper/08474bb55d370cd041fc733b8ce0bba8fb9f9ab3"
    ],
    [
      "Hongyi Yuan",
      "2114128654",
      "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
      "https://www.semanticscholar.org/paper/47e40c4c8d291f6d326ccef7313aba7d98dbf283"
    ],
    [
      "Lasse Hyldig Hansen",
      "2279023954",
      "Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources",
      "https://www.semanticscholar.org/paper/67055691c60caf29c1830fd2af20ff69c3d2277d"
    ],
    [
      "Zhujin Gao",
      "2196760222",
      "Empowering Diffusion Models on the Embedding Space for Text Generation",
      "https://aclanthology.org/2024.naacl-long.261.pdf"
    ],
    [
      "M. Shahbandeh",
      "88623710",
      "JWST/MIRI Observations of Newly Formed Dust in the Cold, Dense Shell of the Type IIn SN 2005ip",
      "https://arxiv.org/abs/2410.09142"
    ],
    [
      "Shansan Gong",
      "2165001433",
      "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "https://iclr.cc/virtual/2023/poster/11561"
    ],
    [
      "Zecheng Tang",
      "1576234850",
      "Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference",
      "https://aclanthology.org/2023.findings-acl.721.pdf"
    ],
    [
      "Tong Wu",
      "2175455570",
      "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
      "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf"
    ],
    [
      "Hao Li",
      "2274084219",
      "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling",
      "https://icml.cc/virtual/2025/poster/43728"
    ],
    [
      "Shansan Gong",
      "2165001433",
      "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
      "https://www.semanticscholar.org/paper/69144d537f90f214d5b07a7c79121d16afd7da16"
    ],
    [
      "Jack W. O'Sullivan",
      "2318818270",
      "Towards Democratization of Subspeciality Medical Expertise",
      "https://www.semanticscholar.org/paper/4563b4e5fa8ed408cfc0b150f0f6e1a5eeba18b6"
    ],
    [
      "Tong Wu",
      "2175455570",
      "AR-DIFFUSION: Auto-Regressive Diffusion Model for Text Generation",
      "https://www.semanticscholar.org/paper/54b6e5dcef733c151adef0ac06430f63cb301a36"
    ],
    [
      "Hongyi Yuan",
      "2114128654",
      "Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation",
      "https://aclanthology.org/2024.naacl-long.2.pdf"
    ],
    [
      "Qianru Han",
      "2326119521",
      "CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification",
      "https://arxiv.org/abs/2410.09382"
    ],
    [
      "Paulo M. Carvalho Neto",
      "2316426706",
      "The Riemann-Liouville fractional integral in Bochner-Lebesgue spaces IV",
      "https://arxiv.org/abs/2410.00830"
    ],
    [
      "Hao Li",
      "2274084219",
      "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling",
      "https://www.semanticscholar.org/paper/bd2eb51e00392bd8a148ba2f60b2284e3dc6a93a"
    ],
    [
      "Isabel Schlangen",
      "2619606",
      "Data-Driven Approaches for Modelling Target Behaviour",
      "https://arxiv.org/abs/2410.10538"
    ],
    [
      "Zhiyuan Peng",
      "2113952662",
      "ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions",
      "https://www.semanticscholar.org/paper/2ec0a33cb6205ea4a5449803260e93bf88c88501"
    ],
    [
      "Sebastian Ochs",
      "2073523894",
      "Private Synthetic Text Generation with Diffusion Models",
      "https://www.semanticscholar.org/paper/5cc9014843fb585fd2436bae2eb9fd2c87e369ae"
    ],
    [
      "Paulo M. Carvalho Neto",
      "2316426706",
      "The Riemann-Liouville fractional integral in Bochner-Lebesgue spaces IV",
      "https://www.semanticscholar.org/paper/f40719aa87dbaa16d8f1607ad2d7127b5f7f9635"
    ],
    [
      "Sebastian Ochs",
      "2073523894",
      "Private Synthetic Text Generation with Diffusion Models",
      "https://aclanthology.org/2025.naacl-long.532.pdf"
    ],
    [
      "Unai Ruiz-Gonzalez",
      "2325728468",
      "Words as Beacons: Guiding RL Agents with High-Level Language Prompts",
      "https://www.semanticscholar.org/paper/83fe6b75ee908d9bf858f443cb12dc0b709a6311"
    ],
    [
      "Isabel Schlangen",
      "2619606",
      "Data-Driven Approaches for Modelling Target Behaviour",
      "https://www.semanticscholar.org/paper/0761b8b47a18bb2450c0b1cd7e188b2d5b370a2f"
    ],
    [
      "M. Shahbandeh",
      "88623710",
      "JWST/MIRI Observations of Newly Formed Dust in the Cold, Dense Shell of the Type IIn SN 2005ip",
      "https://www.semanticscholar.org/paper/0dbc3872412384ecc3e7d30f83ed6dfa0d44851b"
    ],
    [
      "Lasse Hyldig Hansen",
      "2279023954",
      "Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources",
      "https://arxiv.org/abs/2405.05049"
    ],
    [
      "Zecheng Tang",
      "1576234850",
      "Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference",
      "https://www.semanticscholar.org/paper/f2f85068c9e22a4d8fe6b58e2d92e2d30bc10578"
    ],
    [
      "Jack W. O'Sullivan",
      "2318818270",
      "Towards Democratization of Subspeciality Medical Expertise",
      "https://arxiv.org/abs/2410.03741"
    ]
  ],
  "selected_urls_set": [
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf",
    "https://arxiv.org/abs/2410.09142",
    "https://arxiv.org/abs/2410.14567",
    "https://aclanthology.org/2024.naacl-long.2.pdf",
    "https://icml.cc/virtual/2025/poster/43728",
    "https://aclanthology.org/2025.naacl-long.532.pdf",
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf",
    "https://aclanthology.org/2024.naacl-long.261",
    "https://aclanthology.org/2023.findings-acl.721",
    "https://arxiv.org/abs/2410.00830",
    "https://arxiv.org/abs/2410.03741",
    "https://arxiv.org/abs/2410.09382",
    "https://arxiv.org/abs/2405.05049",
    "https://arxiv.org/abs/2410.10538",
    "https://iclr.cc/virtual/2023/poster/11561",
    "https://aclanthology.org/2024.naacl-long.261.pdf",
    "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf",
    "https://peerj.com/articles/cs-1905.pdf",
    "https://aclanthology.org/2023.findings-acl.721.pdf",
    "https://arxiv.org/abs/2410.08632"
  ],
  "selected_serp_url_set": [
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Supplemental-Conference.pdf",
    "https://arxiv.org/abs/2410.00830",
    "https://arxiv.org/abs/2405.05049",
    "https://arxiv.org/abs/2410.10538",
    "https://arxiv.org/abs/2410.09142",
    "https://iclr.cc/virtual/2023/poster/11561",
    "https://aclanthology.org/2024.naacl-long.261.pdf",
    "https://arxiv.org/abs/2410.03741",
    "https://arxiv.org/abs/2410.14567",
    "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.pdf",
    "https://proceedings.neurips.cc/paper_files/paper/2023/file/7d866abba506e5a56335e4644ebe18f9-Paper-Conference.pdf",
    "https://arxiv.org/abs/2410.08632",
    "https://peerj.com/articles/cs-1905.pdf",
    "https://aclanthology.org/2024.naacl-long.2.pdf",
    "https://aclanthology.org/2023.findings-acl.721.pdf",
    "https://arxiv.org/abs/2410.09382",
    "https://icml.cc/virtual/2025/poster/43728",
    "https://aclanthology.org/2025.naacl-long.532.pdf"
  ],
  "created_at": 1761013806.9182026,
  "updated_at": 1761013806.918213
}