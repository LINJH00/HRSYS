{"url": "https://techcrunch.com/2025/10/19/openais-embarrassing-math/", "title": "OpenAI’s ‘embarrassing’ math", "date": "2025-10-19", "content": "“Hoisted by their own GPTards.”\nThat’s how Meta’s Chief AI Scientist Yann LeCun described the blowback after OpenAI researchers did a victory lap over GPT-5’s supposed math breakthroughs.\nGoogle DeepMind CEO Demis Hassabis added , “this is embarrassing.”\nThe Decoder reports that in a since-deleted tweet, OpenAI VP Kevin Weil declared that “GPT-5 found solutions to 10 (!) previously unsolved Erdős problems and made progress on 11 others.” (“Erdős problems” are famous conjectures posed by mathematician Paul Erdős.)\nHowever, mathematician Thomas Bloom, who maintains the Erdos Problems website , said Weil’s post was “a dramatic misrepresentation” — while these problems were indeed listed as “open” on Bloom’s website, he said that only means, “I personally am unaware of a paper which solves it.”\nIn other words, it’s not accurate to claim GPT-5 was able to solve previously unsolved problems. Instead, Bloom wrote, “GPT-5 found references, which solved these problems, that I personally was unaware of.”\nSebastien Bubeck, an OpenAI researcher who’d also been touting GPT-5’s accomplishments, then acknowledged that “only solutions in the literature were found,” but he suggested this remains a real accomplishment: “I know how hard it is to search the literature.”"}
{"url": "https://techcrunch.com/2025/10/18/wikipedia-says-traffic-is-falling-due-to-ai-search-summaries-and-social-video/", "title": "Wikipedia says traffic is falling due to AI search summaries and social video", "date": "2025-10-18", "content": "Wikipedia is often described as the last good website on an internet increasingly filled with toxic social media and AI slop. But it seems the online encyclopedia is not completely immune to broader trends, with human pageviews falling 8% year-over-year, according to a new blog post from Marshall Miller of the Wikimedia Foundation.\nThe foundation works to distinguish between traffic from humans and bots, and Miller writes that the decline “over the past few months” was revealed after an update to Wikipedia’s bot detection systems appeared to show that “much of the unusually high traffic for the period of May and June was coming from bots that were built to evade detection.”\nWhy is traffic falling? Miller points to “the impact of generative AI and social media on how people seek information,” particularly as “search engines are increasingly using generative AI to provide answers directly to searchers rather than linking to sites like ours” and as “younger generations are seeking information on social video platforms rather than the open web.” (Google has disputed the claim that AI summaries reduce traffic from search.)\nMiller says the foundation welcomes “new ways for people to gain knowledge” and argues this doesn’t make Wikipedia any less important, since knowledge sourced from the encyclopedia is still reaching people even if they don’t visit the website. Wikipedia even experimented with AI summaries of its own, though it paused the effort after editors complained .\nBut this shift does present risks, particularly if people are becoming less aware of where their information actually comes from. As Miller puts it, “With fewer visits to Wikipedia, fewer volunteers may grow and enrich the content, and fewer individual donors may support this work.” (Some of those volunteers are truly remarkable, reportedly disarming a gunman at a Wikipedia editors’ conference on Friday.)\nFor that reason, he argues that AI, search, and social companies using content from Wikipedia “must encourage more visitors” to the website itself.\nAnd he says Wikipedia is taking steps of its own, for example by developing a new framework for attributing content from the encyclopedia. The organization also has two teams tasked with helping Wikipedia reach new readers, and it’s looking for volunteers to help.\nMiller also encourages readers to “support content integrity and content creation” more broadly.\n“When you search for information online, look for citations and click through to the original source material,” he writes. “Talk with the people you know about the importance of trusted, human curated knowledge, and help them understand that the content underlying generative AI was created by real people who deserve their support.”"}
{"url": "https://techcrunch.com/2025/10/18/too-burned-out-to-travel-this-new-app-fakes-your-summer-vacation-photos-for-you/", "title": "Too burned out to travel? This new app fakes your summer vacation photos for you", "date": "2025-10-18", "content": "At a time when startup hustle culture is back , when “ locked in ” tech founders have even embraced the “ 996 ” way of working — 9 am to 9 pm, 6 days a week — there is something dystopian about using an AI app to generate fake vacation photos of yourself.\nAnd yet, here we are.\nProduct designer Laurent Del Rey , who recently joined Meta’s Superintelligence Lab, launched a side project called Endless Summer , a photobooth app for iPhone that creates AI-generated vacation photos starring you in locations around the world. Here you are exploring a beach town, or overlooking a European city from your balcony. There you are, out shopping, having dinner with friends, or at a social gathering.\nIt doesn’t look like anyone in these photos is talking about AI or entrepreneurship or a lack of sleep.\nAs Del Rey explained when sharing the launch on X, the new app is for when “burnout hits and you need to manifest the soft life u deserve.”\n(When you can’t live life, you may as well fake it, right?)\nmade this little photobooth app called endless summer for when burnout hits and you need to manifest the soft life u deserve – with fake vacation pics of you :') first app 100% made by me! just released it on the app store try it out <33 pic.twitter.com/i55nRcE71V\nThe product designer told TechCrunch that he was inspired to create the app because summer is his favorite season, and he loves how life feels during that time of the year.\n“As the season ends, I wanted to make something that felt like that. It’s from that feeling that I reverse-engineered the product experience,” he says. “I created an Xcode project and started iterating directly from there, sculpting the code experience, so to speak.”\nThe experience he landed on was a simple user interface where there’s a tiny camera preview button at the bottom of the screen. You tap the button to make an AI-generated “summer” photo. As you click, the photos appear on your screen, in a sort of camera roll-style view. Each photo features you, or rather an AI version of you, exploring the world and looking fairly content while doing so.\nBehind the scenes, Gemini’s Nano-Banana image-model is doing the heavy lifting, as the app prompts the model for different variations of the summer photo output.\nThe app isn’t saving your selfies, Del Rey says, unless you have its optional auto-generation mode enabled. Plus, users can delete their account at any time with just two taps, which erases everything.\nWhile Nano-Banana is relatively cheap, it does cost money. For that reason, you can’t generate unlimited photos for free with Endless Summer. Instead, you’ll hit a paywall after your first six images, with a prompt suggesting payment options even before then.\nThe pricing isn’t too bad if you’re looking to just dabble with the personalized AI imagery out of curiosity — or because you’re lamenting having missed your summer vacay this year.\nIt’s $3.99 to make 30 images, $17.99 for 150, and $34.99 for 300. You can enable or disable a “Room Service” mode that auto-delivers two photos to you every morning, featuring your latest summer escapades and world travels. You can also set your gender in the app or leave it to guess (“Auto” mode), and turn on or off an option that auto-saves the AI images to your iPhone’s Camera Roll.\nA recent option in the app lets you generate Halloween photos instead of summer photos, featuring you in different costumes.\nsince halloween’s coming up, i just released a special theme in my photobooth app to help u figure out how to dress up for it pic.twitter.com/6TaIj04iwY\nThe photos themselves have a vintage film aesthetic, which makes them look like the casual lifestyle pics they’re supposed to resemble. That brings a sense of nostalgia to the app, as it evokes a mid-2000s feel.\nThis reflects other modern trends around online photo sharing. Whether that’s adopting retro technology, like zoomers carrying disposable cameras, or posting Instagram photo dumps of blurry pics, there’s a desire among some for a less-curated, less “technically perfect” version of life.\nHow bizarre is it that it’s AI bringing that to you now?"}
{"url": "https://techcrunch.com/2025/10/18/whatssapp-changes-its-terms-to-bar-general-purpose-chatbots-from-its-platform/", "title": "WhatsApp changes its terms to bar general purpose chatbots from its platform", "date": "2025-10-18", "content": "Meta-owned chat app WhatsApp changed its business API policy this week to ban general-purpose chatbots from its platform. The move will likely affect WhatsApp-based assistants of companies like OpenAI, Perplexity, Khosla Ventures-backed Luzia , and General Catalyst-backed Poke .\nThe company has added a new section to address “AI providers” in its business API terms, focusing on general-purpose chatbots. The terms, which will go into effect on January 15, 2026, say that Meta won’t allow AI model providers to distribute their AI assistants on WhatsApp.\nProviders and developers of artificial intelligence or machine learning technologies, including but not limited to large language models, generative artificial intelligence platforms, general-purpose artificial intelligence assistants, or similar technologies as determined by Meta in its sole discretion (“AI Providers”), are strictly prohibited from accessing or using the WhatsApp Business Solution, whether directly or indirectly, for the purposes of providing, delivering, offering, selling, or otherwise making available such technologies when such technologies are the primary (rather than incidental or ancillary) functionality being made available for use, as determined by Meta in its sole discretion.\nMeta confirmed this move to TechCrunch and specified that this move doesn’t affect businesses that are using AI to serve customers on WhatsApp. For instance, a travel company running a bot for customer service won’t be barred from the service.\nMeta’s rationale behind this move is that WhatsApp Business API is designed for businesses serving customers rather than acting as a platform for chatbot distribution. The company said that while it built the API for business-to-business use cases, in recent months, it saw an unanticipated use case of serving general-purpose chatbots.\n“The purpose of the WhatsApp Business API is to help businesses provide customer support and send relevant updates. Our focus is on supporting the tens of thousands of businesses who are building these experiences on WhatsApp,” a Meta spokesperson said in a comment to TechCrunch.\nMeta said that the new chatbot use cases placed a lot of burden on its system with increased message volume and required a different kind of support, which the company wasn’t ready for. The company is banning use cases that fall outside “the intended design and strategic focus” of the API.\nThe move will effectively make WhatsApp unavailable as a platform to distribute AI solutions like assistants or agents. It also means Meta AI is the only assistant available on the chat app.\nLast year, OpenAI launched ChatGPT on WhatsApp , and earlier this year, Perplexity launched its own bot on the chat app to tap into the user base of more than 3 billion people. Both of the bots could answer queries, understand media files, answer questions about them, reply to voice notes, and generate images. This likely generated a lot of message volume.\nHowever, there was a bigger issue for Meta. WhatsApp’s Business API is one of the primary ways the chat app makes money. It charges businesses based on different message templates like marketing, utility, authentication, and support. As there wasn’t any provision for chatbots in this API design, WhatsApp wasn’t able to charge them.\nDuring Meta’s Q1 2025 earnings call, Mark Zuckerberg pointed out that business messaging is a big opportunity for the company to bring in revenue.\n“Right now, the vast majority of our business is advertising in feeds on Facebook and Instagram,” he said. “But WhatsApp now has more than 3 billion monthly [active users], with more than 100 million people in the US and growing quickly there. Messenger is also used by more than a billion people each month, and there are now as many messages sent each day on Instagram as there are on Messenger. Business messaging should be the next pillar of our business.”"}
{"url": "https://techcrunch.com/2025/10/17/silicon-valley-spooks-the-ai-safety-advocates/", "title": "Silicon Valley spooks the AI safety advocates", "date": "2025-10-17", "content": "Silicon Valley leaders including White House AI & Crypto Czar David Sacks and OpenAI Chief Strategy Officer Jason Kwon caused a stir online this week for their comments about groups promoting AI safety. In separate instances, they alleged that certain advocates of AI safety are not as virtuous as they appear, and are either acting in the interest of themselves or billionaire puppet masters behind the scenes.\nAI safety groups that spoke with TechCrunch say the allegations from Sacks and OpenAI are Silicon Valley’s latest attempt to intimidate its critics, but certainly not the first. In 2024, some venture capital firms spread rumors that a California AI safety bill, SB 1047 , would send startup founders to jail. The Brookings Institution labeled the rumor as one of many “ misrepresentations ” about the bill, but Governor Gavin Newsom ultimately vetoed it anyway.\nWhether or not Sacks and OpenAI intended to intimidate critics, their actions have sufficiently scared several AI safety advocates. Many nonprofit leaders that TechCrunch reached out to in the last week asked to speak on the condition of anonymity to spare their groups from retaliation.\nThe controversy underscores Silicon Valley’s growing tension between building AI responsibly and building it to be a massive consumer product — a theme my colleagues Kirsten Korosec, Anthony Ha, and I unpack on this week’s Equity podcast. We also dive into a new AI safety law passed in California to regulate chatbots, and OpenAI’s approach to erotica in ChatGPT.\nOn Tuesday, Sacks wrote a post on X alleging that Anthropic — which has raised concerns over AI’s ability to contribute to unemployment, cyberattacks, and catastrophic harms to society — is simply fearmongering to get laws passed that will benefit itself and drown out smaller startups in paperwork. Anthropic was the only major AI lab to endorse California’s Senate Bill 53 (SB 53 ), a bill that sets safety reporting requirements for large AI companies, which was signed into law last month.\nSacks was responding to a viral essay from Anthropic co-founder Jack Clark about his fears regarding AI. Clark delivered the essay as a speech at the Curve AI safety conference in Berkeley weeks earlier. Sitting in the audience, it certainly felt like a genuine account of a technologist’s reservations about his products, but Sacks didn’t see it that way.\nAnthropic is running a sophisticated regulatory capture strategy based on fear-mongering. It is principally responsible for the state regulatory frenzy that is damaging the startup ecosystem. https://t.co/C5RuJbVi4P\nSacks said Anthropic is running a “sophisticated regulatory capture strategy,” though it’s worth noting that a truly sophisticated strategy probably wouldn’t involve making an enemy out of the federal government. In a follow up post on X, Sacks noted that Anthropic has positioned “itself consistently as a foe of the Trump administration.”\nAlso this week, OpenAI’s chief strategy officer, Jason Kwon, wrote a post on X explaining why the company was sending subpoenas to AI safety nonprofits, such as Encode, a nonprofit that advocates for responsible AI policy. (A subpoena is a legal order demanding documents or testimony.) Kwon said that after Elon Musk sued OpenAI — over concerns that the ChatGPT-maker has veered away from its nonprofit mission — OpenAI found it suspicious how several organizations also raised opposition to its restructuring. Encode filed an amicus brief in support of Musk’s lawsuit, and other nonprofits spoke out publicly against OpenAI’s restructuring.\nThere’s quite a lot more to the story than this. As everyone knows, we are actively defending against Elon in a lawsuit where he is trying to damage OpenAI for his own financial benefit. Encode, the organization for which @_NathanCalvin serves as the General Counsel, was one… https://t.co/DiBJmEwtE4\n“This raised transparency questions about who was funding them and whether there was any coordination,” said Kwon.\nNBC News reported this week that OpenAI sent broad subpoenas to Encode and six other nonprofits that criticized the company, asking for their communications related to two of OpenAI’s biggest opponents, Musk and Meta CEO Mark Zuckerberg. OpenAI also asked Encode for communications related to its support of SB 53.\nOne prominent AI safety leader told TechCrunch that there’s a growing split between OpenAI’s government affairs team and its research organization. While OpenAI’s safety researchers frequently publish reports disclosing the risks of AI systems, OpenAI’s policy unit lobbied against SB 53, saying it would rather have uniform rules at the federal level.\nOpenAI’s head of mission alignment, Joshua Achiam, spoke out about his company sending subpoenas to nonprofits in a post on X this week.\n“At what is possibly a risk to my whole career I will say: this doesn’t seem great,” said Achiam.\nBrendan Steinhauser, CEO of the AI safety nonprofit Alliance for Secure AI (which has not been subpoenaed by OpenAI), told TechCrunch that OpenAI seems convinced its critics are part of a Musk-led conspiracy. However, he argues this is not the case, and that much of the AI safety community is quite critical of xAI’s safety practices, or lack thereof .\n“On OpenAI’s part, this is meant to silence critics, to intimidate them, and to dissuade other nonprofits from doing the same,” said Steinhauser. “For Sacks, I think he’s concerned that [the AI safety] movement is growing and people want to hold these companies accountable.”\nSriram Krishnan, the White House’s senior policy advisor for AI and a former a16z general partner, chimed in on the conversation this week with a social media post of his own, calling AI safety advocates out of touch. He urged AI safety organizations to talk to “people in the real world using, selling, adopting AI in their homes and organizations.”\nA recent Pew study found that roughly half of Americans are more concerned than excited about AI, but it’s unclear what worries them exactly. Another recent study went into more detail and found that American voters care more about job losses and deepfakes than catastrophic risks caused by AI, which the AI safety movement is largely focused on.\nAddressing these safety concerns could come at the expense of the AI industry’s rapid growth — a trade-off that worries many in Silicon Valley. With AI investment propping up much of America’s economy, the fear of over-regulation is understandable.\nBut after years of unregulated AI progress, the AI safety movement appears to be gaining real momentum heading into 2026. Silicon Valley’s attempts to fight back against safety-focused groups may be a sign that they’re working."}
{"url": "https://techcrunch.com/2025/10/17/senate-republicans-deepfaked-chuck-schumer-and-x-hasnt-taken-it-down/", "title": "Senate Republicans deepfaked Chuck Schumer, and X hasn’t taken it down", "date": "2025-10-17", "content": "Senate Republicans shared a deepfake video of Chuck Schumer, the Senate minority leader, designed to make it seem like Democrats are celebrating the ongoing government shutdown, which has lasted 16 days.\nIn the deepfake, an AI-generated Schumer repeats the phrase “every day gets better for us,” an actual quote taken out of context from a Punchbowl News article . In the original story, Schumer discussed the Democrats’ healthcare-focused shutdown strategy, and said they were not going to back away from Republicans’ playbook of threats and “bambooz[ling].”\nThe shutdown is happening because Democrats and Republicans cannot agree to pass a bill funding government through October and beyond. Democrats are trying to hold on to tax credits that would make health insurance cheaper for millions of Americans, secure a reversal to Trump’s Medicaid cuts, and block cuts to government health agencies.\nThe video was posted Friday on the Senate Republicans’ X account. According to X’s policies, the platform prohibits “deceptively shar[ing] synthetic or manipulated media that are likely to cause harm.” Harmful content includes media that could “mislead people” or “cause significant confusion on public issues.”\nEnforcement actions include removing content, labeling warnings, or reducing visibility. X has not, as of the time of this writing, removed the deepfake or added a warning label — though the video does include a watermark denoting its AI origins.\nThe Schumer video is not the first time X has allowed deepfakes of politicians to remain on the platform. In late 2024, X owner Elon Musk shared a manipulated video of former vice president Kamala Harris in the lead-up to the election, sparking debate about misleading voters.\nTechCrunch has reached out to X for comment.\nUp to 28 states have enacted laws prohibiting deepfakes of political figures, specifically around campaigns and elections, though most don’t outright ban them if they have clear disclosures. California, Minnesota, and Texas have banned deepfakes intended to influence elections, deceive voters, or harm candidates.\nThe latest post comes weeks after President Donald Trump posted deepfakes on Truth Social depicting Schumer and Hakeem Jeffries, the House minority leader, making false statements about immigration and voter fraud.\nResponding to criticism of the lack of honesty and ethics, Joanna Rodriguez, the National Republican Senatorial Committee communications director, said : “AI is here and not going anywhere. Adapt & win or pearl clutch & lose.”"}
{"url": "https://techcrunch.com/2025/10/17/your-ai-tools-run-on-fracked-gas-and-bulldozed-texas-land/", "title": "Your AI tools run on fracked gas and bulldozed Texas land", "date": "2025-10-17", "content": "The AI era is giving fracking a second act, a surprising twist for an industry that, even during its early 2010s boom years, was blamed by climate advocates for poisoned water tables, man-made earthquakes, and the stubborn persistence of fossil fuels.\nAI companies are building massive data centers near major gas-production sites, often generating their own power by tapping directly into fossil fuels. It’s a trend that’s been overshadowed by headlines about the intersection of AI and healthcare (and solving climate change), but it’s one that could reshape — and raise difficult questions for — the communities that host these facilities.\nTake the latest example. This week, the Wall Street Journal reported that AI coding assistant startup Poolside is constructing a data center complex on more than 500 acres in West Texas — about 300 miles west of Dallas — a footprint two-thirds the size of Central Park. The facility will generate its own power by tapping natural gas from the Permian Basin, the nation’s most productive oil and gas field, where hydraulic fracturing isn’t just common but really the only game in town.\nThe project, dubbed Horizon, will produce two gigawatts of computing power. That’s equivalent to the Hoover Dam’s entire electric capacity, except instead of harnessing the Colorado River, it’s burning fracked gas. Poolside is developing the facility with CoreWeave, a cloud computing company that rents out access to Nvidia AI chips and that’s supplying access to more than 40,000 of them. The Journal calls it an “energy Wild West,” which seems apt.\nYet Poolside is far from alone. Nearly all the major AI players are pursuing similar strategies. Last month, OpenAI CEO Sam Altman toured his company’s flagship Stargate data center in Abilene, Texas — around 200 miles from the Permian Basin — where he was candid, saying, “ We’re burning gas to run this data center .”\nThe complex requires about 900 megawatts of electricity across eight buildings and includes a new gas-fired power plant using turbines similar to those that power warships, according to the Associated Press. The companies say the plant provides only backup power, with most electricity coming from the local grid. That grid, for the record, draws from a mix of natural gas and the sprawling wind and solar farms in West Texas.\nBut the people living near these projects aren’t exactly comforted. Arlene Mendler lives across the street from Stargate. She told the AP she wishes someone had asked her opinion before bulldozers eliminated a huge tract of mesquite shrubland to make room for what’s being built atop it.\n“It has completely changed the way we were living,” Mendler told the AP. She moved to the area 33 years ago seeking “peace, quiet, tranquility.” Now construction is the soundtrack in the background, and bright lights on the scene have spoiled her nighttime views.\nThen there’s the water. In drought-prone West Texas, locals are particularly nervous about how new data centers will impact the water supply. The city’s reservoirs were at roughly half capacity during Altman’s visit, with residents on a twice-weekly outdoor watering schedule. Oracle claims each of the eight buildings will need just 12,000 gallons per year after an initial million-gallon fill for closed-loop cooling systems. But Shaolei Ren, a University of California, Riverside, professor who studies AI’s environmental footprint, told the AP that’s misleading. These systems require more electricity, which means more indirect water consumption at the power plants generating that electricity.\nMeta is pursuing a similar strategy. In Richland Parish, the poorest region of Louisiana, the company plans to build a $10 billion data center the size of 1,700 football fields that will require two gigawatts of power for computation alone. Utility company Entergy will spend $3.2 billion to build three large natural-gas power plants with 2.3 gigawatts of capacity to feed the facility by burning gas extracted through fracking in the nearby Haynesville Shale. Louisiana residents, like those in Abilene, aren’t thrilled to be encircled by bulldozers around the clock.\n(Meta is also building in Texas, though elsewhere in the state. This week the company announced a $1.5 billion data center in El Paso, near the New Mexico border, with one gigawatt of capacity expected online in 2028. El Paso isn’t near the Permian Basin, and Meta says the facility will be matched with 100% clean and renewable energy. One point for Meta.)\nEven Elon Musk’s xAI, whose Memphis facility has generated considerable controversy this year, has fracking connections. Memphis Light, Gas and Water — which currently sells power to xAI but will eventually own the substations xAI is building — purchases natural gas on the spot market and pipes it to Memphis via two companies: Texas Gas Transmission Corp. and Trunkline Gas Company.\nTexas Gas Transmission is a bidirectional pipeline carrying natural gas from Gulf Coast supply areas and several major hydraulically fractured shale formations through Arkansas, Mississippi, Kentucky, and Tennessee. Trunkline Gas Company, the other Memphis supplier, also carries natural gas from fracked sources.\nIf you’re wondering why AI companies are pursuing this path, they’ll tell you it’s not just about electricity; it’s also about beating China.\nThat was the argument Chris Lehane made last week. Lehane, a veteran political operative who joined OpenAI as vice president of global affairs in 2024, laid out the case during an onstage i n terview with TechCrunch.\n“We believe that in the not-too-distant future, at least in the U.S., and really around the world, we are going to need to be generating in the neighborhood of a gigawatt of energy a week,” Lehane said. He pointed to China’s massive energy buildout: 450 gigawatts and 33 nuclear facilities constructed in the last year alone.\nWhen TechCrunch asked about Stargate’s decision to build in economically challenged areas like Abilene, or Lordstown, Ohio, where more gas-powered plants are planned, Lehane returned to geopolitics. “If we [as a country] do this right, you have an opportunity to re-industrialize countries, bring manufacturing back and also transition our energy systems so that we do the modernization that needs to take place.”\nThe Trump administration is certainly on board. The July 2025 executive order fast-tracks gas-powered AI data centers by streamlining environmental permits, offering financial incentives, and opening federal lands for projects using natural gas, coal, or nuclear power — while explicitly excluding renewables from support.\nFor now, most AI users remain largely unaware of the carbon footprint behind their dazzling new toys and work tools. They’re more focused on capabilities like Sora 2 — OpenAI’s hyperrealistic video-generation product that requires exponentially more energy than a simple chatbot — than on where the electricity comes from.\nThe companies are counting on this. They’ve positioned natural gas as the pragmatic, inevitable answer to AI’s exploding power demands. But the speed and scale of this fossil fuel buildout deserves more attention than it’s getting.\nIf this is a bubble, it won’t be pretty. The AI sector has become a circular firing squad of dependencies: OpenAI needs Microsoft needs Nvidia needs Broadcom needs Oracle needs data center operators who need OpenAI. They’re all buying from and selling to each other in a self-reinforcing loop. The Financial Times noted this week if the foundation cracks, there’ll be a lot of expensive infrastructure left standing around, both the digital and the gas-burning kind.\nOpenAI’s ability alone to meet its obligations is “increasingly a concern for the wider economy ,” the outlet wrote.\nOne key question that’s been largely absent from the conversation is whether all this new capacity is even necessary. A Duke University study found that utilities typically use only 53% of their available capacity throughout the year. That suggests significant room to accommodate new demand without constructing new power plants, as MIT Technology Review reported earlier this year .\nThe Duke researchers estimate that if data centers reduced electricity consumption by roughly half for just a few hours during annual peak demand periods, utilities could handle an additional 76 gigawatts of new load. That would effectively absorb the 65 gigawatts data centers are projected to need by 2029.\nThat kind of flexibility would allow companies to launch AI data centers faster. More importantly, it could provide a reprieve from the rush to build natural gas infrastructure, giving utilities time to develop cleaner alternatives.\nBut again, that would mean losing ground to an autocratic regime, per Lehane and many others in the industry, so instead, the natural gas building spree appears likely to saddle regions with more fossil-fuel plants and leave residents with soaring electricity bills to finance today’s investments, including long after the tech companies’ contracts expire.\nMeta, for instance, has guaranteed it will cover Entergy’s costs for the new Louisiana generation for 15 years. Poolside’s lease with CoreWeave runs for 15 years. What happens to customers when those contracts end remains an open question.\nThings may eventually change. A lot of private money is being funneled into small modular reactors and solar installations with the expectation that these cleaner energy alternatives will become more central energy sources for these data centers. Fusion startups like Helion and Commonwealth Fusion Systems have similarly raised substantial funding from those on the front lines of AI, including Nvidia and Altman.\nThis optimism isn’t confined to private investment circles. The excitement has spilled over into public markets, where several “non-revenue-generating” energy companies that have managed to go public have truly anticipatory market caps, based on the expectation that they will one day fuel these data centers.\nIn the meantime — which could still be decades — the most pressing concern is that the people who’ll be left holding the bag, financially and environmentally, never asked for any of this in the first place."}
{"url": "https://techcrunch.com/2025/10/17/facebooks-ai-can-now-suggest-edits-to-the-photos-still-on-your-phone/", "title": "Facebook’s AI can now suggest edits to the photos still on your phone", "date": "2025-10-17", "content": "A Facebook feature that gives Meta AI the ability to suggest edits to photos stored on your phone’s camera roll but haven’t yet been shared is now rolling out to all users in the U.S. and Canada. The company announced on Friday that users can choose to opt in to receive these sharing suggestions, which will then prompt them to post photos to their Facebook Feed and Stories with the AI edits.\nFirst launched as a test over the summer , Facebook’s app pops up a permission dialog box requesting access to “allow cloud processing” so users can get “creative ideas made for you from your camera roll.” This box explains that the feature could offer ideas like collages, recaps, AI restyling, birthday themes, and more for the end user.\nFor the AI to work, Facebook’s app would upload images from your device to its cloud on an ongoing basis. This allows Meta’s AI to make its suggested edits. Meta says users’ media will not be used for ad targeting purposes, and it won’t use the media to improve its AI systems, unless the user takes the step of editing the media or sharing the edited photos with friends or others on its social network.\nThe feature can be disabled at any time.\nThough Meta may not train its AI on all your photos, when you agree to Meta’s AI Terms of Service , you permit your media and facial features to be analyzed by AI. The terms say that, by processing your photos, Meta has the ability to “summarize image contents, modify images, and generate new content based on the image.”\nThe company also uses the date and presence of people or objects in your photos to craft its creative ideas, giving Meta a lot more information about you, your relationships, and your life.\nPlus, giving Meta access to photos you haven’t yet shared on Meta’s platforms could give the company an advantage in the AI race by providing a wealth of user data, behavioral insights, and ideas for new AI features.\nSettings for the feature are found under the Preferences section of Facebook’s Settings. On the “Camera roll sharing suggestions” page, there are two toggles. The first lets Facebook suggest photos from your camera roll when browsing the app. The second is where you could enable or disable the “cloud processing,” which lets Meta make AI images using your camera roll photos.\nMeta has been leveraging its position as a dominant social network to improve its AI technology and had previously announced it would train its image recognition AI on publicly shared data, including posts and comments on Facebook and Instagram. (EU users had until May 27, 2025 , to opt out .) Last year, it also said it would train its AI on images that Ray-Ban Meta users asked the device to analyze."}
{"url": "https://techcrunch.com/2025/10/17/chatgpts-mobile-app-is-seeing-slowing-download-growth-and-daily-use-analysis-shows/", "title": "ChatGPT’s mobile app is seeing slowing download growth and daily use, analysis shows", "date": "2025-10-17", "content": "ChatGPT’s mobile app growth may have hit its peak, according to a new analysis of download trends and daily active users provided by the third-party app intelligence firm Apptopia . Its estimates indicate that new user growth, measured by percentage changes in new global downloads, slowed after April.\nThe firm looked at the global daily active user (DAU) growth and found that the numbers have begun to even out over the past month or so.\nAlthough October is only half over, the firm says it’s on pace to be down 8.1% in terms of a month-over-month percentage change in global downloads.\nTo be clear, this is a look at download growth , not total downloads. In terms of sheer number of new installs, ChatGPT’s mobile app is still doing well, with millions of downloads per day.\nHowever, seeing the download growth stall can suggest that an app’s overall pace of growth is slowing. In ChatGPT’s case, increased competition and changes to its AI model’s characteristics could be to blame.\nDiving in deeper, other metrics indicate that average time spent per DAU in the U.S., specifically, has dropped 22.5% since July, and average sessions per DAU in the U.S. are also down by 20.7%.\nThis indicates that U.S. users are spending less time in ChatGPT’s app and are opening it fewer times per day. User churn in the U.S. has also dropped and stabilized during this time, indicating that the app is now retaining its core users and seeing fewer who just drop by briefly to experiment, then abandon the app.\nOpenAI did not respond to a request for comment.\nBeyond simply reaching its peak, there are other factors that could have played a role here. That includes not only competition from Google’s Gemini, but also user engagement changes following an April update that was designed to make the chatbot’s AI model less sycophantic . This continued with the August release of GPT-5 , which was said to be less personable , as well.\nHowever, Apptopia notes that ChatGPT’s average time spent per DAU and average sessions per DAU metrics were trending downward before the sharp rise of its competitor, Google’s Gemini, which shot up to the top charts in September thanks to the release of Google’s new AI image model, Nano Banana.\nSo while Gemini’s growth may have influenced some of the more recent drops in ChatGPT’s core metrics, it doesn’t explain the overall trend, the firm says.\nPlus, Apptopia points out that if only average time spent per DAU was dropping, but not average sessions per DAU, it could have suggested that people were getting more efficient with their ChatGPT queries. But since both are on the decline, that’s not the case.\nInstead, Apptopia says it’s possible that the experimentation phase with the ChatGPT app is over, and now it’s becoming a part of users’ daily routines. People are likely using the app when they need it or remember to use it, as compared with the increased use it saw when it was still new.\nFor OpenAI, that means the company will have to invest in app marketing or release new features for it to boost some of these core metrics again, just as other established mobile apps have to do. It can no longer rely on novelty alone to provide growth."}
{"url": "https://techcrunch.com/2025/10/17/chatgpt-everything-to-know-about-the-ai-chatbot/", "title": "ChatGPT: Everything you need to know about the AI-powered chatbot", "date": "2025-10-17", "content": "ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.\n2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.\nOpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit.\nIn 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek . The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.\nBelow, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.\nTo see a list of 2024 updates, go here .\nOpenAI is partnering with Walmart to allow users to browse products, plan meals, and make purchases through ChatGPT, with support for third-party sellers expected later this fall. The partnership is part of OpenAI’s broader effort to develop AI-driven e-commerce tools, including collaborations with Etsy and Shopify .\nOpenAI is expanding its affordable ChatGPT Go plan , priced under $5, to 16 new countries across Asia, including Afghanistan, Bangladesh, Bhutan, Brunei Darussalam, Cambodia, Laos, Malaysia, Maldives, Thailand, Vietnam, and Pakistan. In some of these countries, users can pay in local currencies, while in others, payments are required in USD, with final costs varying due to local taxes.\nChatGPT now has 800 million weekly active users , reflecting rapid growth across consumers, developers, enterprises, and governments, Sam Altman said. This milestone comes as OpenAI accelerates efforts to expand its AI infrastructure and secure more chips to support rising demand.\nOpenAI now allows developers to build interactive apps directly inside ChatGPT , with early partners like Booking.com, Expedia, Spotify, Figma, Coursera, Zillow, and Canva already onboard. The ChatGPT maker is also rolling out a preview of its Apps SDK, a developer toolkit for creating these chat-based experiences.\nOpenAI is reportedly adding parental controls to ChatGPT on web and mobile, letting parents and teens link accounts to enable safeguards like limiting sensitive content, setting quiet hours, and disabling features such as voice mode or image generation. The move comes amid growing regulatory scrutiny and a lawsuit over the chatbot’s alleged role in a teen’s suicide.\nOpenAI unveiled Pulse, a new ChatGPT feature that delivers personalized morning briefings overnight, encouraging users to start their day with the app. The tool reflects a shift toward making ChatGPT more proactive and asynchronous, positioning it as a true assistant rather than just a chatbot. OpenAI’s new Applications CEO, Fidji Simo, called Pulse the first step toward bringing high-level personal support to everyone, starting with Pro users.\nOpenAI launched Instant Checkout in ChatGPT , letting U.S. users purchase products directly from Etsy and, soon, over a million Shopify merchants without leaving the conversation. Shoppers can browse items, read reviews, and complete purchases with a single tap using Apple Pay, Google Pay, Stripe, or a credit card. The update marks a step toward reshaping online shopping by merging product discovery, recommendations, and payments in one place.\nOpenAI rolled out its budget-friendly ChatGPT Go plan in Indonesia for Rp 75,000 ($4.50) per month, following its initial launch in India. The mid-tier plan, which offers higher usage limits, image generation, file uploads, and better memory compared to the free version, enters the market in direct competition with Google’s new AI Plus plan in Indonesia.\nCEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions.\nOpenAI rolled out GPT-5-Codex , a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot.\nOpenAI is shaking up its Model Behavior team , the small but influential group that helps shape how its AI interacts with people. The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI.\nOpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide , said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their children’s use.\nElon Musk’s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI , alleging that the two companies colluded to lock up key markets and shut out rivals.\nOpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAI’s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features.\nSince its May 2023 launch, ChatGPT’s mobile app has amassed $2 billion in global consumer spending , dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok.\nDespite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options , including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.\nUpdates to ChatGPT: You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people. Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…\nOpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.\nOpenAI released GPT-5 , a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions.\nOpenAI is making a major push into federal government workflows , offering ChatGPT Enterprise to agencies for just $1 for the next year . The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.\nOpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.\nChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X , noting it has quadrupled in size over the past year.\nThis week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…\nOpenAI unveiled Study Mode , a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users , with availability for Edu subscribers expected in the coming weeks.\nChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.\nChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.\nOpenAI has introduced ChatGPT Agent , which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research , according to the company . OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.\nResearchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”\nCEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.\nwe planned to launch our open-weight model next week. we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us. while we trust the community will build great things with this model, once weights are…\nOpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.\nSome ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.\nReferrals from ChatGPT to news publishers are increasing . But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.\nOpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non -Nvidia chips in an important way.\nResearchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.\nThe ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.\nSam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider . In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.\nOpenAI has unveiled o3-pro , an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.\nOpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro. Enterprise and Edu users will get access the week after. As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…\nOpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said .\nOpenAI’s ChatGPT now offers new funtions for business users , including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.\nOpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.\nOpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.\nSam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.\nOpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.\nBy popular request, GPT-4.1 will be available directly in ChatGPT starting today. GPT-4.1 is a specialized model that excels at coding tasks & instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 & o4-mini for everyday coding needs.\nOpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.\nAfter introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.\nOpenAI is unveiling a program called OpenAI for Countries , which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg .\nOpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.\nOpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back . OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.\nAn issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing , a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”\nOpenAI has added a few features to its ChatGPT search , its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.\nOpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch .\nOpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.\nOpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company skipped that step — sending safety cards for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”\nQuestions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.\nOpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.\nOpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini , for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report .\nOpenAI has released two new reasoning models , o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.\nOpen AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post .\nAll of your image creations, all in one place. Introducing the new library for your ChatGPT image creations—rolling out now to all Free, Plus, and Pro users on mobile and https://t.co/nYW5KO1aIg . pic.twitter.com/ADWuf5fPbj\nOpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.\nOpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge . It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.\nOpenAI will discontinue its largest AI model, GPT-4.5 , from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.\nOpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro , Anthropic’s Claude 3.7 Sonnet , and DeepSeek’s upgraded V3.\nOpenAI plans to sunset GPT-4 , an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog . It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.\nOpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported , citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.\nOpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\nIt looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”\nOpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May . The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.\nMore than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap . The image generator was made available to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.\nThe Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.\nIn a series of posts on X , OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote.\nOpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.\nOpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images . The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.\nOpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said .\nThe latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.\nOpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported , citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.\nOpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.\nBrad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products , according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.\nOpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels . The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch .\nOpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information . One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.\nNoyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”\nOpenAI has added new transcription and voice-generating AI models to its APIs : a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.\nOpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.\nNoam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.\nOpenAI CEO Sam Altman said, in a post on X , that the company has trained a “new model” that’s “really good” at creative writing . He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. And it turns out that it might not be that great at creative writing at all.\nwe trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right. PROMPT: Please write a metafictional literary short story…\nOpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product . The Responses API effectively replaces OpenAI’s Assistants API , which the company plans to discontinue in the first half of 2026.\nOpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information . One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.\nThe latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools , including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.\nAccording to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025 . ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.\nOpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X , Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.\nA commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.\nIn response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.\nOpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.\nOpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.\nOpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.\nOpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”\nA new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.\nOpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.\nYounger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.\nOpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.\nOpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.\nOperator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.\nOpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.\nChatGPT’s new beta feature, called tasks, allows users to set simple reminders . For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.\nOpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI . The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\nNovember 30, 2022 is when ChatGPT was released for public use.\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o .\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus .\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\nMultiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool .\nMost recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.  And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\nGPT stands for Generative Pre-Trained Transformer.\nA chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\nYes.\nDue to the nature of how these models work , they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.\nWe will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\nYes, there is a free ChatGPT mobile app for iOS and Android users.\nIt’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\nYes, it was released March 1, 2023.\nEveryday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\nYes. There are multiple AI-powered chatbot competitors such as Together , Google’s Gemini and Anthropic’s Claude , and developers are creating open source alternatives .\nOpenAI has said that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out this form . This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.\nThe web form for making a deletion of data about you request is entitled “ OpenAI Personal Data Removal Request ”.\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here for instructions on how you can opt out of our use of your information to train our models.”\nRecently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.\nAn Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\nSeveral major school systems and colleges, including New York City Public Schools , have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with .\nThere have also been cases of ChatGPT accusing individuals of false crimes .\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase . Another is ChatX . More launch every day.\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests , they’re inconsistent at best.\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.\nThis story is continually updated with new information."}
{"url": "https://techcrunch.com/2025/10/17/together-we-make-disrupt-unforgettable-thank-you-to-our-sponsors/", "title": "Together, we make TechCrunch Disrupt 2025 unforgettable — thank you to our sponsors", "date": "2025-10-17", "content": "TechCrunch Disrupt 2025 wouldn’t be what it is without the incredible companies that power the innovation behind the scenes. From headline partners to emerging collaborators, our sponsors help make Disrupt the ultimate destination for founders, investors, and visionaries shaping the future of tech. Their insights, technologies, and support bring each stage, session, and startup moment to life — turning bold ideas into real-world impact.\nOur sponsors are shaping the future of industries — and you can catch them live at Disrupt :\n2:35 p.m. – 2:55 p.m. Presented by SymphonyAI\nThe headlines say AI pilots are stalling, but global leaders are already scaling AI in production. From manufacturing to payments to retail, they’re proving success comes from focus: solving complex, domain-specific problems. This discussion goes beyond hype to reveal what breaks when AI meets business reality — and how enterprises are fixing it. Expect real-world insights on deployment barriers, the human impact of automation, and why deep expertise drives measurable results.\n10:40 a.m. – 11:00 a.m. Presented by: Pebl\nAs startups scale globally, their biggest challenge isn’t finding talent — it’s paying them. Legacy payroll and banking systems can’t keep up with a distributed, digital-first workforce. Rising visa costs and shifting U.S. policies are accelerating the move to global hiring. Now fintech innovation is redefining payroll through digital wallets, stablecoins, and crypto rails, making payments faster, cheaper, and borderless. This session dives into why payroll is the next frontier of financial infrastructure, where compliance meets innovation and startups turn global teams into a competitive edge.\nNetworking is at the heart of Disrupt , and our sponsors make those memorable moments possible:\nHuge thanks to our Startup Battlefield sponsor, MongoDB, for helping us champion breakthrough ideas and bold founders taking their first big stage at Disrupt . Your support fuels the next generation of game-changing startups.\nMongoDB will also be hosting a Breakout session:\nLeading for Impact: Engineering at the Speed of AI Tuesday, October 28 10:30 a.m. – 11:20 a.m.\nIn the fast-moving world of AI, traditional product cycles no longer work. Constant model releases, fierce competition, and intense work demands call for a new kind of engineering leadership. Leaders from Factory, Mercor, Fireworks, TinyFish, and MongoDB’s Voyage AI share how they’re building resilient teams, driving rapid growth with leaner resources, and leading with impact at the speed of AI.\nOur Roundtables bring founders, investors, and experts together for candid, interactive discussions that spark real insights and connections you won’t get anywhere else. Check out these Roundtable hosts:\nOur marketing partners help amplify the voice of Disrupt — sharing stories, showcasing innovation, and extending our impact far beyond the stage. We’re grateful for your collaboration and continued support.\nTo all of our partners — thank you for fueling the conversations, connections, and breakthroughs that define Disrupt. Your commitment to innovation helps push the global startup ecosystem forward. We’re proud to build this platform together and can’t wait to see what’s next. Until then, here’s to every company, creator, and changemaker who will help make this year’s Disrupt unforgettable.\nThank you for being part of the Disrupt journey. We couldn’t do it without you."}
{"url": "https://techcrunch.com/2025/10/17/less-than-24-hours-to-spotlight-your-startup-at-techcrunch-disrupt-2025-in-front-of-10000-tech-leaders-and-vcs/", "title": "Less than 24 hours to spotlight your startup at TechCrunch Disrupt 2025 in front of 10,000 tech leaders and VCs", "date": "2025-10-17", "content": "You’re looking for big ways to grow your startup, whether that means securing investors, landing enterprise deals, or generating a nonstop pipeline of leads. This is your final moment.\nYou have less than 24 hours — and only a couple of tables left — to lock in the most valuable growth opportunity of the year at TechCrunch Disrupt 2025 .\nPicture this: More than 10,000 tech leaders, investors, decision-makers, and innovators walking through the Expo Hall. They stop at your table. They see your brand across the venue. They connect with you in multiple ways. Book now before a competitor takes the final tables. Exhibit tables close tonight at 11:59 p.m. PT .\nLearn more about exhibitor benefits here .\nYour competitors are circling the same opportunity. Act now to own the attention, the leads, and the momentum at the tech event of the year, bringing together 10,000+ founders, VCs, key decision-makers, and innovators. Book your table now . Exhibit tables close tonight at 11:59 p.m. PT ."}
{"url": "https://techcrunch.com/2025/10/17/last-flash-sale-before-techcrunch-disrupt-2025-doors-open-save-up-to-624/", "title": "Last flash sale before TechCrunch Disrupt 2025 doors open — save up to $624", "date": "2025-10-17", "content": "Today is your last chance to save! Register for TechCrunch Disrupt 2025 before 11:59 p.m. PT tonight and save up to $624 on your pass. This is the lowest rate available before Disrupt 2025 hits San Francisco’s Moscone West on October 27-29. After today, prices rise and will increase at the door.\nTechCrunch Disrupt is known as a launchpad for scaling and innovation. Connections are how that happens. You can make a year’s worth of connections in just three days with the brightest minds in tech.\nThe Braindate app makes it easy to schedule 1:1 or small-group discussions on topics that matter to you. Get candid feedback on your pitch, have your questions answered by leaders, and find potential partners, investors, or mentors.\nIn addition to formal networking in the Networking Lounge, the venue has three floors, five industry stages, roundtables, breakouts, and the Expo Hall. Anywhere you go, you might bump into someone you have been hoping to meet. Founders and investors can also enjoy exclusive access to the Deal Flow Cafe, a quiet space to discuss deals over coffee.\nThere is no shortage of next-gen insights coming from some of the biggest players in the tech ecosystem. Explore the Disrupt speaker page to meet the fast-growing lineup.\nFrom AI and fintech to climate and transportation, Disrupt has sessions for everyone in tech. This year’s five industry stages include AI, Builders, Going Public, Space, and the Main Stage, where top leaders discuss the state of tech, scaling, and innovation.\nRoundtables and breakouts run throughout the three days, offering opportunities to learn from the greatest minds in tech through highly engaging and dynamic sessions.\nSee the growing session lineup on the Disrupt agenda .\nExplore the unprecedented number of startups exhibiting this year . Walk through the Expo Hall and venue to see innovations from early-stage startups to enterprise brands and experience live demos firsthand.\nThis is the last opportunity to secure the lowest Disrupt pass. After today, prices increase. Save up to $624 by registering now . We’ll see you October 27 to 29 at Moscone West in San Francisco."}
{"url": "https://techcrunch.com/2025/10/17/sk-telecoms-ai-unit-offers-staff-voluntary-retirement-program-just-weeks-after-launch/", "title": "SK Telecom’s AI unit offers staff voluntary retirement program just weeks after launch", "date": "2025-10-17", "content": "South Korean telco giant SK Telecom is making big changes at its new AI division, AI CIC , just weeks after it was launched. Staff employed by the unit are being offered a voluntary retirement program as part of a broader effort to bring together the company’s various AI-related divisions, SK Telecom confirmed to TechCrunch.\n“In late September, SK Telecom announced the launch of the AI CIC (Company-in-Company) unit and confirmed that detailed organizational restructuring would be specified by the end of October,” a spokesperson at SK Telecom told TechCrunch. “This special retirement program is entirely a supportive measure and is not intended as a restructuring or downsizing measure.”\nThe voluntary retirement program will not involve forced layoffs and is meant to support employees whose roles, organizations, or work locations may change, the spokesperson said. Employees who opt to stay with the company may be reassigned to regional offices.\nDetails of the voluntary retirement program have been communicated to staff across all experience levels, including both junior and senior employees, industry sources told TechCrunch. The AI unit has about 1,000 employees, per media reports.\nAI CIC is meant to bring together SK Telecom’s various AI-related units under a centralized organization, per the spokesperson. “This integration involves streamlining overlapping roles and functions, which may inevitably lead to changes such as role transitions, organizational realignments, or relocations,” they said.\nThe new division will oversee the development of SK Telecom’s personal AI agent, A. (pronounced “A-dot”), as well as its AI data center operations, enterprise AI business, and global AI partnerships and investments.\nSeverance packages are reportedly expected to vary based on employees’ tenure and position, but the spokesperson told TechCrunch the company has set no such internal targets. “As participation is entirely voluntary, it is difficult at this stage to predict [how many employees] it may impact on the organization as a whole,” the spokesperson said.\nThe restructuring comes as SK Telecom seeks to streamline operations and boost efficiency, with a specific focus on AI. The company plans for the AI division to record annual revenue of ₩5 trillion (around $3.5 billion) by 2030, and expects AI-driven B2C and B2B services as well as related infrastructure to drive that growth.\nThe telecom giant recently unveiled an AI infrastructure effort, offering Nvidia Blackwell GPUs-as-a-service , and earlier this month partnered with OpenAI to develop AI data centers in southwestern Korea as part of the “Stargate Korea” initiative."}
{"url": "https://techcrunch.com/2025/10/17/meta-previews-new-parental-controls-for-its-ai-experiences/", "title": "Meta previews new parental controls for its AI experiences", "date": "2025-10-17", "content": "Meta on Friday previewed its upcoming parental control features for teens’ conversations with AI characters on its platforms. The features, which will be rolled out next year, include the ability to block certain characters and monitor conversation topics.\nStarting in the coming months, parents will be able to turn off chats with AI characters entirely for teens. This action won’t block access to the Meta AI chatbot — the company’s general-purpose AI chatbot — which will only discuss age-appropriate content.\nParents will also be able to turn off chats with individual characters if they prefer more selective control. Plus, they will receive information about the topics teens are discussing with AI characters and Meta AI.\nThe company said it plans to roll out these controls on Instagram early next year. They will be available in English in the U.S., U.K., Canada, and Australia.\n“We recognize parents already have a lot on their plates when it comes to navigating the internet safely with their teens, and we’re committed to providing them with helpful tools and resources that make things simpler for them, especially as they think about new technology like AI,” the company said in a post written by Instagram head Adam Mosseri and newly appointed Meta AI head Alexandr Wang.\nEarlier this week, Meta said that its content and AI experiences for teens will follow a PG-13 movie rating standard and will avoid sensitive topics such as extreme violence, nudity, and graphic drug use.\nThe company added that currently, teens are only allowed to interact with a limited number of characters that follow age-appropriate content guidelines. Parents can also set time limits on teens’ interactions with AI characters. Earlier this year, Instagram announced that it is using AI to identify attempting to skirt age limits by faking their age on the app.\nIn the past few weeks, multiple platforms, including OpenAI , Meta , and YouTube , have released tools and controls focused on teen safety. These changes come amid growing concerns about the impact of social media on teen mental health and lawsuits against AI companies that allege they played a part in teen suicides."}
{"url": "https://techcrunch.com/2025/10/16/reddit-expands-its-ai-powered-search-to-five-new-languages/", "title": "Reddit expands its AI-powered search to 5 new languages", "date": "2025-10-16", "content": "Reddit announced Thursday that it is expanding its AI-powered search experience to five new languages: French, German, Spanish, Italian, and Portuguese. With this expansion, the feature is now available in countries like Brazil, France, Germany, Spain, Mexico, and Italy.\nUsers who have set one of these languages as their default, instead of English, can now chat with the AI in question-and-answer format. Reddit uses a Google AI model to power the feature.\nReddit first debuted AI-powered search last year and has been working to expand it in different ways. The feature is part of Reddit Answers, which lives alongside the platform’s traditional search.\nReddit CEO Steve Huffman said in August that Reddit search has more than 70 million weekly users, while Reddit Answers is used by more than 6 million people. He also discussed plans to unify the search experience during the company’s quarterly earnings call.\nQ&A-style search and chat interfaces have been gaining popularity since ChatGPT integrated web search. Incumbent search engines like Google and Brave have introduced similar features to improve user engagement and retention. Newer startups like Perplexity have also gained steam with chat-based search interfaces."}
{"url": "https://techcrunch.com/2025/10/16/openai-pauses-sora-video-generations-of-martin-luther-king-jr/", "title": "OpenAI pauses Sora video generations of Martin Luther King Jr.", "date": "2025-10-16", "content": "OpenAI announced Thursday it paused the ability for users to generate videos resembling the late civil rights activist Martin Luther King Jr. using its AI video model, Sora. The company says it’s adding this safeguard at the request of Dr. King’s estate after some Sora users generated “disrespectful depictions” of his image.\n“While there are strong free speech interests in depicting historical figures, OpenAI believes public figures and their families should ultimately have control over how their likeness is used,” OpenAI said in a post on X from its official newsroom account. “Authorized representatives or estate owners can request that their likeness not be used in Sora cameos.”\nStatement from OpenAI and King Estate, Inc. The Estate of Martin Luther King, Jr., Inc. (King, Inc.) and OpenAI have worked together to address how Dr. Martin Luther King Jr.’s likeness is represented in Sora generations. Some users generated disrespectful depictions of Dr.…\nThe restriction comes just a few weeks after OpenAI launched its social video platform , Sora, which allows users to create realistic AI-generated videos resembling historical figures, their friends, and users who elect to have their likeness re-created on the platform. The launch has stirred fervent public debate around the dangers of AI-generated videos and how platforms should implement guardrails around the technology.\nDr. Bernice King, Dr. King’s daughter, posted on Instagram last week asking people to stop sending her AI videos resembling her father. She joined Robin Williams’ daughter, who also asked Sora users to stop generating AI videos of her father.\nThe Washington Post reported earlier this week that Sora users had created AI-generated videos of Dr. King making monkey noises and wrestling with another civil rights icon, Malcolm X. Scrolling through OpenAI’s Sora app, it’s easy to find crude videos resembling other historical figures, including artist Bob Ross, singer Whitney Houston, and former president John F. Kennedy.\nThe licensor of Dr. King’s estate did not immediately respond to TechCrunch’s request for comment.\nBeyond how Sora represents humans, the launch has also raised a flurry of questions around how social media platforms should handle AI videos of copyrighted works . The Sora app is also full of videos depicting cartoons like SpongeBob, South Park, and Pokémon.\nOpenAI has added other restrictions to Sora in weeks since its launch. Earlier in October, the company said it planned to give copyright holders more granular control over the types of AI videos that can be generated with their likeness. That may have been a response to Hollywood’s initial reaction to Sora, which was not great .\nAs OpenAI adds restrictions to Sora, the company seems to be taking a more hands-off approach to moderating content in ChatGPT. OpenAI announced this week that it would allow adult users to have “erotic” chats with ChatGPT in the coming months.\nWith Sora, it seems that OpenAI is grappling with the concerns that come along with AI video generation. Some OpenAI researchers publicly wrestled with questions about the company’s first AI-powered social media platform in the days after its launch, and how such a product fits into the nonprofit’s mission. OpenAI CEO Sam Altman said the company felt “ trepidation ” about Sora on launch day.\nNick Turley, the head of ChatGPT, told me earlier this month that the best way to teach the world about a new technology is by putting it out in the world. He said that’s what the company learned with ChatGPT, and that’s what OpenAI is finding with Sora, too. It seems the company is learning something about how to distribute this technology, as well."}
{"url": "https://techcrunch.com/2025/10/16/kayak-launches-an-ai-mode-for-travel-questions-search-and-bookings/", "title": "Kayak launches an ‘AI Mode’ for travel questions, search, and bookings", "date": "2025-10-16", "content": "Travel search engine Kayak will now allow users to research trips ahead of booking using AI. The company this week launched an “AI Mode” feature that lets users ask travel-related questions as well as compare and book flights, hotels, and cars, through an AI chatbot integrated on the company’s website.\nThe feature is currently available across both desktop and mobile web, and takes advantage of Kayak’s integration with ChatGPT to deliver contextual results.\nThe rollout follows the company’s April launch of Kayak.ai, built as a testing ground for working with AI technology. That site also combined Kayak’s data and tools with OpenAI’s technology, letting its tech team try out AI features ahead of bringing them over to Kayak.com\nEssentially, the AI Mode feature offers the same functionality as the Kayak.ai website but is now built directly into Kayak’s website. The company suggests users could ask the chatbot for travel ideas, like locations to fly to for under a certain price point, the best deals to a preferred destination, comparing hotel amenities, finding nonstop flights and rental car options, and more.\nPlus, users can ask the AI more open-ended questions, like “I want to party for NYE — where should I go?” to get recommendations without having specific destinations in mind. Or they could learn when the best time to fly somewhere would be, based on ticket prices. (Kayak has shared other AI prompt ideas on its own blog.)\nThe feature could be useful in helping consumers in the earlier stages of travel planning, when they’re just exploring ideas. However, it remains to be seen if AI users readily convert to paying customers using these methods.\nAI Mode is initially available in English in the United States but will expand to other countries and languages later in the month. The company also plans to roll out the feature to more platforms and add support for voice-based requests “soon.”\nTravel is an area that’s being explored by AI providers and travel companies alike, as online booking can be a frustrating and tedious experience for consumers as it stands today. To test consumer demand for AI solutions, OpenAI recently announced deals with travel companies like Expedia and Booking.com (the latter is also owned by Kayak’s parent company, Booking Holdings ). As a result, those services can now operate as apps inside ChatGPT.\nBy comparison, Kayak’s decision to run the AI chatbot on its own site could provide the company with more direct access to consumer insights about the AI’s use."}
{"url": "https://techcrunch.com/2025/10/16/why-ai-startups-are-taking-data-into-their-own-hands/", "title": "Why AI startups are taking data into their own hands", "date": "2025-10-16", "content": "For one week this summer, Taylor and her roommate wore GoPro cameras strapped to their foreheads as they painted, sculpted, and did household chores. They were training an AI vision model, carefully syncing their footage so the system could get multiple angles on the same behavior. It was difficult work in many ways, but they were well paid for it — and it allowed Taylor to spend most of her day making art.\n“We woke up, did our regular routine, and then strapped the cameras on our head and synced the times together,” she told me. “Then we would make our breakfast and clean the dishes. Then we’d go our separate ways and work on art.”\nThey were hired to produce five hours of synced footage each day, but Taylor quickly learned she needed to allot seven hours a day for the work, to leave enough time for breaks and physical recovery.\n“It would give you headaches,” she said. “You take it off and there’s just a red square on your forehead.”\nTaylor, who asked not to give her last name, was working as a data freelancer for Turing, an AI company that connected her to TechCrunch. Turing’s goal wasn’t to teach the AI how to make oil paintings, but to gain more abstract skills around sequential problem-solving and visual reasoning. Unlike a large language model, Turing’s vision model would be trained entirely on video — and most of it would be collected directly by Turing.\nAlongside artists like Taylor, Turing is contracting with chefs, construction workers, and electricians — anyone who works with their hands. Turing Chief AGI Officer Sudarshan Sivaraman told TechCrunch the manual collection is the only way to get a varied enough dataset.\n“We are doing it for so many different kinds of blue-collar work, so that we have a diversity of data in the pre-training phase,” Sivaraman told TechCrunch. “After we capture all this information, the models will be able to understand how a certain task is performed.”\nTuring’s work on vision models is part of a growing shift in how AI companies deal with data. Where training sets were once scraped freely from the web or collected from low-paid annotators, companies are now paying top dollar for carefully curated data.\nWith the raw power of AI already established, companies are looking to proprietary training data as a competitive advantage. And instead of farming out the task to contractors, they’re often taking on the work themselves.\nThe email company Fyxer , which uses AI models to sort emails and draft replies, is one example.\nAfter some early experiments, founder Richard Hollingsworth discovered the best approach was to use an array of small models with tightly focused training data. Unlike Turing, Fyxer is building off someone else’s foundation model — but the underlying insight is the same.\n“We realized that the quality of the data, not the quantity, is the thing that really defines the performance,” Hollingsworth told me.\nIn practical terms, that meant some unconventional personnel choices. In the early days, Fyxer engineers and managers were sometimes outnumbered four to one by the executive assistants needed to train the model, Hollingsworth says.\n“We used a lot of experienced executive assistants, because we needed to train on the fundamentals of whether an email should be responded to,” he told TechCrunch. “It’s a very people-oriented problem. Finding great people is very hard.”\nThe pace of data collection never slowed down, but over time Hollingsworth became more precious about the datasets, preferring smaller sets of more tightly curated datasets when it came time for post-training. As he puts it, “the quality of the data, not the quantity, is the thing that really defines the performance.”\nThat’s particularly true when synthetic data is used, magnifying both the scope of possible training scenarios and the impact of any flaws in the original dataset. On the vision side, Turing estimates that 75% to 80% of its data is synthetic, extrapolated from the original GoPro videos. But that makes it even more important to keep the original dataset as high-quality as possible.\n“If the pre-training data itself is not of good quality, then whatever you do with synthetic data is also not going to be of good quality,” Sivaraman says.\nBeyond concerns of quality, there’s a powerful competitive logic behind keeping data collection in-house. For Fyxer, the hard work of data collection is one of the best moats the company has against competition. As Hollingsworth sees it, anyone can build an open source model into their product — but not everyone can find expert annotators to train it into a workable product.\n“We believe that the best way to do it is through data,” he told TechCrunch, “through building custom models, through high-quality, human-led data training.”\nCorrection: A previous version of this piece referred to Turing by an incorrect name. TechCrunch regrets the error."}
{"url": "https://techcrunch.com/2025/10/16/the-real-reason-google-deepmind-is-working-with-a-fusion-energy-startup/", "title": "The real reason Google DeepMind is working with a fusion energy startup", "date": "2025-10-16", "content": "Energy startup Commonwealth Fusion Systems (CFS) said Thursday it’s working with Google’s DeepMind division to fine tune — and even improve — the operation of its forthcoming Sparc reactor using AI.\nThe companies’ plan will simulate the plasma that will burn inside CFS’s reactor using specialized DeepMind software known as Torax. They also plan on pairing Torax with AI models to help CFS figure out how best to achieve fusion power.\nFusion power promises to deliver massive amounts of electricity with zero emissions from a near limitless source of fuel: water. AI-related companies have been bullish on fusion startups as a source of electricity to power energy-hungry data centers. Google appears to be eyeing them as potential customer as well.\nThis isn’t Google’s first foray into nuclear fusion. The tech company has worked with another fusion startup, TAE Technologies, to use AI to study how plasma behaves inside TAE’s fusion machine.\nThere’s a reason Google keeps coming back to the problem: AI might be uniquely suited to making fusion power possible.\nOne of the biggest challenges facing fusion startups is keeping the plasma inside a reactor hot enough for long enough. Unlike nuclear fission reactions, which are self-sustaining, fusion reactions are difficult to maintain outside of stars like the sun. Without that sort of mass and gravity, the plasma is constantly in danger of diffusing and snuffing itself out.\nIn CFS’s reactors, powerful magnets substitute for gravity to help corral the plasma, but they’re not perfect. Reactor operators have to develop control software that can enable the device to continuously react to changing plasma conditions.\nProblem is, there are almost too many knobs to turn, certainly more than a human is capable of. That’s the sort of problem that AI excels at. Experts have cited AI as one of the key technologies that has enabled the industry’s remarkable advances over the past several years.\nCFS is currently building Sparc, its demonstration reactor, in a suburb outside Boston. The device is about two-thirds completed , and when finished later in 2026, the startup is predicting that it will be the first fusion device capable of producing more power than the fusion reaction consumes.\nGoogle said Torax can be used with reinforcement learning or evolutionary search models to find the “most efficient and robust paths to generating net energy.” The two companies are also exploring whether AI can be used to control the reactor’s operation.\nIn August, Google participated in CFS’s $863 million Series B2 round alongside Nvidia. Earlier this year, Google also said it would buy 200 megawatts of electricity from CFS’s first commercial power plant, Arc, which is planned to be built outside Richmond, Virginia . The tech company is also an investor in CFS competitor TAE Technologies."}
{"url": "https://techcrunch.com/2025/10/16/apple-loses-another-ai-exec-to-meta/", "title": "Apple loses another AI exec to Meta", "date": "2025-10-16", "content": "Ke Yang, the Apple executive leading the iPhone maker’s efforts to build AI-driven web search, is heading to Meta, according to a Bloomberg report .\nYang’s departure marks the latest in a string of exits from Apple’s AI unit, putting the company into jeopardy in the lead-up to a much-anticipated Siri revamp scheduled for March. Ruoming Pang, Apple’s former head of AI models, left for Meta earlier this year . Roughly a dozen team members on Apple’s AIML (AI and machine learning) team also left the company. Several members joined Meta’s new Superintelligence Labs .\nA few weeks ago, Yang began overseeing the Answers, Knowledge, and Information (AKI) team, which is tasked with improving Siri’s functionality by allowing it to pull information from the web so Apple can better compete with rivals in the AI search market, like OpenAI, Perplexity, and Google. The new Siri also promises to be able to tap into personal data for more complex tasks.\nBloomberg reports that Apple’s remaining team members expect more AI team members to jump ship in the coming months.\nTechCrunch has reached out to Apple and Meta for comment."}
{"url": "https://techcrunch.com/2025/10/16/pinterest-adds-controls-to-let-you-limit-the-amount-of-ai-slop-in-your-feed/", "title": "Pinterest adds controls to let you  limit the amount of ‘AI slop’ in your feed", "date": "2025-10-16", "content": "Following backlash over an increase in “AI slop” taking over users’ feeds, Pinterest on Thursday added new tools that let users limit how much AI-generated content they see on the platform.\nUsers can now personalize their feeds to restrict generative AI imagery in select categories, and the company said it will make its existing GenAI content labels more noticeable in the days to come.\nThe site, widely used to browse and bookmark inspirational content and potential purchases, has come under fire from users who have complained about the massive uptick in GenAI content. The media has also been documenting the problem , while openly wondering if AI has already ruined Pinterest or if it could still be fixed.\nThe problem, if left unresolved, could destroy Pinterest’s reputation and, ultimately, its bottom line.\nAI slop is potentially a tough nut to crack as more of the web fills up with AI-generated content and the quality of the AI content improves, making it less obvious to spot. Citing academic literature , Pinterest notes that GenAI content now makes up 57% of all online material.\nTo address the issue, Pinterest earlier this year introduced “AI modified” labels that would appear on images whose metadata indicated AI generation, or if Pinterest’s own systems detected that the content was AI-generated. At the time, the company said it would “soon” introduce consumer-facing tools that would let users choose to see less AI content.\nThose tools have now arrived and will be available in the app’s “Settings” menu, under “Refine your recommendations.”\nHere, users will be able to configure whether they’d like to see less GenAI content in certain categories that are prone to AI-generated imagery, like beauty, art, fashion, and home décor. Pinterest said it will introduce more categories in the future, based on user feedback. Plus, if users want to modify their settings, they can do so at any time.\nIn addition, users can send feedback about AI imagery as they browse the site. If they see a Pin that’s not appealing because of its generative AI nature, they can tap the three-dot overflow menu and select a category to refine their preferences.\nThe new controls are launching first on the website and Android and will roll out to iOS users over the weeks ahead, Pinterest said.\n“Our community is at the heart of everything we do,” said Matt Madrigal, Pinterest’s chief technology officer, in a statement about the launch. “With our new GenAI controls, we’re empowering people to personalize their Pinterest experience more than ever — striking the right balance between human creativity and AI innovation, and ensuring every feed truly reflects what inspires them most.”"}
{"url": "https://techcrunch.com/2025/10/16/final-2-days-to-claim-your-exhibit-table-at-techcrunch-disrupt-2025/", "title": "Final 2 days to claim your exhibit table at TechCrunch Disrupt 2025", "date": "2025-10-16", "content": "TechCrunch Disrupt 2025 takes place October 27-29 in San Francisco’s Moscone West, and exhibit space is nearly full. With less than two days left to secure your table, now is the time to step in before a competitor takes your place.\nShowcase your brand to 10,000 founders, investors, media, and tech leaders on the hunt for the next breakthrough. Build a year’s worth of connections in just three days. Generate hot leads. Capture investor attention.\nIf your work is making waves, your vision excites, or your team is ready to grow, this is your moment to shine at one of the most anticipated tech conferences of the year.\nEvery conversation. Every connection. Every moment counts at Disrupt. Lock in your table by tomorrow, October 17, before a competitor takes your spotlight. Book now ."}
{"url": "https://techcrunch.com/2025/10/16/general-intuition-lands-134m-seed-to-teach-agents-spatial-reasoning-using-video-game-clips/", "title": "General Intuition lands $134M seed to teach agents spatial reasoning using video game clips", "date": "2025-10-16", "content": "Medal, a platform for uploading and sharing video game clips, has spun out a new frontier AI research lab that’s using its trove of gaming videos to train and build foundation models and AI agents that can understand how objects and entities move through space and time — a concept known as spatial-temporal reasoning.\nCalled General Intuition, the startup is betting that Medal’s dataset — which consists of 2 billion videos per year from 10 million monthly active users across tens of thousands of games — surpasses alternatives like Twitch or YouTube for training agents.\n“When you play video games, you essentially transfer your perception, usually through a first-person view of the camera, to different environments,” Pim de Witte, CEO of Medal and General Intuition, told TechCrunch.  He noted that gamers who upload clips tend to post very negative or positive examples, which serve as really useful edge cases for training. “You get this selection bias towards precisely the kind of data you actually want to use for training work.”\nThis data moat is what reportedly attracted the attention of OpenAI, which late last year attempted to acquire Medal for $500 million, per The Information . (Neither OpenAI nor General Intuition would comment on the report.)\nIt’s also what has led to General Intuition’s raising a whopping $133.7 million in seed funding, led by Khosla Ventures and General Catalyst with participation from Raine.\nThe startup intends to use the funds to grow its team of researchers and engineers focused on training a general agent that can interact with the world around it, aiming for initial applications in gaming, and search-and-rescue drones.\nDe Witte says the founding team has already made strides: General Intuition’s model can understand environments it wasn’t trained on and correctly predict actions within them. It’s able to do this purely through visual input; agents only see what a human player would see, and they move through space by following controller inputs. This approach, the company says, can transfer naturally to physical systems like robotic arms, drones, and autonomous vehicles, which are often manipulated by humans using video game controllers.\nGeneral Intuition’s next milestone is twofold: generating new simulated worlds for training other agents and autonomously navigating entirely unfamiliar physical environments.\nThat technical approach is shaping how the company plans to commercialize its technology and sets it apart from competitors building world models.\nWhile General Intuition is also building world models on which to train its agents, such models aren’t the product. Unlike other world model makers like DeepMind and World Labs, which are selling their world models Genie and Marble , respectively, for training agents and content creation, General Intuition is focusing on other use cases to avoid copyright issues.\n“Our goal is not to produce models that compete with game developers,” de Witte said.\nInstead, the startup’s gaming applications center around creating bots and non-player characters that can surpass traditional “deterministic bots,” or preprogrammed characters that produce the same output every time.\n“[The bots] can scale to any level of difficulty,” Moritz Baier-Lentz, a founding member of General Intuition and partner at Lightspeed Ventures, told TechCrunch. “It’s not compelling to create a god bot that beats everyone, but if you can scale gradually and fill in liquidity for any player situation so that their win rate is always around 50%, that will maximize their engagement and retention.”\nDe Witte also has a background in humanitarian work, which informs the startup’s focus on powering search-and-rescue drones, which sometimes have to navigate unfamiliar environments and extract information without GPS.\nUltimately, de Witte and Baier-Lentz see General Intuition’s core functionality — spatial-temporal reasoning — as a crucial piece in the race toward artificial general intelligence (AGI). While major AI labs focus on building ever more powerful large language models, General Intuition believes true AGI requires something LLMs fundamentally lack.\n“As humans, we create text to describe what’s going on in our world, but in doing so, you lose a lot of information,” de Witte said. “You lose general intuition around spatial-temporal reasoning.”"}
{"url": "https://techcrunch.com/2025/10/16/only-48-hours-left-to-save-before-the-techcrunch-disrupt-2025-flash-sale-ends/", "title": "Last 48 hours to save before TechCrunch Disrupt 2025 flash sale ends", "date": "2025-10-16", "content": "Ticktock! TechCrunch Disrupt 2025 hits San Francisco’s Moscone West on October 27–29, and this is your final chance to lock in major savings before doors open. Ticket prices increase after tomorrow, October 17 at 11:59 p.m. PT, so don’t wait. Save up to $624 on your pass right now, and if you’re coming with your team, you can save 15% to 30% on group passes .\nDisrupt is where the startup world converges. Join 10,000 founders, VCs, and tech innovators to hear 250+ industry leaders across 200+ sessions, explore startup breakthroughs from 300+ showcasing startups, and experience the intensity of Startup Battlefield 200 — the iconic pitch competition that launched companies like Dropbox, Cloudflare, and Vurb.\nThis year’s speaker lineup features impressive names sharing insights on the future of AI, funding, space, scaling breakthrough ideas, and more, including:\nCheck out our full list of speakers here .\nDisrupt is designed for anyone launching, operating, innovating, investing, and more. Choose the ticket that best helps you reach your goals.\nFor founders: Your pass opens doors to help you build invaluable connections with investors, potential partners, and mentors — plus exclusive access to startup how-to sessions designed to help you raise smarter and scale faster. Explore founder benefits →\nFor investors: Disrupt gives you front-row access to tomorrow’s most promising startups, curated deal flow, and private networking opportunities designed to spark your next big investment. See investor perks →\nDon’t pay more for the same seat! Secure your pass here before the clock runs out tomorrow, October 17 at 11:59 p.m. PT and join the leaders shaping what’s next in tech. Get passes for your team with up to 30% discount here."}
{"url": "https://techcrunch.com/2025/10/16/spotify-partners-with-record-labels-to-create-artist-first-ai-music-products/", "title": "Spotify partners with record labels to create ‘artist-first’ AI music products", "date": "2025-10-16", "content": "Spotify on Thursday announced a series of deals with major record labels to develop new AI products designed to ensure fair compensation and center artists and songwriters in the experience. In partnership with Sony, Universal, Warner, and Merlin, the streamer said it would develop “responsible AI” products that not only respect copyright, but also allow the artists to choose whether they want to allow the use of AI tools.\nThe company didn’t delve into the specifics of how the new tools would operate, but the company already offers generative AI experiences for users, including with its AI DJ that plays a personalized selection of songs and others that allow users to request playlists using AI prompts, for instance.\nSpotify was recently criticized for allowing an AI-generated band’s music to go viral on its service, raising questions about whether the future of music would push human artistry to the side.\nLast month, the company revamped its AI policy to cut down on spam, particularly users who upload AI content at mass scale, create duplicates, and manipulate the search and recommendations systems. Spotify also said it would adopt the music labeling system DDEX to label when AI was used as part of the music creation process.\nThe upcoming GenAI features follow that promise by allowing artists to opt in to using AI tools if they choose. In all likelihood, the upcoming system would allow artists to identify when their music is used in AI-generated tracks and collect some sort of payment. Spotify notes the system will expand beyond artists to include other rights holders and distributors over time.\n“Some voices in the tech industry believe copyright should be abolished. We don’t. Musicians’ rights matter. Copyright is essential,” Spotify shared in its announcement. “If the music industry doesn’t lead in this moment, AI-powered innovation will happen elsewhere, without rights, consent, or compensation. Together with rights holders, artists, and songwriters, we are making significant investments in AI research and product development,” it read.\nIn addition, Spotify said it has begun building a generative AI research lab and product team focused on building out new technologies that reflect its principles that artists should be able to choose if and how they participate in the AI music ecosystem. It says work on the first products has already started, and more tools will be on the way."}
{"url": "https://techcrunch.com/2025/10/16/jack-jill-raises-20-million-to-bring-conversational-ai-to-job-hunting/", "title": "Jack & Jill raises $20M to bring conversational AI to job-hunting", "date": "2025-10-16", "content": "Between infinitely scrolling job boards and the puzzling rise of fake applicants using AI to apply en masse, job-searching has quickly become one of the most bewildering experiences the internet has to offer. Listings are posted and reposted across different platforms as applications go unanswered, creating a spam-like flood of activity on both sides.\n“If you put a job on LinkedIn, you might get 1,000 people applying for that job within the first six hours,” says Matt Wilson, a London-based serial entrepreneur. “Some companies don’t even review the applicants that apply for those jobs, because the signal to noise ratio is very, very low.”\nWilson’s new solution is Jack & Jill , a new platform that uses conversational AI to reinvent the recruitment process from the ground up. The company announced $20 million in seed funding today, led by EU investor Creandum, but it’s hardly been in stealth. Service is already live in London, where the outfit has garnered nearly 50,000 users — and Wilson wants to use the influx of cash to fuel a U.S. expansion and take Jack & Jill to a new level.\n“There hasn’t been a major change in how people find jobs since LinkedIn and Indeed came on the scene 20 years ago,” says Wilson. His bet is that, with AI chatbots changing workplaces across the world, now might be the time to shake things up.\nAs you might guess from the name, Jack & Jill is a two-part platform. The “Jack” side of the platform handles the applicant side, giving users a 20-minute, AI-powered profile interview before providing them with a select list of roles pulled from online databases. From there, Jack can be used for mock interviews or more involved professional coaching. “Jill” works with employers, building a profile of a particular role and elevating candidates that match its requirements. Like LinkedIn, part of the goal is for both workers and hiring managers to keep an active presence on their respective apps, letting the app pull players off the sidelines as needed. The service takes a standard commission from any successful hire, and as the scope of the platform grows, Wilson hopes to make Jack & Jill indispensable for both sides.\nThat might sound like a standard recruiting system with a little AI sprinkled on top, but Wilson thinks conversational chatbots are more important than a simple matching algorithm. By building the process around chatbot interviews, he believes he’s found a scalable alternative to the endless shuffle of listings and résumés, potentially reinventing the basic elements of the contemporary hiring process.\nUsing AI systems to conduct first-round interviews is increasingly common in many parts of the world — particularly in China, where many multinational corporations have used the practice for hiring local roles . But while a surprise interview with an AI hiring manager might seem alienating, Wilson hopes that Jack & Jill’s approach will result in more intelligence applied to job placement overall.\n“I think the way that we are mapped to the companies we work for, and vice versa, is just extremely inefficient,” Wilson says. “There are billions of people out there that could be in better jobs for them. And that’s a mission worth working on.”\nAn earlier version of this piece was published with an erroneous figure in the headline. TechCrunch regrets the error."}
{"url": "https://techcrunch.com/2025/10/15/eightfold-co-founders-raise-35m-for-viven-an-ai-digital-twin-startup-for-querying-unavailable-coworkers/", "title": "Eightfold co-founders raise $35M for Viven, an AI digital twin startup for querying unavailable co-workers", "date": "2025-10-15", "content": "While employees spend much of their day communicating and coordinating amongst themselves on projects, this effort is often undermined by the availability of specific individuals. When a colleague with vital information is away — whether on vacation or in a different time zone — the rest of the team must delay progress until that person responds.\nAshutosh Garg and Varun Kacholia, the co-founders of Eightfold — an AI recruiting startup last valued at $2.1 billion — believe that advances in LLMs and data privacy technologies can help solve some aspects of this costly problem. Earlier this year, they launched Viven , a digital twin startup with a mission to grant employees access to crucial information from teammates even when those colleagues are unavailable.\nOn Wednesday, Viven emerged out of stealth mode with $35 million in seed funding from Khosla Ventures, Foundation Capital, FPV Ventures, and others.\nViven develops a specialized LLM for each employee, effectively creating a digital twin by accessing their internal electronic documents such as email, Slack, and Google Docs. Other employees in the organization can then query that person’s digital twin to get immediate answers related to common projects and shared knowledge.\n“When each and every person has a digital twin, you can just talk to their twin as if you’re talking to that person and get the response,” Ashutosh Garg told TechCrunch.\nOne major hurdle is that people just can’t share everything with anyone who asks. Employees often handle sensitive  information or have personal files they want to keep private from the rest of the team.\nAccording to Ashutosh Garg, Viven’s technology solves that complex problem through a concept known as pairwise context and privacy. This enables the startup’s LLMs to precisely determine what information can be shared and with whom across the organization.\nViven’s LLMs are smart enough to recognize personal context and know what information needs to stay private — like questions related to an employee’s personal life. But perhaps the most important safeguard is that everyone can see the query history of their digital twin, which acts as a deterrent against people asking inappropriate questions.\n“It’s a very hard problem to solve, and until recently, it was unsolvable,” Ashu Garg, a general partner at Foundation Capital told TechCrunch.\nViven is already in use by several enterprise clients, including Genpact and Eightfold. (Co-founders Ashutosh Garg and Varun Kacholia continue to lead Eightfold, splitting their time between that company and running Viven.)\nAs for competition, Ashutosh Garg claims that no other company is tackling digital twins for the enterprise yet.\nHe wasn’t sure that there were no competitors when he first started thinking about the idea. So he called Vinod Khosla to ask about it. The legendary investor assured Ashutosh Garg that nobody is doing this and agreed to invest.\nAshu Garg of Foundation Capital was equally excited about Viven.\n“When Ashutosh came to me and described the product, the big aha for me was: there’s this horizontal problem across all jobs of coordination and communication, which no one is automating,” Ashu Garg told TechCrunch.\nBut just because there are no direct competitors now doesn’t mean that other companies won’t build digital twins for companies in the future. Ashu Garg said that Anthropic, Google’s Gemini, Microsoft Copilot, and OpenAI’s enterprise search products have a personalization component. But, if they do enter this market, Viven hopes its “pairwise” context technology will be its moat."}
{"url": "https://techcrunch.com/2025/10/17/whatsapp-will-curb-the-number-of-messages-people-and-businesses-can-send-without-a-response/", "title": "WhatsApp will curb the number of messages people and businesses can send without a response", "date": "2025-10-17", "content": "WhatsApp is attempting to solve its spam problem by curbing how many messages individual users and businesses can send to unknown people without getting a response.\nWhile the app started as an easy way to send messages to personal contacts, over time, it has become more complex with groups, communities, and business messaging. With those changes, people are getting more messages than ever, and it is hard to catch up with all of them.\nAll messages users and businesses send to others will count against this new per-month limit, unless they get a response. For instance, if you meet someone at a conference and send three messages, that counts against the limit.\nWhatsApp hasn’t said what the limit will be, as it’s testing different limits during this time.\nHowever, when a business or an individual is about to hit the limit, the app will display a warning to those users with a pop-up showing the count, so they can avoid getting blocked from sending messages.\nThe company told TechCrunch that this test will be live in multiple countries in the coming weeks. It also said that average users won’t usually hit the limit, and their messaging experience won’t be affected. Instead, the controls are designed to be effective against people and businesses that blast messages and spam people.\nWhen I look at my WhatsApp inbox, I often find over 50 unread messages. When I try to see who sent them, a number of them are from businesses and unknown people. People around me have had similar experiences, as WhatsApp acts as a multiuse communication tool for a market like India, where I’m based.\nOver the last year, WhatsApp has tried to curb some of this spammy behavior through tools and guardrails. In July 2024, the company started testing limits on how many marketing messages a business can send to people in a month . In 2024, it started floating an option for users to unsubscribe from marketing messages from businesses . This way, they can receive updates or get support from a business without getting spammed.\nEarlier this year, WhatsApp started experimenting by putting a limit on the number of broadcast messages users and businesses can send to others . The company said that it has started expanding this experiment in more than a dozen countries, including India, one of the company’s biggest markets with over 500 million users."}
{"url": "https://techcrunch.com/2025/10/16/amazons-ring-to-partner-with-flock-a-network-of-ai-cameras-used-by-ice-feds-and-police/", "title": "Amazon’s Ring to partner with Flock, a network of AI cameras used by ICE, feds, and police", "date": "2025-10-16", "content": "Amazon’s surveillance camera maker Ring announced a partnership on Thursday with Flock , a maker of AI-powered surveillance cameras that share footage with law enforcement.\nNow agencies that use Flock can request that Ring doorbell users share footage to help with “evidence collection and investigative work.”\nFlock cameras work by scanning the license plates and other identifying information about cars they see. Flock’s government and police customers can also make natural language searches of their video footage to find people who match specific descriptions. However, AI-powered technology used by law enforcement has been proven to exacerbate racial biases .\nOn the same day that Ring announced this partnership, 404 Media reported that ICE, the Secret Service, and the Navy had access to Flock’s network of cameras. By partnering with Ring, Flock could potentially access footage from millions more cameras.\nRing has long had a poor track record with keeping customers’ videos safe and secure . In 2023, the FTC ordered the company to pay $5.8 million over claims that employees and contractors had unrestricted access to customers’ videos for years."}
{"url": "https://techcrunch.com/2025/10/14/openai-has-five-years-to-turn-13-billion-into-1-trillion/", "title": "OpenAI has five years to turn $13 billion into $1 trillion", "date": "2025-10-14", "content": "OpenAI is printing money right now. The company is pulling in roughly $13 billion in annual revenue, with 70% coming from everyday people paying $20 a month to chat with an AI, according to the Financial Times . That’s pretty wild when you consider ChatGPT has 800 million regular users, but only 5% are actually paying subscribers.\nRaking in billions though it may be, OpenAI has also committed to spending over $1 trillion over the next decade (yes, trillion). The company has recently locked in deals for more than 26 gigawatts of computing capacity from Oracle, Nvidia, AMD, and Broadcom — infrastructure that’ll cost vastly more than what’s coming in.\nTo bridge this gap, OpenAI is getting creative, reports the FT. A five-year plan includes exploring government contracts, shopping tools, video services, consumer hardware, and even becoming a computing supplier itself through its Stargate data center project.\nA growing number of businesses need the math to work out. Some of America’s most valuable companies are now leaning on OpenAI to fulfill major contracts, notes the FT; if OpenAI falters (no pressure!), it could potentially destabilize the broader U.S. market."}
{"url": "https://techcrunch.com/2025/10/14/sam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users/", "title": "Sam Altman says ChatGPT will soon allow erotica for adult users", "date": "2025-10-14", "content": "OpenAI CEO Sam Altman announced in a post on X Tuesday the company will soon relax some of ChatGPT’s safety restrictions, allowing users to make the chatbot’s responses friendlier or more “human-like,” and for “verified adults” to engage in erotic conversations.\n“We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right,” said Altman. “In December, as we roll out age-gating more fully and as part of our ‘treat adult users like adults’ principle, we will allow even more, like erotica for verified adults.”\nWe made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right. Now that we have…\nThe announcement is a notable pivot from OpenAI’s months-long effort to address the concerning relationships that some mentally unstable users have developed with ChatGPT. Altman seems to declare an early victory over these problems, claiming OpenAI has “been able to mitigate the serious mental health issues” around ChatGPT. However, the company has provided little to no evidence for this, and is now plowing ahead with plans for ChatGPT to engage in sexual chats with users.\nSeveral concerning stories emerged this summer around ChatGPT, specifically its GPT-4o model, suggesting the AI chatbot could lead vulnerable users down delusional rabbit holes. In one case, ChatGPT seemed to convince a man he was a math genius who needed to save the world. In another, the parents of a teenager sued OpenAI , alleging ChatGPT encouraged their son’s suicidal ideations in the weeks leading up to his death.\nIn response, OpenAI released a series of safety features to address AI sycophancy: the tendency for an AI chatbot to hook users by agreeing with whatever they say, even negative behaviors.\nOpenAI launched GPT-5 in August, a new AI model that exhibits lower rates of sycophancy and features a router that can identify concerning user behavior. A month later, OpenAI launched safety features for minors, including an age prediction system and a way for parents to control their teen’s ChatGPT account. OpenAI announced Tuesday the formation of an expert council of mental health professionals to advise the company on well-being and AI.\nJust a few months after these concerning stories emerged, OpenAI seems to think ChatGPT’s problems around vulnerable users are under control. It’s unclear whether users are still falling down delusional rabbit holes with GPT-5. And while GPT-4o is no longer the default in ChatGPT, the AI model is still available today and being used by thousands of people.\nThe introduction of erotica in ChatGPT is unchartered territory for OpenAI and raises broader concerns around how vulnerable users will interact with the new features. While Altman insists OpenAI isn’t “usage-maxxing” or optimizing for engagement, making ChatGPT more erotic could certainly draw users in.\nAllowing chatbots to engage in romantic or erotic role play has been an effective engagement strategy for other AI chatbot providers, such as Character.AI. The company has gained tens of millions of users, many of whom use its chatbots at a high rate. Character.AI said in 2023 that users spent an average of two hours a day talking to its chatbots. The company is also facing a lawsuit around how it handles vulnerable users.\nOpenAI is under pressure to grow its user base. While ChatGPT is already used by 800 million weekly active users, OpenAI is racing against Google and Meta to build mass-adopted AI-powered consumer products. The company has also raised billions of dollars for a historic infrastructure buildout, an investment OpenAI eventually needs to pay back.\nWhile adults are surely having romantic relationships with AI chatbots , it’s also quite popular for minors. A new report from the Center for Democracy and Technology found that 19% of high school students have either had a romantic relationship with an AI chatbot, or know a friend who has.\nAltman says OpenAI will soon allow erotica for “verified adults.” An OpenAI spokesperson tells TechCrunch the company will rely on the age-prediction system it’s building to ensure that ChatGPT’s erotic features are only available to adult users.\nAs Altman previously wrote in a blog post, if OpenAI’s age-prediction system incorrectly marks an adult as a minor, ChatGPT users may have to upload a picture of their government-issued ID into ChatGPT to correct it. Altman writes that, though this is a privacy compromise, the company believes it’s a “worthy tradeoff.”\nIt is unclear whether OpenAI will extend erotica to its AI voice, image, and video generation tools.\nAltman claims that OpenAI is also making ChatGPT friendlier and erotic because of the company’s “treat adult users like adults” principle. Over the last year, OpenAI has shifted towards a more lenient content moderation strategy for ChatGPT, allowing the chatbot to be more permissive and offer less refusals. In February, OpenAI pledged to represent more political viewpoints in ChatGPT, and in March, the company updated ChatGPT to allow AI-generated images of hate symbols .\nThese policies seem to be an attempt to make ChatGPT’s response more popular with a wide variety of users. However, vulnerable ChatGPT users may benefit from safeguards that limit what a chatbot can engage with. As OpenAI races towards a billion weekly active users, the tension between growth and protecting vulnerable users may only grow.\nUpdate 10/14/25 at 4:40pm PT: This story has been updated to include comment from OpenAI."}
{"url": "https://techcrunch.com/2025/10/14/googles-gemini-can-now-help-you-schedule-google-calendar-meetings/", "title": "Google’s Gemini can now help you schedule Google Calendar meetings", "date": "2025-10-14", "content": "Google is launching a new tool that uses AI to make it easier for Gmail users with Google Calendar to schedule their meetings. On Tuesday, the company launched a Gemini-powered “Help me schedule” feature that will surface ideal meeting times based on calendar availability and then display them to the person you’re emailing to set up a meeting.\nThe company notes that the feature is designed to work for one-on-one meetings, not those with multiple contacts or group meetings.\nThe launch of the new feature comes amid a flurry of Google Workspace announcements that focus on infusing AI more deeply into users’ everyday tools. This includes the introduction of Google’s latest image editing model, Nano Banana, and Gemini features in Google Slides; tools to share custom AI assistants called Gems with other team members; new formats in NotebookLM; improved AI video tools in Google Vids; and more.\nTo use the meeting scheduling option, you’ll click the new “Help me schedule” button that appears below your email compose screen in Gmail. This will display a series of timeslots where you have open availability. You can click an edit button to change or remove some of the options, then insert them into your email and send it to the recipient as usual. When the recipient picks a time that works for them, the calendar invite automatically appears on both people’s calendars.\nWhile there are several meeting assistants and automated scheduling tools already on the market, like those from Calendly, Doodle, Zoom, HubSpot, and others, Google notes that its tool uses Gemini’s AI to use the email’s context when it makes its meeting suggestions. For instance, if someone writes in the email that they’d like to book a 30-minute time slot next, then the meeting assistant will only suggest half-hour slots before the end of next week that fit your schedule.\nGoogle previously offered an appointment scheduling feature in Google Calendar , but it wasn’t integrated with Gmail, nor did it use AI.\nSeparately, Google updated another Workplace feature on Tuesday, noting that Google Keep reminders will now automatically be saved to Google Tasks."}
{"url": "https://techcrunch.com/2025/10/13/california-becomes-first-state-to-regulate-ai-companion-chatbots/", "title": "California becomes first state to regulate AI companion chatbots", "date": "2025-10-13", "content": "California Governor Gavin Newsom signed a landmark bill on Monday that regulates AI companion chatbots , making it the first state in the nation to require AI chatbot operators to implement safety protocols for AI companions.\nThe law, SB 243, is designed to protect children and vulnerable users from some of the harms associated with AI companion chatbot use. It holds companies — from the big labs like Meta and OpenAI to more focused companion startups like Character AI and Replika — legally accountable if their chatbots fail to meet the law’s standards.\nSB 243 was introduced in January by state senators Steve Padilla and Josh Becker, and gained momentum after the death of teenager Adam Raine , who died by suicide after a long series of suicidal conversations with OpenAI’s ChatGPT. The legislation also responds to leaked internal documents that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children. More recently, a Colorado family has filed suit against role-playing startup Character AI after their 13-year-old daughter took her own life following a series of problematic and sexualized conversations with the company’s chatbots.\n“Emerging technology like chatbots and social media can inspire, educate, and connect — but without real guardrails, technology can also exploit, mislead, and endanger our kids,” Newsom said in a statement. “We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability. We can continue to lead in AI and technology, but we must do it responsibly — protecting our children every step of the way. Our children’s safety is not for sale.”\nSB 243 will go into effect January 1, 2026, and requires companies to implement certain features such as age verification, and warnings regarding social media and companion chatbots. The law also implements stronger penalties for those who profit from illegal deepfakes, including up to $250,000 per offense. Companies must also establish protocols to address suicide and self-harm, which will be shared with the state’s Department of Public Health alongside statistics on how the service provided users with crisis center prevention notifications.\nPer the bill’s language, platforms must also make it clear that any interactions are artificially generated, and chatbots must not represent themselves as healthcare professionals. Companies are required to offer break reminders to minors and prevent them from viewing sexually explicit images generated by the chatbot.\nSome companies have already begun to implement some safeguards aimed at children. For example, OpenAI recently began rolling out parental controls , content protections, and a self-harm detection system for children using ChatGPT. Replika, which is designed for adults over the age of 18, told TechCrunch it dedicates “significant resources” to safety through content-filtering systems and guardrails that direct users to trusted crisis resources, and is committed to complying with current regulations.\nCharacter AI has said that its chatbot includes a disclaimer that all chats are AI-generated and fictionalized. A Character AI spokesperson told TechCrunch that the company “welcomes working with regulators and lawmakers as they develop regulations and legislation for this emerging space, and will comply with laws, including SB 243.”\nSenator Padilla told TechCrunch the bill was “a step in the right direction” toward putting guardrails in place on “an incredibly powerful technology.”\n“We have to move quickly to not miss windows of opportunity before they disappear,” Padilla said. “I hope that other states will see the risk. I think many do. I think this is a conversation happening all over the country, and I hope people will take action. Certainly the federal government has not, and I think we have an obligation here to protect the most vulnerable people among us.”\nSB 243 is the second significant AI regulation to come out of California in recent weeks. On September 29, Governor Newsom signed SB 53 into law, establishing new transparency requirements on large AI companies. The bill mandates that large AI labs, like OpenAI, Anthropic, Meta, and Google DeepMind, be transparent about safety protocols. It also ensures whistleblower protections for employees at those companies.\nOther states, like Illinois, Nevada, and Utah, have passed laws to restrict or fully ban the use of AI chatbots as a substitute for licensed mental health care.\nTechCrunch has reached out to Meta and OpenAI for comment.\nThis article has been updated with comments from Senator Padilla, Character AI, and Replika."}
{"url": "https://techcrunch.com/2025/10/14/openai-and-broadcom-partner-on-ai-hardware/", "title": "OpenAI and Broadcom partner on AI hardware", "date": "2025-10-14", "content": "OpenAI has landed a new hardware partner.\nThe AI research lab announced Monday it formed a partnership with semiconductor company Broadcom for 10 gigawatts’ worth of custom AI accelerator hardware. These AI accelerator racks will be deployed to OpenAI data centers and partner data centers starting in 2026 and running through 2029.\n“By designing its own chips and systems, OpenAI can embed what it’s learned from developing frontier models and products directly into the hardware, unlocking new levels of capability and intelligence,” the company said in a press release.\nWhile terms of the deal were not disclosed, the Financial Times estimated it could cost OpenAI an estimated $350 billion to $500 billion .\nThis is just the latest infrastructure deal for OpenAI in recent weeks.\nLast week, OpenAI announced it was purchasing an additional six gigawatts of chips from AMD in a deal worth tens of billions of dollars. In September, Nvidia announced it was investing $100 billion into OpenAI alongside a letter of intent for OpenAI to tap 10 gigawatts’ worth of Nvidia hardware.\nOpenAI also allegedly signed a historic $300 billion cloud infrastructure deal with Oracle in September. Neither company has confirmed the deal.\nTechCrunch reached out to OpenAI for more information."}
{"url": "https://techcrunch.com/2025/10/14/google-updates-search-and-discover-with-collapsible-ads-ai-features-and-more/", "title": "Google updates Search and Discover with collapsible ads, AI features, and more", "date": "2025-10-14", "content": "Google is rolling out a series of changes to its Search and Discover pages, the company shared across multiple announcements . The updates will bring new AI-powered features to these key destinations, while also improving navigation and allowing users to collapse ads on Google Search.\nGiven that ads are Google’s primary cash cow, the latter initially seems like a more surprising change. The feature will now allow users browsing Google’s Search results to tap a new button, “Hide sponsored results,” to collapse the ads at the top of the search results page.\nHowever, while this action will remove the ads from displaying on the screen, sponsored results are not going away entirely. Instead, Google notes that the “Sponsored Results” label will remain at the top of the screen as you scroll down. In a way, this makes the ads more prominent as they can follow you down the page, even though they’re collapsed.\nPlus, Google says that the “Sponsored results” header can appear both above and below AI Overviews — the short AI-written summaries that appear at the top of search results to provide quick answers. The “Sponsored results” header for text ads will also appear at the bottom of the page, with all text ads grouped under the label. These can be collapsed with the same “Hide sponsored results” button if you want to focus on organic content.\nGoogle says the new design makes it easier for people to navigate to the top of the page, and it keeps the size of ads the same, with users never seeing more than four text ads in a group.\nThe new “Sponsored” label will show up in other places across Google, too, including Shopping ads, where it will be branded as “Sponsored Products.”\nThe updates will roll out across desktop and mobile.\nThe company is also making other changes across Search and Discover. When searching for sports information, like looking up players or teams, you’ll now see a new “What’s New” button that displays a feed of trending updates and news articles that could help you catch up with the latest. This will roll out to Google Search in the U.S. in the weeks ahead.\nMeanwhile, the Google app’s Discover feed on mobile will introduce an AI-powered feature that also helps you keep up with trending topics you’re interested in. Here, the app will display short previews that you can expand to see more information, plus other links to explore. The company says this feature is designed to help users stay up to date on stories from a variety of publishers, but it also comes at a time when publishers are seeing their search traffic decline due to the shift to AI-provided answers and consumers’ changing media habits.\nThis latter feature is rolling out now to the U.S., South Korea, and India."}
{"url": "https://techcrunch.com/2025/10/14/sheryl-sandberg-backed-flint-wants-to-use-ai-to-autonomously-build-and-update-websites/", "title": "Sheryl Sandberg-backed Flint wants to use AI to autonomously build and update websites", "date": "2025-10-14", "content": "Sometimes, you can only spot what’s wrong when you’ve been part of the process for a while. That was the case for Michelle Lim, who, while running Warp ’s growth marketing efforts through last year, realized that the company wasn’t updating its website quickly enough.\nShe noticed that potential customers were asking ChatGPT and other AI bots all kinds of questions about Warp’s offering, but the information they sought, such as how the product compared with a newer competitor, wasn’t available on the startup’s website. Lim felt that this content gap would become even more critical as next-generation AI agents begin actively crawling the internet to gather intelligence for users.\nIt was clear that Warp needed to add more content, but making and uploading each additional web page was a time-consuming task involving a design agency and multiple people across different departments.\n“Marketers just can’t wait one month for design and development teams to build the page,” she told TechCrunch. “With AI engines, you need to be producing content a lot faster than before to capture your consumer demand.”\nLim, who had long planned to launch a startup, recognized that this was fast becoming a problem that needed solving. So, in March, she co-founded Flint , an AI platform that lets you set up websites that update themselves. Joining her in the effort was Max Levenson, an engineer who previously led simulation and infrastructure teams for autonomous vehicle startup Nuro.\nOn Tuesday, Flint emerged from stealth mode with $5 million in seed funding. The investment was led by Accel, and saw participation from Sheryl Sandberg’s fund, Sandberg Bernthal Venture Partners, and existing backer Neo.\nFlint’s goal is to create websites that continuously optimize themselves, perform their own A/B tests, and dynamically learn from both visitors and market trends, such as a sudden interest in a specific keyword. Flint also aims to generate pages customized to each visitor, much like how Amazon shows you customized product recommendations.\nThat said, Flint’s technology isn’t ready to do all of that just yet. “For now, users still have to tell us what they want to build,” Lim said.\nIn its current form, once the parameters are set, Flint can automatically generate a web page’s design and layout, interactive elements (like tables and buttons), and also offer form tracking and ad optimization. Lim claims the platform can do all of this in “about a day,” though she didn’t give any more details.\n“At this point, customers provide their own copy,” Lim said. She added that while Flint’s content writing functionality is roughly a year away, future versions will give customers the option to have AI write the text.\nEven without that, Lim claims that whipping up a page with all of the necessary components in a day is already a big time-saver for its customers.\nFlint says it doesn’t design sites or “vibe code” anything. For existing websites, its technology analyzes the look and feel to build and deploy fully coded web pages that are consistent with the design.\nThe startup is already working with customers like Cognition, Modal, and Graphite, for whom it has created live pages. You can see Windsurf’s here , Modal’s site , and this is what Graphite’s looks like .\nFlint’s ambition is to help marketers at rapidly growing startups and Fortune 500 companies increase their websites’ visibility and create content.\nThe focus on selling to CMOs is what made Lim so excited to have Sheryl Sandberg join as an investor. “I like to think of her as someone who has influenced the way the internet has monetized over the past decade,” Lim said.\nAccording to Lim, Sandberg instantly understood Flint’s vision. “I was showing her this deck, and I was sharing how, in my personal experience, it took five teams three months to build one A/B test just to increase conversion by 10% on our Google ad,” Lim said. “And then she stopped me, [and] said, ‘Michelle, it was 140 people at Meta who had to do this’.”"}
{"url": "https://techcrunch.com/2025/10/14/spacex-wraps-action-packed-starship-v2-era-as-program-moves-to-v3/", "title": "SpaceX wraps action-packed Starship V2 era as program moves to V3", "date": "2025-10-14", "content": "Farewell, V2: SpaceX on Monday night sent Starship’s current configuration on one last test flight, in a mission that the company says hit all its key goals, moving the program into its next phase.\nThe nearly 400-foot-tall rocket lifted off from Starbase, Texas at 6:23 p.m. local time. The Super Heavy booster, reused from a March test, tried a new landing-burn profile, reigniting 13 engines before throttling down to five, and finally three for the final hover before completing a planned soft splashdown in the Gulf of Mexico roughly seven minutes after liftoff.\nMeanwhile, Starship’s upper stage deployed eight mock Starlink satellite simulators, trialing a new “dynamic banking maneuver” profile that the company aims to use for future return-to-pad attempts at Starbase. The upper stage then splashed down in the Indian Ocean.\nThis marked the final launch of the second-gen Starship and the first-gen Super Heavy variants. As with the previous test flight, engineers also experimented with the heat shield tiles on the upper stage, including selective removals and novel tile variations to gather reentry data.\nSpaceX also duplicated Flight 10’s other key milestones : deploying simulators, and relighting one of Starship’s six Raptor engines on orbit.\nMonday’s test formally started the program’s next phase: flying an upgraded prototype called V3, outfitted for in-orbit docking and propellant-transfer demonstrations, capabilities essential for crafts that aim to reach the moon and Mars. SpaceX says V3 also incorporates structural changes and upgrades to the Raptor engine that are aimed at increasing lifting capacity, though the company did not share specific figures.\n“This next iteration will be used for the first Starship orbital flights, operational payload missions, propellant transfer, and more as we iterate to a fully and rapidly reusable vehicle with service to Earth orbit, the Moon, Mars, and beyond,” the company said.\nIn parallel, SpaceX is upgrading Pad A at Starbase, and shifting launches to Pad B. The company is simultaneously working to build dual Starship launch pads in Cape Canaveral and Kennedy Space Center in Florida.\nStarship is the most powerful rocket ever developed. It’s also the cornerstone of both NASA’s Artemis campaign and SpaceX’s plan to start deploying higher-capacity Starlink satellites.\nActing NASA Administrator Sean Duffy applauded the mission on X, saying it was “another major step toward landing Americans on the Moon’s south pole.”\nSpaceX was awarded more than $4 billion to develop a human-rated variant of Starship, called the Human Landing System, for the Artemis 3 crewed mission currently scheduled for 2027. But meeting that date will require SpaceX to demonstrate increasingly complex milestones first, especially orbital docking and in-orbit propellant transfer."}
