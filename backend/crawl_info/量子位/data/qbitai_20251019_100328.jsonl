{"url": "https://www.qbitai.com/2025/10/343231.html", "title": "量子位「MEET2026智能未来大会」启动！年度榜单征集中", "date": "2025-10-19", "content": "量子位「MEET2026智能未来大会」启动！年度榜单征集中 量子位「MEET2026智能未来大会」启动！年度榜单征集中 西风 2025-10-19 09:22:32 来源： 量子位 西风 西风 西风 西风 2025-10-19 2025-10-19 09:22:32 09:22:32 来源： 量子位 来源： 量子位 量子位 摘要样式 想知道每年顶级的科技大佬们都在哪里分享真知灼见吗？ 想知道每年顶级的科技大佬们都在哪里分享真知灼见吗？ 想知道每年顶级的科技大佬们都在哪里分享真知灼见吗？ 想知道每年顶级的科技大佬们都在哪里分享真知灼见吗？ 量子位的答案是，MEET智能未来大会。 想知道每年顶级的科技大佬们都在哪里分享真知灼见吗？ 量子位的答案是，MEET智能未来大会。 🧑🎓 来看看我们的“朋友圈” 🧑🎓 来看看我们的“朋友圈” 这里既有李开复、张亚勤等产业大咖，也有倪光南、谭建荣、李培根、郑纬民、周志华、唐杰等学术领路人，更汇聚了来自百度、阿里、腾讯、华为、京东、美团、小米、商汤等公司的实干家与新星。 这里既有李开复、张亚勤等产业大咖，也有倪光南、谭建荣、李培根、郑纬民、周志华、唐杰等学术领路人，更汇聚了来自百度、阿里、腾讯、华为、京东、美团、小米、商汤等公司的实干家与新星。 🎙️ 今年我们聊什么？ 🎙️ 今年我们聊什么？ 话题覆盖：人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力… 总之，前沿的我们都聊。 话题覆盖：人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力… 总之，前沿的我们都聊。 🙌 我们想邀请谁？ 🙌 我们想邀请谁？ 当然是你！我们希望汇聚更多技术、产业、投资领域的同行者，一起搞点大事情。 当然是你！我们希望汇聚更多技术、产业、投资领域的同行者，一起搞点大事情。 📢 同期重磅发布 📢 同期重磅发布 #量子位人工智能年度榜单（五大奖项征集中，速来！） 👉 报名链接：https://wj.qq.com/s2/23740133/iso8/ #量子位人工智能年度榜单（五大奖项征集中，速来！） 👉 报名链接：https://wj.qq.com/s2/23740133/iso8/ #量子位2025年度AI十大趋势报告（揭秘十大潜力股，剖析代表案例） #量子位2025年度AI十大趋势报告（揭秘十大潜力股，剖析代表案例） 作为智能科技的年度风向标，MEET大会每年都吸引：上千人现场参与、百万人线上围观、近百家媒体曝光。 作为智能科技的年度风向标，MEET大会每年都吸引：上千人现场参与、百万人线上围观、近百家媒体曝光。 🎯 所以，今年12月，北京见吗？ 🎯 所以，今年12月，北京见吗？ 来 #MEET智能未来大会 共论破局之道，共赴智能新未来！ 来 #MEET智能未来大会 共论破局之道，共赴智能新未来！ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/343152.html", "title": "首创“AI+真人”双保障模式！刚刚，百度健康推出7×24小时「能聊、有料、会管」AI管家", "date": "2025-10-18", "content": "首创“AI+真人”双保障模式！刚刚，百度健康推出7×24小时「能聊、有料、会管」AI管家 首创“AI+真人”双保障模式！刚刚，百度健康推出7×24小时「能聊、有料、会管」AI管家 时令 2025-10-18 15:17:45 来源： 量子位 时令 时令 时令 时令 2025-10-18 2025-10-18 15:17:45 15:17:45 来源： 量子位 来源： 量子位 量子位 摘要样式 36万医生实时参与标注和校验 36万医生实时参与标注和校验 36万医生实时参与标注和校验 一水 发自 凹非寺 量子位 | 公众号 QbitAI 一水 发自 凹非寺 一水 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 你的百度健康，这下把求医问诊的体验用AI革新了。 你的百度健康，这下把求医问诊的体验用AI革新了。 不知道大家是不是这样，日常生活中遇到头疼脑热，不管咋样都会习惯先“百度一下”。而现在，有了AI加持的百度健康，体验确实不一样了。 不知道大家是不是这样，日常生活中遇到头疼脑热，不管咋样都会习惯先“百度一下”。而现在，有了AI加持的百度健康，体验确实不一样了。 就在今天，百度健康首次对外发布主打 「能聊、有料、会管」 的7×24小时AI管家，所有人 打开百度APP搜索「百度健康AI管家」 就能轻松找到。 就在今天，百度健康首次对外发布主打 「能聊、有料、会管」 「能聊、有料、会管」 的7×24小时AI管家，所有人 打开百度APP搜索「百度健康AI管家」 打开百度APP搜索「百度健康AI管家」 就能轻松找到。 看界面你是不是以为它和目前市面上常见的AI健康管家一样，只能提供一些AI问诊服务？ 看界面你是不是以为它和目前市面上常见的AI健康管家一样，只能提供一些AI问诊服务？ 非也，非也。 非也，非也。 简单上手你就会发现，这个AI主打一个“别人有我有，别人没有我更有”。除了提供基于AI的“科普-问诊-就医-健康档案管理”的全链路服务， 其最大特点就是首创了“AI+真人”双认证健康咨询模式 。 简单上手你就会发现，这个AI主打一个“别人有我有，别人没有我更有”。除了提供基于AI的“科普-问诊-就医-健康档案管理”的全链路服务， 其最大特点就是首创了“AI+真人”双认证健康咨询模式 其最大特点就是首创了“AI+真人”双认证健康咨询模式 。 举个例子，大部分AI给完诊疗建议就没有下文了，你也不知道到底对不对。而百度健康AI管家会将AI生成的重要内容提交给真人医生进行二次实时核验，这不仅安全性更高，更重要的是也让用户更放心了。 举个例子，大部分AI给完诊疗建议就没有下文了，你也不知道到底对不对。而百度健康AI管家会将AI生成的重要内容提交给真人医生进行二次实时核验，这不仅安全性更高，更重要的是也让用户更放心了。 当然了，“AI+真人”双认证还只是百度健康尝试让大家放心用AI求医问诊的“冰山一角”，其背后的模型能力、数据实力、应用设计等，无一不在告诉大家—— 当然了，“AI+真人”双认证还只是百度健康尝试让大家放心用AI求医问诊的“冰山一角”，其背后的模型能力、数据实力、应用设计等，无一不在告诉大家—— 国民级应用+AI医疗 ，百度健康这次确实要玩点不一样的了。 国民级应用+AI医疗 国民级应用+AI医疗 ，百度健康这次确实要玩点不一样的了。 能聊、有料、会管，你的百度健康这下真不一样了！ 能聊、有料、会管，你的百度健康这下真不一样了！ 具体怎么个不一样，咱直接一边实测一边唠。 具体怎么个不一样，咱直接一边实测一边唠。 先说这打开方式，以前很多医疗AI都需要单独下一个APP才能用，懒人党一整个劝退。 先说这打开方式，以前很多医疗AI都需要单独下一个APP才能用，懒人党一整个劝退。 而现在，百度健康AI管家直接“住在”百度APP这款国民级应用里，直接捡现成就能用（随手打开百度搜索“百度健康AI管家”即可）。 而现在，百度健康AI管家直接“住在”百度APP这款国民级应用里，直接捡现成就能用（随手打开百度搜索“百度健康AI管家”即可）。 而且从功能上讲，这个AI不再局限于辅助性工具，而更像是一个有始有终的“智能健康伙伴”了——只要与求医问诊相关的（包括买药、预约专家号等），全都能一条龙搞定。 而且从功能上讲，这个AI不再局限于辅助性工具，而更像是一个有始有终的“智能健康伙伴”了——只要与求医问诊相关的（包括买药、预约专家号等），全都能一条龙搞定。 能聊：支持多轮对话，智能识别127种皮肤问题 能聊：支持多轮对话，智能识别127种皮肤问题 就从最基础的智能咨询说起。 就从最基础的智能咨询说起。 它不仅能流畅地进行多轮对话，实现有问必答，更能精准识别用户上传的各种医学图片。 它不仅能流畅地进行多轮对话，实现有问必答，更能精准识别用户上传的各种医学图片。 比如家里老人骨折了，拍完片后想看看到底有多严重（一般还要等结果），直接丢给它测试一下。 比如家里老人骨折了，拍完片后想看看到底有多严重（一般还要等结果），直接丢给它测试一下。 对比医院最终出具的真实结果，百度健康AI管家确实诊断正确，而且给出的手术方案也和人类医生建议的一致。 对比医院最终出具的真实结果，百度健康AI管家确实诊断正确，而且给出的手术方案也和人类医生建议的一致。 看来在健康咨询准确率这一块，这个AI确实有点东西。 看来在健康咨询准确率这一块，这个AI确实有点东西。 据悉，该AI对各类医疗文档，如检验报告、就诊病历以及影像学报告（包括B超单据）等的解读准确率高达98%。 据悉，该AI对各类医疗文档，如检验报告、就诊病历以及影像学报告（包括B超单据）等的解读准确率高达98%。 而且还支持127种皮肤问题（如荨麻疹、湿疹、接触性皮炎等）的初步判断。 而且还支持127种皮肤问题（如荨麻疹、湿疹、接触性皮炎等）的初步判断。 像在咨询皮肤问题时，它会先解读症状，再列出几种可能的皮肤病，并 提供典型的病例图片供用户参考比对 ，帮助其更准确地理解自身状况。（还很贴心地给图片打码了） 像在咨询皮肤问题时，它会先解读症状，再列出几种可能的皮肤病，并 提供典型的病例图片供用户参考比对 提供典型的病例图片供用户参考比对 ，帮助其更准确地理解自身状况。（还很贴心地给图片打码了） 在聊完大致情况后，某些特定场景还能触发“真人医生确认小结”这一彩蛋（类似于找个医生把之前的对话都检查一遍）。 在聊完大致情况后，某些特定场景还能触发“真人医生确认小结”这一彩蛋（类似于找个医生把之前的对话都检查一遍）。 这主要发生在两种情况下： 这主要发生在两种情况下： 专业医疗决策类（专业性强需要医生确认）：包括病因分析、治疗方案、用药指导、复杂指标解读等。 潜在高风险类：当用户描述的症状或情况表明需要立即就医，或涉及自杀、自残、滥用药物等极端行为时。 专业医疗决策类（专业性强需要医生确认）：包括病因分析、治疗方案、用药指导、复杂指标解读等。 专业医疗决策类（专业性强需要医生确认）：包括病因分析、治疗方案、用药指导、复杂指标解读等。 潜在高风险类：当用户描述的症状或情况表明需要立即就医，或涉及自杀、自残、滥用药物等极端行为时。 潜在高风险类：当用户描述的症状或情况表明需要立即就医，或涉及自杀、自残、滥用药物等极端行为时。 这正是百度健康AI管家率先推出的「AI+真人」双认证健康咨询模式的核心所在。该模式通过 “AI预诊+真人确诊” 的协同机制，将AI生成的诊疗小结交由真人医生进行二次实时核验与专业背书，从而为用户提供兼具效率与安全性的双重保障。 这正是百度健康AI管家率先推出的「AI+真人」双认证健康咨询模式的核心所在。该模式通过 “AI预诊+真人确诊” “AI预诊+真人确诊” 的协同机制，将AI生成的诊疗小结交由真人医生进行二次实时核验与专业背书，从而为用户提供兼具效率与安全性的双重保障。 有一说一，能链接到真人医生，这也说明百度健康AI管家确实“有料”，而且细究之下其“有料”表现还不止于此—— 有一说一，能链接到真人医生，这也说明百度健康AI管家确实“有料”，而且细究之下其“有料”表现还不止于此—— 有料：还能推荐科室/医生，医生AI分身7×24小时不间断服务 有料：还能推荐科室/医生，医生AI分身7×24小时不间断服务 这不，最让人头疼的就医环节必须“榜上有名”。 这不，最让人头疼的就医环节必须“榜上有名”。 此时摆在用户面前的“老大难”通常是如何选医院、选科室、选医生（是谁选择困难症发作了）。毕竟医学信息门槛高，用户既不知道哪家医院、哪个医生最对症，也担心浪费宝贵的时间与金钱。 此时摆在用户面前的“老大难”通常是如何选医院、选科室、选医生（是谁选择困难症发作了）。毕竟医学信息门槛高，用户既不知道哪家医院、哪个医生最对症，也担心浪费宝贵的时间与金钱。 对此，百度健康AI管家也选择“对症下药”了。 对此，百度健康AI管家也选择“对症下药”了。 整合30万+优质医生资源及权威医院榜单信息，它直接 为用户提供从科室推荐、医生筛选到号源预约的完整辅助就医服务 （还能直接下单买药）。 整合30万+优质医生资源及权威医院榜单信息，它直接 为用户提供从科室推荐、医生筛选到号源预约的完整辅助就医服务 为用户提供从科室推荐、医生筛选到号源预约的完整辅助就医服务 （还能直接下单买药）。 比如问治疗鼻炎适合去哪家医院，它会优先推荐在复旦医院排行榜排全国第二的首都医科大学附属北京同仁医院；并且还会根据挂号情况推荐该医院相关经验更丰富、时间合适的某位医生，选定后直接就能挂号（黄牛这算是被AI取代了？）。 比如问治疗鼻炎适合去哪家医院，它会优先推荐在复旦医院排行榜排全国第二的首都医科大学附属北京同仁医院；并且还会根据挂号情况推荐该医院相关经验更丰富、时间合适的某位医生，选定后直接就能挂号（黄牛这算是被AI取代了？）。 当然了，如果不想花钱挂专家号，这个AI也提供 “免费问医生” 服务。 当然了，如果不想花钱挂专家号，这个AI也提供 “免费问医生” “免费问医生” 服务。 直接点击对话框上方的第一个图标即可。 直接点击对话框上方的第一个图标即可。 如果遇到真人医生无法及时线上回复的情况，“医生AI助理”这就闪亮登场。 如果遇到真人医生无法及时线上回复的情况，“医生AI助理”这就闪亮登场。 通过深度学习和自然语言处理技术，AI助理复刻了顶级专家的知识、经验和诊疗逻辑，并对外提供 7×24小时全天候、高效率 的诊疗服务。 通过深度学习和自然语言处理技术，AI助理复刻了顶级专家的知识、经验和诊疗逻辑，并对外提供 7×24小时全天候、高效率 7×24小时全天候、高效率 的诊疗服务。 目前，百度健康AI管家已吸引 超1万名三甲医院医生开通助理 ，比如北京协和医院妇科主任医师田秦杰的分身、复旦大学附属华山医院感染科毛日成副主任医师的分身…… 目前，百度健康AI管家已吸引 超1万名三甲医院医生开通助理 超1万名三甲医院医生开通助理 ，比如北京协和医院妇科主任医师田秦杰的分身、复旦大学附属华山医院感染科毛日成副主任医师的分身…… 这一模式不仅让患者能随时获得专业参考，也让医生能集中精力处理更复杂的线下诊疗工作。 这一模式不仅让患者能随时获得专业参考，也让医生能集中精力处理更复杂的线下诊疗工作。 会管：一键上传所有单子，全家人的健康数据都能管 会管：一键上传所有单子，全家人的健康数据都能管 而看完病之后，最后到手的就是一大堆单子了。 而看完病之后，最后到手的就是一大堆单子了。 相信大家都有这样的经历：看完病后拿着一叠检查单，既怕弄丢，又想不起来上次的指标是多少。 相信大家都有这样的经历：看完病后拿着一叠检查单，既怕弄丢，又想不起来上次的指标是多少。 如何让这些散落的病历“活”起来，成为一份清晰的健康日记？百度健康AI管家的档案功能正是为此而生。 如何让这些散落的病历“活”起来，成为一份清晰的健康日记？百度健康AI管家的档案功能正是为此而生。 用户仅需一键上传个人及家人的病历、检查报告等医疗类单据照片 ，系统即可自动解析并智能识别报告中的结构化信息，同时精准关联至对应家庭成员，帮助用户快速构建完整的家庭医疗数据图谱。 用户仅需一键上传个人及家人的病历、检查报告等医疗类单据照片 用户仅需一键上传个人及家人的病历、检查报告等医疗类单据照片 ，系统即可自动解析并智能识别报告中的结构化信息，同时精准关联至对应家庭成员，帮助用户快速构建完整的家庭医疗数据图谱。 目前，该AI管家的医疗文档 抽取分类准确率达95%+ ，而且还在持续优化。 目前，该AI管家的医疗文档 抽取分类准确率达95%+ 抽取分类准确率达95%+ ，而且还在持续优化。 下一步，该功能计划通过结合时序和理解的智能算法对健康趋势与病情演变进行动态追踪，并将关键指标的变化历程可视化，使用户能直观掌握自身重要健康指标的长期变化。 下一步，该功能计划通过结合时序和理解的智能算法对健康趋势与病情演变进行动态追踪，并将关键指标的变化历程可视化，使用户能直观掌握自身重要健康指标的长期变化。 至此小结一下，作为一个7×24小时个人专属AI健康管家，百度健康这个AI已经构建起从 “科普问答-个性化医疗方案建议-就医决策信息支持-健康档案数据管理-健康数据动态追踪” 的全链路服务。 至此小结一下，作为一个7×24小时个人专属AI健康管家，百度健康这个AI已经构建起从 “科普问答-个性化医疗方案建议-就医决策信息支持-健康档案数据管理-健康数据动态追踪” “科普问答-个性化医疗方案建议-就医决策信息支持-健康档案数据管理-健康数据动态追踪” 的全链路服务。 而且实测过程中也能感受到，这个AI明显具有以下优势： 而且实测过程中也能感受到，这个AI明显具有以下优势： 趋零幻觉 ：在专业医疗知识的回答上比较精准可靠，真人医生的参与让模型几乎没有“一本正经胡说八道”的幻觉问题； 实时校验 ：在关键环节会引入“真人医生确认小结”机制，对AI的结论进行二次核验，为安全性上了双保险； 动态询证 ：像真正的医生一样，它会主动追问病史细节，而非机械问答或长时间思考后给出一个通用化回答，确保最终的健康建议是基于充分的沟通理解和个性化诉求解读后输出的； 自主调度 ：能智能识别需求，在AI分导诊、真人医生介入、AI分身服务间无缝切换，为用户调度最合适的资源和服务。 趋零幻觉 ：在专业医疗知识的回答上比较精准可靠，真人医生的参与让模型几乎没有“一本正经胡说八道”的幻觉问题； 趋零幻觉 趋零幻觉 ：在专业医疗知识的回答上比较精准可靠，真人医生的参与让模型几乎没有“一本正经胡说八道”的幻觉问题； 实时校验 ：在关键环节会引入“真人医生确认小结”机制，对AI的结论进行二次核验，为安全性上了双保险； 实时校验 实时校验 ：在关键环节会引入“真人医生确认小结”机制，对AI的结论进行二次核验，为安全性上了双保险； 动态询证 ：像真正的医生一样，它会主动追问病史细节，而非机械问答或长时间思考后给出一个通用化回答，确保最终的健康建议是基于充分的沟通理解和个性化诉求解读后输出的； 动态询证 动态询证 ：像真正的医生一样，它会主动追问病史细节，而非机械问答或长时间思考后给出一个通用化回答，确保最终的健康建议是基于充分的沟通理解和个性化诉求解读后输出的； 自主调度 ：能智能识别需求，在AI分导诊、真人医生介入、AI分身服务间无缝切换，为用户调度最合适的资源和服务。 自主调度 自主调度 ：能智能识别需求，在AI分导诊、真人医生介入、AI分身服务间无缝切换，为用户调度最合适的资源和服务。 所以接下来的问题是—— 所以接下来的问题是—— 怎么做到的？AI医疗为什么选百度健康？ 怎么做到的？AI医疗为什么选百度健康？ 概括而言，这一切背后靠的是 36万医生实时参与标注和校验支撑起的三层模型架构 。 概括而言，这一切背后靠的是 36万医生实时参与标注和校验支撑起的三层模型架构 36万医生实时参与标注和校验支撑起的三层模型架构 。 关于架构整体定位，官方介绍是这样的—— 关于架构整体定位，官方介绍是这样的—— 百度健康以大规模的Post-Tranining技术，结合海量医疗专业知识、Online-RL训练范式与真人专家的高效协同等机制，在保障医学专业性的基础上，构建了从数据层到应用层的全链路技术体系。 百度健康以大规模的Post-Tranining技术，结合海量医疗专业知识、Online-RL训练范式与真人专家的高效协同等机制，在保障医学专业性的基础上，构建了从数据层到应用层的全链路技术体系。 百度健康以大规模的Post-Tranining技术，结合海量医疗专业知识、Online-RL训练范式与真人专家的高效协同等机制，在保障医学专业性的基础上，构建了从数据层到应用层的全链路技术体系。 数据层：真人加持的医疗可信数据管线 数据层：真人加持的医疗可信数据管线 首先是数据层。 首先是数据层。 它好比整个AI健康管家的“记忆库”与“知识源”，其质量直接决定了模型是否专业、回答是否可信。 它好比整个AI健康管家的“记忆库”与“知识源”，其质量直接决定了模型是否专业、回答是否可信。 为构建高质量数据，百度健康搭建起了一套 “高质量数据闭环+真人专家深度介入” 的体系，来对海量医疗数据进行精准筛选与深度加工。 为构建高质量数据，百度健康搭建起了一套 “高质量数据闭环+真人专家深度介入” “高质量数据闭环+真人专家深度介入” 的体系，来对海量医疗数据进行精准筛选与深度加工。 具体来说，数据层主要包含四大核心资产： 具体来说，数据层主要包含四大核心资产： 专业内容库 ：收录了200万+医学期刊文献、1400万+权威科普与真实案例。 多模态数据 ：包含200万+医学报告影像与100万+专业素材。 独家诊疗逻辑 ：积累了1亿+问诊对话与100万+专科标注数据。 数据安全 ：完成了100万+隐私脱敏处理，并建立了10万+条词汇的红线风险词库。 专业内容库 ：收录了200万+医学期刊文献、1400万+权威科普与真实案例。 专业内容库 专业内容库 ：收录了200万+医学期刊文献、1400万+权威科普与真实案例。 多模态数据 ：包含200万+医学报告影像与100万+专业素材。 多模态数据 多模态数据 ：包含200万+医学报告影像与100万+专业素材。 独家诊疗逻辑 ：积累了1亿+问诊对话与100万+专科标注数据。 独家诊疗逻辑 独家诊疗逻辑 ：积累了1亿+问诊对话与100万+专科标注数据。 数据安全 ：完成了100万+隐私脱敏处理，并建立了10万+条词汇的红线风险词库。 数据安全 数据安全 ：完成了100万+隐私脱敏处理，并建立了10万+条词汇的红线风险词库。 这些数据会经过一个三层加工流程，从“原材料”变成具备“医疗思维”的优质数据： 这些数据会经过一个三层加工流程，从“原材料”变成具备“医疗思维”的优质数据： 第一层是 基础数据层 。主要就是整合多方来源数据（包括病例、问诊、病案库等核心医疗信息），以此构建医疗数据的“原始资产池”。 第一层是 基础数据层 基础数据层 。主要就是整合多方来源数据（包括病例、问诊、病案库等核心医疗信息），以此构建医疗数据的“原始资产池”。 第二层是 逻辑数据层 。通过多维度标注以及引入CoT思维链技术，将专家的诊疗逻辑“编码”进数据，从而让数据具备“医疗决策思维”。 第二层是 逻辑数据层 逻辑数据层 。通过多维度标注以及引入CoT思维链技术，将专家的诊疗逻辑“编码”进数据，从而让数据具备“医疗决策思维”。 第三层是 泛化增强层 。这一步有点像是让只会看教科书的“医学生”，变成能灵活应对各种场景的“资深健康顾问”。借助画像生成（虚拟用户/虚拟医生）、对话仿真（模拟二者对话）等技术，让数据能覆盖从严肃医疗到泛健康等多元场景。 第三层是 泛化增强层 泛化增强层 。这一步有点像是让只会看教科书的“医学生”，变成能灵活应对各种场景的“资深健康顾问”。借助画像生成（虚拟用户/虚拟医生）、对话仿真（模拟二者对话）等技术，让数据能覆盖从严肃医疗到泛健康等多元场景。 整个过程中，为把控数据质量，百度健康设置了双重关卡： 整个过程中，为把控数据质量，百度健康设置了双重关卡： 真人专家把关 ：医生参与医学确认、修改和经验补充，确保数据的医学专业性与临床合理性。 智能模型评审 ：通过多个大模型从专业性、因果性等维度自动校验，最终形成“真人+智能”的双重质量闸门。 真人专家把关 ：医生参与医学确认、修改和经验补充，确保数据的医学专业性与临床合理性。 真人专家把关 真人专家把关 ：医生参与医学确认、修改和经验补充，确保数据的医学专业性与临床合理性。 智能模型评审 ：通过多个大模型从专业性、因果性等维度自动校验，最终形成“真人+智能”的双重质量闸门。 智能模型评审 智能模型评审 ：通过多个大模型从专业性、因果性等维度自动校验，最终形成“真人+智能”的双重质量闸门。 至此，一条清晰的数据闭环已然成型： 至此，一条清晰的数据闭环已然成型： 从海量原始数据的汇聚，到经过三层加工被赋予专业的“医疗思维”，再到最后由“真人+智能”双重质检—— 从海量原始数据的汇聚，到经过三层加工被赋予专业的“医疗思维”，再到最后由“真人+智能”双重质检—— 毫无疑问，百度健康已经构建起属于自己的核心数据壁垒。 毫无疑问，百度健康已经构建起属于自己的核心数据壁垒。 模型层：多模态+领域增强+Online-RL进化 模型层：多模态+领域增强+Online-RL进化 如果说数据层是AI的“记忆库”，那模型层无疑是AI进行思考和决策的“大脑”。 如果说数据层是AI的“记忆库”，那模型层无疑是AI进行思考和决策的“大脑”。 百度健康以 “多模态+领域增强+Online-RL进化” 为技术主线，构建了一个能自主学习和持续优化的医疗大模型家族。 百度健康以 “多模态+领域增强+Online-RL进化” “多模态+领域增强+Online-RL进化” 为技术主线，构建了一个能自主学习和持续优化的医疗大模型家族。 这个家族的“大脑”由三大基础模型（进行了领域增强）协同工作，实现核心医疗场景全覆盖： 这个家族的“大脑”由三大基础模型（进行了领域增强）协同工作，实现核心医疗场景全覆盖： 多模态推理大模型 ：实现医疗影像、文本、语音等多模态数据的融合推理，支撑报告单解读、多模态病历分析等复杂任务； 医疗诊疗大模型 ：专注于临床诊疗全流程，内嵌海量指南与病例知识，核心能力是进行疾病基础诊断和推荐治疗方案； 医疗AIGC生成模型 ：扮演“内容创作助手”，负责生成科普内容、问诊话术、病例摘要等多样化医疗文本。 多模态推理大模型 ：实现医疗影像、文本、语音等多模态数据的融合推理，支撑报告单解读、多模态病历分析等复杂任务； 多模态推理大模型 多模态推理大模型 ：实现医疗影像、文本、语音等多模态数据的融合推理，支撑报告单解读、多模态病历分析等复杂任务； 医疗诊疗大模型 ：专注于临床诊疗全流程，内嵌海量指南与病例知识，核心能力是进行疾病基础诊断和推荐治疗方案； 医疗诊疗大模型 医疗诊疗大模型 ：专注于临床诊疗全流程，内嵌海量指南与病例知识，核心能力是进行疾病基础诊断和推荐治疗方案； 医疗AIGC生成模型 ：扮演“内容创作助手”，负责生成科普内容、问诊话术、病例摘要等多样化医疗文本。 医疗AIGC生成模型 医疗AIGC生成模型 ：扮演“内容创作助手”，负责生成科普内容、问诊话术、病例摘要等多样化医疗文本。 更重要的是，这套系统还具备 “自主进化” 的能力： 更重要的是，这套系统还具备 “自主进化” “自主进化” 的能力： 其一，它并非训练完就固定不变，而是能够通过多阶段领域增强（类似医生进修），持续提升模型在医疗细分领域的专业性。 其一，它并非训练完就固定不变，而是能够通过多阶段领域增强（类似医生进修），持续提升模型在医疗细分领域的专业性。 其二，模型被赋予了智能体调度能力，能够自主决策、动态调整推理路径，可根据实际应用中的反馈不断优化自己的思考方式。 其二，模型被赋予了智能体调度能力，能够自主决策、动态调整推理路径，可根据实际应用中的反馈不断优化自己的思考方式。 同时，它还具备自适应的快慢思考机制——既能快速响应简单咨询，也能启动隐式推理能力对用户咨询进行深度思考后针对复杂病因做个性化分析回答，从而在效率与精准度之间取得最佳平衡。 同时，它还具备自适应的快慢思考机制——既能快速响应简单咨询，也能启动隐式推理能力对用户咨询进行深度思考后针对复杂病因做个性化分析回答，从而在效率与精准度之间取得最佳平衡。 而其持续进化的核心，在于 Online-RL在线强化学习机制 ——模型基于每天数亿次真实用户交互进行“天级别”的能力进化。这彻底打破传统模型“训练即固化”的瓶颈，真正做到“越用越聪明”，确保模型始终贴合最新医疗实践与用户需求。 而其持续进化的核心，在于 Online-RL在线强化学习机制 Online-RL在线强化学习机制 ——模型基于每天数亿次真实用户交互进行“天级别”的能力进化。这彻底打破传统模型“训练即固化”的瓶颈，真正做到“越用越聪明”，确保模型始终贴合最新医疗实践与用户需求。 综上所述不难发现，一个会思考、能进化、兼具广度与深度的“AI医疗大脑”已清晰可见。 综上所述不难发现，一个会思考、能进化、兼具广度与深度的“AI医疗大脑”已清晰可见。 应用层：覆盖“科普-诊疗-健康管理”等全场景医疗需求 应用层：覆盖“科普-诊疗-健康管理”等全场景医疗需求 有了上述数据与模型能力做支撑，最终要解决的就是 落地应用 这一核心问题。 有了上述数据与模型能力做支撑，最终要解决的就是 落地应用 落地应用 这一核心问题。 而在应用层，百度健康已经构建了一个覆盖“科普-诊疗-健康管理”等全流程的AI服务体系。 而在应用层，百度健康已经构建了一个覆盖“科普-诊疗-健康管理”等全流程的AI服务体系。 这个体系包括但不限于：AI健康管家、医生分身、AI单据解读&AI健康咨询、AIGC科普视频创作、超级工作台。 这个体系包括但不限于：AI健康管家、医生分身、AI单据解读&AI健康咨询、AIGC科普视频创作、超级工作台。 这些应用并非孤立存在，而是相互协同，共同构成了一个完整的医疗服务生态—— 这些应用并非孤立存在，而是相互协同，共同构成了一个完整的医疗服务生态—— 从用户打开百度健康AI管家进行健康咨询，到获得诊断建议、预约挂号，再到管理个人健康档案，每一个环节都有相应的AI应用提供支持。 从用户打开百度健康AI管家进行健康咨询，到获得诊断建议、预约挂号，再到管理个人健康档案，每一个环节都有相应的AI应用提供支持。 从用户打开百度健康AI管家进行健康咨询，到获得诊断建议、预约挂号，再到管理个人健康档案，每一个环节都有相应的AI应用提供支持。 总之，从数据层到应用层，百度健康确实构建起了一套全链路技术体系。 总之，从数据层到应用层，百度健康确实构建起了一套全链路技术体系。 这套体系帮助百度健康切实解决了传统医疗大模型在专业性、时效性、个性化与隐私保护上的瓶颈，从而使其能够从一众竞争对手中脱颖而出。 这套体系帮助百度健康切实解决了传统医疗大模型在专业性、时效性、个性化与隐私保护上的瓶颈，从而使其能够从一众竞争对手中脱颖而出。 专业性 ：36万医生标注+多维度知识库+思维链技术，实现趋零幻觉，让AI的回答真正具备临床参考价值； 时效性 ：超36万医生校验&背书+多源RAG（检索增强生成），让系统实时获取最新医学进展和健康热点； 个性化 ：基于用户画像和动态询证机制，为每个用户提供“因人而异”的健康建议，拒绝标准化回答； 隐私保护 ：通过全流程隐私脱敏和红线风险召回系统，诊前/诊中/诊后全链路保护用户隐私。 专业性 ：36万医生标注+多维度知识库+思维链技术，实现趋零幻觉，让AI的回答真正具备临床参考价值； 专业性 专业性 ：36万医生标注+多维度知识库+思维链技术，实现趋零幻觉，让AI的回答真正具备临床参考价值； 时效性 ：超36万医生校验&背书+多源RAG（检索增强生成），让系统实时获取最新医学进展和健康热点； 时效性 时效性 ：超36万医生校验&背书+多源RAG（检索增强生成），让系统实时获取最新医学进展和健康热点； 个性化 ：基于用户画像和动态询证机制，为每个用户提供“因人而异”的健康建议，拒绝标准化回答； 个性化 个性化 ：基于用户画像和动态询证机制，为每个用户提供“因人而异”的健康建议，拒绝标准化回答； 隐私保护 ：通过全流程隐私脱敏和红线风险召回系统，诊前/诊中/诊后全链路保护用户隐私。 隐私保护 隐私保护 ：通过全流程隐私脱敏和红线风险召回系统，诊前/诊中/诊后全链路保护用户隐私。 再加上百度健康已构建的 医疗行业MCP生态 ——通过联动医院、药企、科研机构等产业链上下游伙伴，打造出坚实的医疗AI生态闭环，为技术落地与迭代提供了强大的产业支撑。 再加上百度健康已构建的 医疗行业MCP生态 医疗行业MCP生态 ——通过联动医院、药企、科研机构等产业链上下游伙伴，打造出坚实的医疗AI生态闭环，为技术落地与迭代提供了强大的产业支撑。 可以说，拥有“技术+生态”双重优势的百度健康，已然成为AI医疗赛道上的一匹黑马。 可以说，拥有“技术+生态”双重优势的百度健康，已然成为AI医疗赛道上的一匹黑马。 医疗AI从“辅助性工具”到“智能健康伙伴” 医疗AI从“辅助性工具”到“智能健康伙伴” 最后，回到百度健康此次推出的AI健康管家上，或许有小伙伴就问了—— 最后，回到百度健康此次推出的AI健康管家上，或许有小伙伴就问了—— 其出现究竟意味着什么呢？ 其出现究竟意味着什么呢？ 答案是，这远非市场上又多了一款AI产品那么简单。从行业视角看， 它更是标志着医疗AI从“辅助性工具”向“智能健康伙伴”的关键跃迁 。 答案是，这远非市场上又多了一款AI产品那么简单。从行业视角看， 它更是标志着医疗AI从“辅助性工具”向“智能健康伙伴”的关键跃迁 它更是标志着医疗AI从“辅助性工具”向“智能健康伙伴”的关键跃迁 。 过去，人们看病靠医生，查资料靠搜索。而现在， 人人都能通过百度健康拥有一个7×24小时在线的AI健康伙伴 。 过去，人们看病靠医生，查资料靠搜索。而现在， 人人都能通过百度健康拥有一个7×24小时在线的AI健康伙伴 人人都能通过百度健康拥有一个7×24小时在线的AI健康伙伴 。 它已超越一个简单的“问答AI”，而是升级为能陪你走完完整就医旅程的智能助理——从科普问答、初步问诊，到医生推荐、挂号购药，再到档案管理、健康追踪，每一步都力求“懂你、懂病、更懂健康”。 它已超越一个简单的“问答AI”，而是升级为能陪你走完完整就医旅程的智能助理——从科普问答、初步问诊，到医生推荐、挂号购药，再到档案管理、健康追踪，每一步都力求“懂你、懂病、更懂健康”。 这意味着，医疗服务的核心模式已从过去的“人找服务”，颠覆性地转变为“服务找人”。 这意味着，医疗服务的核心模式已从过去的“人找服务”，颠覆性地转变为“服务找人”。 试想，当AI能真正理解你的健康数据、记住病史、并提前预警风险时，求医问诊这件关乎国计民生的大事，无疑将被重塑。 试想，当AI能真正理解你的健康数据、记住病史、并提前预警风险时，求医问诊这件关乎国计民生的大事，无疑将被重塑。 而且脱离这款产品来看，百度健康的“野心”还远不止于此。 而且脱离这款产品来看，百度健康的“野心”还远不止于此。 围绕“打造中国百姓首选的健康内容和决策平台”这一核心愿景，它正在搭建一套覆盖AI医疗全链条的健康体系。 围绕“打造中国百姓首选的健康内容和决策平台”这一核心愿景，它正在搭建一套覆盖AI医疗全链条的健康体系。 面向普通用户 ，推出能聊、有料、会管的7×24小时个人专属健康管家； 面向健康从业者 （如医生、营养师、心理咨询师等），推出诸如百度健康超级医生工作台这样的“内容创作+分身服务”应用； 面向医院 ，推出用来提升医院服务效率的AI医院智能解决方案。 面向普通用户 ，推出能聊、有料、会管的7×24小时个人专属健康管家； 面向普通用户 面向普通用户 ，推出能聊、有料、会管的7×24小时个人专属健康管家； 面向健康从业者 （如医生、营养师、心理咨询师等），推出诸如百度健康超级医生工作台这样的“内容创作+分身服务”应用； 面向健康从业者 面向健康从业者 （如医生、营养师、心理咨询师等），推出诸如百度健康超级医生工作台这样的“内容创作+分身服务”应用； 面向医院 ，推出用来提升医院服务效率的AI医院智能解决方案。 面向医院 面向医院 ，推出用来提升医院服务效率的AI医院智能解决方案。 以及通过自研Agent+行业MCP，百度健康正持续扩大其健康服务的生态与能力边界。 以及通过自研Agent+行业MCP，百度健康正持续扩大其健康服务的生态与能力边界。 而最终，这一切都指向同一个目标： 而最终，这一切都指向同一个目标： 通过日均服务1.3亿+用户、整合6亿+健康内容、连接36万+医疗专家 ，百度健康正在用最接地气的方式，让曾经“高冷”的AI技术，变成每个人身边触手可及、可信赖的“智能健康管家”。 通过日均服务1.3亿+用户、整合6亿+健康内容、连接36万+医疗专家 通过日均服务1.3亿+用户、整合6亿+健康内容、连接36万+医疗专家 ，百度健康正在用最接地气的方式，让曾经“高冷”的AI技术，变成每个人身边触手可及、可信赖的“智能健康管家”。 u1s1，虽然求医问诊的方式在变，但不变的是—— u1s1，虽然求医问诊的方式在变，但不变的是—— 以后咱还是接着“百度（健康）一下”（doge）。 以后咱还是接着“百度（健康）一下”（doge）。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/343094.html", "title": "卡帕西：强化学习很糟糕，但其他所有方法都更糟", "date": "2025-10-18", "content": "卡帕西：强化学习很糟糕，但其他所有方法都更糟 卡帕西：强化学习很糟糕，但其他所有方法都更糟 时令 2025-10-18 14:38:04 来源： 量子位 时令 时令 时令 时令 2025-10-18 2025-10-18 14:38:04 14:38:04 来源： 量子位 来源： 量子位 量子位 摘要样式 AGi起码还有十年 AGi起码还有十年 AGi起码还有十年 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 卡帕西大神的最新专访来了！ 卡帕西大神的最新专访来了！ 作为 特斯拉前AI总监 、 OpenAI创始成员 ，卡帕西在近两个半小时的访谈中，深入回答了一系列引人深思的问题： 作为 特斯拉前AI总监 特斯拉前AI总监 、 OpenAI创始成员 OpenAI创始成员 ，卡帕西在近两个半小时的访谈中，深入回答了一系列引人深思的问题： 为何强化学习表现糟糕（但其他方法更糟糕）？ 为何通用人工智能会延续2%的GDP增长率？ 为何自动驾驶技术历经漫长攻坚期？ 为何强化学习表现糟糕（但其他方法更糟糕）？ 为何强化学习表现糟糕（但其他方法更糟糕）？ 为何通用人工智能会延续2%的GDP增长率？ 为何通用人工智能会延续2%的GDP增长率？ 为何自动驾驶技术历经漫长攻坚期？ 为何自动驾驶技术历经漫长攻坚期？ 解答问题之余，由于卡帕西早已宣布全职搞教育，那不得不提的还有他对未来教育发展的见解。 解答问题之余，由于卡帕西早已宣布全职搞教育，那不得不提的还有他对未来教育发展的见解。 网友表示：知识点实在太密集了，卡帕西访谈的两个小时等于别人的四个小时。 网友表示：知识点实在太密集了，卡帕西访谈的两个小时等于别人的四个小时。 干货要来了，请系好安全带，别被轰晕了！ 干货要来了，请系好安全带，别被轰晕了！ AGI起码还要十年 AGI起码还要十年 访谈一开始，主持人就先对卡帕西提出了一个人令许多人都很好奇的问题： 访谈一开始，主持人就先对卡帕西提出了一个人令许多人都很好奇的问题： 为什么说未来将是“智能体的十年”，而不是“智能体的一年”？ 为什么说未来将是“智能体的十年”，而不是“智能体的一年”？ 为什么说未来将是“智能体的十年”，而不是“智能体的一年”？ 卡帕西解答道，现在确实有一些非常早期的智能体，比如他每天都在使用的Claude、Codex等，它们已经展现出令人惊叹的能力。 卡帕西解答道，现在确实有一些非常早期的智能体，比如他每天都在使用的Claude、Codex等，它们已经展现出令人惊叹的能力。 但不可否认的是，这些系统还需要不断进化，最终达到理想状态，而 十年 正是实现这一蜕变所需要的时间跨度。 但不可否认的是，这些系统还需要不断进化，最终达到理想状态，而 十年 十年 正是实现这一蜕变所需要的时间跨度。 那这个时间节点为什么是十年呢？ 那这个时间节点为什么是十年呢？ 卡帕西接着举了个例子，他认为，当智能体能够像员工或实习生一样与人协作时，才是它真正发挥作用的时候。 卡帕西接着举了个例子，他认为，当智能体能够像员工或实习生一样与人协作时，才是它真正发挥作用的时候。 显然，目前智能体还做不到这样。那么，为了让它们做到，需要什么条件呢？为什么人们今天还没用它们来做呢？ 显然，目前智能体还做不到这样。那么，为了让它们做到，需要什么条件呢？为什么人们今天还没用它们来做呢？ 原因很简单，就是现有系统尚未成熟。智能水平尚未达标、多模态能力存在局限、也缺乏操作计算机完成复杂任务的能力。 原因很简单，就是现有系统尚未成熟。智能水平尚未达标、多模态能力存在局限、也缺乏操作计算机完成复杂任务的能力。 此外，它们也没有持续学习能力——你无法通过单次告知就让系统永久掌握知识。在认知架构层面仍存在显著缺陷，导致现有方案完全不可行。 此外，它们也没有持续学习能力——你无法通过单次告知就让系统永久掌握知识。在认知架构层面仍存在显著缺陷，导致现有方案完全不可行。 凭借卡帕西15年做AI的经验，要系统性解决这些难题，大约还需要十年。 凭借卡帕西15年做AI的经验，要系统性解决这些难题，大约还需要十年。 LLM认知缺陷 LLM认知缺陷 之后，卡帕西还讲了自己构建代码仓库的一些事情。 之后，卡帕西还讲了自己构建代码仓库的一些事情。 他认为目前人们与代码交互的方式主要有三类： 他认为目前人们与代码交互的方式主要有三类： 完全拒绝所有大语言模型（LLM），坚持手动编写所有代码。 中间派系（也是卡帕西所属的阵营）仍然会亲自编写大量代码，但会利用现有的自动补全功能。 氛围编程，直接输入“请实现某某功能”，然后让模型完成。 完全拒绝所有大语言模型（LLM），坚持手动编写所有代码。 完全拒绝所有大语言模型（LLM），坚持手动编写所有代码。 中间派系（也是卡帕西所属的阵营）仍然会亲自编写大量代码，但会利用现有的自动补全功能。 中间派系（也是卡帕西所属的阵营）仍然会亲自编写大量代码，但会利用现有的自动补全功能。 氛围编程，直接输入“请实现某某功能”，然后让模型完成。 氛围编程，直接输入“请实现某某功能”，然后让模型完成。 卡帕西承认，现有的智能体在做模块化代码方面确实很有效，但他做的NanoChat是一个很独特的仓库，几乎每行都需要深度思考，所有细节都必须精确安排。 卡帕西承认，现有的智能体在做模块化代码方面确实很有效，但他做的NanoChat是一个很独特的仓库，几乎每行都需要深度思考，所有细节都必须精确安排。 然而，现有的模型存在太多认知缺陷。由于它们在训练中吸收了网络上常见的编程范式，所以它们总是无法突破思维定势，执意要将代码改造成生产级标准。 然而，现有的模型存在太多认知缺陷。由于它们在训练中吸收了网络上常见的编程范式，所以它们总是无法突破思维定势，执意要将代码改造成生产级标准。 但卡帕西的代码本身已包含若干假设，根本不需要那些冗余内容。它们不仅膨胀了代码库规模，增加了复杂度，还频繁使用已弃用的API，最终搞得一团糟。 但卡帕西的代码本身已包含若干假设，根本不需要那些冗余内容。它们不仅膨胀了代码库规模，增加了复杂度，还频繁使用已弃用的API，最终搞得一团糟。 总的来说，卡帕西认为现在的模型还没有达到理想状态，业界对它们的能力有些过度夸大，其实它们仍需要大量改进。 总的来说，卡帕西认为现在的模型还没有达到理想状态，业界对它们的能力有些过度夸大，其实它们仍需要大量改进。 强化学习很糟糕 强化学习很糟糕 接着，主持人聊到了现在大火的强化学习。 接着，主持人聊到了现在大火的强化学习。 卡帕西表示： 卡帕西表示： 强化学习远比普通人想象的还要糟糕，它确实很差，但其他方法更差。 强化学习远比普通人想象的还要糟糕，它确实很差，但其他方法更差。 强化学习远比普通人想象的还要糟糕，它确实很差，但其他方法更差。 以解数学题为例，在强化学习中，你会首先生成大量尝试方案：针对同一问题产出数百种解法，可能涉及不同思路的探索与调整，最终某个答案恰好正确。 以解数学题为例，在强化学习中，你会首先生成大量尝试方案：针对同一问题产出数百种解法，可能涉及不同思路的探索与调整，最终某个答案恰好正确。 这时强化学习的做法是：对最终正确的解题路径上的每个步骤都进行权重强化，仿佛在说“请多做这类操作”。 这时强化学习的做法是：对最终正确的解题路径上的每个步骤都进行权重强化，仿佛在说“请多做这类操作”。 但问题在于这种做法充满噪声。它默认正确解法的每个环节都完美无缺，但现实中人们常会绕弯路，只是最终误打误撞找到答案。只要结果正确，所有错误步骤反而都被强化了——这显然不合理。 但问题在于这种做法充满噪声。它默认正确解法的每个环节都完美无缺，但现实中人们常会绕弯路，只是最终误打误撞找到答案。只要结果正确，所有错误步骤反而都被强化了——这显然不合理。 人们投入大量计算资源，最终仅获得“正确/错误”的二元判断，并据此对整个轨迹进行加权，卡帕西认为，“这实在荒谬”。 人们投入大量计算资源，最终仅获得“正确/错误”的二元判断，并据此对整个轨迹进行加权，卡帕西认为，“这实在荒谬”。 真正的人类绝不会这么干。第一，人类不会做数百次尝试；第二，当人类找到答案时，会进行复杂的复盘：“哪些做得好，哪些没做好”。他们会思考，而当前LLM完全没有这种机制。 真正的人类绝不会这么干。第一，人类不会做数百次尝试；第二，当人类找到答案时，会进行复杂的复盘：“哪些做得好，哪些没做好”。他们会思考，而当前LLM完全没有这种机制。 以阅读为例，当LLM“阅读”时，只是在做下一个词预测并从中获取知识。但人类阅读时，书本更像是激发思考的提示集——人们会通过信息重组来内化知识。 以阅读为例，当LLM“阅读”时，只是在做下一个词预测并从中获取知识。但人类阅读时，书本更像是激发思考的提示集——人们会通过信息重组来内化知识。 对此，卡帕西期待在预训练阶段加入“思考消化”环节，让模型能真正整合新信息与既有认知。 对此，卡帕西期待在预训练阶段加入“思考消化”环节，让模型能真正整合新信息与既有认知。 AGI将延续2%的GDP增长趋势 AGI将延续2%的GDP增长趋势 接着，主持人还提到了衡量AGI的标尺，以教育水平为例，AGI是从高中生水平通过强化学习达到大学生水平，最终取得博士学位。 接着，主持人还提到了衡量AGI的标尺，以教育水平为例，AGI是从高中生水平通过强化学习达到大学生水平，最终取得博士学位。 卡帕西可不认同上述标准，他认同的是OpenAI初创时对AGI的定义：能完成任何具有经济价值任务且达到或超越人类水平的系统。 卡帕西可不认同上述标准，他认同的是OpenAI初创时对AGI的定义：能完成任何具有经济价值任务且达到或超越人类水平的系统。 这就涉及到现有工作被替代的程度，卡帕西认为，即使是如客服中心员工这种更易自动化的职业，AGI也不能瞬间完全替代，而是实现“自主性滑块”——AI处理80%常规工作，剩下20%留给人类监督。 这就涉及到现有工作被替代的程度，卡帕西认为，即使是如客服中心员工这种更易自动化的职业，AGI也不能瞬间完全替代，而是实现“自主性滑块”——AI处理80%常规工作，剩下20%留给人类监督。 那如果有AGI替代人类工作，它的并行复制会显著加速AI进步吗？会出现智力爆炸吗？ 那如果有AGI替代人类工作，它的并行复制会显著加速AI进步吗？会出现智力爆炸吗？ 卡帕西回答道：智力爆炸已经在发生了，通过历史GDP的指数增长就能体现出来。这是渐进的自动化趋势：工业革命是物理自动化，早期软件是数字自动化。 卡帕西回答道：智力爆炸已经在发生了，通过历史GDP的指数增长就能体现出来。这是渐进的自动化趋势：工业革命是物理自动化，早期软件是数字自动化。 他认为： 他认为： 这种增长模式大体保持不变。就像互联网让我们维持2%的增长一样，AGI也只是延续这种模式，不会突然产生巨大的跳跃。 这种增长模式大体保持不变。就像互联网让我们维持2%的增长一样，AGI也只是延续这种模式，不会突然产生巨大的跳跃。 这种增长模式大体保持不变。就像互联网让我们维持2%的增长一样，AGI也只是延续这种模式，不会突然产生巨大的跳跃。 自动驾驶为何耗时如此之长 自动驾驶为何耗时如此之长 主持人还提到了卡帕西在特斯拉的经历，问道：“你曾在2017年到2022年领导特斯拉自动驾驶项目，为什么这个项目耗时如此之长？” 主持人还提到了卡帕西在特斯拉的经历，问道：“你曾在2017年到2022年领导特斯拉自动驾驶项目，为什么这个项目耗时如此之长？” 首先，卡帕西澄清了一点：自动驾驶还远未完成。 首先，卡帕西澄清了一点：自动驾驶还远未完成。 对于某些任务或工作来说，演示到产品的差距非常大。演示可能很容易，但做成真正的产品非常难。自动驾驶尤其如此，因为失败代价太高。 对于某些任务或工作来说，演示到产品的差距非常大。演示可能很容易，但做成真正的产品非常难。自动驾驶尤其如此，因为失败代价太高。 软件工程也有类似特性。比如普通编程可能没那么严格，但如果你写的是生产级代码，任何小错误都可能导致安全漏洞，泄露数百万人的个人信息。 软件工程也有类似特性。比如普通编程可能没那么严格，但如果你写的是生产级代码，任何小错误都可能导致安全漏洞，泄露数百万人的个人信息。 自动驾驶如果出错可能有人受伤，但软件出错可能带来的后果几乎是无限的。 自动驾驶如果出错可能有人受伤，但软件出错可能带来的后果几乎是无限的。 其中的关键在于所谓的“9的进度”。每增加一位9（比如从90%到99%的可靠性），都需要大量工作。卡帕西在特斯拉的五年里，他们可能达到了三位或两位9，但还有更多9等着去完成。 其中的关键在于所谓的“9的进度”。每增加一位9（比如从90%到99%的可靠性），都需要大量工作。卡帕西在特斯拉的五年里，他们可能达到了三位或两位9，但还有更多9等着去完成。 毕竟真正的产品要面对现实中的各种挑战，需要不断修补各种边缘情况。 毕竟真正的产品要面对现实中的各种挑战，需要不断修补各种边缘情况。 教育的未来 教育的未来 最后，卡帕西作为一名全职教育家，不得不提的还有教育。 最后，卡帕西作为一名全职教育家，不得不提的还有教育。 卡帕西表示： 卡帕西表示： 我们在尝试建立一所技术知识方面的顶尖学府，一所非常现代化、领先的学校。我想做的是一种真正的“导师体验”。 我们在尝试建立一所技术知识方面的顶尖学府，一所非常现代化、领先的学校。我想做的是一种真正的“导师体验”。 我们在尝试建立一所技术知识方面的顶尖学府，一所非常现代化、领先的学校。我想做的是一种真正的“导师体验”。 以他学韩语为例，一开始是自学，然后加入韩国的一个小班，和十来个学生一起上课。后来他换成了一对一导师。他发现这位导师的教学非常棒，可以迅速判断他的知识水平，提出合适的问题来理解他的认知模型。 以他学韩语为例，一开始是自学，然后加入韩国的一个小班，和十来个学生一起上课。后来他换成了一对一导师。他发现这位导师的教学非常棒，可以迅速判断他的知识水平，提出合适的问题来理解他的认知模型。 目前，即使是优秀的LLM也做不到这一点，但好的导师可以做到。一旦导师了解自己，就能提供给学生最需要的知识——适度的挑战，既不太难也不太简单。 目前，即使是优秀的LLM也做不到这一点，但好的导师可以做到。一旦导师了解自己，就能提供给学生最需要的知识——适度的挑战，既不太难也不太简单。 此外，卡帕西还想做一门非常优秀的课程，让学生学习AI时能有顶尖的体验。这个课程就是LLM101N，Nanochat是其中的经典项目。之后他还需要构建中间内容，招募助教团队，完善整门课程。 此外，卡帕西还想做一门非常优秀的课程，让学生学习AI时能有顶尖的体验。这个课程就是LLM101N，Nanochat是其中的经典项目。之后他还需要构建中间内容，招募助教团队，完善整门课程。 最后的最后，有的网友也是狠狠附议了卡帕西访谈中的一些观点。 最后的最后，有的网友也是狠狠附议了卡帕西访谈中的一些观点。 比如LLM的“健忘症”。 比如LLM的“健忘症”。 但有的人也表示： 但有的人也表示： 完全不同意，现在的编码智能体已经很可靠了。 完全不同意，现在的编码智能体已经很可靠了。 完全不同意，现在的编码智能体已经很可靠了。 对此，你怎么看呢？欢迎在评论区分享你的观点～ 对此，你怎么看呢？欢迎在评论区分享你的观点～ 参考链接：https://www.dwarkesh.com/p/andrej-karpathy 参考链接：https://www.dwarkesh.com/p/andrej-karpathy 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/343078.html", "title": "61岁退休后，华为海思创始总裁成了复旦北大清华老师", "date": "2025-10-18", "content": "61岁退休后，华为海思创始总裁成了复旦北大清华老师 61岁退休后，华为海思创始总裁成了复旦北大清华老师 时令 2025-10-18 14:28:19 来源： 量子位 时令 时令 时令 时令 2025-10-18 2025-10-18 14:28:19 14:28:19 来源： 量子位 来源： 量子位 量子位 摘要样式 从「大徐总」到徐教授 从「大徐总」到徐教授 从「大徐总」到徐教授 Jay 发自 凹非寺 量子位 | 公众号 QbitAI Jay 发自 凹非寺 Jay 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 原来低调退休的华为海思创始总裁 徐文伟 ，现在的新身份是 大学老师 。 原来低调退休的华为海思创始总裁 徐文伟 徐文伟 ，现在的新身份是 大学老师 大学老师 。 最近，清华五道口AI首期班开学的报道中，徐文伟以教授身份亮相，给企业家学员上了一堂 《AI时代的企业创新》 为题的课程。 最近，清华五道口AI首期班开学的报道中，徐文伟以教授身份亮相，给企业家学员上了一堂 《AI时代的企业创新》 《AI时代的企业创新》 为题的课程。 据说课上，徐文伟教授结合华为突破欧洲市场的故事，生动地解析了创新与商业的关系，还为企业家们分享了干货满满的创新方法论。 据说课上，徐文伟教授结合华为突破欧洲市场的故事，生动地解析了创新与商业的关系，还为企业家们分享了干货满满的创新方法论。 这也是这位前华为董事、科学家咨询委员会主任、战略研究院院长、战略Marketing总裁、企业业务总裁、IRB主任、欧洲地区部总裁以及海思半导体总裁…… 在满满当当的履历中，一步一个脚印凝结下来的宝贵经验 。 这也是这位前华为董事、科学家咨询委员会主任、战略研究院院长、战略Marketing总裁、企业业务总裁、IRB主任、欧洲地区部总裁以及海思半导体总裁…… 在满满当当的履历中，一步一个脚印凝结下来的宝贵经验 在满满当当的履历中，一步一个脚印凝结下来的宝贵经验 。 1963年9月，徐文伟出生于江苏常州，1990年从东南大学毕业，一年后加入华为，开启了长达三十多年的职业生涯长跑。 1963年9月，徐文伟出生于江苏常州，1990年从东南大学毕业，一年后加入华为，开启了长达三十多年的职业生涯长跑。 任职期间，徐文伟战功赫赫 ，包括但不限于：主持研发首款局用程控交换机、首颗芯片、首套GSM系统及首台云数据中心核心交换机、提出创新2.0战略，2020年发布面向数学的十大挑战问题，布局光子计算、裸眼3D显示等前沿技术研发…… 任职期间，徐文伟战功赫赫 任职期间，徐文伟战功赫赫 ，包括但不限于：主持研发首款局用程控交换机、首颗芯片、首套GSM系统及首台云数据中心核心交换机、提出创新2.0战略，2020年发布面向数学的十大挑战问题，布局光子计算、裸眼3D显示等前沿技术研发…… 直到2024年，在61岁时低调退休。 直到2024年，在61岁时低调退休。 低调荣休后的新生活 低调荣休后的新生活 从2023年4月起，华为启动新一轮高层换届，徐文伟卸任常务董事。此后数月间，他又陆续退出海思管理层的多个职务。 从2023年4月起，华为启动新一轮高层换届，徐文伟卸任常务董事。此后数月间，他又陆续退出海思管理层的多个职务。 到了2024年3月，徐文伟在朋友圈低调发布消息，正式宣布离开华为。此后，他渐渐淡出了公众视野。 到了2024年3月，徐文伟在朋友圈低调发布消息，正式宣布离开华为。此后，他渐渐淡出了公众视野。 近一年的时间里，关于这位华为老将的动向没有了任何风声。 近一年的时间里，关于这位华为老将的动向没有了任何风声。 直到2025年2月， 复旦大学官网上 ，突然出现了徐文伟的照片与职务信息。 直到2025年2月， 复旦大学官网上 复旦大学官网上 ，突然出现了徐文伟的照片与职务信息。 这才反应过来，原来徐总并没有彻底隐退江湖，而是到学界继续发光发热了。 这才反应过来，原来徐总并没有彻底隐退江湖，而是到学界继续发光发热了。 目前，他的主要工作在复旦大学，担任复旦大学发展研究院、技术创新战略研究中心教授，博士生导师（管理科学与工程专业），以及复旦大学新工科建设战略咨询委员会副主任。 目前，他的主要工作在复旦大学，担任复旦大学发展研究院、技术创新战略研究中心教授，博士生导师（管理科学与工程专业），以及复旦大学新工科建设战略咨询委员会副主任。 同时，徐文伟也在清华大学经管学院与北京大学光华管理学院出任 管理实践教授 。 同时，徐文伟也在清华大学经管学院与北京大学光华管理学院出任 管理实践教授 管理实践教授 。 “管理实践教授”是一类非传统学术职称，通常由具有深厚行业经验的高管担任，主要负责实务教学、案例研究与学生指导。 “管理实践教授”是一类非传统学术职称，通常由具有深厚行业经验的高管担任，主要负责实务教学、案例研究与学生指导。 在清华大学，他参与了清华AI首期班的课程体系，负责了开班模块的授课。 在清华大学，他参与了清华AI首期班的课程体系，负责了开班模块的授课。 近五年，徐文伟开始在学术方面产出：出版学术专著3部；以通讯作者发表SCI论文1篇；以共同通讯作者发表SCI论文4篇、国内核心期刊论文2篇；主持国家级科研项目1项。 近五年，徐文伟开始在学术方面产出：出版学术专著3部；以通讯作者发表SCI论文1篇；以共同通讯作者发表SCI论文4篇、国内核心期刊论文2篇；主持国家级科研项目1项。 除了高校教授，他现在还承担多项国家与行业层面的咨询职务，包括中国半导体协会专家委员会副主任、中国工程院第七届教育委员会委员，以及粤港澳大湾区国家技术创新中心战略咨询专家委员会委员。 除了高校教授，他现在还承担多项国家与行业层面的咨询职务，包括中国半导体协会专家委员会副主任、中国工程院第七届教育委员会委员，以及粤港澳大湾区国家技术创新中心战略咨询专家委员会委员。 三十三年华为征程 三十三年华为征程 自2024年离开华为后，徐文伟的名字后逐渐多了“教授”两个字。 自2024年离开华为后，徐文伟的名字后逐渐多了“教授”两个字。 然而，在他人生33年的光阴里，更熟悉的称呼是「大徐总」。 然而，在他人生33年的光阴里，更熟悉的称呼是「大徐总」。 这“ 大 ”，不仅意味着资历与分量，也是华为内部心照不宣的默契…… 这“ 大 ”，不仅意味着资历与分量，也是华为内部心照不宣的默契…… 公司里还有另一位“徐总”——曾任轮值董事长的徐直军。 公司里还有另一位“徐总”——曾任轮值董事长的徐直军。 不过，2024年3月后，可能称呼又统一回徐总了。 不过，2024年3月后，可能称呼又统一回徐总了。 2024年3月，大徐总徐文伟在朋友圈低调荣休，宣布三十多年的华为旅程圆满结束。 2024年3月，大徐总徐文伟在朋友圈低调荣休，宣布三十多年的华为旅程圆满结束。 首颗ASIC芯片 首颗ASIC芯片 徐文伟和华为的故事，得从34年前说起。 徐文伟和华为的故事，得从34年前说起。 有的人，只要他在，你就会觉得心安。 有的人，只要他在，你就会觉得心安。 有的人，只要他在，你就会觉得心安。 1991年，硕士毕业不久的徐文伟加入刚刚起步的华为，建立了器件室，负责印刷电路板与芯片设计工作。 1991年，硕士毕业不久的徐文伟加入刚刚起步的华为，建立了器件室，负责印刷电路板与芯片设计工作。 那时的国产芯片还处于艰难爬坡期，华为无论是财力或资源自然都不能与今日声名赫赫的2012实验室相提并论。 那时的国产芯片还处于艰难爬坡期，华为无论是财力或资源自然都不能与今日声名赫赫的2012实验室相提并论。 一段时间里，器件室只有 2台示波器、4只万用表和6名开发人员 。 一段时间里，器件室只有 2台示波器、4只万用表和6名开发人员 2台示波器、4只万用表和6名开发人员 。 按照流程，徐文伟首先设计自己的电路，成熟后，再委托一家拥有EDA能力的香港公司设计成ASIC芯片，再交由德州仪器流片和生产。 按照流程，徐文伟首先设计自己的电路，成熟后，再委托一家拥有EDA能力的香港公司设计成ASIC芯片，再交由德州仪器流片和生产。 这个过程代价不菲，光是一次流片，就要几万美元。 这个过程代价不菲，光是一次流片，就要几万美元。 而为了撑起这间成本高昂的研发黑洞，任正非已经倾注了一切，甚至不得不考虑借高利贷。 而为了撑起这间成本高昂的研发黑洞，任正非已经倾注了一切，甚至不得不考虑借高利贷。 新产品研发不成功，你们可以换个工作，我只能从这里跳下去了！ 新产品研发不成功，你们可以换个工作，我只能从这里跳下去了！ 新产品研发不成功，你们可以换个工作，我只能从这里跳下去了！ 幸运的是，徐文伟没有让这份孤注一掷的信任落空，也没有让任老落空。 幸运的是，徐文伟没有让这份孤注一掷的信任落空，也没有让任老落空。 不到一年，华为成功设计出首颗自研ASIC芯片 SD502 ，这枚小小的芯片，成为了华为半导体自主化的起点，也为后来整个中国通信产业的茁壮成长埋下了种子。 不到一年，华为成功设计出首颗自研ASIC芯片 SD502 SD502 ，这枚小小的芯片，成为了华为半导体自主化的起点，也为后来整个中国通信产业的茁壮成长埋下了种子。 自此，华为的芯片之路终于步入正轨，也由此踏上全球化的征程。 自此，华为的芯片之路终于步入正轨，也由此踏上全球化的征程。 把基站卖到了欧洲 把基站卖到了欧洲 1994年，任正非带领核心团队出国考察，徐文伟也在其中。 1994年，任正非带领核心团队出国考察，徐文伟也在其中。 而目的地，正是当时万千芯片从业者所向往的“千金市骨”之地——美国。 而目的地，正是当时万千芯片从业者所向往的“千金市骨”之地——美国。 △左四为徐文伟 △左四为徐文伟 在那里，他们跋涉了包括达拉斯、加州硅谷、波士顿等城市在内的多个科技重镇，并先后拜访了 德州仪器 （TI）、 国家半导体公司（National Semiconductor） 等世界顶尖半导体企业。 在那里，他们跋涉了包括达拉斯、加州硅谷、波士顿等城市在内的多个科技重镇，并先后拜访了 德州仪器 德州仪器 （TI）、 国家半导体公司（National Semiconductor） 国家半导体公司（National Semiconductor） 等世界顶尖半导体企业。 美国之行结束后，任正非深有感触，执笔写下了 《赴美考察散记》 ，记录了他对教育、科技、公司制度等方面的思考。 美国之行结束后，任正非深有感触，执笔写下了 《赴美考察散记》 《赴美考察散记》 ，记录了他对教育、科技、公司制度等方面的思考。 不过，这趟求学之旅并没有让任正非感到受挫，反而激起了他强烈的好胜心，并且在内部会议上放出了那句经典豪言： 不过，这趟求学之旅并没有让任正非感到受挫，反而激起了他强烈的好胜心，并且在内部会议上放出了那句经典豪言： 10年之后，世界通信行业三分天下，华为占其一。 10年之后，世界通信行业三分天下，华为占其一。 10年之后，世界通信行业三分天下，华为占其一。 同样伴随华为轰隆轰隆向前驶进的，还有徐文伟的职业轨迹。 同样伴随华为轰隆轰隆向前驶进的，还有徐文伟的职业轨迹。 1995年，华为成立“中央研究部”，下设基础研究部，全面开启体系化研发的序幕。徐文伟出任 无线研发总经理 ，负责通信系统核心芯片设计。 1995年，华为成立“中央研究部”，下设基础研究部，全面开启体系化研发的序幕。徐文伟出任 无线研发总经理 无线研发总经理 ，负责通信系统核心芯片设计。 到1997年，华为员工规模已突破7000人，公司进入高速扩张期。此时，徐文伟升任 预研部总裁 ，主导最前沿技术的探索与攻关。 到1997年，华为员工规模已突破7000人，公司进入高速扩张期。此时，徐文伟升任 预研部总裁 预研部总裁 ，主导最前沿技术的探索与攻关。 可惜好景不长。2000年前后，外部冲击接连袭来，「互联网泡沫破裂」与「亚洲金融危机」的两朵乌云，笼罩了通信行业的大厦。 可惜好景不长。2000年前后，外部冲击接连袭来，「互联网泡沫破裂」与「亚洲金融危机」的两朵乌云，笼罩了通信行业的大厦。 受经济周期的影响，国内市场急剧萎缩，通信巨头产能严重过剩，整个行业迫切需要寻找新的出路。 受经济周期的影响，国内市场急剧萎缩，通信巨头产能严重过剩，整个行业迫切需要寻找新的出路。 在此背景下，出海成了华为的首要任务。 在此背景下，出海成了华为的首要任务。 进入21世纪，华为正式进军欧洲市场，徐文伟被任命为欧洲地区部总裁，负责带领团队开拓这一高标准、强竞争的阵地。 进入21世纪，华为正式进军欧洲市场，徐文伟被任命为欧洲地区部总裁，负责带领团队开拓这一高标准、强竞争的阵地。 2005年，华为与 英国电信（BT） 签署首份战略合作协议，参与其国家宽带网络建设计划，这是华为突破欧洲市场的起点。 2005年，华为与 英国电信（BT） 英国电信（BT） 签署首份战略合作协议，参与其国家宽带网络建设计划，这是华为突破欧洲市场的起点。 支撑这一跨越的，是华为过硬的技术实力。 支撑这一跨越的，是华为过硬的技术实力。 当时，华为推出了全球首款分布式基站——体积更小、功耗更低、安装更灵活。 当时，华为推出了全球首款分布式基站——体积更小、功耗更低、安装更灵活。 一经问世，这款新型基站便迅速成为全球运营商的新宠。包括 沃达丰（Vodafone） 在内的多家顶级通信公司，都将这款设备纳入核心网络部署。 一经问世，这款新型基站便迅速成为全球运营商的新宠。包括 沃达丰（Vodafone） 沃达丰（Vodafone） 在内的多家顶级通信公司，都将这款设备纳入核心网络部署。 从那一刻起，华为不再只是一个追赶者，而是以技术创新的姿态叩开了欧洲市场的大门。 从那一刻起，华为不再只是一个追赶者，而是以技术创新的姿态叩开了欧洲市场的大门。 第二个转折点出现在2007至2008年。 第二个转折点出现在2007至2008年。 彼时，通信行业正处于网络转型升级的关键节点，3G技术刚被引入标准讨论，技术路线的不确定性使运营商在设备采购上格外谨慎。 彼时，通信行业正处于网络转型升级的关键节点，3G技术刚被引入标准讨论，技术路线的不确定性使运营商在设备采购上格外谨慎。 雪上加霜的是，源自华尔街的金融海啸全面爆发。次贷危机重挫全球投资者信心，通信基础设施市场进一步收缩。 雪上加霜的是，源自华尔街的金融海啸全面爆发。次贷危机重挫全球投资者信心，通信基础设施市场进一步收缩。 面对双重压力，徐文伟带领团队再次走在了前面。他们推出了可兼容2G、3G与4G多制式的第四代基站产品，打消了运营商对技术变迁的担忧。 面对双重压力，徐文伟带领团队再次走在了前面。他们推出了可兼容2G、3G与4G多制式的第四代基站产品，打消了运营商对技术变迁的担忧。 2008年，在徐文伟的领导下，华为在德国完成 8000个GSM基站 的搬迁与新建工程，实现对欧洲主流市场的规模突破。 2008年，在徐文伟的领导下，华为在德国完成 8000个GSM基站 8000个GSM基站 的搬迁与新建工程，实现对欧洲主流市场的规模突破。 此后，华为又与挪威TeliaSonera合作，先后开通了全球首张4G商用网络与首张4.5G商用网络，成为全球通信技术演进的领跑者。 此后，华为又与挪威TeliaSonera合作，先后开通了全球首张4G商用网络与首张4.5G商用网络，成为全球通信技术演进的领跑者。 经此一役，身为欧洲地区部总裁的徐文伟，凭借精准的技术判断与稳健的执行力，在动荡的经济周期中一战成名，彻底征服了欧洲运营商。 经此一役，身为欧洲地区部总裁的徐文伟，凭借精准的技术判断与稳健的执行力，在动荡的经济周期中一战成名，彻底征服了欧洲运营商。 根据华为2008年年报，公司当年全球销售额达233亿美元，同比增长46%，其中 海外市场占比超过75% 。 根据华为2008年年报，公司当年全球销售额达233亿美元，同比增长46%，其中 海外市场占比超过75% 海外市场占比超过75% 。 直到今天，欧洲仍是华为海外通信业务的核心阵地，而余承东等后继者在欧洲市场的成功，正是建立在徐文伟当年打下的坚实基础之上。 直到今天，欧洲仍是华为海外通信业务的核心阵地，而余承东等后继者在欧洲市场的成功，正是建立在徐文伟当年打下的坚实基础之上。 打通企业业务 打通企业业务 值得一提的是，徐文伟在负责欧洲市场的同时也兼任海思半导体的总裁，主要是做消费电子芯片。 值得一提的是，徐文伟在负责欧洲市场的同时也兼任海思半导体的总裁，主要是做消费电子芯片。 不过，在完成海思组织架构的搭建后，他将重任交给 何庭波 ，自己则转任 企业业务总裁 ，继续开拓新的增长引擎。 不过，在完成海思组织架构的搭建后，他将重任交给 何庭波 何庭波 ，自己则转任 企业业务总裁 企业业务总裁 ，继续开拓新的增长引擎。 2013年，徐文伟主导研发的 全球首款敏捷交换机S12700 正式发布，性能相比上一代提升十倍，成为企业网络领域的标志性创新。 2013年，徐文伟主导研发的 全球首款敏捷交换机S12700 全球首款敏捷交换机S12700 正式发布，性能相比上一代提升十倍，成为企业网络领域的标志性创新。 同年，华为企业业务营收突破25亿美元，同比增长超过32%，为华为打开了 继运营商与终端之后的第三条增长曲线 。 同年，华为企业业务营收突破25亿美元，同比增长超过32%，为华为打开了 继运营商与终端之后的第三条增长曲线 继运营商与终端之后的第三条增长曲线 。 创新2.0时代 创新2.0时代 自2014年起，徐文伟的角色开始从业务一线转向战略中枢，他出任 战略Marketing总裁兼IRB（产品投资评审委员会）主任 。 自2014年起，徐文伟的角色开始从业务一线转向战略中枢，他出任 战略Marketing总裁兼IRB（产品投资评审委员会）主任 战略Marketing总裁兼IRB（产品投资评审委员会）主任 。 业务前线的接力棒，则交到了 余承东 手中。 业务前线的接力棒，则交到了 余承东 余承东 手中。 2014年到2018年，余承东率领华为终端全面爆发，整体营收从2800亿涨到7200多亿元，翻了一倍不止。 2014年到2018年，余承东率领华为终端全面爆发，整体营收从2800亿涨到7200多亿元，翻了一倍不止。 然而，华为的异军突起终于触碰到了美国的逆鳞。 然而，华为的异军突起终于触碰到了美国的逆鳞。 2018年，美国通过《国防授权法案》，明令禁止政府部门采购华为设备。科技竞争一触即发。 2018年，美国通过《国防授权法案》，明令禁止政府部门采购华为设备。科技竞争一触即发。 任正非敏锐地察觉到骤然刺骨的冷战气息，开始主动调整战略： 收缩市场、聚焦创新，为即将到来的长期博弈蓄力 。 任正非敏锐地察觉到骤然刺骨的冷战气息，开始主动调整战略： 收缩市场、聚焦创新，为即将到来的长期博弈蓄力 收缩市场、聚焦创新，为即将到来的长期博弈蓄力 。 同年年底，华为正式成立 战略研究院 ，出任首任院长的，正是曾靠创新在欧洲市场杀出一条血路的先驱者，徐文伟。 同年年底，华为正式成立 战略研究院 战略研究院 ，出任首任院长的，正是曾靠创新在欧洲市场杀出一条血路的先驱者，徐文伟。 上任后，他提出了著名的 创新2.0 。 上任后，他提出了著名的 创新2.0 创新2.0 。 在他的定义中，华为的创新要从“基于客户需求的技术、工程与解决方案创新1.0”，迈向“基于愿景假设的基础理论突破与基础技术发明的创新2.0”，去解决从0到1的根本性问题。 在他的定义中，华为的创新要从“基于客户需求的技术、工程与解决方案创新1.0”，迈向“基于愿景假设的基础理论突破与基础技术发明的创新2.0”，去解决从0到1的根本性问题。 为实现这一目标，徐文伟推动了两项核心行动： 为实现这一目标，徐文伟推动了两项核心行动： 第一，产学共研，携手突围。 第一，产学共研，携手突围。 第一，产学共研，携手突围。 他主导华为与高校共建了一系列联合实验室和研究院，包括北大-华为智能媒体联合实验室、北大-华为数学联合实验室、清华-华为联合研究院等，每年投入超过20亿元。 他主导华为与高校共建了一系列联合实验室和研究院，包括北大-华为智能媒体联合实验室、北大-华为数学联合实验室、清华-华为联合研究院等，每年投入超过20亿元。 同时，他还设立了面向全球的数据存储领域科研奖项—— 奥林帕斯奖 ，以此牵引基础理论研究，聚焦关键技术攻关，加速产学研成果转化。 同时，他还设立了面向全球的数据存储领域科研奖项—— 奥林帕斯奖 奥林帕斯奖 ，以此牵引基础理论研究，聚焦关键技术攻关，加速产学研成果转化。 第二，前瞻投资，布局未来。 第二，前瞻投资，布局未来。 第二，前瞻投资，布局未来。 在徐文伟的推动下，华为成立了 哈勃投资 ，专注于与华为主营业务紧密相关的前沿技术领域，如半导体、光计算、DNA存储等。 在徐文伟的推动下，华为成立了 哈勃投资 哈勃投资 ，专注于与华为主营业务紧密相关的前沿技术领域，如半导体、光计算、DNA存储等。 徐文伟明确提出： 哈勃投资不是投资者，而是战略合作者 ，他们的目标是收购关键技术并融入华为生态，而非追求资本回报。 徐文伟明确提出： 哈勃投资不是投资者，而是战略合作者 哈勃投资不是投资者，而是战略合作者 ，他们的目标是收购关键技术并融入华为生态，而非追求资本回报。 正是徐文伟率领战略研究院种下的一颗颗创新火苗，才让华为成功挺过了2020年的芯片寒冬。 正是徐文伟率领战略研究院种下的一颗颗创新火苗，才让华为成功挺过了2020年的芯片寒冬。 2021年，他发布了《迈向智能世界2030》报告，提出 九大技术挑战与研究方向 ，勾勒出华为未来十年的科技路线图。 2021年，他发布了《迈向智能世界2030》报告，提出 九大技术挑战与研究方向 九大技术挑战与研究方向 ，勾勒出华为未来十年的科技路线图。 到2022年，这位见证华为从追赶到引领的老将，正式进入华为权力最高层，成为 华为常务董事 。 到2022年，这位见证华为从追赶到引领的老将，正式进入华为权力最高层，成为 华为常务董事 华为常务董事 。 从研发到市场，从市场到战略，徐文伟用三十余年的时间，亲手书写了华为技术创新的底层逻辑—— 永远向未来下注 。 从研发到市场，从市场到战略，徐文伟用三十余年的时间，亲手书写了华为技术创新的底层逻辑—— 永远向未来下注 永远向未来下注 。 引领者的起跑线 引领者的起跑线 其实，刚刚踏入职场不久，徐文伟便与同样是才起步的华为相遇，成为了华为最早的一批技术骨干。 其实，刚刚踏入职场不久，徐文伟便与同样是才起步的华为相遇，成为了华为最早的一批技术骨干。 1980年，他考入 东南大学（前身南京工学院）自动控制系 。 1980年，他考入 东南大学（前身南京工学院）自动控制系 东南大学（前身南京工学院）自动控制系 。 东南大学是国内最早设立集成电路学院的高校之一，被誉为“中国芯片工程师的摇篮”。从这里走出了包括 艾为电子创始人孙洪军、芯朋微创始人张立新、中兴通讯技术负责人陆平 在内的一批中国半导体产业中坚人物。 东南大学是国内最早设立集成电路学院的高校之一，被誉为“中国芯片工程师的摇篮”。从这里走出了包括 艾为电子创始人孙洪军、芯朋微创始人张立新、中兴通讯技术负责人陆平 艾为电子创始人孙洪军、芯朋微创始人张立新、中兴通讯技术负责人陆平 在内的一批中国半导体产业中坚人物。 多年后，徐文伟回忆起那段校园岁月，言语中难掩对那段朴素时光的怀念： 多年后，徐文伟回忆起那段校园岁月，言语中难掩对那段朴素时光的怀念： 一个书包，两个碗，教室宿舍图书馆。 一个书包，两个碗，教室宿舍图书馆。 一个书包，两个碗，教室宿舍图书馆。 1990年，徐文伟硕士毕业后踏入职场，第一份工作并不是华为，而是彼时声名显赫的 深圳亿利达电子公司 。 1990年，徐文伟硕士毕业后踏入职场，第一份工作并不是华为，而是彼时声名显赫的 深圳亿利达电子公司 深圳亿利达电子公司 。 在上世纪90年代初的深圳电子行业，亿利达是妥妥的“明星企业”，年营收位列前茅。 在上世纪90年代初的深圳电子行业，亿利达是妥妥的“明星企业”，年营收位列前茅。 许多后来在 华为、中兴、TCL、步步高 等公司担任技术或管理骨干的人，都曾在此任职。 许多后来在 华为、中兴、TCL、步步高 华为、中兴、TCL、步步高 等公司担任技术或管理骨干的人，都曾在此任职。 也正因如此，亿利达被业界誉为中国电子产业的黄埔军校。 也正因如此，亿利达被业界誉为中国电子产业的黄埔军校。 徐文伟当时在亿利达主要负责高速激光打印机，由于表现非常出色，仅用半年时间便成为团队骨干。 徐文伟当时在亿利达主要负责高速激光打印机，由于表现非常出色，仅用半年时间便成为团队骨干。 就在这一年，他的办公室隔壁，有一家名不见经传的小公司，正在经历生死转折。 就在这一年，他的办公室隔壁，有一家名不见经传的小公司，正在经历生死转折。 由于主力产品HAX交换机被母公司收回了代理权，他们不得不从代理转向自主研发，但若想在激烈的通信市场中立足，他们还必须拥有自研芯片。 由于主力产品HAX交换机被母公司收回了代理权，他们不得不从代理转向自主研发，但若想在激烈的通信市场中立足，他们还必须拥有自研芯片。 通过朋友介绍， 任正非第一次见到了徐文伟 。 通过朋友介绍， 任正非第一次见到了徐文伟 任正非第一次见到了徐文伟 。 是的，徐文伟的隔壁，就是刚刚成立四年的华为。 是的，徐文伟的隔壁，就是刚刚成立四年的华为。 当时华为正处于黑暗时期，连工资都难以保障，任正非的账上也是现金寥寥，甚至买不起一条像样的皮带。 当时华为正处于黑暗时期，连工资都难以保障，任正非的账上也是现金寥寥，甚至买不起一条像样的皮带。 即便如此，徐文伟依旧放弃了在亿利达光鲜亮丽的工作，毅然加入了这个濒临破产的小团队。 即便如此，徐文伟依旧放弃了在亿利达光鲜亮丽的工作，毅然加入了这个濒临破产的小团队。 这一干，就是33年。 这一干，就是33年。 这一干，就是33年。 33年间，徐文伟没有再换过工作，一家公司，一份工作，15个岗位，参与造就了一个全新的科技时代。 33年间，徐文伟没有再换过工作，一家公司，一份工作，15个岗位，参与造就了一个全新的科技时代。 直到2024年3月，61岁退休离任。 直到2024年3月，61岁退休离任。 事了拂衣去，深藏功与名。 事了拂衣去，深藏功与名。 事了拂衣去，深藏功与名。 参考链接： [1]https://www.cnbeta.com.tw/articles/tech/1425501.htm [2]https://www.c114.com.cn/news/126/a959080.html [3]https://mp.weixin.qq.com/s/-GZCzxd_lZ99ym7aqhGNiw 参考链接： [1]https://www.cnbeta.com.tw/articles/tech/1425501.htm [2]https://www.c114.com.cn/news/126/a959080.html [3]https://mp.weixin.qq.com/s/-GZCzxd_lZ99ym7aqhGNiw 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/343031.html", "title": "印奇再次叩开港交所：500亿智驾明星，吉利和奔驰护航保送", "date": "2025-10-17", "content": "杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 500亿智驾大佬，准备冲刺港股IPO了。 吉利系科技公司 千里科技 ，现在正式向港交所递表，向“A股+H股”双资本平台架构冲刺。 从2020年脱胎换骨再出发，到如今成功转型为一家智能出行科技公司，6年间，千里科技把市值提了 近乎4倍 。 带队的AI大牛 印奇 ，又一次来到了港交所门口。 但这一次，天时地利人和都有了。 千里科技的核心业务 在招股书中，来自重庆的千里科技，将自身定位为 “AI+Mobility”的闭环解决方案供应商 。 其来历最早可追溯至1992年，前身是 力帆股份 。 公司早期以 摩托车 业务起家，后发展为集汽车制造、出口贸易于一体的重庆龙头民企，曾是中国 “民营汽车第一股” 。 但在2020年，由于经营困难，力帆股份破产重整，在 重庆市政府与吉利集团 主导下，转型为聚焦新能源的”力帆科技”。 关键转折是在 2024年 ，吉利在7月将 19.91% 的股份，转让给旷视科技创始人 印奇 旗下公司，而印奇则在同年10月出任 董事长 。 4个月后，公司正式更名”千里科技”，全面转向”AI+车”战略，并引入了原华为车BU总裁 王军 强化技术团队，加速资源整合。 如今的千里科技，已经正式成为一家智能出行科技公司，市值从2020年初到现在的 515亿元 ，几乎快翻了4倍。 其当前产品和业务可以分为两部分： 一部分仍是 传统制造业务 。 汽车 方面，千里科技和吉利合作推出了 “睿蓝” 品牌，有燃油车也有新能源车。 新能源车主打 换电模式 ，聚焦B端网约车市场，以及小型家庭用车型。 摩托车 方面，也分为传统燃油和新能源类别，并且集成了蓝牙钥匙、远程车辆控制、驾驶辅助功能（BSD、LCA、RCW）等等。 另一部分业务，聚焦 AI技术解决方案 ，包括 智能驾驶、智能座舱和Robotaxi 三条增长曲线。 智能驾驶产品，是提供L2-L4级自动驾驶解决方案，其中包括AI算法、传感器硬件及数据闭环系统，核心为RLM强化学习多模态模型。 智能座舱产品，以AGIL3智能座舱系统为例，基于多模态交互模型和Agent OS，能实现自然语音/视觉交互、情绪识别和个性化推荐。 最后是Robotaxi产品，千里科技为运营商提供了 从自动驾驶到座舱，再到运营支持 的全流程方案。 目前，千里科技正计划在18个月内，完成Robotaxi全链路产业布局，未来打算在全球10座城市实现规模化运营。 在招股书中，有一个名字被反复提及，那就是千里科技的重要战略合作伙伴 吉利 。 吉利之于千里科技，既是 最大供应商 ，也是 最大客户 ： 千里科技向吉利采购整车、汽车零部件等，吉利则采用千里科技的智能辅助驾驶解决方案。 2022年到2024年，以及2025年上半年，吉利分别为千里贡献了34.2亿元、22.5亿元、21.4亿元以及13.8亿元的收入，占后者同期总收入的比重，分别为39.7%、33.6%、30.8%及33.2%。 千里科技的转型过程，本身就由吉利主导，吉利已是千里的大股东。 而就在不久前的9月25日， 奔驰 押注 13亿 入股千里科技，持股3%，成为了后者的第五大股东。 那么千里科技，正在用怎样的财务业绩递表呢？ 千里科技财务表现如何？ 2022年~2024年，千里科技的营收分别为86.27亿元、66.98亿元、69.64亿元；到2025年有所回升，上半年的营收41.84亿元，同比增长40.45%。 拆解收入结构， 汽车和摩托车 仍是公司收入的主要来源，上半年为公司合力贡献约93%的总收入。 但公司的最新增长动力—— AI技术业务 ，正在慢慢扩大影响。预计下半年，辅助驾驶解决方案陆续交付后，就能看到商业化阶段的成果。 盈利能力方面，2022年~2024年，以及今年上半年，公司毛利分别为7亿元、2.72亿元、4.82亿元和2.28亿元。 对应同期毛利率分别为8.2%、4.1%、6.9%、及5.5%。 2022年公司利润分别为1.7亿，从2023年开始亏损，2023年、2024年和今年上半年，分别亏损了2.63亿元、3.29亿元和1.16亿元。 支出上，公司对研发的投入增长明显，已经从2022年的9070万元，增加到了2024年的4.1亿元，今年上半年继续增加到了2.88亿元。 同时，由于供应链效率提升，公司的现金流情况，在2024年好转，今年上半年进一步优化，经营活动现所得现金流为9.79亿元。截至今年6月末，公司的现金及等价物为18.96亿元。 不过在“烧钱”如流水的智驾行业，资金后盾再坚实也不为过。 所以在招股书中，千里科技透露了本次赴港上市的募资用途： 大头将用作 技术与研发投入 ，实施AI驱动战略，包括增强研发能力、开发及升级 “AI+Mobility” 相关产品与解决方案。 其余资金，将用于产业链资源的战略整合，加强中国及海外市场的销售与服务网络建设，同时提升全球品牌影响力，支持国际扩张战略。 清华姚班天才、AI技术大牛 印奇 ，再一次站到了港交所门口。 而且这一次天时地利人和早已拉满，运气也不再能左右。 外部气氛也像极了马云时隔数年再次站到纽约华尔街的情景。 “今天我又回来了，这次多要点。” 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 杰西卡 发自 副驾寺 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 智能车参考 | 公众号 AI4Auto 500亿智驾大佬，准备冲刺港股IPO了。 500亿智驾大佬，准备冲刺港股IPO了。 吉利系科技公司 千里科技 ，现在正式向港交所递表，向“A股+H股”双资本平台架构冲刺。 吉利系科技公司 千里科技 千里科技 ，现在正式向港交所递表，向“A股+H股”双资本平台架构冲刺。 从2020年脱胎换骨再出发，到如今成功转型为一家智能出行科技公司，6年间，千里科技把市值提了 近乎4倍 。 从2020年脱胎换骨再出发，到如今成功转型为一家智能出行科技公司，6年间，千里科技把市值提了 近乎4倍 近乎4倍 。 带队的AI大牛 印奇 ，又一次来到了港交所门口。 带队的AI大牛 印奇 印奇 ，又一次来到了港交所门口。 但这一次，天时地利人和都有了。 但这一次，天时地利人和都有了。 千里科技的核心业务 千里科技的核心业务 在招股书中，来自重庆的千里科技，将自身定位为 “AI+Mobility”的闭环解决方案供应商 。 在招股书中，来自重庆的千里科技，将自身定位为 “AI+Mobility”的闭环解决方案供应商 “AI+Mobility”的闭环解决方案供应商 。 其来历最早可追溯至1992年，前身是 力帆股份 。 其来历最早可追溯至1992年，前身是 力帆股份 力帆股份 。 公司早期以 摩托车 业务起家，后发展为集汽车制造、出口贸易于一体的重庆龙头民企，曾是中国 “民营汽车第一股” 。 公司早期以 摩托车 摩托车 业务起家，后发展为集汽车制造、出口贸易于一体的重庆龙头民企，曾是中国 “民营汽车第一股” “民营汽车第一股” 。 但在2020年，由于经营困难，力帆股份破产重整，在 重庆市政府与吉利集团 主导下，转型为聚焦新能源的”力帆科技”。 但在2020年，由于经营困难，力帆股份破产重整，在 重庆市政府与吉利集团 重庆市政府与吉利集团 主导下，转型为聚焦新能源的”力帆科技”。 关键转折是在 2024年 ，吉利在7月将 19.91% 的股份，转让给旷视科技创始人 印奇 旗下公司，而印奇则在同年10月出任 董事长 。 关键转折是在 2024年 2024年 ，吉利在7月将 19.91% 19.91% 的股份，转让给旷视科技创始人 印奇 印奇 旗下公司，而印奇则在同年10月出任 董事长 董事长 。 4个月后，公司正式更名”千里科技”，全面转向”AI+车”战略，并引入了原华为车BU总裁 王军 强化技术团队，加速资源整合。 4个月后，公司正式更名”千里科技”，全面转向”AI+车”战略，并引入了原华为车BU总裁 王军 王军 强化技术团队，加速资源整合。 如今的千里科技，已经正式成为一家智能出行科技公司，市值从2020年初到现在的 515亿元 ，几乎快翻了4倍。 如今的千里科技，已经正式成为一家智能出行科技公司，市值从2020年初到现在的 515亿元 515亿元 ，几乎快翻了4倍。 其当前产品和业务可以分为两部分： 其当前产品和业务可以分为两部分： 一部分仍是 传统制造业务 。 一部分仍是 传统制造业务 传统制造业务 。 汽车 方面，千里科技和吉利合作推出了 “睿蓝” 品牌，有燃油车也有新能源车。 汽车 汽车 方面，千里科技和吉利合作推出了 “睿蓝” “睿蓝” 品牌，有燃油车也有新能源车。 新能源车主打 换电模式 ，聚焦B端网约车市场，以及小型家庭用车型。 新能源车主打 换电模式 换电模式 ，聚焦B端网约车市场，以及小型家庭用车型。 摩托车 方面，也分为传统燃油和新能源类别，并且集成了蓝牙钥匙、远程车辆控制、驾驶辅助功能（BSD、LCA、RCW）等等。 摩托车 摩托车 方面，也分为传统燃油和新能源类别，并且集成了蓝牙钥匙、远程车辆控制、驾驶辅助功能（BSD、LCA、RCW）等等。 另一部分业务，聚焦 AI技术解决方案 ，包括 智能驾驶、智能座舱和Robotaxi 三条增长曲线。 另一部分业务，聚焦 AI技术解决方案 AI技术解决方案 ，包括 智能驾驶、智能座舱和Robotaxi 智能驾驶、智能座舱和Robotaxi 三条增长曲线。 智能驾驶产品，是提供L2-L4级自动驾驶解决方案，其中包括AI算法、传感器硬件及数据闭环系统，核心为RLM强化学习多模态模型。 智能驾驶产品，是提供L2-L4级自动驾驶解决方案，其中包括AI算法、传感器硬件及数据闭环系统，核心为RLM强化学习多模态模型。 智能座舱产品，以AGIL3智能座舱系统为例，基于多模态交互模型和Agent OS，能实现自然语音/视觉交互、情绪识别和个性化推荐。 智能座舱产品，以AGIL3智能座舱系统为例，基于多模态交互模型和Agent OS，能实现自然语音/视觉交互、情绪识别和个性化推荐。 最后是Robotaxi产品，千里科技为运营商提供了 从自动驾驶到座舱，再到运营支持 的全流程方案。 最后是Robotaxi产品，千里科技为运营商提供了 从自动驾驶到座舱，再到运营支持 从自动驾驶到座舱，再到运营支持 的全流程方案。 目前，千里科技正计划在18个月内，完成Robotaxi全链路产业布局，未来打算在全球10座城市实现规模化运营。 目前，千里科技正计划在18个月内，完成Robotaxi全链路产业布局，未来打算在全球10座城市实现规模化运营。 在招股书中，有一个名字被反复提及，那就是千里科技的重要战略合作伙伴 吉利 。 在招股书中，有一个名字被反复提及，那就是千里科技的重要战略合作伙伴 吉利 吉利 。 吉利之于千里科技，既是 最大供应商 ，也是 最大客户 ： 吉利之于千里科技，既是 最大供应商 最大供应商 ，也是 最大客户 最大客户 ： 千里科技向吉利采购整车、汽车零部件等，吉利则采用千里科技的智能辅助驾驶解决方案。 千里科技向吉利采购整车、汽车零部件等，吉利则采用千里科技的智能辅助驾驶解决方案。 2022年到2024年，以及2025年上半年，吉利分别为千里贡献了34.2亿元、22.5亿元、21.4亿元以及13.8亿元的收入，占后者同期总收入的比重，分别为39.7%、33.6%、30.8%及33.2%。 2022年到2024年，以及2025年上半年，吉利分别为千里贡献了34.2亿元、22.5亿元、21.4亿元以及13.8亿元的收入，占后者同期总收入的比重，分别为39.7%、33.6%、30.8%及33.2%。 千里科技的转型过程，本身就由吉利主导，吉利已是千里的大股东。 千里科技的转型过程，本身就由吉利主导，吉利已是千里的大股东。 而就在不久前的9月25日， 奔驰 押注 13亿 入股千里科技，持股3%，成为了后者的第五大股东。 而就在不久前的9月25日， 奔驰 奔驰 押注 13亿 13亿 入股千里科技，持股3%，成为了后者的第五大股东。 那么千里科技，正在用怎样的财务业绩递表呢？ 那么千里科技，正在用怎样的财务业绩递表呢？ 千里科技财务表现如何？ 千里科技财务表现如何？ 2022年~2024年，千里科技的营收分别为86.27亿元、66.98亿元、69.64亿元；到2025年有所回升，上半年的营收41.84亿元，同比增长40.45%。 2022年~2024年，千里科技的营收分别为86.27亿元、66.98亿元、69.64亿元；到2025年有所回升，上半年的营收41.84亿元，同比增长40.45%。 拆解收入结构， 汽车和摩托车 仍是公司收入的主要来源，上半年为公司合力贡献约93%的总收入。 拆解收入结构， 汽车和摩托车 汽车和摩托车 仍是公司收入的主要来源，上半年为公司合力贡献约93%的总收入。 但公司的最新增长动力—— AI技术业务 ，正在慢慢扩大影响。预计下半年，辅助驾驶解决方案陆续交付后，就能看到商业化阶段的成果。 但公司的最新增长动力—— AI技术业务 AI技术业务 ，正在慢慢扩大影响。预计下半年，辅助驾驶解决方案陆续交付后，就能看到商业化阶段的成果。 盈利能力方面，2022年~2024年，以及今年上半年，公司毛利分别为7亿元、2.72亿元、4.82亿元和2.28亿元。 盈利能力方面，2022年~2024年，以及今年上半年，公司毛利分别为7亿元、2.72亿元、4.82亿元和2.28亿元。 对应同期毛利率分别为8.2%、4.1%、6.9%、及5.5%。 对应同期毛利率分别为8.2%、4.1%、6.9%、及5.5%。 2022年公司利润分别为1.7亿，从2023年开始亏损，2023年、2024年和今年上半年，分别亏损了2.63亿元、3.29亿元和1.16亿元。 2022年公司利润分别为1.7亿，从2023年开始亏损，2023年、2024年和今年上半年，分别亏损了2.63亿元、3.29亿元和1.16亿元。 支出上，公司对研发的投入增长明显，已经从2022年的9070万元，增加到了2024年的4.1亿元，今年上半年继续增加到了2.88亿元。 支出上，公司对研发的投入增长明显，已经从2022年的9070万元，增加到了2024年的4.1亿元，今年上半年继续增加到了2.88亿元。 同时，由于供应链效率提升，公司的现金流情况，在2024年好转，今年上半年进一步优化，经营活动现所得现金流为9.79亿元。截至今年6月末，公司的现金及等价物为18.96亿元。 同时，由于供应链效率提升，公司的现金流情况，在2024年好转，今年上半年进一步优化，经营活动现所得现金流为9.79亿元。截至今年6月末，公司的现金及等价物为18.96亿元。 不过在“烧钱”如流水的智驾行业，资金后盾再坚实也不为过。 不过在“烧钱”如流水的智驾行业，资金后盾再坚实也不为过。 所以在招股书中，千里科技透露了本次赴港上市的募资用途： 所以在招股书中，千里科技透露了本次赴港上市的募资用途： 大头将用作 技术与研发投入 ，实施AI驱动战略，包括增强研发能力、开发及升级 “AI+Mobility” 相关产品与解决方案。 大头将用作 技术与研发投入 技术与研发投入 ，实施AI驱动战略，包括增强研发能力、开发及升级 “AI+Mobility” 相关产品与解决方案。 其余资金，将用于产业链资源的战略整合，加强中国及海外市场的销售与服务网络建设，同时提升全球品牌影响力，支持国际扩张战略。 其余资金，将用于产业链资源的战略整合，加强中国及海外市场的销售与服务网络建设，同时提升全球品牌影响力，支持国际扩张战略。 清华姚班天才、AI技术大牛 印奇 ，再一次站到了港交所门口。 清华姚班天才、AI技术大牛 印奇 印奇 ，再一次站到了港交所门口。 而且这一次天时地利人和早已拉满，运气也不再能左右。 而且这一次天时地利人和早已拉满，运气也不再能左右。 外部气氛也像极了马云时隔数年再次站到纽约华尔街的情景。 外部气氛也像极了马云时隔数年再次站到纽约华尔街的情景。 “今天我又回来了，这次多要点。” “今天我又回来了，这次多要点。”"}
{"url": "https://www.qbitai.com/2025/10/342908.html", "title": "波士顿动力狗gogo回来了！“五条腿”协同发力", "date": "2025-10-17", "content": "波士顿动力狗gogo回来了！“五条腿”协同发力 波士顿动力狗gogo回来了！“五条腿”协同发力 henry 2025-10-17 17:26:39 来源： 量子位 henry henry henry henry 2025-10-17 2025-10-17 17:26:39 17:26:39 来源： 量子位 来源： 量子位 量子位 摘要样式 狗子快去回收站去搬轮胎吧！ 狗子快去回收站去搬轮胎吧！ 狗子快去回收站去搬轮胎吧！ henry 发自 凹非寺 量子位 | 公众号 QbitAI henry 发自 凹非寺 henry 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 机器狗搬轮胎，“五只腿”齐发力！ 机器狗搬轮胎，“五只腿”齐发力！ 在 波士顿动力人工智能研究所 的最新方法—— 结合采样与学习的动态全身操作 中，波士顿动力的机器狗 Spot 最快仅用 3.7 秒就能搬起轮胎。 在 波士顿动力人工智能研究所 波士顿动力人工智能研究所 的最新方法—— 结合采样与学习的动态全身操作 结合采样与学习的动态全身操作 中，波士顿动力的机器狗 Spot Spot 最快仅用 3.7 3.7 秒就能搬起轮胎。 搬运的轮胎重达 15 公斤，相当于Spot自身重量的一半（32.7千克），并远超其最大臂力。 搬运的轮胎重达 15 15 公斤，相当于Spot自身重量的一半（32.7千克），并远超其最大臂力。 而且，搬起轮胎后，它还能将轮胎滚动到指定位置。 而且，搬起轮胎后，它还能将轮胎滚动到指定位置。 甚至还能把一个轮胎叠到另一个轮胎上面（还会用头帮忙顶一下）。 甚至还能把一个轮胎叠到另一个轮胎上面（还会用头帮忙顶一下）。 这一方法克服了传统操作策略（如摇操）在不同机器人形态学结构上的迁移限制，并通过 分层控制 实现了机器狗四肢与全身的协调动力学操作。 这一方法克服了传统操作策略（如摇操）在不同机器人形态学结构上的迁移限制，并通过 分层控制 分层控制 实现了机器狗四肢与全身的协调动力学操作。 网友表示，狗子快去回收站去搬轮胎吧！ 网友表示，狗子快去回收站去搬轮胎吧！ 这是怎么做到的？ 这是怎么做到的？ 结合采样与学习的动态全身操作 结合采样与学习的动态全身操作 总的来说，结合采样与学习的动态全身操作（Combining Sampling and Learning for Dynamic Whole-Body Manipulation）利用强化学习与基于采样的控制（sampling-based control）相结合的方法，使机器人能够执行需要手臂、双腿和躯干协同配合的动态力交互任务。 总的来说，结合采样与学习的动态全身操作（Combining Sampling and Learning for Dynamic Whole-Body Manipulation）利用强化学习与基于采样的控制（sampling-based control）相结合的方法，使机器人能够执行需要手臂、双腿和躯干协同配合的动态力交互任务。 为应对复杂的操作任务，研究采用了 分层控制（hierarchical control） 方法，将控制问题划分为两个互补且同步的层级。 为应对复杂的操作任务，研究采用了 分层控制（hierarchical control） 分层控制（hierarchical control） 方法，将控制问题划分为两个互补且同步的层级。 在低层，基于强化学习的运动策略直接控制电机力矩，以实现平衡、稳定性与运动执行。 在低层，基于强化学习的运动策略直接控制电机力矩，以实现平衡、稳定性与运动执行。 高层控制 则根据任务类型而有所不同： 高层控制 高层控制 则根据任务类型而有所不同： 对于轮胎扶正、拖拽与堆叠等任务，系统采用 基于采样的控制 ，通过模拟潜在的未来情境来发现最优操作策略。 对于轮胎滚动任务，则使用 强化学习 来捕捉维持物体稳定运动所需的细微动力学特征与反应性控制机制。 对于轮胎扶正、拖拽与堆叠等任务，系统采用 基于采样的控制 ，通过模拟潜在的未来情境来发现最优操作策略。 对于轮胎扶正、拖拽与堆叠等任务，系统采用 基于采样的控制 基于采样的控制 ，通过模拟潜在的未来情境来发现最优操作策略。 对于轮胎滚动任务，则使用 强化学习 来捕捉维持物体稳定运动所需的细微动力学特征与反应性控制机制。 对于轮胎滚动任务，则使用 强化学习 强化学习 来捕捉维持物体稳定运动所需的细微动力学特征与反应性控制机制。 所有的高层方法，最终都会输出包括底盘速度、姿态参数（包括滚转、俯仰、高度 ）、腿部控制以及手臂动作等指令。 所有的高层方法，最终都会输出包括底盘速度、姿态参数（包括滚转、俯仰、高度 ）、腿部控制以及手臂动作等指令。 在采样控制中，采样控制器通过并行模拟多个未来情境，寻找最有效的操作策略，从而选择最能实现任务目标的动作。 在采样控制中，采样控制器通过并行模拟多个未来情境，寻找最有效的操作策略，从而选择最能实现任务目标的动作。 在采样控制中，采样控制器通过并行模拟多个未来情境，寻找最有效的操作策略，从而选择最能实现任务目标的动作。 对于那些需要精确施力和多接触协调的任务，系统会运行32个并行CPU线程，每个线程使用MuJoCo模拟未来几秒内的不同动作序列。 对于那些需要精确施力和多接触协调的任务，系统会运行32个并行CPU线程，每个线程使用MuJoCo模拟未来几秒内的不同动作序列。 与直接采样原始轨迹不同，研究在样条曲线空间（space of splines）中进行采样，这种方式能生成更平滑、更自然的运动轨迹，同时降低搜索空间的维度。 与直接采样原始轨迹不同，研究在样条曲线空间（space of splines）中进行采样，这种方式能生成更平滑、更自然的运动轨迹，同时降低搜索空间的维度。 该控制器展现出源自物理仿真的机会性行为。在轮胎扶正过程中，控制器自主发现了复杂的操作策略：机器人通过Spot Arm与前腿动作的协调，产生足够的杠杆力以抬起沉重的轮胎。 该控制器展现出源自物理仿真的机会性行为。在轮胎扶正过程中，控制器自主发现了复杂的操作策略：机器人通过Spot Arm与前腿动作的协调，产生足够的杠杆力以抬起沉重的轮胎。 为了适应多样的初始构型，机器人可能使用手臂、前腿、身体，或这些部位的组合来灵活调整操作策略。 为了适应多样的初始构型，机器人可能使用手臂、前腿、身体，或这些部位的组合来灵活调整操作策略。 值得一提的是，系统并未预设任何固定的操作模式。 这种多肢体、多接触的行为，是在采样过程中优化自然涌现的结果，而非通过显式编程设定接触顺序实现的。 值得一提的是，系统并未预设任何固定的操作模式。 这种多肢体、多接触的行为，是在采样过程中优化自然涌现的结果，而非通过显式编程设定接触顺序实现的。 这种多肢体、多接触的行为，是在采样过程中优化自然涌现的结果，而非通过显式编程设定接触顺序实现的。 此外，控制器会根据实验室空间中机器人与轮胎的当前构型动态调整策略。 此外，控制器会根据实验室空间中机器人与轮胎的当前构型动态调整策略。 在具体的强化学习策略方面，研究通过PPO算法在IsaacLab中训练得到的运动策略。 在具体的强化学习策略方面，研究通过PPO算法在IsaacLab中训练得到的运动策略。 这一策略为高层控制提供了稳健的低层控制抽象，能够在多种操作场景中保持平衡，从而使高层控制问题更易处理。 这一策略为高层控制提供了稳健的低层控制抽象，能够在多种操作场景中保持平衡，从而使高层控制问题更易处理。 在轮胎滚动任务中，研究利用强化学习来应对难以精确建模的复杂摩擦与接触动力学。 在轮胎滚动任务中，研究利用强化学习来应对难以精确建模的复杂摩擦与接触动力学。 其采用 非对称演员-评论家（asymmetric actor-critic architecture） 方法，在单块GPU上经过约24小时训练，得到高层技能策略。 其采用 非对称演员-评论家（asymmetric actor-critic architecture） 非对称演员-评论家（asymmetric actor-critic architecture） 方法，在单块GPU上经过约24小时训练，得到高层技能策略。 该策略接收的观测状态包括机器人、轮胎与目标之间的相对姿态，以及关节位置与速度。奖励函数则根据物体几何形状及其与环境的空间关系，计算期望的躯干与末端执行器位置，引导策略学习达到目标姿态。 该策略接收的观测状态包括机器人、轮胎与目标之间的相对姿态，以及关节位置与速度。奖励函数则根据物体几何形状及其与环境的空间关系，计算期望的躯干与末端执行器位置，引导策略学习达到目标姿态。 训练得到的轮胎滚动策略使机器人能够动态调整其躯干与Spot Arm的位置，以稳定控制滚动的轮胎，防止其倾倒，并将其引导至目标位置。 训练得到的轮胎滚动策略使机器人能够动态调整其躯干与Spot Arm的位置，以稳定控制滚动的轮胎，防止其倾倒，并将其引导至目标位置。 最后，为解决从仿真到现实的差距，训练过程中引入了随机化，包括对物体的质量、摩擦系数与形状等属性进行随机变化。 最后，为解决从仿真到现实的差距，训练过程中引入了随机化，包括对物体的质量、摩擦系数与形状等属性进行随机变化。 实测表现 实测表现 正如我们开头提到的，在轮胎扶正任务中，机器人最佳成绩为3.7秒，平均每个轮胎用时5.9秒，几乎达到人类在该任务中的操作速度。 正如我们开头提到的，在轮胎扶正任务中，机器人最佳成绩为3.7秒，平均每个轮胎用时5.9秒，几乎达到人类在该任务中的操作速度。 这一表现远超传统的准静态假设。 这一表现远超传统的准静态假设。 在准静态假设下，机器人操作物体时速度很慢，加速度产生的惯性被忽略，关节驱动力矩主要依赖静态平衡。 在准静态假设下，机器人操作物体时速度很慢，加速度产生的惯性被忽略，关节驱动力矩主要依赖静态平衡。 而在这篇研究中，机器狗能够高效搬运重达15千克的轮胎——远超其夹持器的峰值举升能力（11 千克）和持续能力（5 千克）。 而在这篇研究中，机器狗能够高效搬运重达15千克的轮胎——远超其夹持器的峰值举升能力（11 千克）和持续能力（5 千克）。 这说明机器人通过动态协调全身动作，将运动与操作紧密耦合，拓展了操作范围，超越了传统的拾取与放置方式。 这说明机器人通过动态协调全身动作，将运动与操作紧密耦合，拓展了操作范围，超越了传统的拾取与放置方式。 此外，研究表明，将高层控制与低层控制分离能够显著简化控制问题。 此外，研究表明，将高层控制与低层控制分离能够显著简化控制问题。 高层控制器无需在拥有数十个自由度的系统中推理关节力矩、接触力以及稳定性约束，而是仅在一个简化的动作空间中工作，该空间由底盘速度和姿态参数构成，其将执行细节交由运动控制器处理，从而极大降低了复杂度。 高层控制器无需在拥有数十个自由度的系统中推理关节力矩、接触力以及稳定性约束，而是仅在一个简化的动作空间中工作，该空间由底盘速度和姿态参数构成，其将执行细节交由运动控制器处理，从而极大降低了复杂度。 分层控制架构使得高层控制器能够专注于任务完成，而无需显式地推理平衡约束或地面接触。 分层控制架构使得高层控制器能够专注于任务完成，而无需显式地推理平衡约束或地面接触。 由此，学习得到的运动抽象层让高层控制更简单、计算更可行，控制器只需专注于“在哪里”和“如何操作物体”，无需处理复杂的低层动力学细节。 由此，学习得到的运动抽象层让高层控制更简单、计算更可行，控制器只需专注于“在哪里”和“如何操作物体”，无需处理复杂的低层动力学细节。 参考链接： 参考链接： [1]https://rai-inst.com/resources/blog/combining-sampling-and-learning-for-dynamic-whole-body-manipulation/ [1]https://rai-inst.com/resources/blog/combining-sampling-and-learning-for-dynamic-whole-body-manipulation/ [2]https://x.com/rai_inst/status/1978113805604258161 [2]https://x.com/rai_inst/status/1978113805604258161 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342847.html", "title": "库克在抖音卖iPhone，M5芯片却偷偷上MacBook Pro，网友：没有Pro/Max，你咋敢？", "date": "2025-10-17", "content": "库克在抖音卖iPhone，M5芯片却偷偷上MacBook Pro，网友：没有Pro/Max，你咋敢？ 库克在抖音卖iPhone，M5芯片却偷偷上MacBook Pro，网友：没有Pro/Max，你咋敢？ henry 2025-10-17 17:02:37 来源： 量子位 henry henry henry henry 2025-10-17 2025-10-17 17:02:37 17:02:37 来源： 量子位 来源： 量子位 量子位 摘要样式 也就苹果能干得出来这种事了。 也就苹果能干得出来这种事了。 也就苹果能干得出来这种事了。 henry 发自 凹非寺 量子位 | 公众号 QbitAI henry 发自 凹非寺 henry 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 这头 库克 前脚还在抖音直播间带货新iPhone，大洋彼岸那头的苹果总部就官宣了全新的 M5芯片 。 这头 库克 库克 前脚还在抖音直播间带货新iPhone，大洋彼岸那头的苹果总部就官宣了全新的 M5芯片 M5芯片 。 这枚全新芯片将率先登场于新一代的 MacBook Pro 、 iPad Pro 和 Apple Vision Pro 。 这枚全新芯片将率先登场于新一代的 MacBook Pro MacBook Pro 、 iPad Pro iPad Pro 和 Apple Vision Pro Apple Vision Pro 。 （国行售价分别为12999元、8999元和29999元） （国行售价分别为12999元、8999元和29999元） 据苹果介绍，M5芯片的10核GPU，配备了 神经引擎加速器 ，让基于GPU的AI任务处理速度大幅提升。 据苹果介绍，M5芯片的10核GPU，配备了 神经引擎加速器 神经引擎加速器 ，让基于GPU的AI任务处理速度大幅提升。 GPU峰值性能较M4翻了4倍有余，整体图形性能最高提升可达 45% 。 GPU峰值性能较M4翻了4倍有余，整体图形性能最高提升可达 45% 45% 。 M5芯片的统一内存带宽也提升近 30% ，从M4的120GB/s跃升至153GB/s。 M5芯片的统一内存带宽也提升近 30% 30% ，从M4的120GB/s跃升至153GB/s。 这些性能提升看上去很猛，但眼尖的网友一针见血： 这些性能提升看上去很猛，但眼尖的网友一针见血： 没有Pro、Max版本，就把M5直接安到MacBook Pro上？ 没有Pro、Max版本，就把M5直接安到MacBook Pro上？ 没有Pro、Max版本，就把M5直接安到MacBook Pro上？ 那Air里该装什么呢？ 那Air里该装什么呢？ 其实对于这次的新芯片，网友的吐槽可远不止这些…… 其实对于这次的新芯片，网友的吐槽可远不止这些…… Only apple can do，也就苹果能干得出来 Only apple can do，也就苹果能干得出来 虽然Apple硬件技术高级副总裁 Johny Srouji 信誓旦旦地表示： 虽然Apple硬件技术高级副总裁 Johny Srouji Johny Srouji 信誓旦旦地表示： M5 芯片代表着Apple芯片AI性能的又一次跃升，造就了MacBook Pro、iPad Pro和Apple Vision Pro性能与功能的大幅升级。 M5 芯片代表着Apple芯片AI性能的又一次跃升，造就了MacBook Pro、iPad Pro和Apple Vision Pro性能与功能的大幅升级。 M5 芯片代表着Apple芯片AI性能的又一次跃升，造就了MacBook Pro、iPad Pro和Apple Vision Pro性能与功能的大幅升级。 但网友们的反应……这次升级好像也没那么大幅。 但网友们的反应……这次升级好像也没那么大幅。 往日那句振奋人心的Only Apple Can Do，也变成了意味深长的—— 也就苹果能干得出来这种事了。 往日那句振奋人心的Only Apple Can Do，也变成了意味深长的—— 也就苹果能干得出来这种事了。 也就苹果能干得出来这种事了。 不得不说，这波苹果的营销，可能真的……翻！车！了！ 不得不说，这波苹果的营销，可能真的……翻！车！了！ 首先，最让人感到疑惑的就是：基础版M5芯片要放到MacBook Pro上？ 首先，最让人感到疑惑的就是：基础版M5芯片要放到MacBook Pro上？ 再怎么说，也应该是Pro对Pro吧？ 再怎么说，也应该是Pro对Pro吧？ 另外，M5的图形性能宣称比M1提升了6倍，但5代跟1代比，多少有点田忌赛马了。 另外，M5的图形性能宣称比M1提升了6倍，但5代跟1代比，多少有点田忌赛马了。 网友也是直接开麦： 网友也是直接开麦： 你咋不等到一千年以后，拿第251代和第一代比呢？ 你咋不等到一千年以后，拿第251代和第一代比呢？ 你咋不等到一千年以后，拿第251代和第一代比呢？ 而且，苹果这种对比方式也基本上告别了和其他家机器的比较， 专注于“自卖自夸”。 而且，苹果这种对比方式也基本上告别了和其他家机器的比较， 专注于“自卖自夸”。 仿佛每一代都是苹果最好，只需要和自己比就完了。 仿佛每一代都是苹果最好，只需要和自己比就完了。 就像以前是“比其他旗舰快N倍”，现在变成了比M1快N倍，未来可能就成了比五年前发布的苹果 M* 芯片快N倍。 就像以前是“比其他旗舰快N倍”，现在变成了比M1快N倍，未来可能就成了比五年前发布的苹果 M* 芯片快N倍。 多少有点荒谬。 多少有点荒谬。 其次，发布会那一套实际上也从“最强”变成了“最新”。 其次，发布会那一套实际上也从“最强”变成了“最新”。 宣传上说的是性能的又一次跃升，但仔细一看，M5甚至不如M4 Max。 宣传上说的是性能的又一次跃升，但仔细一看，M5甚至不如M4 Max。 而M4 Max甚至不如M3 Ultra…… 而M4 Max甚至不如M3 Ultra…… ？？？ ？？？ 一个M芯片线，已经比整个晋西北都乱了。 一个M芯片线，已经比整个晋西北都乱了。 而被这种复杂命名和逆天发布忽悠的人并不在少数。 而被这种复杂命名和逆天发布忽悠的人并不在少数。 这就好比你兴冲冲地看了发布会，买了台最新款MacBook，结果性能还不如别人两年前买的M4 Pro或M4 Max。 这就好比你兴冲冲地看了发布会，买了台最新款MacBook，结果性能还不如别人两年前买的M4 Pro或M4 Max。 有网友就表示，真的需要一些表格，按核心数量或基准测试分组。这样可以对比所有Pro、Max、Ultra型号， 有网友就表示，真的需要一些表格，按核心数量或基准测试分组。这样可以对比所有Pro、Max、Ultra型号， 大多数人完全搞不清楚M2 Ultra和M4 Pro哪个更好。 大多数人完全搞不清楚M2 Ultra和M4 Pro哪个更好。 而对于M5而言，它看样子只是替代了旧的M4芯片， 但性能仍然落后于现有的M4 Pro和M4 Max芯片。 而对于M5而言，它看样子只是替代了旧的M4芯片， 但性能仍然落后于现有的M4 Pro和M4 Max芯片。 但性能仍然落后于现有的M4 Pro和M4 Max芯片。 也就是说，发布会上的全新，最强也多少只是为了新而新，买它也只是让自己保持最新的版本罢了。 也就是说，发布会上的全新，最强也多少只是为了新而新，买它也只是让自己保持最新的版本罢了。 当然，也有人替苹果圆场：M5的AI性能可是比M4、M1强很多！ 当然，也有人替苹果圆场：M5的AI性能可是比M4、M1强很多！ 于是有人问：跟M4 MAX比呢？ 于是有人问：跟M4 MAX比呢？ 结果，最怕空气突然安静。 结果，最怕空气突然安静。 针对苹果的品牌自信，网友们纷纷调侃起了苹果售价9.9刀的抹布： 针对苹果的品牌自信，网友们纷纷调侃起了苹果售价9.9刀的抹布： 震惊！Apple抹布与新款 M5 iPad Pro和M5 MacBook Pro兼容！ 震惊！Apple抹布与新款 M5 iPad Pro和M5 MacBook Pro兼容！ 震惊！Apple抹布与新款 M5 iPad Pro和M5 MacBook Pro兼容！ 等不及要看新的抹布了！ 等不及要看新的抹布了！ 其实如果只看发布会，可能压根没想到这次的M5会这么难绷。 其实如果只看发布会，可能压根没想到这次的M5会这么难绷。 但看到推特网友的铺天盖地的吐槽，只能说苹果的营销这一次也糟了重。 但看到推特网友的铺天盖地的吐槽，只能说苹果的营销这一次也糟了重。 （那么，说到营销……） （那么，说到营销……） 如今，“最强的苹果芯片”已经成了一个哲学问题，以至于在2025年花12999元买一台16GB内存的笔记本，也没人太在意了。 如今，“最强的苹果芯片”已经成了一个哲学问题，以至于在2025年花12999元买一台16GB内存的笔记本，也没人太在意了。 如果不是神豪、不是收集控、也不是果粉信徒，真没必要一年一更了。 如果不是神豪、不是收集控、也不是果粉信徒，真没必要一年一更了。 最后，从夯到拉，各位彦祖亦菲如何评价这次的M5芯片？ 最后，从夯到拉，各位彦祖亦菲如何评价这次的M5芯片？ M5：苹果芯片AI性能的再次跃升 M5：苹果芯片AI性能的再次跃升 接下来来看看，这次M5到底发布啥，让网友这么不爽。 接下来来看看，这次M5到底发布啥，让网友这么不爽。 在制程方面，与9月发布的A19 Pro芯片一样，M5采用台积电 第三代3nm 工艺打造。 在制程方面，与9月发布的A19 Pro芯片一样，M5采用台积电 第三代3nm 第三代3nm 工艺打造。 这颗芯片搭载全新的10核GPU架构，每颗GPU核心都内置神经网络加速器（Neural Accelerator）。 这颗芯片搭载全新的10核GPU架构，每颗GPU核心都内置神经网络加速器（Neural Accelerator）。 同时，M5也搭载了搭载了 苹果历来最快的性能核心 ，最多达10核CPU（4颗性能核心 + 6能效核心）。 同时，M5也搭载了搭载了 苹果历来最快的性能核心 苹果历来最快的性能核心 ，最多达10核CPU（4颗性能核心 + 6能效核心）。 基于上述制程/架构，与 上一代M4 相比，M5的GPU峰值性能提升超过 4倍 ，基于AI任务的图形处理性能比 M1 提升 6倍 ，多线程CPU性能最高提升 15% 。 基于上述制程/架构，与 上一代M4 上一代M4 相比，M5的GPU峰值性能提升超过 4倍 4倍 ，基于AI任务的图形处理性能比 M1 M1 提升 6倍 6倍 ，多线程CPU性能最高提升 15% 15% 。 图形性能提升最高 45% ，统一内存带宽从 120GB/s 提升至153GB/s，提升近 30% 。 图形性能提升最高 45% 45% ，统一内存带宽从 120GB/s 120GB/s 提升至153GB/s，提升近 30% 30% 。 此外，M5芯片还集成了 16核神经网络引擎 和强大的媒体处理引擎，使设备端 AI 模型运行更快、更高效。 此外，M5芯片还集成了 16核神经网络引擎 16核神经网络引擎 和强大的媒体处理引擎，使设备端 AI 模型运行更快、更高效。 无论是在扩散模型、LM Studio、webAI等应用中进行 AI 推理，还是处理大型创意文件、视频渲染、3D 图形项目，M5 都能带来显著提速，同时保证能效表现，为MacBook Pro、iPad Pro 和 Apple Vision Pro提供史上最强的算力和流畅体验。 无论是在扩散模型、LM Studio、webAI等应用中进行 AI 推理，还是处理大型创意文件、视频渲染、3D 图形项目，M5 都能带来显著提速，同时保证能效表现，为MacBook Pro、iPad Pro 和 Apple Vision Pro提供史上最强的算力和流畅体验。 为AI与图形性能优化的新一代GPU架构 为AI与图形性能优化的新一代GPU架构 M5的GPU架构专为AI与图形性能优化，10核处理器的每一颗核心都配备神经网络加速器，并引入第三代光线追踪引擎和第二代动态缓存。 M5的GPU架构专为AI与图形性能优化，10核处理器的每一颗核心都配备神经网络加速器，并引入第三代光线追踪引擎和第二代动态缓存。 这让M5的图形性能相比M4提升最多30%，相比M1提升超过2.5倍，光线追踪等图形处理性能最高提升可达45%。 这让M5的图形性能相比M4提升最多30%，相比M1提升超过2.5倍，光线追踪等图形处理性能最高提升可达45%。 在Apple Vision Pro上，micro-OLED显示屏的像素渲染能力提升10%，刷新率最高达120Hz，画面更细腻、动态模糊更低，为游戏、3D 渲染和图形密集型创意应用提供更流畅、更真实的视觉效果。 在Apple Vision Pro上，micro-OLED显示屏的像素渲染能力提升10%，刷新率最高达120Hz，画面更细腻、动态模糊更低，为游戏、3D 渲染和图形密集型创意应用提供更流畅、更真实的视觉效果。 而且，M5芯片的16核神经网络引擎配合CPU和GPU中的神经加速器，全面优化AI任务，使Apple Vision Pro上的空间场景生成、自影像等功能运行更快、更高效。 而且，M5芯片的16核神经网络引擎配合CPU和GPU中的神经加速器，全面优化AI任务，使Apple Vision Pro上的空间场景生成、自影像等功能运行更快、更高效。 在更快的神经网络引擎加持下，AI 驱动的系统体验（如Apple Vision Pro 上拍摄自影像）运行速度提升最高可达50%。 在更快的神经网络引擎加持下，AI 驱动的系统体验（如Apple Vision Pro 上拍摄自影像）运行速度提升最高可达50%。 此外，GPU 与苹果软件框架（Core ML、Metal Performance Shaders、Metal 4 等）无缝整合，开发者可以利用Metal4张量API直接调用神经网络加速器，为应用构建高效AI解决方案。 此外，GPU 与苹果软件框架（Core ML、Metal Performance Shaders、Metal 4 等）无缝整合，开发者可以利用Metal4张量API直接调用神经网络加速器，为应用构建高效AI解决方案。 内存与多线程：为设备端大模型赋能 内存与多线程：为设备端大模型赋能 在内存方面，M5芯片支持高达32GB的统一内存，带宽高达153GB/s，较M4芯片提升近30%，是M1芯片的两倍以上。 在内存方面，M5芯片支持高达32GB的统一内存，带宽高达153GB/s，较M4芯片提升近30%，是M1芯片的两倍以上。 统一内存架构不仅提升了多线程性能，也让图形处理和神经网络加速器的 AI 推理速度大幅增加。 统一内存架构不仅提升了多线程性能，也让图形处理和神经网络加速器的 AI 推理速度大幅增加。 在MacBook Pro、iPad Pro和Apple Vision Pro上，用户可以同时运行Adobe Photoshop、Final Cut Pro等高负载创意应用，同时处理大型文件，效率大幅提升。 在MacBook Pro、iPad Pro和Apple Vision Pro上，用户可以同时运行Adobe Photoshop、Final Cut Pro等高负载创意应用，同时处理大型文件，效率大幅提升。 One more thing One more thing 这两天，库克来华除了卖手机，还联动了泡泡玛特的王宁。 这两天，库克来华除了卖手机，还联动了泡泡玛特的王宁。 苹果官网也上了库克形象的labubu，售价99美元。 苹果官网也上了库克形象的labubu，售价99美元。 （期待一手泡泡玛特和苹果影业的联动？） （期待一手泡泡玛特和苹果影业的联动？） 但就网友对M5的这反应…… 但就网友对M5的这反应…… 要不——厨子先别走了，接着带货，接着舞？ 要不——厨子先别走了，接着带货，接着舞？ 参考链接 参考链接 [1]https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/ [1]https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/ [2]https://x.com/TailosiveTech/status/1978543142321246704 [2]https://x.com/TailosiveTech/status/1978543142321246704 [3]https://x.com/aaronp613/status/1978470617927073873 [3]https://x.com/aaronp613/status/1978470617927073873 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342841.html", "title": "刚刚，一家具身智能明星公司原地解散了", "date": "2025-10-17", "content": "刚刚，一家具身智能明星公司原地解散了 刚刚，一家具身智能明星公司原地解散了 henry 2025-10-17 16:50:53 来源： 量子位 henry henry henry henry 2025-10-17 2025-10-17 16:50:53 16:50:53 来源： 量子位 来源： 量子位 量子位 摘要样式 5月推出，10月解散，快得多数创始员工还没过“试用期”。 5月推出，10月解散，快得多数创始员工还没过“试用期”。 5月推出，10月解散，快得多数创始员工还没过“试用期”。 亨利 发自 凹非寺 量子位 | 公众号 QbitAI 亨利 发自 凹非寺 亨利 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 消息太猛太突然，一度以为是误传。 消息太猛太突然，一度以为是误传。 就在今天， “一家明星具身智能公司原地解散” 的传闻在圈内迅速传开，而且因为公司成立时间很短，甚至都不涉及员工赔偿。 就在今天， “一家明星具身智能公司原地解散” “一家明星具身智能公司原地解散” 的传闻在圈内迅速传开，而且因为公司成立时间很短，甚至都不涉及员工赔偿。 就在一个多月前，这家公司还高调公开了新融资，以及AI技术大牛加盟作为联合创始人及CTO。 就在一个多月前，这家公司还高调公开了新融资，以及AI技术大牛加盟作为联合创始人及CTO。 以及这家具身智能公司虽然初创，但因为创始人的特殊身份和背靠的资源大树，不论如何都很难“原地解散”…… 以及这家具身智能公司虽然初创，但因为创始人的特殊身份和背靠的资源大树，不论如何都很难“原地解散”…… 然而没想到，事情被证实了。 然而没想到，事情被证实了。 量子位从不同渠道获悉，这家传闻中的具身智能明星就是 OneStar一星机器人 。 量子位从不同渠道获悉，这家传闻中的具身智能明星就是 OneStar一星机器人 OneStar一星机器人 。 一星机器人（苏州）是吉利创始人李书福之子 李星星 发起的具身智能创业项目，今年5月成立，上个月还对外官宣了新一轮投资。 一星机器人（苏州）是吉利创始人李书福之子 李星星 李星星 发起的具身智能创业项目，今年5月成立，上个月还对外官宣了新一轮投资。 更早之前，一星机器人从上海AI Lab挖来了明星研究员 ，联合创始人身份、CTO头衔。 更早之前，一星机器人从上海AI Lab挖来了明星研究员 ，联合创始人身份、CTO头衔。 ，联合创始人身份、CTO头衔。 现在，一星机器人如此突然原地解散的原因尚未可知。 现在，一星机器人如此突然原地解散的原因尚未可知。 但据说后续可能会一分为二处理——一是原有吉利相关的基础平台和业务回归吉利汽车集团； 但据说后续可能会一分为二处理——一是原有吉利相关的基础平台和业务回归吉利汽车集团； 二是具身技术团队可能会单独创业——据说技术团队已经遭遇哄抢了。 二是具身技术团队可能会单独创业——据说技术团队已经遭遇哄抢了。 从吉利走出的“具身实验室” 从吉利走出的“具身实验室” 一星机器人（OneStar Robotics）成立于2025年5月9日，由吉利控股集团股东李星星——也就是李书福之子——发起创立。 一星机器人（OneStar Robotics）成立于2025年5月9日，由吉利控股集团股东李星星——也就是李书福之子——发起创立。 公司定位于“具身智能”赛道，被视为吉利在机器人领域的关键布局。 公司定位于“具身智能”赛道，被视为吉利在机器人领域的关键布局。 董事长由潘运滨担任，早期投资人包括曹操出行、晶能微电子等吉利系产业资本。 董事长由潘运滨担任，早期投资人包括曹操出行、晶能微电子等吉利系产业资本。 公司还组建了相当强悍的科研阵容：联合复旦大学 教授团队、清华大学教授团队，以及国际知名的FastUMI数据采集团队，共同构建“模型+数据+本体”的研发体系。 公司还组建了相当强悍的科研阵容：联合复旦大学 教授团队、清华大学教授团队，以及国际知名的FastUMI数据采集团队，共同构建“模型+数据+本体”的研发体系。 教授团队、清华大学教授团队，以及国际知名的FastUMI数据采集团队，共同构建“模型+数据+本体”的研发体系。 与大多数追求炫技Demo的人形机器人公司不同，一星从成立起就明确了一条与众不同的路线——“倒做AI”。 与大多数追求炫技Demo的人形机器人公司不同，一星从成立起就明确了一条与众不同的路线——“倒做AI”。 这意味着他们不再从算法或视觉Demo出发，而是从真实任务与生产场景开始，倒推算法设计、操作流程和产线布局。其目标，是让机器人在真实场景的磨练中不断进化，而不是在模拟器或展厅里表演。 这意味着他们不再从算法或视觉Demo出发，而是从真实任务与生产场景开始，倒推算法设计、操作流程和产线布局。其目标，是让机器人在真实场景的磨练中不断进化，而不是在模拟器或展厅里表演。 这种“场景优先”的理念在当时显得颇为独特，也带有某种吉利风格：他们要让AI在工厂里学会工作，而非在舞台上跳舞。 这种“场景优先”的理念在当时显得颇为独特，也带有某种吉利风格：他们要让AI在工厂里学会工作，而非在舞台上跳舞。 迅速成长，光速陨落 迅速成长，光速陨落 一星机器人在成立后动作频繁。 一星机器人在成立后动作频繁。 7月，公司官宣完成数亿元“亲友轮”融资，投资方几乎全部来自吉利生态体系。 7月，公司官宣完成数亿元“亲友轮”融资，投资方几乎全部来自吉利生态体系。 同月，上海AI Lab研究员被官宣正式加盟，出任公司CTO兼联合创始人。 同月，上海AI Lab研究员被官宣正式加盟，出任公司CTO兼联合创始人。 8月28日，一星机器人与复旦大学签署协议，共建“智能机器人校企联合实验室”，并推出首款产品——“星轮1号”轮式双臂机器人。 8月28日，一星机器人与复旦大学签署协议，共建“智能机器人校企联合实验室”，并推出首款产品——“星轮1号”轮式双臂机器人。 9月17日，苏州一星机器人再次完成数亿元种子轮融资。 9月17日，苏州一星机器人再次完成数亿元种子轮融资。 这轮融资既包括BV百度风投、同创伟业等市场化机构，也有蓝黛科技等产业链投资方，以及中新集团等“城市共进”资本共同参与。 这轮融资既包括BV百度风投、同创伟业等市场化机构，也有蓝黛科技等产业链投资方，以及中新集团等“城市共进”资本共同参与。 而直到一个月后的今天，消息传来：公司团队已原地解散。 而直到一个月后的今天，消息传来：公司团队已原地解散。 一星机器人的官方公众号也清空了消息。 一星机器人的官方公众号也清空了消息。 5月推出，10月解散，快得多数创始员工还没过“试用期”。 5月推出，10月解散，快得多数创始员工还没过“试用期”。 唉…… 唉…… 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342798.html", "title": "小米最新大模型成果！罗福莉现身了", "date": "2025-10-17", "content": "小米最新大模型成果！罗福莉现身了 小米最新大模型成果！罗福莉现身了 Jay 2025-10-17 15:58:14 来源： 量子位 Jay Jay Jay Jay 2025-10-17 2025-10-17 15:58:14 15:58:14 来源： 量子位 来源： 量子位 量子位 摘要样式 MoE也能大规模强化学习 MoE也能大规模强化学习 MoE也能大规模强化学习 Jay 发自 凹非寺量子位 | 公众号 QbitAI Jay 发自 凹非寺量子位 | 公众号 QbitAI Jay 发自 凹非寺量子位 | 公众号 QbitAI 小米的最新大模型科研成果，对外曝光了。 小米的最新大模型科研成果，对外曝光了。 就在最近，小米AI团队携手北京大学联合发布了一篇聚焦MoE与强化学习的论文。 就在最近，小米AI团队携手北京大学联合发布了一篇聚焦MoE与强化学习的论文。 而其中，因为更早之前在DeepSeek R1爆火前转会小米的 罗福莉 ，也赫然在列，还是通讯作者。 而其中，因为更早之前在DeepSeek R1爆火前转会小米的 罗福莉 罗福莉 ，也赫然在列，还是通讯作者。 罗福莉硕士毕业于北京大学，这次也算是因AI串联起了小米和北大。 罗福莉硕士毕业于北京大学，这次也算是因AI串联起了小米和北大。 有意思的是，就在今年9月DeepSeek登上《Nature》的时候，罗福莉也出现在了作者名单，不过是以“北京独立研究者”的身份。 有意思的是，就在今年9月DeepSeek登上《Nature》的时候，罗福莉也出现在了作者名单，不过是以“北京独立研究者”的身份。 当时还有过风言风语，说当初“雷军千万年薪挖来AI天才少女”，当事人可能离职了。 当时还有过风言风语，说当初“雷军千万年薪挖来AI天才少女”，当事人可能离职了。 但这篇小米最新AI论文披露后，一切似乎有了答案… 但这篇小米最新AI论文披露后，一切似乎有了答案… 小米最新AI成果：找到RL中稳定和效率的平衡 小米最新AI成果：找到RL中稳定和效率的平衡 这篇论文大道至简，提出了一种在MoE架构中提高大模型强化学习的思路。 这篇论文大道至简，提出了一种在MoE架构中提高大模型强化学习的思路。 相对已经共识的是，当前强化学习已成为在预训练遇到瓶颈后，推动LLM突破能力边界的关键工具。 相对已经共识的是，当前强化学习已成为在预训练遇到瓶颈后，推动LLM突破能力边界的关键工具。 不过在MoE架构中，情况就没那么简单了，由于需要根据问题分配不同的专家，路由机制会让训练过程变得不稳定，严重时甚至会直接把模型“整崩”。 不过在MoE架构中，情况就没那么简单了，由于需要根据问题分配不同的专家，路由机制会让训练过程变得不稳定，严重时甚至会直接把模型“整崩”。 为了解决这个问题，研究团队提出了一种全新的思路，让MoE也能平稳且高效地推进大规模强化学习。 为了解决这个问题，研究团队提出了一种全新的思路，让MoE也能平稳且高效地推进大规模强化学习。 强化学习的灾难性崩溃 强化学习的灾难性崩溃 自从预训练时代告一段落，后训练成了巨头们拿起Scaling Law瞄准的的下一个战场。 自从预训练时代告一段落，后训练成了巨头们拿起Scaling Law瞄准的的下一个战场。 靠着大规模强化学习，大模型开始学会更长链路的推理，也能搞定那些需要调用工具的复杂Agent任务。 靠着大规模强化学习，大模型开始学会更长链路的推理，也能搞定那些需要调用工具的复杂Agent任务。 不过，强化学习在扩展规模的过程中，总会不可避免地撞上一道铁幕： 效率和稳定性的权衡 。 不过，强化学习在扩展规模的过程中，总会不可避免地撞上一道铁幕： 效率和稳定性的权衡 效率和稳定性的权衡 。 想要高效率，就得训练得更“猛”——更高的学习率、更大的并行度、更频繁的样本更新。可这样一来，稳定性也更容易出现问题。 想要高效率，就得训练得更“猛”——更高的学习率、更大的并行度、更频繁的样本更新。可这样一来，稳定性也更容易出现问题。 但一味追求稳定也不行，效率会被拖住，模型训练慢得像蜗牛。 但一味追求稳定也不行，效率会被拖住，模型训练慢得像蜗牛。 想要解决这个问题，得先回到强化学习的底层一探究竟。 想要解决这个问题，得先回到强化学习的底层一探究竟。 LLM的强化学习，通常分两步： LLM的强化学习，通常分两步： 第一步是推理，模型自己生成内容、和环境互动、拿到反馈分数； 第二步是训练，根据这些分数去微调自己，并想办法在下次拿更高分。 第一步是推理，模型自己生成内容、和环境互动、拿到反馈分数； 第二步是训练，根据这些分数去微调自己，并想办法在下次拿更高分。 不过，这两步通常不是在同一套系统里跑的。 不过，这两步通常不是在同一套系统里跑的。 比如，现在主流方案是 SGLang 负责生成内容，追求速度快；而 Megatron 负责训练更新，追求算得准。 比如，现在主流方案是 SGLang SGLang 负责生成内容，追求速度快；而 Megatron Megatron 负责训练更新，追求算得准。 虽然两边用的是同一套模型参数，但底层实现有细微差别，比如像随机性、精度、并行方式、缓存策略，这些看似微不足道的细节波动，都会让结果出现偏差。 虽然两边用的是同一套模型参数，但底层实现有细微差别，比如像随机性、精度、并行方式、缓存策略，这些看似微不足道的细节波动，都会让结果出现偏差。 于是就出现了一个尴尬现象： 于是就出现了一个尴尬现象： 一模一样的Prompt，两套模式下最终生成的结果都能不一样。 一模一样的Prompt，两套模式下最终生成的结果都能不一样。 这种「概率漂移」积累多了，模型就会越学越偏，最后学着学着，训练目标和实际表现彻底牛头不对马嘴。 这种「概率漂移」积累多了，模型就会越学越偏，最后学着学着，训练目标和实际表现彻底牛头不对马嘴。 这就是业内常说， 强化学习灾难性崩溃 。 这就是业内常说， 强化学习灾难性崩溃 强化学习灾难性崩溃 。 路由重放机制 路由重放机制 研究团队指出，导致MoE在强化学习中容易崩掉的罪魁祸首，在于 路由分布 。 研究团队指出，导致MoE在强化学习中容易崩掉的罪魁祸首，在于 路由分布 路由分布 。 在MoE模型中，路由器不会把所有参数都用上，而是会根据每个输入token的特征， 挑几位在该领域更擅长的“专家”出来干活 ，从而可以节省不少资源。 在MoE模型中，路由器不会把所有参数都用上，而是会根据每个输入token的特征， 挑几位在该领域更擅长的“专家”出来干活 挑几位在该领域更擅长的“专家”出来干活 ，从而可以节省不少资源。 但副作用也很明显，这种动态模式会让模型在训练阶段和推理阶段得出的最佳策略大相径庭，比传统的稠密模型要“飘忽”得多。 但副作用也很明显，这种动态模式会让模型在训练阶段和推理阶段得出的最佳策略大相径庭，比传统的稠密模型要“飘忽”得多。 对此，这篇论文给出了一种新颖的解决方案。 对此，这篇论文给出了一种新颖的解决方案。 既然问题出在路由随机，那为何不直接把路由锁住呢？ 既然问题出在路由随机，那为何不直接把路由锁住呢？ 他们的做法是：在推理时把路由分布记录下来，等到训练时再把这些分布原封不动地“重放”进去。 他们的做法是：在推理时把路由分布记录下来，等到训练时再把这些分布原封不动地“重放”进去。 这样，训练和推理就走同一条路线，不再各干各的。 这样，训练和推理就走同一条路线，不再各干各的。 根据这种“重放”的特定，研究将这种方法命名为—— Rollout Routing Replay （R3）。 根据这种“重放”的特定，研究将这种方法命名为—— Rollout Routing Replay Rollout Routing Replay （R3）。 解决了稳定性的问题，再来看看如何把 效率 也稳稳拿下。 解决了稳定性的问题，再来看看如何把 效率 效率 也稳稳拿下。 在强化学习中，模型会不断重复 “生成→获得奖励→更新→再生成” 的飞轮，一个完整过程下来，可能要跑上几十万、甚至上百万次推理。 在强化学习中，模型会不断重复 “生成→获得奖励→更新→再生成” “生成→获得奖励→更新→再生成” 的飞轮，一个完整过程下来，可能要跑上几十万、甚至上百万次推理。 要是每次生成都要从头计算上下文，算力与时间成本将呈几何式增长。 要是每次生成都要从头计算上下文，算力与时间成本将呈几何式增长。 为应对这种情况，主流推理引擎普遍采用 KVCache前缀缓存策略 ：把之前算好的上下文保存下来，下次直接“接着算”。 为应对这种情况，主流推理引擎普遍采用 KVCache前缀缓存策略 KVCache前缀缓存策略 ：把之前算好的上下文保存下来，下次直接“接着算”。 不过，除了上下文不一致，MoE架构还涉及到路由选择不一致的问题——按照传统的解决方案，即便是重复的上下文，每一次计算，模型还是要重新选专家、激活专家。 不过，除了上下文不一致，MoE架构还涉及到路由选择不一致的问题——按照传统的解决方案，即便是重复的上下文，每一次计算，模型还是要重新选专家、激活专家。 因此，研究团队在KVCache的基础上又加了一招—— 路由掩码 （routing mask）。 因此，研究团队在KVCache的基础上又加了一招—— 路由掩码 路由掩码 （routing mask）。 他们的想法是，既然对于对相同的上下文，MoE的路由结果应该一样，那干脆，把推理阶段的路由掩码和前缀KVCache一起缓存起来。 他们的想法是，既然对于对相同的上下文，MoE的路由结果应该一样，那干脆，把推理阶段的路由掩码和前缀KVCache一起缓存起来。 这样当相同上下文再次出现时，模型就能直接用上次的掩码，不必重算。 这样当相同上下文再次出现时，模型就能直接用上次的掩码，不必重算。 这样，R3就能够与现有的前缀缓存系统无缝衔接，在大规模强化学习及复杂的Agent任务中，也依然能保持出色的计算效率。 这样，R3就能够与现有的前缀缓存系统无缝衔接，在大规模强化学习及复杂的Agent任务中，也依然能保持出色的计算效率。 实验结果 实验结果 为评估R3的实际效果，研究团队基于 Qwen3-30B-A3B 模型进行了一系列实验。 为评估R3的实际效果，研究团队基于 Qwen3-30B-A3B Qwen3-30B-A3B 模型进行了一系列实验。 总体性能： 总体性能： 总体性能： 结果发现，不管在哪种场景下，R3的整体成绩都更好。 结果发现，不管在哪种场景下，R3的整体成绩都更好。 在多mini-step设置下，GRPO+R3的表现比GSPO高出 1.29分 。 在多mini-step设置下，GRPO+R3的表现比GSPO高出 1.29分 1.29分 。 若将R3与GSPO结合，性能还可以进一步提升 0.95分 。 若将R3与GSPO结合，性能还可以进一步提升 0.95分 0.95分 。 训练稳定性： 训练稳定性： 训练稳定性： 崩溃情况也少了很多。 崩溃情况也少了很多。 不难看出，随着训练时间的延长，即便到了第150步，R3依然能保持相对平缓的曲线。 不难看出，随着训练时间的延长，即便到了第150步，R3依然能保持相对平缓的曲线。 相比之下，如果是用GRPO训练，到第60步时就已经严重跑偏。 相比之下，如果是用GRPO训练，到第60步时就已经严重跑偏。 优化与生成行为： 优化与生成行为： 优化与生成行为： 而且，R3不光让模型更稳，也让它更聪明。 而且，R3不光让模型更稳，也让它更聪明。 实验结果结果表明，R3能更快找到正确方向、优化过程更丝滑，还能更早开始探索更优策略。 实验结果结果表明，R3能更快找到正确方向、优化过程更丝滑，还能更早开始探索更优策略。 一句话总结，研究团队在这篇论文提出了一种叫R3的方法，通过在训练中复用推理阶段的路由分布，能够让 MoE模型的强化学习更稳定、更高效 。 一句话总结，研究团队在这篇论文提出了一种叫R3的方法，通过在训练中复用推理阶段的路由分布，能够让 MoE模型的强化学习更稳定、更高效 MoE模型的强化学习更稳定、更高效 。 论文作者 论文作者 说完论文，再让我们看看这支由小米系和北京大学携手牵起的研究团队。 说完论文，再让我们看看这支由小米系和北京大学携手牵起的研究团队。 论文的第一作者叫 Wenhan Ma 。 论文的第一作者叫 Wenhan Ma Wenhan Ma 。 资料不多，只知道Wenhan是小米LLM-Core团队的研究员，而且还是 实习生 。 资料不多，只知道Wenhan是小米LLM-Core团队的研究员，而且还是 实习生 实习生 。 此前，他还曾参与过小米MiMo模型与多模态MiMo-VL的研发。 此前，他还曾参与过小米MiMo模型与多模态MiMo-VL的研发。 相比起来，这篇论文的两名通讯作者，大家可能更耳熟能详一点。 相比起来，这篇论文的两名通讯作者，大家可能更耳熟能详一点。 一位是 罗福莉 。 一位是 罗福莉 罗福莉 。 罗福莉本科毕业于 北京师范大学计算机专业 ，硕士阶段进入 北京大学计算语言学 深造。期间，她在不少NLP顶级会议上都发表过论文。 罗福莉本科毕业于 北京师范大学计算机专业 北京师范大学计算机专业 ，硕士阶段进入 北京大学计算语言学 北京大学计算语言学 深造。期间，她在不少NLP顶级会议上都发表过论文。 硕士毕业后，罗福莉加入 阿里巴巴达摩院 ，担任机器智能实验室研究员，负责开发多语言预训练模型 VECO ，并推动 AliceMind 项目的开源工作。 硕士毕业后，罗福莉加入 阿里巴巴达摩院 阿里巴巴达摩院 ，担任机器智能实验室研究员，负责开发多语言预训练模型 VECO VECO ，并推动 AliceMind AliceMind 项目的开源工作。 2022年，罗福莉加入DeepSeek母公司幻方量化从事深度学习相关工作，后又担任DeepSeek的深度学习研究员，参与研发DeepSeek-V2等模型。 2022年，罗福莉加入DeepSeek母公司幻方量化从事深度学习相关工作，后又担任DeepSeek的深度学习研究员，参与研发DeepSeek-V2等模型。 截至目前，罗福莉的学术论文 总引用次数已超过1.1万次 ，仅在今年一年内就新增了约 八千次引用 。 截至目前，罗福莉的学术论文 总引用次数已超过1.1万次 总引用次数已超过1.1万次 ，仅在今年一年内就新增了约 八千次引用 八千次引用 。 而另一名通讯作者，正是罗福莉的北大硕士导师—— 穗志方 。 而另一名通讯作者，正是罗福莉的北大硕士导师—— 穗志方 穗志方 。 穗教授是北京大学信息科学技术学院的教授、博士生导师，长期从事 计算语言学、文本挖掘与知识工程 研究，在NLP与AI领域发表了大量高水平论文。 穗教授是北京大学信息科学技术学院的教授、博士生导师，长期从事 计算语言学、文本挖掘与知识工程 计算语言学、文本挖掘与知识工程 研究，在NLP与AI领域发表了大量高水平论文。 但稍有有个新问题，在这篇论文成果的单位注释中，罗福莉的单位没有被明确，她既不是北大的，也没有被归入小米。 但稍有有个新问题，在这篇论文成果的单位注释中，罗福莉的单位没有被明确，她既不是北大的，也没有被归入小米。 咦……依然是独立研究者？ 咦……依然是独立研究者？ 论文： https://arxiv.org/abs/2510.11370 论文： https://arxiv.org/abs/2510.11370 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342796.html", "title": "400元遥操95%机械臂！上海交大推出开源项目U-Arm，打造通用、低成本的人机遥操作接口", "date": "2025-10-17", "content": "400元遥操95%机械臂！上海交大推出开源项目U-Arm，打造通用、低成本的人机遥操作接口 400元遥操95%机械臂！上海交大推出开源项目U-Arm，打造通用、低成本的人机遥操作接口 一水 2025-10-17 15:18:24 来源： 量子位 一水 一水 一水 一水 2025-10-17 2025-10-17 15:18:24 15:18:24 来源： 量子位 来源： 量子位 量子位 摘要样式 已在多种机械臂真机上进行遥操作验证 已在多种机械臂真机上进行遥操作验证 已在多种机械臂真机上进行遥操作验证 400元遥操95%机械臂，上海交大推出开源项目U-Arm！ 400元遥操95%机械臂，上海交大推出开源项目U-Arm！ 目前它已在XArm6、Dobot CR5、ARX R5等多种机械臂真机上进行了遥操作的验证。 目前它已在XArm6、Dobot CR5、ARX R5等多种机械臂真机上进行了遥操作的验证。 △从左往右分别为U-Arm遥操作XArm6、Dobot CR5、ARX R5 △从左往右分别为U-Arm遥操作XArm6、Dobot CR5、ARX R5 如何用更低的成本、更高的效率，去采集、复现和扩展人类的操作数据？ 如何用更低的成本、更高的效率，去采集、复现和扩展人类的操作数据？ 遥操作是当前阶段的主流数据采集方案。 遥操作是当前阶段的主流数据采集方案。 然而，完全同构的遥操作系统往往花费昂贵，例如ALOHA项目用两主两从完全同的机械臂进行遥操作，整套系统花费超过2万美金，而相对低成本的VR、手柄、GELLO框架又存在奇异点、适配难等问题。 然而，完全同构的遥操作系统往往花费昂贵，例如ALOHA项目用两主两从完全同的机械臂进行遥操作，整套系统花费超过2万美金，而相对低成本的VR、手柄、GELLO框架又存在奇异点、适配难等问题。 近日，来自上海交通大学的团队推出了一项开源解决方案—— LeRobot-Anything-U-Arm 。 近日，来自上海交通大学的团队推出了一项开源解决方案—— LeRobot-Anything-U-Arm LeRobot-Anything-U-Arm 。 这是一套仅需400元即可搭建、适配95%主流机械臂的通用遥操作系统。 这是一套仅需400元即可搭建、适配95%主流机械臂的通用遥操作系统。 3种结构覆盖市面主流机械臂类型 3种结构覆盖市面主流机械臂类型 传统的主从遥操作系统通常要求主从臂严格同构，或以一个固定比例放缩几何尺度，这在直觉上确保人类操作者能够如预期地遥控从臂，但这在实践中并非必要。 传统的主从遥操作系统通常要求主从臂严格同构，或以一个固定比例放缩几何尺度，这在直觉上确保人类操作者能够如预期地遥控从臂，但这在实践中并非必要。 团队指出，人类的视觉反馈可以自然地补偿硬件几何差异，只需保证关节的排布顺序一致，就能获得良好的操作体验。 团队指出，人类的视觉反馈可以自然地补偿硬件几何差异，只需保证关节的排布顺序一致，就能获得良好的操作体验。 而由于逆运动学解析解的存在性（Pieper准则约束）与仿人构型的设计，当前市面上主流的6轴、7轴机械臂的关节顺序只有3种。 而由于逆运动学解析解的存在性（Pieper准则约束）与仿人构型的设计，当前市面上主流的6轴、7轴机械臂的关节顺序只有3种。 于是，U-Arm便针对这三种拓扑结构分别设计了三款机械构型，用户只需根据自己机械臂的类型选择对应config的硬件，即可实现 即插即用 。 于是，U-Arm便针对这三种拓扑结构分别设计了三款机械构型，用户只需根据自己机械臂的类型选择对应config的硬件，即可实现 即插即用 即插即用 。 △三种关节构型覆盖市面主流机械臂类型 △三种关节构型覆盖市面主流机械臂类型 如文章开头的图片展示，U-Arm已在XArm6、Dobot CR5、ARX R5三种机械臂真机上进行了遥操作的验证。 如文章开头的图片展示，U-Arm已在XArm6、Dobot CR5、ARX R5三种机械臂真机上进行了遥操作的验证。 在软件兼容性方面，U-Arm推荐用基于ROS的控制方案实现遥操作框架中指令发送与接收的解耦，他们将控制器封装成了ROS节点，对于不同的从臂，只需订阅U-Arm发布的关节角度话题并发送到对应的机械臂接口即可。 在软件兼容性方面，U-Arm推荐用基于ROS的控制方案实现遥操作框架中指令发送与接收的解耦，他们将控制器封装成了ROS节点，对于不同的从臂，只需订阅U-Arm发布的关节角度话题并发送到对应的机械臂接口即可。 面向遥操专门优化的硬件设计 面向遥操专门优化的硬件设计 △U-Arm Config-2，所有硬件全部开源可复现 △U-Arm Config-2，所有硬件全部开源可复现 此前已经有了一些低成本的3D打印遥操臂工作，舵机成本是这些硬件设备的大头。以GELLO为例，不计算3D打印耗材成本的情况下，其单臂总BOM成本为288.24美元，其中所采用的Dynamixel舵机与控制板所占成本就超过了250美元。 此前已经有了一些低成本的3D打印遥操臂工作，舵机成本是这些硬件设备的大头。以GELLO为例，不计算3D打印耗材成本的情况下，其单臂总BOM成本为288.24美元，其中所采用的Dynamixel舵机与控制板所占成本就超过了250美元。 U-Arm重新设计了硬件方案，在压低成本的同时提升了可维护性和寿命。 U-Arm重新设计了硬件方案，在压低成本的同时提升了可维护性和寿命。 其选用的舵机单价仅45元人民币，一整套系统（不含3D打印材料）成本 不到400元 。 其选用的舵机单价仅45元人民币，一整套系统（不含3D打印材料）成本 不到400元 不到400元 。 此外，团队还在此基础上优化了结构设计与装配方式，来解决实际遥操过程中可能会遇到的易用性问题。 此外，团队还在此基础上优化了结构设计与装配方式，来解决实际遥操过程中可能会遇到的易用性问题。 例如，他们将舵机的齿轮箱拆除，仅保留编码器，同时在所有关节处均采用双轴固定设计，使得各关节运动时的阻力仅来自于可调节的舵盘螺丝，在确保操作顺滑的同时避免无主动扭矩的遥操臂在接近工作空间极限时，某些关节由于重力作用下坠的情况。 例如，他们将舵机的齿轮箱拆除，仅保留编码器，同时在所有关节处均采用双轴固定设计，使得各关节运动时的阻力仅来自于可调节的舵盘螺丝，在确保操作顺滑的同时避免无主动扭矩的遥操臂在接近工作空间极限时，某些关节由于重力作用下坠的情况。 实验验证效率与数据质量优势 实验验证效率与数据质量优势 团队在5种夹爪操作任务（从2层货架上夹取芬达放入纸箱、从1层货架夹取饼干、从纸箱中分拣商品放回货架、堆叠易拉罐、在猫砂盆中夹取草莓）对U-Arm的遥操作性能进行了实验。 团队在5种夹爪操作任务（从2层货架上夹取芬达放入纸箱、从1层货架夹取饼干、从纸箱中分拣商品放回货架、堆叠易拉罐、在猫砂盆中夹取草莓）对U-Arm的遥操作性能进行了实验。 在baseline的选择上，他们并没有选用VR遥操进行对比，而是选择了成本在相近水平的游戏手柄。 在baseline的选择上，他们并没有选用VR遥操进行对比，而是选择了成本在相近水平的游戏手柄。 △团队在5种操作任务上使用手柄和U-Arm进行遥操作 △团队在5种操作任务上使用手柄和U-Arm进行遥操作 实验表明，U-Arm在5种任务上的平均操作时间比使用游戏手柄进行操控缩短了39%，这主要得益于主从臂遥操的架构在优化了冗余自由度的操控性能后，在任务的大范围扫掠阶段能够以更快且自然的动作接近目标。 实验表明，U-Arm在5种任务上的平均操作时间比使用游戏手柄进行操控缩短了39%，这主要得益于主从臂遥操的架构在优化了冗余自由度的操控性能后，在任务的大范围扫掠阶段能够以更快且自然的动作接近目标。 然而，在例如堆叠易拉罐的精细任务操作上，U-Arm的执行成功率会下降，这主要是由于操作者在接近物体后，非预期的小范围移动会直接导致这些任务的失败，而使用手柄时则允许操作者“看清楚了再行动”。 然而，在例如堆叠易拉罐的精细任务操作上，U-Arm的执行成功率会下降，这主要是由于操作者在接近物体后，非预期的小范围移动会直接导致这些任务的失败，而使用手柄时则允许操作者“看清楚了再行动”。 但相较于数采效率的大幅提升，这部分失败是完全可以接受的trade-off。 但相较于数采效率的大幅提升，这部分失败是完全可以接受的trade-off。 在数据质量上，U-Arm相较手柄也能够获得更自然的运动轨迹，如下图所示。团队指出，在与其他来源的数据进行共同训练时，分布上的相似性也更有利于模型的收敛。 在数据质量上，U-Arm相较手柄也能够获得更自然的运动轨迹，如下图所示。团队指出，在与其他来源的数据进行共同训练时，分布上的相似性也更有利于模型的收敛。 △手柄（蓝）与U-Arm（红）遥操作采样轨迹对比，主从臂架构能产生更自然的末端轨迹动作 △手柄（蓝）与U-Arm（红）遥操作采样轨迹对比，主从臂架构能产生更自然的末端轨迹动作 目前，该项目已经在GitHub上开源了全部的硬件STL与STEP文件、软件例程与装配指引，提供了SAPIEN仿真环境的测试例程。团队同步在huggingface上开源了用U-Arm采集的XArm6数据，并持续更新中。 目前，该项目已经在GitHub上开源了全部的硬件STL与STEP文件、软件例程与装配指引，提供了SAPIEN仿真环境的测试例程。团队同步在huggingface上开源了用U-Arm采集的XArm6数据，并持续更新中。 项目GitHub链接：github.com/MINT-SJTU/LeRobot-Anything-U-Arm 相关技术报告：arxiv.org/abs/2509.02437 部分使用U-Arm采集的XArm数据：https://huggingface.co/MINT-SJTU 项目GitHub链接：github.com/MINT-SJTU/LeRobot-Anything-U-Arm 相关技术报告：arxiv.org/abs/2509.02437 部分使用U-Arm采集的XArm数据：https://huggingface.co/MINT-SJTU 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342786.html", "title": "爱诗科技完成B+轮1亿元融资，ARR突破4000万美金", "date": "2025-10-17", "content": "爱诗科技完成B+轮1亿元融资，ARR突破4000万美金 爱诗科技完成B+轮1亿元融资，ARR突破4000万美金 量子位的朋友们 2025-10-17 15:08:50 来源： 量子位 量子位的朋友们 量子位的朋友们 量子位的朋友们 量子位的朋友们 2025-10-17 2025-10-17 15:08:50 15:08:50 来源： 量子位 来源： 量子位 量子位 摘要样式 从模型突破到普惠应用 从模型突破到普惠应用 从模型突破到普惠应用 10月17日，AI视频企业爱诗科技宣布完成1亿元人民币B+轮融资，由复星锐正、同创伟业、顺禧基金等共同投资。公司旗下产品 PixVerse 与 拍我AI 服务于C端大众与专业创作者，目前用户规模已突破一亿，并在全球范围内快速成长：年度经常性收入（ARR）超过4000万美元，目前产品MAU超过1600万。公司2024年11月正式商业化，不到一年时间收入增长超过10倍，是过去一年全球收入和用户增长最快的AI平台之一。 10月17日，AI视频企业爱诗科技宣布完成1亿元人民币B+轮融资，由复星锐正、同创伟业、顺禧基金等共同投资。公司旗下产品 PixVerse 与 拍我AI 服务于C端大众与专业创作者，目前用户规模已突破一亿，并在全球范围内快速成长：年度经常性收入（ARR）超过4000万美元，目前产品MAU超过1600万。公司2024年11月正式商业化，不到一年时间收入增长超过10倍，是过去一年全球收入和用户增长最快的AI平台之一。 此前9月10日，爱诗科技完成B轮融资，总金额超过6000万美元。该轮融资由阿里巴巴领投，达晨财智、深创投、北京市AI基金、湖南电广传媒、巨人网络和Antler跟投。此轮融资创下国内视频生成领域单次最大融资额，资金将为公司未来的技术研发和市场拓展储备力量，持续推动AI视频生成技术的普惠。 此前9月10日，爱诗科技完成B轮融资，总金额超过6000万美元。该轮融资由阿里巴巴领投，达晨财智、深创投、北京市AI基金、湖南电广传媒、巨人网络和Antler跟投。此轮融资创下国内视频生成领域单次最大融资额，资金将为公司未来的技术研发和市场拓展储备力量，持续推动AI视频生成技术的普惠。 在AI视频生成领域，从技术探索到规模化应用的转变是一个关键阶段。能够同时聚集海量用户、构建社交场域并展现出清晰商业化路径的产品仍然较为稀少。在AI原生应用中，PixVerse两年时间内迅速成为全球普通消费者体验和消费AI视频内容的“第一站”。 在AI视频生成领域，从技术探索到规模化应用的转变是一个关键阶段。能够同时聚集海量用户、构建社交场域并展现出清晰商业化路径的产品仍然较为稀少。在AI原生应用中，PixVerse两年时间内迅速成为全球普通消费者体验和消费AI视频内容的“第一站”。 从技术突破到普惠体验：AI视频进入“实用”阶段 从技术突破到普惠体验：AI视频进入“实用”阶段 作为国内首个发布DiT架构视频生成模型的创业公司，爱诗科技在极速生成与一致性等关键维度实现全球领先。成立两年来，爱诗科技自研视频生成大模型进行了五次迭代，共八个版本的更新，为用户提供准实时、高质量且音画同步的视频生成服务。 作为国内首个发布DiT架构视频生成模型的创业公司，爱诗科技在极速生成与一致性等关键维度实现全球领先。成立两年来，爱诗科技自研视频生成大模型进行了五次迭代，共八个版本的更新，为用户提供准实时、高质量且音画同步的视频生成服务。 8月27日，PixVerse V5上线，基于准实时生成能力，全面优化了动态效果、超清视觉处理、一致性保持、指令遵循等核心环节，在效率与质量上同步跃升。与PixVerse V5同步上线的，是全新Agent创作助手功能，在Agent创作助手帮助下，普通用户无需掌握复杂的prompt技巧，也能一键生成专业级视频。 8月27日，PixVerse V5上线，基于准实时生成能力，全面优化了动态效果、超清视觉处理、一致性保持、指令遵循等核心环节，在效率与质量上同步跃升。与PixVerse V5同步上线的，是全新Agent创作助手功能，在Agent创作助手帮助下，普通用户无需掌握复杂的prompt技巧，也能一键生成专业级视频。 PixVerse（拍我AI）凭借“速度快、易上手、创意可控”的产品理念，逐步成为全球创作者使用AI视频生成的首选平台。平台通过准实时生成与角色驱动视频等核心技术，大幅降低创作门槛，并在影像、广告、游戏制作等领域逐步应用。 PixVerse（拍我AI）凭借“速度快、易上手、创意可控”的产品理念，逐步成为全球创作者使用AI视频生成的首选平台。平台通过准实时生成与角色驱动视频等核心技术，大幅降低创作门槛，并在影像、广告、游戏制作等领域逐步应用。 社交化飞轮推动增长，创意模板驱动全球文化共鸣 社交化飞轮推动增长，创意模板驱动全球文化共鸣 PixVerse 的增长并非依赖单一爆款，而是源于“创作–分享–互动”的社交飞轮与本地化运营。自2023年10月推出特效模板功能以来，美国、欧洲、巴西、印度、日本等市场展现出鲜明的本地化偏好：在墨西哥和印度，“KissKiss”“Hug”等模板长期位列热门，单日生成使用峰值均超30万，用户借此创作拥抱耶稣、Brahmin等文化象征的视频，引发广泛共鸣；美国、意大利、英国等地，“Hug Your Love”“Kiss Me, AI!”等浪漫主题模板热度持续，用户甚至自发创作“Creepy Devil Smile”等二次传播模板。 PixVerse 的增长并非依赖单一爆款，而是源于“创作–分享–互动”的社交飞轮与本地化运营。自2023年10月推出特效模板功能以来，美国、欧洲、巴西、印度、日本等市场展现出鲜明的本地化偏好：在墨西哥和印度，“KissKiss”“Hug”等模板长期位列热门，单日生成使用峰值均超30万，用户借此创作拥抱耶稣、Brahmin等文化象征的视频，引发广泛共鸣；美国、意大利、英国等地，“Hug Your Love”“Kiss Me, AI!”等浪漫主题模板热度持续，用户甚至自发创作“Creepy Devil Smile”等二次传播模板。 通过模型性能与创作体验的双向优化，平台持续提升AI视频生成的灵活性与可玩性。例如，Agent创作助手里的“3D Figurine Factory” 模板带动多国DAU增长超200%。而平台另一个特效模板“Earth Zoom Challenge”成为全球用户展示家乡风景与创意叙事的新窗口，进一步强化了平台的社交属性。 通过模型性能与创作体验的双向优化，平台持续提升AI视频生成的灵活性与可玩性。例如，Agent创作助手里的“3D Figurine Factory” 模板带动多国DAU增长超200%。而平台另一个特效模板“Earth Zoom Challenge”成为全球用户展示家乡风景与创意叙事的新窗口，进一步强化了平台的社交属性。 目前，公司全球用户规模已突破 1 亿。PixVerse（拍我AI）持续推动 AI 视频生成走向更广泛的日常应用场景。 目前，公司全球用户规模已突破 1 亿。PixVerse（拍我AI）持续推动 AI 视频生成走向更广泛的日常应用场景。 商业化与生态共建：从用户订阅到开放平台 商业化与生态共建：从用户订阅到开放平台 稳定的用户增长和高社区粘性，为商业化奠定了坚实基础。爱诗科技的ARR主要来源于会员订阅服务，2024年11月公司启动商业化业务。同时，今年初才开放的API生态也表现突出。 稳定的用户增长和高社区粘性，为商业化奠定了坚实基础。爱诗科技的ARR主要来源于会员订阅服务，2024年11月公司启动商业化业务。同时，今年初才开放的API生态也表现突出。 截至8月31日，PixVerse（拍我AI）开放平台在过去半年里通过API生成的视频数量突破1000万个。 随着V5大模型、Agent智能体以及多主体生成等能力的更新，八月单月API调用量即实现翻倍，助力合作伙伴更轻松地创建叙事驱动的视频内容。 截至8月31日，PixVerse（拍我AI）开放平台在过去半年里通过API生成的视频数量突破1000万个。 随着V5大模型、Agent智能体以及多主体生成等能力的更新，八月单月API调用量即实现翻倍，助力合作伙伴更轻松地创建叙事驱动的视频内容。 PixVerse 9月入选了 a16z “全球 Top 50 生成式 AI 消费级移动应用”榜单第 25 位。根据AIGCRank数据，PixVerse9月网站访问量增长超过26.91%，移动和网页端双增长佐证了平台推动AI视频从个人娱乐向产业生产全面升级。 PixVerse 9月入选了 a16z “全球 Top 50 生成式 AI 消费级移动应用”榜单第 25 位。根据AIGCRank数据，PixVerse9月网站访问量增长超过26.91%，移动和网页端双增长佐证了平台推动AI视频从个人娱乐向产业生产全面升级。 市场潜力与拓展AI创作边界 市场潜力与拓展AI创作边界 爱诗科技通过准实时生成、角色驱动视频等核心技术大幅降低创作门槛。PixVerse作为全球最早实现角色驱动视频生成的平台之一，在V4更早实现音画同步，极大增强了内容的生动性与情感连接。首尾帧、续写和重绘等功能让创意和故事在AI视频中“活”起来，增强了创作者对“故事叙事”的掌控力，在广告、影视、游戏制作中逐步应用起来。 爱诗科技通过准实时生成、角色驱动视频等核心技术大幅降低创作门槛。PixVerse作为全球最早实现角色驱动视频生成的平台之一，在V4更早实现音画同步，极大增强了内容的生动性与情感连接。首尾帧、续写和重绘等功能让创意和故事在AI视频中“活”起来，增强了创作者对“故事叙事”的掌控力，在广告、影视、游戏制作中逐步应用起来。 日前，爱诗科技创始人兼CEO王长虎在为FIRST惊喜电影展Untitled单元“任意门大奖”颁奖时表示：“任何伟大的创作都源于一次还未被命名的瞬间。我们特别期待看到实验性的、阶段性的、但充满无限可能的作品。就像一扇扇任意门，让我们看到了更广阔的世界。”华人导演蒋珊珊以AIGC重构视觉逻辑的《小丑》，凭借其独特的AI影像风格和深刻的表现张力，赢得了评委的高度评价，荣获任意门大奖。PixVerse也在9月中旬携10部全球创作者打造的AI影像作品亮相釜山电影节InnoAsia，并发起 AI Boot Camp（人工智能训练营），面向全球导演、创作者与影视从业者，与来自世界各地的导演、编剧和影像爱好者面对面交流。 日前，爱诗科技创始人兼CEO王长虎在为FIRST惊喜电影展Untitled单元“任意门大奖”颁奖时表示：“任何伟大的创作都源于一次还未被命名的瞬间。我们特别期待看到实验性的、阶段性的、但充满无限可能的作品。就像一扇扇任意门，让我们看到了更广阔的世界。”华人导演蒋珊珊以AIGC重构视觉逻辑的《小丑》，凭借其独特的AI影像风格和深刻的表现张力，赢得了评委的高度评价，荣获任意门大奖。PixVerse也在9月中旬携10部全球创作者打造的AI影像作品亮相釜山电影节InnoAsia，并发起 AI Boot Camp（人工智能训练营），面向全球导演、创作者与影视从业者，与来自世界各地的导演、编剧和影像爱好者面对面交流。 凭借“速度快、易上手、创意可控”的产品哲学，PixVerse（拍我 AI）正成为全球普通创作者体验AI视频的第一站。从准实时生成、角色驱动视频到开放平台生态，爱诗科技正以持续的产品迭代与普惠化创新，引领AI视频行业从“概念热”走向“真实用”。 凭借“速度快、易上手、创意可控”的产品哲学，PixVerse（拍我 AI）正成为全球普通创作者体验AI视频的第一站。从准实时生成、角色驱动视频到开放平台生态，爱诗科技正以持续的产品迭代与普惠化创新，引领AI视频行业从“概念热”走向“真实用”。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342761.html", "title": "AGI今天起有了量化标准！Bengio牵头定义，当前进度条58%", "date": "2025-10-17", "content": "AGI今天起有了量化标准！Bengio牵头定义，当前进度条58% AGI今天起有了量化标准！Bengio牵头定义，当前进度条58% 闻乐 2025-10-17 14:11:00 来源： 量子位 闻乐 闻乐 闻乐 闻乐 2025-10-17 2025-10-17 14:11:00 14:11:00 来源： 量子位 来源： 量子位 量子位 摘要样式 最强AI也还差得远 最强AI也还差得远 最强AI也还差得远 闻乐 发自 凹非寺 量子位 | 公众号 QbitAI 闻乐 发自 凹非寺 闻乐 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 长期以来，AGI都笼罩在“类人智能”的模糊表述中。 长期以来，AGI都笼罩在“类人智能”的模糊表述中。 都说它像人一样聪明，那到底有多聪明呢？ 都说它像人一样聪明，那到底有多聪明呢？ 图灵奖得主 Yoshua Bengio 联合Center for AI Safety、加州大学伯克利分校等机构的新作 《A Definition of AGI》 给AGI下了个可衡量的定义。 图灵奖得主 Yoshua Bengio Yoshua Bengio 联合Center for AI Safety、加州大学伯克利分校等机构的新作 《A Definition of AGI》 《A Definition of AGI》 给AGI下了个可衡量的定义。 “AGI is an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.” AGI是能匹配或超越受过良好教育成年人的认知广度（versatility ）和熟练度（ proficiency）的人工智能。 “AGI is an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.” “AGI is an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.” AGI是能匹配或超越受过良好教育成年人的认知广度（versatility ）和熟练度（ proficiency）的人工智能。 AGI是能匹配或超越受过良好教育成年人的认知广度（versatility ）和熟练度（ proficiency）的人工智能。 该定义包含两个关键维度： 该定义包含两个关键维度： 确定了参照系 直接锚定“受过良好教育的成年人”，避免了“AGI是超人类智能”这类模糊表述，让评估有了具体标准。 强调全面性 不看AI在单一任务上的表现，而是要求它在多个核心认知领域（如推理、记忆、感知等）都达标，不能有严重的偏科。 确定了参照系 确定了参照系 确定了参照系 直接锚定“受过良好教育的成年人”，避免了“AGI是超人类智能”这类模糊表述，让评估有了具体标准。 直接锚定“受过良好教育的成年人”，避免了“AGI是超人类智能”这类模糊表述，让评估有了具体标准。 强调全面性 强调全面性 强调全面性 不看AI在单一任务上的表现，而是要求它在多个核心认知领域（如推理、记忆、感知等）都达标，不能有严重的偏科。 不看AI在单一任务上的表现，而是要求它在多个核心认知领域（如推理、记忆、感知等）都达标，不能有严重的偏科。 研究团队设计了一套量化方法来评估当前AI离AGI的距离。 研究团队设计了一套量化方法来评估当前AI离AGI的距离。 分数越高，离AGI越近 分数越高，离AGI越近 为了把这个标准落地，研究者参考了心理学里验证过的 卡特尔-霍恩-卡罗尔（CHC）理论 这个研究人类认知能力的经典模型。 为了把这个标准落地，研究者参考了心理学里验证过的 卡特尔-霍恩-卡罗尔（CHC）理论 卡特尔-霍恩-卡罗尔（CHC）理论 这个研究人类认知能力的经典模型。 该模型将人类通用智力拆解为10个相互独立但又关联的核心认知领域，涵盖了从基础感知到高阶推理的完整认知链条，基于这10个领域，研究团队对人类传统认知测试题进行了 AI适配改造 。 该模型将人类通用智力拆解为10个相互独立但又关联的核心认知领域，涵盖了从基础感知到高阶推理的完整认知链条，基于这10个领域，研究团队对人类传统认知测试题进行了 AI适配改造 AI适配改造 。 剔除依赖人类生理感知（如触觉测试）或特定场景（如驾驶场景测试）的题目，保留核心认知逻辑，形成了一套包含500余道题目的AGI评估题库。具体包括： 剔除依赖人类生理感知（如触觉测试）或特定场景（如驾驶场景测试）的题目，保留核心认知逻辑，形成了一套包含500余道题目的AGI评估题库。具体包括： 知识（K）：主要测试常识、自然科学、社会科学、历史、文化等方面的知识储备。 读写（RW）：考察阅读和写作能力，包括对文本的理解、语言表达、文字创作等。 数学（M）：涉及数学计算、定量推理、数字概念的掌握等数学能力。 临场推理（R）：即处理新颖问题、进行逻辑分析与抽象思维的能力，也就是流体推理能力。 工作记忆（WM）：指短期信息的保持与实时加工能力。 长时记忆存储（MS）：衡量AI系统将信息进行长期稳定存储的能力。 长时记忆提取（MR）：考查AI能否从长期记忆中高效地提取所需信息。 视觉（V）：包括图像识别、空间定位、视觉信息解读等视觉加工能力。 听觉（A）：涉及声音识别、语音理解、听觉信息处理等听觉加工能力。 速度（S）：主要评估AI快速处理简单认知任务的效率。 知识（K）：主要测试常识、自然科学、社会科学、历史、文化等方面的知识储备。 知识（K）：主要测试常识、自然科学、社会科学、历史、文化等方面的知识储备。 读写（RW）：考察阅读和写作能力，包括对文本的理解、语言表达、文字创作等。 读写（RW）：考察阅读和写作能力，包括对文本的理解、语言表达、文字创作等。 数学（M）：涉及数学计算、定量推理、数字概念的掌握等数学能力。 数学（M）：涉及数学计算、定量推理、数字概念的掌握等数学能力。 临场推理（R）：即处理新颖问题、进行逻辑分析与抽象思维的能力，也就是流体推理能力。 临场推理（R）：即处理新颖问题、进行逻辑分析与抽象思维的能力，也就是流体推理能力。 工作记忆（WM）：指短期信息的保持与实时加工能力。 工作记忆（WM）：指短期信息的保持与实时加工能力。 长时记忆存储（MS）：衡量AI系统将信息进行长期稳定存储的能力。 长时记忆存储（MS）：衡量AI系统将信息进行长期稳定存储的能力。 长时记忆提取（MR）：考查AI能否从长期记忆中高效地提取所需信息。 长时记忆提取（MR）：考查AI能否从长期记忆中高效地提取所需信息。 视觉（V）：包括图像识别、空间定位、视觉信息解读等视觉加工能力。 视觉（V）：包括图像识别、空间定位、视觉信息解读等视觉加工能力。 听觉（A）：涉及声音识别、语音理解、听觉信息处理等听觉加工能力。 听觉（A）：涉及声音识别、语音理解、听觉信息处理等听觉加工能力。 速度（S）：主要评估AI快速处理简单认知任务的效率。 速度（S）：主要评估AI快速处理简单认知任务的效率。 评估采用百分制，每个认知领域满分10分，系统总分达到100分即判定为达到AGI水平，分数越高代表离AGI的距离越近。 评估采用百分制，每个认知领域满分10分，系统总分达到100分即判定为达到AGI水平，分数越高代表离AGI的距离越近。 AI虽然进步快，但离AGI还很远 AI虽然进步快，但离AGI还很远 研究团队运用上述评估体系，对当前主流LLM进行了全面测试，结果既展现了AI的快速进步，也暴露了其与AGI的巨大差距。 研究团队运用上述评估体系，对当前主流LLM进行了全面测试，结果既展现了AI的快速进步，也暴露了其与AGI的巨大差距。 从总分来看，2023年发布的GPT-4总分仅为27分，而2025年版GPT-5总分提升至58分. 从总分来看，2023年发布的GPT-4总分仅为27分，而2025年版GPT-5总分提升至58分. 两年间，分数增幅超过115%，反映出大模型在认知能力上的快速迭代。 两年间，分数增幅超过115%，反映出大模型在认知能力上的快速迭代。 但从AGI的及格线100分来看，即使是GPT-5，也尚未突破半程线，甚至在长时记忆存储领域中拿了0分。 但从AGI的及格线100分来看，即使是GPT-5，也尚未突破半程线，甚至在长时记忆存储领域中拿了0分。 具体来说，当前AI与论文中定义的AGI更关键的差异体现在 认知领域的不均衡性 上。 具体来说，当前AI与论文中定义的AGI更关键的差异体现在 认知领域的不均衡性 认知领域的不均衡性 上。 优势领域集中 优势领域集中 据实验结果来看，当前AI的 优势高度集中于知识储备与符号处理类领域 。 据实验结果来看，当前AI的 优势高度集中于知识储备与符号处理类领域 优势高度集中于知识储备与符号处理类领域 。 在知识（K）、读写（RW）、数学（M）三个领域表现突出，GPT-5在这三项的得分都超过了8。 在知识（K）、读写（RW）、数学（M）三个领域表现突出，GPT-5在这三项的得分都超过了8。 △知识（K）领域评估 △知识（K）领域评估 △知识（K）领域评估 △读写（RW）领域评估 △读写（RW）领域评估 △读写（RW）领域评估 △数学（M）领域评估 △数学（M）领域评估 △数学（M）领域评估 这些优势的共性在于均围绕文本符号的理解与应用展开，是大模型在万亿级数据训练中形成的模式匹配能力的集中体现。 这些优势的共性在于均围绕文本符号的理解与应用展开，是大模型在万亿级数据训练中形成的模式匹配能力的集中体现。 AI在依赖海量数据训练的任务中，在这些方面展现出了接近人类成年人的水平。 AI在依赖海量数据训练的任务中，在这些方面展现出了接近人类成年人的水平。 核心短板显著 核心短板显著 与集中的优势形成鲜明对比，实验暴露出AI在 感知、记忆、推理等基础认知领域存在致命短板 ，并且这些短板无法通过单纯的扩大规模弥补。 与集中的优势形成鲜明对比，实验暴露出AI在 感知、记忆、推理等基础认知领域存在致命短板 感知、记忆、推理等基础认知领域存在致命短板 ，并且这些短板无法通过单纯的扩大规模弥补。 在 “视觉（V）” 、 “听觉（A）”领域，大模型的表现堪称惨淡。 在 “视觉（V）” 、 “听觉（A）”领域，大模型的表现堪称惨淡。 △视觉（V）领域评估 △视觉（V）领域评估 △视觉（V）领域评估 △听觉（A）领域评估 △听觉（A）领域评估 △听觉（A）领域评估 GPT-4完全不具备图像识别与声音处理能力，即使GPT-5也仅能完成简单的猫犬分类、基础语音转文字，远无法实现人类级别的复杂场景解读与情感识别。 GPT-4完全不具备图像识别与声音处理能力，即使GPT-5也仅能完成简单的猫犬分类、基础语音转文字，远无法实现人类级别的复杂场景解读与情感识别。 “长时记忆存储（MS）”与“提取（MR）”是另一致命缺陷，说明AI有健忘症。 “长时记忆存储（MS）”与“提取（MR）”是另一致命缺陷，说明AI有健忘症。 △长时记忆存储（MS）领域评估 △长时记忆存储（MS）领域评估 △长时记忆存储（MS）领域评估 △长时记忆提取（MR）领域评估 △长时记忆提取（MR）领域评估 △长时记忆提取（MR）领域评估 无法实现信息的长期稳定存储，也就做不到对学习的内容灵活运用。 无法实现信息的长期稳定存储，也就做不到对学习的内容灵活运用。 “伪全能” 的本质 “伪全能” 的本质 部分大模型看似具备多任务处理能力，实则是 通过技术手段掩盖短板 。 部分大模型看似具备多任务处理能力，实则是 通过技术手段掩盖短板 通过技术手段掩盖短板 。 例如，部分模型通过扩大上下文窗口（如支持128k tokens的文本输入），假装具备长期记忆能力，但本质上仍是短期工作记忆的扩展，无法实现信息的长期存储与跨场景调用。 例如，部分模型通过扩大上下文窗口（如支持128k tokens的文本输入），假装具备长期记忆能力，但本质上仍是短期工作记忆的扩展，无法实现信息的长期存储与跨场景调用。 还有模型依赖联网搜索功能补充知识，看似无所不知，实则暴露了自身知识更新滞后、易产生幻觉的缺陷。 还有模型依赖联网搜索功能补充知识，看似无所不知，实则暴露了自身知识更新滞后、易产生幻觉的缺陷。 而这项研究的评估体系明确排除了外部工具的辅助， 仅衡量AI系统的原生认知能力 ，使得这些伪全能表现无所遁形。 而这项研究的评估体系明确排除了外部工具的辅助， 仅衡量AI系统的原生认知能力 仅衡量AI系统的原生认知能力 ，使得这些伪全能表现无所遁形。 当然了，论文也明确指出，这套评估只看AI自身的认知硬实力，不管它能调用多少外部工具，也不看它能赚多少钱、替代多少工作， 纯粹聚焦于智力本身 。 当然了，论文也明确指出，这套评估只看AI自身的认知硬实力，不管它能调用多少外部工具，也不看它能赚多少钱、替代多少工作， 纯粹聚焦于智力本身 纯粹聚焦于智力本身 。 就算某个AI总分再高，只要像长期记忆这样的核心领域是零分，本质上还是有严重缺陷的“残次版”智能，离真正的AGI也还差得远。 就算某个AI总分再高，只要像长期记忆这样的核心领域是零分，本质上还是有严重缺陷的“残次版”智能，离真正的AGI也还差得远。 这下，AGI有了可以衡量的定义，从概念到现实，还有多久呢？ 这下，AGI有了可以衡量的定义，从概念到现实，还有多久呢？ 论文地址：https://www.agidefinition.ai/paper.pdf 参考链接：https://x.com/DanHendrycks/status/1978828377269117007 论文地址：https://www.agidefinition.ai/paper.pdf 参考链接：https://x.com/DanHendrycks/status/1978828377269117007 — 完 — — 完 — 量子位 QbitAI · 头条号签约 量子位 QbitAI · 头条号签约 关注我们，第一时间获知前沿科技动态 关注我们，第一时间获知前沿科技动态 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342735.html", "title": "李飞飞发布全新世界模型，单GPU就能跑！", "date": "2025-10-17", "content": "李飞飞发布全新世界模型，单GPU就能跑！ 李飞飞发布全新世界模型，单GPU就能跑！ 时令 2025-10-17 12:39:35 来源： 量子位 时令 时令 时令 时令 2025-10-17 2025-10-17 12:39:35 12:39:35 来源： 量子位 来源： 量子位 量子位 摘要样式 可永久互动 可永久互动 可永久互动 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 李飞飞的世界模型创业，最新成果来了！ 李飞飞的世界模型创业，最新成果来了！ 刚刚，教母亲自宣布对外推出全新模型 RTFM （A Real-Time Frame Model），不仅具备实时运行、持久性和3D一致性，更关键的是—— 刚刚，教母亲自宣布对外推出全新模型 RTFM RTFM （A Real-Time Frame Model），不仅具备实时运行、持久性和3D一致性，更关键的是—— 单张H100 GPU就能跑 。 单张H100 GPU就能跑 单张H100 GPU就能跑 。 此外，RTFM的设计遵循三大核心原则： 此外，RTFM的设计遵循三大核心原则： 效率：仅需单张H100 GPU，RTFM便能以交互级帧率实时完成推理运算。 效率：仅需单张H100 GPU，RTFM便能以交互级帧率实时完成推理运算。 可扩展性：该架构具备随数据量与算力增长而持续扩展的能力。它通过端到端的通用架构从海量视频数据中自主学习，无需依赖显式3D表征即可构建三维世界模型。 可扩展性：该架构具备随数据量与算力增长而持续扩展的能力。它通过端到端的通用架构从海量视频数据中自主学习，无需依赖显式3D表征即可构建三维世界模型。 持久性：用户可无限时长与RTFM交互，所有场景将永久留存。该系统构建的持久化3D世界不会因视角转换而消失。 持久性：用户可无限时长与RTFM交互，所有场景将永久留存。该系统构建的持久化3D世界不会因视角转换而消失。 下面具体来看。 下面具体来看。 世界模型需要大量计算资源 世界模型需要大量计算资源 强大的世界模型能够实时重建、生成并模拟具有持久性、可交互且物理精确的世界。这类模型将彻底改变从媒体到机器人技术等各行各业。 强大的世界模型能够实时重建、生成并模拟具有持久性、可交互且物理精确的世界。这类模型将彻底改变从媒体到机器人技术等各行各业。 过去一年，生成式视频建模的进展已成功应用于生成式世界建模领域。 过去一年，生成式视频建模的进展已成功应用于生成式世界建模领域。 随着技术发展，一个事实愈发清晰：生成式世界模型对算力的需求将远超当今的大型语言模型。 随着技术发展，一个事实愈发清晰：生成式世界模型对算力的需求将远超当今的大型语言模型。 若直接套用现有视频架构，生成60帧的4K交互视频流每秒需产生超过10万个token（约等于《弗兰肯斯坦》或首部《哈利·波特》的篇幅）。 若直接套用现有视频架构，生成60帧的4K交互视频流每秒需产生超过10万个token（约等于《弗兰肯斯坦》或首部《哈利·波特》的篇幅）。 而要维持一小时以上的持续交互，需处理的上下文token更将突破1亿大关。基于当前计算基础设施，这既不可行也不具备经济性。 而要维持一小时以上的持续交互，需处理的上下文token更将突破1亿大关。基于当前计算基础设施，这既不可行也不具备经济性。 李飞飞团队深信“惨痛教训”揭示的规律： 李飞飞团队深信“惨痛教训”揭示的规律： 那些能随算力增长优雅扩展的简洁方法终将在AI领域占据主导，因为它们能享受数十年来推动技术发展的算力成本指数级下降红利。生成式世界模型正处在绝佳位置，必将从持续降低的算力成本中获益。 那些能随算力增长优雅扩展的简洁方法终将在AI领域占据主导，因为它们能享受数十年来推动技术发展的算力成本指数级下降红利。生成式世界模型正处在绝佳位置，必将从持续降低的算力成本中获益。 那些能随算力增长优雅扩展的简洁方法终将在AI领域占据主导，因为它们能享受数十年来推动技术发展的算力成本指数级下降红利。生成式世界模型正处在绝佳位置，必将从持续降低的算力成本中获益。 这也就引出一个关键问题：生成式世界模型是否会被当前硬件条件所限制？能否现在就预览这项技术的雏形？ 这也就引出一个关键问题：生成式世界模型是否会被当前硬件条件所限制？能否现在就预览这项技术的雏形？ 于是，李飞飞团队设定了一个明确目标：设计一款足够高效、可立即部署，并能随算力提升持续扩展的生成式世界模型。 于是，李飞飞团队设定了一个明确目标：设计一款足够高效、可立即部署，并能随算力提升持续扩展的生成式世界模型。 他们的目的是打造仅需单张H100 GPU即可驱动的模型，在保持交互帧率的同时，确保虚拟世界永不消散。实现这些技术指标，将让他们提前窥见未来——在当下硬件上体验明日模型可能达到的高度。 他们的目的是打造仅需单张H100 GPU即可驱动的模型，在保持交互帧率的同时，确保虚拟世界永不消散。实现这些技术指标，将让他们提前窥见未来——在当下硬件上体验明日模型可能达到的高度。 这一目标深刻影响着他们从任务设定到模型架构的整个系统设计。通过精心优化推理堆栈的每个环节，融合架构设计、模型蒸馏与推理优化的前沿突破，他们致力于在当今硬件上呈现对未来模型最高保真度预览。 这一目标深刻影响着他们从任务设定到模型架构的整个系统设计。通过精心优化推理堆栈的每个环节，融合架构设计、模型蒸馏与推理优化的前沿突破，他们致力于在当今硬件上呈现对未来模型最高保真度预览。 世界模型作为学习渲染器 世界模型作为学习渲染器 传统的3D图形管线采用显式3D表征（如三角网格、高斯泼溅）构建世界模型，再通过渲染生成2D图像。这些管线依赖人工设计的数据结构与算法来模拟3D几何、材质、光照、阴影及反射等效果。 传统的3D图形管线采用显式3D表征（如三角网格、高斯泼溅）构建世界模型，再通过渲染生成2D图像。这些管线依赖人工设计的数据结构与算法来模拟3D几何、材质、光照、阴影及反射等效果。 数十年来，这类方法始终是计算机图形学领域的中流砥柱，但其难以随数据量与算力增长实现线性扩展。 数十年来，这类方法始终是计算机图形学领域的中流砥柱，但其难以随数据量与算力增长实现线性扩展。 RTFM则另辟蹊径。基于生成式视频建模的最新突破，研究团队通过训练单一神经网络，输入场景的单张或多张2D图像，即可从全新视角生成该场景的2D图像，全程无需构建任何显式3D表征。 RTFM则另辟蹊径。基于生成式视频建模的最新突破，研究团队通过训练单一神经网络，输入场景的单张或多张2D图像，即可从全新视角生成该场景的2D图像，全程无需构建任何显式3D表征。 RTFM还采用作用于帧序列的自回归扩散变换器架构，通过海量视频数据进行端到端训练，实现基于历史帧的后续帧预测。 RTFM还采用作用于帧序列的自回归扩散变换器架构，通过海量视频数据进行端到端训练，实现基于历史帧的后续帧预测。 RTFM 可以被视为一种可学习的渲染器（learned renderer）。它首先将输入的图像帧转换为神经网络中的激活（即KV cache），这些激活以隐式方式表示整个世界，在生成新帧的过程中，网络通过注意力机制从这种表示中读取信息，从而根据输入视角生成与之保持一致的世界新视图。 RTFM 可以被视为一种可学习的渲染器（learned renderer）。它首先将输入的图像帧转换为神经网络中的激活（即KV cache），这些激活以隐式方式表示整个世界，在生成新帧的过程中，网络通过注意力机制从这种表示中读取信息，从而根据输入视角生成与之保持一致的世界新视图。 从输入视图转换为世界表示，以及再从该表示中渲染新帧的机制，并不是通过手工设计的，而是通过端到端的数据训练自动学得的。 从输入视图转换为世界表示，以及再从该表示中渲染新帧的机制，并不是通过手工设计的，而是通过端到端的数据训练自动学得的。 RTFM只需在训练过程中观察到这些现象，就能够学会建模诸如反射、阴影等复杂效果。 RTFM只需在训练过程中观察到这些现象，就能够学会建模诸如反射、阴影等复杂效果。 可以说，RTFM模糊了“重建”（在已有视角之间进行插值）与“生成”（创造输入视角中不可见的新内容）之间的界限，而这两者在计算机视觉中历史上一直被视为两个独立的问题。 可以说，RTFM模糊了“重建”（在已有视角之间进行插值）与“生成”（创造输入视角中不可见的新内容）之间的界限，而这两者在计算机视觉中历史上一直被视为两个独立的问题。 当RTFM被提供大量输入视角时，由于任务约束更强，它更倾向于执行重建；当输入视角较少时，它则被迫进行超出已有视角的外推生成。 当RTFM被提供大量输入视角时，由于任务约束更强，它更倾向于执行重建；当输入视角较少时，它则被迫进行超出已有视角的外推生成。 将姿态帧作为空间记忆 将姿态帧作为空间记忆 现实世界的一个关键特性是持久性（persistence）：当你移开视线时，世界不会消失或完全改变，无论你离开多长时间，你总是可以回到之前去过的地方。 现实世界的一个关键特性是持久性（persistence）：当你移开视线时，世界不会消失或完全改变，无论你离开多长时间，你总是可以回到之前去过的地方。 这对自回归帧模型来说一直是一个挑战。世界仅通过二维图像帧被隐式表示，因此，实现持久性要求模型在用户探索世界的过程中，对不断增长的帧集合进行推理。这意味着每生成一帧的成本都比前一帧更高，因此模型对世界的记忆实际上受到其计算资源预算的限制。 这对自回归帧模型来说一直是一个挑战。世界仅通过二维图像帧被隐式表示，因此，实现持久性要求模型在用户探索世界的过程中，对不断增长的帧集合进行推理。这意味着每生成一帧的成本都比前一帧更高，因此模型对世界的记忆实际上受到其计算资源预算的限制。 RTFM通过将每一帧建模为在三维空间中具有一个姿态（位置和方向）来规避这一问题。他们通过向模型提供待生成帧的姿态来生成新帧。 RTFM通过将每一帧建模为在三维空间中具有一个姿态（位置和方向）来规避这一问题。他们通过向模型提供待生成帧的姿态来生成新帧。 模型对世界的记忆（包含在其帧中）具有空间结构。它将带有姿态的帧作为空间记忆使用。这为模型提供了一个弱先验——即它所建模的世界是三维欧几里得空间——而无需强制模型显式预测该世界中物体的三维几何形状。 模型对世界的记忆（包含在其帧中）具有空间结构。它将带有姿态的帧作为空间记忆使用。这为模型提供了一个弱先验——即它所建模的世界是三维欧几里得空间——而无需强制模型显式预测该世界中物体的三维几何形状。 RTFM的空间记忆使得持久性不受限制。在生成新帧时，他们会从已姿态帧的空间记忆中检索附近帧，以为模型构建一个定制的上下文。 RTFM的空间记忆使得持久性不受限制。在生成新帧时，他们会从已姿态帧的空间记忆中检索附近帧，以为模型构建一个定制的上下文。 团队将这一技术称为上下文切换（context juggling）：模型在不同空间区域生成内容时会使用不同的上下文帧。这使得RTFM能够在长时间交互中保持对大型世界的持久记忆，而无需对不断增长的帧集合进行推理。 团队将这一技术称为上下文切换（context juggling）：模型在不同空间区域生成内容时会使用不同的上下文帧。这使得RTFM能够在长时间交互中保持对大型世界的持久记忆，而无需对不断增长的帧集合进行推理。 最后，该模型即日起以预览版形式开放体验，现在就可以试起来了… 最后，该模型即日起以预览版形式开放体验，现在就可以试起来了… 试完欢迎回来补个反馈评论哦，笔芯～ 试完欢迎回来补个反馈评论哦，笔芯～ 参考链接： [1]https://x.com/drfeifei/status/1978840835341914164 [2]https://x.com/theworldlabs/status/1978839175320186988 [3]https://www.worldlabs.ai/blog/rtfm 参考链接： [1]https://x.com/drfeifei/status/1978840835341914164 [2]https://x.com/theworldlabs/status/1978839175320186988 [3]https://www.worldlabs.ai/blog/rtfm 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342714.html", "title": "日产找到了爆款密码：华为技术，中国主导", "date": "2025-10-17", "content": "日产找到了爆款密码：华为技术，中国主导 日产找到了爆款密码：华为技术，中国主导 杰西卡 2025-10-17 12:37:50 来源： 量子位 杰西卡 杰西卡 杰西卡 杰西卡 2025-10-17 2025-10-17 12:37:50 12:37:50 来源： 量子位 来源： 量子位 量子位 摘要样式 首款插混轿车亮相 首款插混轿车亮相 首款插混轿车亮相 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 杰西卡 发自 副驾寺 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 智能车参考 | 公众号 AI4Auto N7爆款之后，日产已经找到中国市场的爆单密码了。 N7爆款之后，日产已经找到中国市场的爆单密码了。 中国设计、中国技术，尽可能中国化。 中国设计、中国技术，尽可能中国化。 中国设计、中国技术，尽可能中国化。 刚刚，就在今年的最后一个季度，日产一口气拿出了三款新能源新车： 刚刚，就在今年的最后一个季度，日产一口气拿出了三款新能源新车： 日产首款插混轿车 N6 、首搭华为座舱的 天籁·鸿蒙座舱 、以及首款插混皮卡 FRONTIER PRO 。 日产首款插混轿车 N6 N6 、首搭华为座舱的 天籁·鸿蒙座舱 天籁·鸿蒙座舱 、以及首款插混皮卡 FRONTIER PRO FRONTIER PRO 。 更关键的是——这三款车，都由中国团队主导研发。 更关键的是——这三款车，都由中国团队主导研发。 一个明显的讯号是，日产在中国，开始用全新的思路造车。 一个明显的讯号是，日产在中国，开始用全新的思路造车。 这或许才是日产来到中国 40周年 ，一种最有意义的庆祝方式——不靠情怀牌，而是用新的技术和速度，回应时代之变。 这或许才是日产来到中国 40周年 40周年 ，一种最有意义的庆祝方式——不靠情怀牌，而是用新的技术和速度，回应时代之变。 四季度发布三款新车，日产变快了 四季度发布三款新车，日产变快了 今年四季度，日产计划发布三款新车： 今年四季度，日产计划发布三款新车： 日产N6 、 天籁·鸿蒙座舱 ，以及 FRONTIER PRO 。 日产N6 日产N6 、 天籁·鸿蒙座舱 天籁·鸿蒙座舱 ，以及 FRONTIER PRO FRONTIER PRO 。 日产“N系列”的第二款车 日产N6 ，延续了N7家族化设计语言，车身尺寸4831×1885×1494mm，轴距2815mm，是日产的 首款插电混动轿车 。 日产“N系列”的第二款车 日产N6 日产N6 ，延续了N7家族化设计语言，车身尺寸4831×1885×1494mm，轴距2815mm，是日产的 首款插电混动轿车 首款插电混动轿车 。 根据工信部披露，N6将搭载1.5L自然吸气发动机，配备21.1kWh电池，CLTC工况下纯电续航里程将达 130公里 。 根据工信部披露，N6将搭载1.5L自然吸气发动机，配备21.1kWh电池，CLTC工况下纯电续航里程将达 130公里 130公里 。 “神车”天籁的最新版本—— 天籁·鸿蒙座舱 ，外界称之为“天籁PLUS”，是 全球首款 搭载华为鸿蒙座舱5的燃油车。 “神车”天籁的最新版本—— 天籁·鸿蒙座舱 天籁·鸿蒙座舱 ，外界称之为“天籁PLUS”，是 全球首款 全球首款 搭载华为鸿蒙座舱5的燃油车。 车内升级了15.6英寸大屏，还配备了HUAWEI SOUND音响。 车内升级了15.6英寸大屏，还配备了HUAWEI SOUND音响。 外观是全新V-Motion家族式设计语言，前脸采用大尺寸飞翼式格栅，悬浮立体式车标上方配备贯穿式LED灯带。 外观是全新V-Motion家族式设计语言，前脸采用大尺寸飞翼式格栅，悬浮立体式车标上方配备贯穿式LED灯带。 车身延续轿跑风格，长度增加至4920mm，轴距保持2825mm，溜背造型延续了轿跑风格，视觉上更显修长。 车身延续轿跑风格，长度增加至4920mm，轴距保持2825mm，溜背造型延续了轿跑风格，视觉上更显修长。 还有一款FRONTIER PRO是日产 首款插混皮卡 ，同时也提供燃油版本，上海车展的时候已经亮相过。 还有一款FRONTIER PRO是日产 首款插混皮卡 首款插混皮卡 ，同时也提供燃油版本，上海车展的时候已经亮相过。 插混版搭载1.5T发动机+电机，配备32.8kWh电池，纯电续航135km。 插混版搭载1.5T发动机+电机，配备32.8kWh电池，纯电续航135km。 燃油版有2.0T汽油和2.3T柴油可选。最大功率136Kw，最大扭矩500Nm。 燃油版有2.0T汽油和2.3T柴油可选。最大功率136Kw，最大扭矩500Nm。 特别的是，这三款车都是由 中国团队主导开发 的，日产中国管理委员会主席、东风汽车有限公司总裁马智欣表示： 特别的是，这三款车都是由 中国团队主导开发 中国团队主导开发 的，日产中国管理委员会主席、东风汽车有限公司总裁马智欣表示： 在产品定义、开发节奏、供应链整合，以及价格策略上，中国团队都拿到了比以往更大的主动权。 在产品定义、开发节奏、供应链整合，以及价格策略上，中国团队都拿到了比以往更大的主动权。 在产品定义、开发节奏、供应链整合，以及价格策略上，中国团队都拿到了比以往更大的主动权。 这意味着日产面向中国的产品逻辑变了：从走进中国，变成了更懂中国，真正实现了为中国造车，并从中国走向全球。 这意味着日产面向中国的产品逻辑变了：从走进中国，变成了更懂中国，真正实现了为中国造车，并从中国走向全球。 而且日产CEO伊凡·埃斯皮诺萨透露，日产经典款的全新 Z Nismo ，也会在明年进入中国市场。 而且日产CEO伊凡·埃斯皮诺萨透露，日产经典款的全新 Z Nismo Z Nismo ，也会在明年进入中国市场。 他还表示，日产转型的关键，就在中国。中国不只是重要，而应当是至关重要。 他还表示，日产转型的关键，就在中国。中国不只是重要，而应当是至关重要。 事实上，中国汽车工业的现代化历程，如果被拉成一条时间线，那么日产一定在其中占有一席之地。 事实上，中国汽车工业的现代化历程，如果被拉成一条时间线，那么日产一定在其中占有一席之地。 40年前，中国街头还少有进口汽车；40年后，日产的轩逸、天籁、奇骏，已成了几代家庭的出行记忆。 40年前，中国街头还少有进口汽车；40年后，日产的轩逸、天籁、奇骏，已成了几代家庭的出行记忆。 日产与中国的关系，已经不止于“合资车”的范畴，更像是一个老朋友，一路见证了中国汽车市场从无到有、从油到电、从机械到智能的一次次跃迁。 日产与中国的关系，已经不止于“合资车”的范畴，更像是一个老朋友，一路见证了中国汽车市场从无到有、从油到电、从机械到智能的一次次跃迁。 但也是在这40年里，这家曾被誉为 “技术日产” 的日本品牌，走到了一个全新的拐点。 但也是在这40年里，这家曾被誉为 “技术日产” “技术日产” 的日本品牌，走到了一个全新的拐点。 进入中国市场40周年的当口，对日产而言，在纪念意义之外，更像是一场自我更新的倒计时。 进入中国市场40周年的当口，对日产而言，在纪念意义之外，更像是一场自我更新的倒计时。 日产中国，40年一巨变 日产中国，40年一巨变 1985年，日产设立了日产汽车公司北京办事处，自此正式宣告打开中国市场大门。 1985年，日产设立了日产汽车公司北京办事处，自此正式宣告打开中国市场大门。 等到1993年，日产成立了与在华的第一家整车合资企业——郑州日产汽车有限公司。2000年5月，东风与日产开始接触；三年之后，东风汽车有限公司正式成立——那是中国汽车工业最经典的合资年代。 等到1993年，日产成立了与在华的第一家整车合资企业——郑州日产汽车有限公司。2000年5月，东风与日产开始接触；三年之后，东风汽车有限公司正式成立——那是中国汽车工业最经典的合资年代。 彼时的日产，带着当时最先进的CVT无级变速技术、VQ系列发动机进入中国市场。 彼时的日产，带着当时最先进的CVT无级变速技术、VQ系列发动机进入中国市场。 机械上的细腻、动力的平顺、油耗的控制，让日产一度成为“家用轿车教科书”；从蓝鸟、阳光到天籁、轩逸、奇骏……又让其被冠以 “技术日产” 的名号，一路高歌猛进。 机械上的细腻、动力的平顺、油耗的控制，让日产一度成为“家用轿车教科书”；从蓝鸟、阳光到天籁、轩逸、奇骏……又让其被冠以 “技术日产” “技术日产” 的名号，一路高歌猛进。 一直到2018年，日产在中国的销量到达巅峰，全年销量突破 156万辆 ，成为中国市场最稳健的合资车企之一。 一直到2018年，日产在中国的销量到达巅峰，全年销量突破 156万辆 156万辆 ，成为中国市场最稳健的合资车企之一。 同年，轩逸单车年销接近 50万辆 ，成为中国最畅销的轿车。 同年，轩逸单车年销接近 50万辆 50万辆 ，成为中国最畅销的轿车。 那是日产在中国最辉煌的阶段，合资黄金时代的顶点。产品逻辑清晰、品牌形象稳定、经销网络庞大……在燃油车的逻辑下，日产几乎没有短板。 那是日产在中国最辉煌的阶段，合资黄金时代的顶点。产品逻辑清晰、品牌形象稳定、经销网络庞大……在燃油车的逻辑下，日产几乎没有短板。 只是，时代的风口，总是会在最安稳的时候转关。 只是，时代的风口，总是会在最安稳的时候转关。 转折出现在 2019年 ，中国市场内新能源与智能化的火苗，颠覆了“好车”的标准。 转折出现在 2019年 2019年 ，中国市场内新能源与智能化的火苗，颠覆了“好车”的标准。 驾驶体验、交互智能以及性价比，开始成为消费者的新关注点。 驾驶体验、交互智能以及性价比，开始成为消费者的新关注点。 而对所有日系品牌来说，这一场技术跃迁，几乎是一次“系统性冲击”。 而对所有日系品牌来说，这一场技术跃迁，几乎是一次“系统性冲击”。 日产的反应并不算慢。早在2010年代初，它就推出了全球第一款量产纯电车型—— 聆风 。但问题在于，这场创新并没有在中国市场延续。 日产的反应并不算慢。早在2010年代初，它就推出了全球第一款量产纯电车型—— 聆风 聆风 。但问题在于，这场创新并没有在中国市场延续。 这边的中国车企，正在用海量的本土数据训练智能辅助驾驶系统、打造智能座舱、构建生态闭环时，而日产一派的不少传统车企，仍在用燃油车的思路和研发节奏运营。 这边的中国车企，正在用海量的本土数据训练智能辅助驾驶系统、打造智能座舱、构建生态闭环时，而日产一派的不少传统车企，仍在用燃油车的思路和研发节奏运营。 带来的结果是，在新能源浪潮中，日产陷入了挑战： 带来的结果是，在新能源浪潮中，日产陷入了挑战： 一方面是 电动车上市节奏较慢 ，错过市场红利期，早期凭借聆风抢占的纯电先机，也在逐渐被追赶、超越后，才让中国版本Ariya姗姗来迟。 一方面是 电动车上市节奏较慢 电动车上市节奏较慢 ，错过市场红利期，早期凭借聆风抢占的纯电先机，也在逐渐被追赶、超越后，才让中国版本Ariya姗姗来迟。 另一方面是智驾体系较国内其他车企也不占优，速度也难以匹配本土用户需求升级。 另一方面是智驾体系较国内其他车企也不占优，速度也难以匹配本土用户需求升级。 市场数据也印证了这一点： 市场数据也印证了这一点： 2023年，日产在中国的销量约为 79万辆 ，相比巅峰期几乎腰斩。轩逸仍在撑起品牌销量，但新能源渗透率远低于行业平均。 2023年，日产在中国的销量约为 79万辆 79万辆 ，相比巅峰期几乎腰斩。轩逸仍在撑起品牌销量，但新能源渗透率远低于行业平均。 日产与整个日系阵营一起，进入了“重新定义自己”的阶段，但日产仍保留着对技术底层的深刻理解。 日产与整个日系阵营一起，进入了“重新定义自己”的阶段，但日产仍保留着对技术底层的深刻理解。 这使得它在调整节奏后，仍有可能卷土重来。 这使得它在调整节奏后，仍有可能卷土重来。 40周年后，日产中国再出发 40周年后，日产中国再出发 2025年，是日产进入中国的第40个年头，也是它正式宣布“第二增长曲线”的节点。 2025年，是日产进入中国的第40个年头，也是它正式宣布“第二增长曲线”的节点。 日产中国的关键词，从“制造”变成了“智电化”。 日产中国的关键词，从“制造”变成了“智电化”。 改变首先体现在 技术结构的迁移 上。 改变首先体现在 技术结构的迁移 技术结构的迁移 上。 过去多是日本设计，中国制造。而现在则是中日联合开发，中国验证，面向全球。 过去多是日本设计，中国制造。而现在则是中日联合开发，中国验证，面向全球。 其次是 智能化加速 。 其次是 智能化加速 智能化加速 。 日产很早就提出了“日产智行（Nissan Intelligent Mobility）”战略，但过去更偏重于安全辅助与驾驶稳定。 日产很早就提出了“日产智行（Nissan Intelligent Mobility）”战略，但过去更偏重于安全辅助与驾驶稳定。 如今，它开始全面转向软件定义汽车的新方向： 如今，它开始全面转向软件定义汽车的新方向： 最近，日产亮相了新一代 ProPilot 2.0辅助驾驶系统 ，融合了英国自动驾驶公司 Wayve 的AI Driver软件，以及下一代激光雷达“地面实况感知”技术。 最近，日产亮相了新一代 ProPilot 2.0辅助驾驶系统 ProPilot 2.0辅助驾驶系统 ，融合了英国自动驾驶公司 Wayve Wayve 的AI Driver软件，以及下一代激光雷达“地面实况感知”技术。 功能上支持多车道的驾驶辅助，预计可以在复杂的城市道路上提供驾驶辅助功能。 功能上支持多车道的驾驶辅助，预计可以在复杂的城市道路上提供驾驶辅助功能。 这么看来，日产并不试图去“复制”中国新能源车，而是学习其速度与用户导向。这是合资品牌生存于下半场的关键。 这么看来，日产并不试图去“复制”中国新能源车，而是学习其速度与用户导向。这是合资品牌生存于下半场的关键。 而产品策略上，日产仍将油电双线并进。新能源会继续加码电动车型，计划到 2027年 ，会投放 10款新能源汽车 。 而产品策略上，日产仍将油电双线并进。新能源会继续加码电动车型，计划到 2027年 2027年 ，会投放 10款新能源汽车 10款新能源汽车 。 第一款是已经上市的N7，今年已经连续4个月销量过 6000台 ，8月甚至单月销量破万，给日产转型开了个好头。 第一款是已经上市的N7，今年已经连续4个月销量过 6000台 6000台 ，8月甚至单月销量破万，给日产转型开了个好头。 同时，燃油车也会继续坚持，并且要把智能化加入其中，让“传统燃油也智能”。 同时，燃油车也会继续坚持，并且要把智能化加入其中，让“传统燃油也智能”。 我们可以看到，日产正在把危机感转化为行动力，在中国的投入节奏明显加快。 我们可以看到，日产正在把危机感转化为行动力，在中国的投入节奏明显加快。 对于一家曾以“稳健”著称的日系品牌来说，这种“快起来”的姿态，恰恰说明日产确实在觉醒。 对于一家曾以“稳健”著称的日系品牌来说，这种“快起来”的姿态，恰恰说明日产确实在觉醒。 40年时间，对于个人而言是人生大半，对一个品牌而言，则是一次周期轮回。 40年时间，对于个人而言是人生大半，对一个品牌而言，则是一次周期轮回。 日产中国的前40年，代表了一个时代——那是外资技术主导、中国市场腾飞的黄金年代。 日产中国的前40年，代表了一个时代——那是外资技术主导、中国市场腾飞的黄金年代。 但接下来的40年，舞台已经换了主角。中国车企在智能化上领先，合资品牌要想继续存在，必须重新定义“合作”的含义。 但接下来的40年，舞台已经换了主角。中国车企在智能化上领先，合资品牌要想继续存在，必须重新定义“合作”的含义。 这也让日产40周年的意义超越纪念——它既是一个阶段性终点，也是起跑线。 这也让日产40周年的意义超越纪念——它既是一个阶段性终点，也是起跑线。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342709.html", "title": "全球创业比赛，139个国家和地区参加，中国具身机器人公司获奖！", "date": "2025-10-17", "content": "全球创业比赛，139个国家和地区参加，中国具身机器人公司获奖！ 全球创业比赛，139个国家和地区参加，中国具身机器人公司获奖！ 量子位的朋友们 2025-10-17 12:09:24 来源： 量子位 量子位的朋友们 量子位的朋友们 量子位的朋友们 量子位的朋友们 2025-10-17 2025-10-17 12:09:24 12:09:24 来源： 量子位 来源： 量子位 量子位 摘要样式 HICOOL 2025全球创业大赛获奖名单揭晓 HICOOL 2025全球创业大赛获奖名单揭晓 HICOOL 2025全球创业大赛获奖名单揭晓 10月16日，HICOOL 2025全球创业大赛获奖名单揭晓，智平方（AI² Robotics）从全球139个国家和地区的一万多个参赛项目中脱颖而出，斩获海外组一等奖，成为一等奖中唯一的机器人企业！ 10月16日，HICOOL 2025全球创业大赛获奖名单揭晓，智平方（AI² Robotics）从全球139个国家和地区的一万多个参赛项目中脱颖而出，斩获海外组一等奖，成为一等奖中唯一的机器人企业！ HICOOL全球创业大赛堪称国际创业者的“奥斯卡”，已连续五年吸引全球顶尖创新项目参与。2025年赛事规模实现历史性突破，共有10055个创业项目、13150名创业人才参赛，首次实现“双破万”。大赛累计吸引全球167个国家和地区的3.4万个项目参赛，赛后融资额超500亿元，是国际影响力最高、竞争最激烈的创业赛事之一。 HICOOL全球创业大赛堪称国际创业者的“奥斯卡”，已连续五年吸引全球顶尖创新项目参与。2025年赛事规模实现历史性突破，共有10055个创业项目、13150名创业人才参赛，首次实现“双破万”。大赛累计吸引全球167个国家和地区的3.4万个项目参赛，赛后融资额超500亿元，是国际影响力最高、竞争最激烈的创业赛事之一。 作为全球领先的通用智能机器人企业，智平方自2023年成立以来，始终坚持“大模型最智能、机器人最可靠、商业逻辑最合理”的发展路线，快速成长为中国具身智能的代表企业。 作为全球领先的通用智能机器人企业，智平方自2023年成立以来，始终坚持“大模型最智能、机器人最可靠、商业逻辑最合理”的发展路线，快速成长为中国具身智能的代表企业。 持续领先的具身大模型 ：作为全球最早坚持与推动端到端VLA技术发展的创业公司（比Figure AI还早一年），智平方原创研发了全球首个全域全身具身大模型GOVLA，且在此基础上推出开源版本FiS-VLA，在权威评测中综合性能超越国际标杆π0达30%，并获得图灵奖得主杨立昆（Yann LeCun）的关注与点赞，实现中国企业在VLA领域的全球领先。 持续领先的具身大模型 持续领先的具身大模型 ：作为全球最早坚持与推动端到端VLA技术发展的创业公司（比Figure AI还早一年），智平方原创研发了全球首个全域全身具身大模型GOVLA，且在此基础上推出开源版本FiS-VLA，在权威评测中综合性能超越国际标杆π0达30%，并获得图灵奖得主杨立昆（Yann LeCun）的关注与点赞，实现中国企业在VLA领域的全球领先。 面向量产的硬件设计 ：智平方的硬件设计以面向量产为导向，采用多次迭代、可交付的成型硬件解决方案，通过结构设计优化、模组选型优化、底层运控优化等软硬一体化技术，围绕GOVLA大模型，正向设计推出AlphaBot（爱宝）系列这样能够适应多场景、完成多任务操作的机器人，且通过自有产线保证机器人产品的稳定性及一致性，其核心部件无故障运行时间超5万小时。 面向量产的硬件设计 面向量产的硬件设计 ：智平方的硬件设计以面向量产为导向，采用多次迭代、可交付的成型硬件解决方案，通过结构设计优化、模组选型优化、底层运控优化等软硬一体化技术，围绕GOVLA大模型，正向设计推出AlphaBot（爱宝）系列这样能够适应多场景、完成多任务操作的机器人，且通过自有产线保证机器人产品的稳定性及一致性，其核心部件无故障运行时间超5万小时。 有技术复利的商业路径 ：智平方坚持最合理的商业化场景布局思路，选择有技术复利的商业路径，主张通用智能机器人从高端制造的柔性服务场景、半结构化的公共服务切入，逐步拓展到高度开放的家庭场景。目前公司已在半导体、汽车制造、生物科技、公共服务等多个领域落地应用，具身行业商业化（非表演型）单张订单体量（3年1000台）世界第一，形成行业首个真实数据闭环与场景复利。 有技术复利的商业路径 有技术复利的商业路径 ：智平方坚持最合理的商业化场景布局思路，选择有技术复利的商业路径，主张通用智能机器人从高端制造的柔性服务场景、半结构化的公共服务切入，逐步拓展到高度开放的家庭场景。目前公司已在半导体、汽车制造、生物科技、公共服务等多个领域落地应用，具身行业商业化（非表演型）单张订单体量（3年1000台）世界第一，形成行业首个真实数据闭环与场景复利。 凭借在技术、产品与商业化三方面的全面领先，智平方也赢得了资本市场的高度青睐。过去半年，公司连续完成7轮融资，单轮金额均达数亿元人民币，其中A轮由深创投领投、单家出资超亿元，成为具身智能领域融资节奏最快、规模最大的创业企业之一。 凭借在技术、产品与商业化三方面的全面领先，智平方也赢得了资本市场的高度青睐。过去半年，公司连续完成7轮融资，单轮金额均达数亿元人民币，其中A轮由深创投领投、单家出资超亿元，成为具身智能领域融资节奏最快、规模最大的创业企业之一。 此次斩获HICOOL2025全球创业大赛一等奖，不仅是对智平方技术实力与全球视野的认可，更标志着中国具身智能在世界舞台上迈向新高度。 此次斩获HICOOL2025全球创业大赛一等奖，不仅是对智平方技术实力与全球视野的认可，更标志着中国具身智能在世界舞台上迈向新高度。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342701.html", "title": "北京清华长庚医院与北电数智签署战略合作，赋能药学创新和睡眠医学研究", "date": "2025-10-17", "content": "北京清华长庚医院与北电数智签署战略合作，赋能药学创新和睡眠医学研究 北京清华长庚医院与北电数智签署战略合作，赋能药学创新和睡眠医学研究 十三 2025-10-17 12:00:36 来源： 量子位 十三 十三 十三 十三 2025-10-17 2025-10-17 12:00:36 12:00:36 来源： 量子位 来源： 量子位 量子位 摘要样式 “星火·医疗底座”助力加速健康中国建设 “星火·医疗底座”助力加速健康中国建设 “星火·医疗底座”助力加速健康中国建设 10月16日，北京清华长庚医院与北京电子数智科技有限责任公司（简称“北电数智”）达成战略合作。依托北电数智“星火·医疗底座”，双方将在药学大模型、睡眠大模型、药学可信空间、具身智能等多个“AI+医疗”创新领域开展联合攻关，并在北京清华长庚医院率先落地应用，打通技术迭代与临床验证的闭环，提升医疗服务效率与智能化水平，推动医疗普惠进程，助力健康中国战略。 10月16日，北京清华长庚医院与北京电子数智科技有限责任公司（简称“北电数智”）达成战略合作。依托北电数智“星火·医疗底座”，双方将在药学大模型、睡眠大模型、药学可信空间、具身智能等多个“AI+医疗”创新领域开展联合攻关，并在北京清华长庚医院率先落地应用，打通技术迭代与临床验证的闭环，提升医疗服务效率与智能化水平，推动医疗普惠进程，助力健康中国战略。 北京清华长庚医院院长董家鸿院士，北京清华长庚医院副院长张萍，北电数智董事长荆磊，北电数智首席科学家、复旦大学特聘教授窦德景，北电数智产业生态负责人吴岳，AI可信负责人邵兵等出席签约仪式。 北京清华长庚医院院长董家鸿院士，北京清华长庚医院副院长张萍，北电数智董事长荆磊，北电数智首席科学家、复旦大学特聘教授窦德景，北电数智产业生态负责人吴岳，AI可信负责人邵兵等出席签约仪式。 作为依托清华大学学科优势的大型公立综合性三级医院，以及市属22家医院之一，北京清华长庚医院以解决临床问题、满足社会健康需求为导向，依托清华大学综合学科优势，将医工交叉作为突破点，搭建了临床问题驱动的健康科技创新体系，具有扎实深厚的科研能力。北京清华长庚医院睡眠医学中心被称为“睡眠医学的样板工程”，在睡眠医学领域有深厚的临床实践经验。同时，作为国家食品药品监督管理总局批准的“国家药物临床试验机构”，北京清华长庚医院现已有30个专业获得开展药物临床试验的资质。 作为依托清华大学学科优势的大型公立综合性三级医院，以及市属22家医院之一，北京清华长庚医院以解决临床问题、满足社会健康需求为导向，依托清华大学综合学科优势，将医工交叉作为突破点，搭建了临床问题驱动的健康科技创新体系，具有扎实深厚的科研能力。北京清华长庚医院睡眠医学中心被称为“睡眠医学的样板工程”，在睡眠医学领域有深厚的临床实践经验。同时，作为国家食品药品监督管理总局批准的“国家药物临床试验机构”，北京清华长庚医院现已有30个专业获得开展药物临床试验的资质。 本次战略合作将深度融合北京清华长庚医院丰富的临床实践与科研经验，以及北电数智在全栈AI底座、可信数据服务和产业赋能方面的系统性优势，共同研发药学大模型、睡眠大模型，并推动药学可信空间建设，以及具身智能等前沿智能技术的应用，全面提升诊疗、医学科研、医院管理服务水平。 本次战略合作将深度融合北京清华长庚医院丰富的临床实践与科研经验，以及北电数智在全栈AI底座、可信数据服务和产业赋能方面的系统性优势，共同研发药学大模型、睡眠大模型，并推动药学可信空间建设，以及具身智能等前沿智能技术的应用，全面提升诊疗、医学科研、医院管理服务水平。 双方还将探索医疗大模型与国产AI芯片的全栈国产化适配，并研究适合医疗行业的智算中心、边缘算力中心、一体机等灵活算力部署形式。未来，北电数智与北京清华长庚医院还将共同推动大模型、数据要素等标准制定，共同编写相关行业白皮书，为行业提供可复制的创新范式。 双方还将探索医疗大模型与国产AI芯片的全栈国产化适配，并研究适合医疗行业的智算中心、边缘算力中心、一体机等灵活算力部署形式。未来，北电数智与北京清华长庚医院还将共同推动大模型、数据要素等标准制定，共同编写相关行业白皮书，为行业提供可复制的创新范式。 北京清华长庚医院院长董家鸿院士表示：“人工智能等新一代信息技术正深刻重塑各行各业，医疗健康领域也迎来了前所未有的变革机遇。‘健康中国’战略的深入推进，对提升医疗卫生服务的质量、效率、可及性和公平性提出了更高要求，也为我们利用科技手段破解发展难题指明了方向。本次战略合作旨在打破传统医疗科研的壁垒，构建一个跨学科、跨领域的‘AI+医疗’创新生态。” 北京清华长庚医院院长董家鸿院士表示：“人工智能等新一代信息技术正深刻重塑各行各业，医疗健康领域也迎来了前所未有的变革机遇。‘健康中国’战略的深入推进，对提升医疗卫生服务的质量、效率、可及性和公平性提出了更高要求，也为我们利用科技手段破解发展难题指明了方向。本次战略合作旨在打破传统医疗科研的壁垒，构建一个跨学科、跨领域的‘AI+医疗’创新生态。” 北电数智董事长荆磊表示：“医疗行业的智能化升级，关乎全民健康福祉，是人工智能最具社会价值的应用方向之一。北电数智希望以此次签约为起点，携手北京清华长庚医院共同推进AI技术在医疗领域的多场景渗透与深度应用，加速实现成果转化，并共同探索‘AI+医疗’深度融合的新路径、新范式，为行业提供可复制、可推广的落地经验。” 北电数智董事长荆磊表示：“医疗行业的智能化升级，关乎全民健康福祉，是人工智能最具社会价值的应用方向之一。北电数智希望以此次签约为起点，携手北京清华长庚医院共同推进AI技术在医疗领域的多场景渗透与深度应用，加速实现成果转化，并共同探索‘AI+医疗’深度融合的新路径、新范式，为行业提供可复制、可推广的落地经验。” 国务院日前印发的《关于深入实施“人工智能+”行动的意见》提出实施“人工智能+”民生福祉行动，指出“有序推动人工智能在辅助诊疗、健康管理、医保服务等场景的应用，大幅提高基层医疗健康服务能力和效率”。北电数智积极响应国家战略，以“星火·医疗底座”聚焦医疗行业“医、教、研、管”四大业务领域，构建起贯通数据要素激活、模型能力强化、场景落地应用的全链条医疗数智化体系，贯通“病患-基层机构-医院”服务链路，加速AI在医疗行业深度渗透，构建精准医疗服务生态。 国务院日前印发的《关于深入实施“人工智能+”行动的意见》提出实施“人工智能+”民生福祉行动，指出“有序推动人工智能在辅助诊疗、健康管理、医保服务等场景的应用，大幅提高基层医疗健康服务能力和效率”。北电数智积极响应国家战略，以“星火·医疗底座”聚焦医疗行业“医、教、研、管”四大业务领域，构建起贯通数据要素激活、模型能力强化、场景落地应用的全链条医疗数智化体系，贯通“病患-基层机构-医院”服务链路，加速AI在医疗行业深度渗透，构建精准医疗服务生态。 北电数智与北京清华长庚医院达成合作，正是对“人工智能+”行动在医疗行业落地的生动实践，通过产研协同，以AI技术赋能临床诊疗、医学科研和医院管理水平提升，加速AI技术在医疗场景的成果转化和落地应用，让基层患者同步享受优质医疗服务，加速医疗普惠进程。 北电数智与北京清华长庚医院达成合作，正是对“人工智能+”行动在医疗行业落地的生动实践，通过产研协同，以AI技术赋能临床诊疗、医学科研和医院管理水平提升，加速AI技术在医疗场景的成果转化和落地应用，让基层患者同步享受优质医疗服务，加速医疗普惠进程。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342696.html", "title": "NEURA Robotics落子杭州，为“物理AI”架设全球桥梁", "date": "2025-10-17", "content": "NEURA Robotics落子杭州，为“物理AI”架设全球桥梁 NEURA Robotics落子杭州，为“物理AI”架设全球桥梁 量子位的朋友们 2025-10-17 10:37:28 来源： 量子位 量子位的朋友们 量子位的朋友们 量子位的朋友们 量子位的朋友们 2025-10-17 2025-10-17 10:37:28 10:37:28 来源： 量子位 来源： 量子位 量子位 摘要样式 正加速推出首款通用型人形机器人 正加速推出首款通用型人形机器人 正加速推出首款通用型人形机器人 10月16日，欧洲认知机器人龙头NEURA Robotics宣布其杭州新址及协作中心正式启用。 10月16日，欧洲认知机器人龙头NEURA Robotics宣布其杭州新址及协作中心正式启用。 该“NEURA Hub”将聚焦数据驱动的机器人训练，并与国内龙头产业伙伴展开深度协作。 该“NEURA Hub”将聚焦数据驱动的机器人训练，并与国内龙头产业伙伴展开深度协作。 此次落地标志着NEURA全球战略的重要里程碑：在保持其欧洲创新基因的同时，立足亚洲机器人产业腹地，以全球视野加速技术迭代。 此次落地标志着NEURA全球战略的重要里程碑：在保持其欧洲创新基因的同时，立足亚洲机器人产业腹地，以全球视野加速技术迭代。 “未来已来”：中国机器人产业新纪元 “未来已来”：中国机器人产业新纪元 机器人行业最大痛点在于“全球数据鸿沟”——当前人形AI模型的训练数据量仅为成熟大语言模型的1/120,000，严重制约其泛化与复杂场景落地能力。 机器人行业最大痛点在于“全球数据鸿沟”——当前人形AI模型的训练数据量仅为成熟大语言模型的1/120,000，严重制约其泛化与复杂场景落地能力。 为应对这一挑战，NEURA给出的解题思路是“Neuraverse”：通过收集、连接并分发现实场景中的机器人数据，构建覆盖全球的生态系统，形成“数据共同体”，让每一台接入的机器人“学得更快、做得更好”。 为应对这一挑战，NEURA给出的解题思路是“Neuraverse”：通过收集、连接并分发现实场景中的机器人数据，构建覆盖全球的生态系统，形成“数据共同体”，让每一台接入的机器人“学得更快、做得更好”。 随着杭州中心启动，NEURA继续扩容Neuraverse，并计划落地中国首座NEURAGym（Neura实训中心）。 随着杭州中心启动，NEURA继续扩容Neuraverse，并计划落地中国首座NEURAGym（Neura实训中心）。 该中心作为独特的物理训练，可让机器人在真实场景中“学习”任务，并将数据反哺Neuraverse，实现“仿真—落地”闭环，大幅缩短人形及认知机器人商业化周期。 该中心作为独特的物理训练，可让机器人在真实场景中“学习”任务，并将数据反哺Neuraverse，实现“仿真—落地”闭环，大幅缩短人形及认知机器人商业化周期。 打造全球协作门户 打造全球协作门户 杭州中心不仅将推动本地人才培养及与中国合作伙伴的联合项目开发，还将为国际企业提供直接对接中国机器人生态的通道。 杭州中心不仅将推动本地人才培养及与中国合作伙伴的联合项目开发，还将为国际企业提供直接对接中国机器人生态的通道。 这一布局为跨境创新、市场准入及合作项目落地创造了条件，而所有合作成果都将为 “Neuraverse” 生态建设赋能。 这一布局为跨境创新、市场准入及合作项目落地创造了条件，而所有合作成果都将为 “Neuraverse” 生态建设赋能。 构建战略合作伙伴网络 构建战略合作伙伴网络 在庆典当天，NEURA与中国及跨国巨头阿里云、蒂森克虏伯（ThyssenKrupp）等9家企业集中签署合作协议，这些合作将聚焦联合创新以及NEURA技术在多行业的规模化应用，进一步完善产业协同体系。 在庆典当天，NEURA与中国及跨国巨头阿里云、蒂森克虏伯（ThyssenKrupp）等9家企业集中签署合作协议，这些合作将聚焦联合创新以及NEURA技术在多行业的规模化应用，进一步完善产业协同体系。 活动看点 活动看点 启动仪式 NEURA人形与服务机器人现场演示，全程接入Neuraverse 中国首家NEURAGym首发，展示“数据驱动”如何加速机器人创新 政府、企业、金融机构、科研院所及媒体高端交流 NEURA创始人兼CEO David Reger与产业领袖同台分享 启动仪式 启动仪式 NEURA人形与服务机器人现场演示，全程接入Neuraverse NEURA人形与服务机器人现场演示，全程接入Neuraverse 中国首家NEURAGym首发，展示“数据驱动”如何加速机器人创新 中国首家NEURAGym首发，展示“数据驱动”如何加速机器人创新 政府、企业、金融机构、科研院所及媒体高端交流 政府、企业、金融机构、科研院所及媒体高端交流 NEURA创始人兼CEO David Reger与产业领袖同台分享 NEURA创始人兼CEO David Reger与产业领袖同台分享 本次盛会吸引来自中国、欧洲及其他地区的120余家企业代表，涵盖合作伙伴、客户、供应商、金融机构、投资人及科研机构，既印证了NEURA在全球机器人赛道的“核心创新者”地位，也反映出市场对 “Neuraverse”、“NEURAGym” 等协作平台的热切期待。 本次盛会吸引来自中国、欧洲及其他地区的120余家企业代表，涵盖合作伙伴、客户、供应商、金融机构、投资人及科研机构，既印证了NEURA在全球机器人赛道的“核心创新者”地位，也反映出市场对 “Neuraverse”、“NEURAGym” 等协作平台的热切期待。 NEURA Robotics创始人兼CEO David Reger 表示：“Neuraverse之于机器人，正如iOS、Android之于智能手机——它是创新发生并规模化的平台。随着杭州中心及中国首家NEURAGym落地，我们向‘全球机器人操作系统’目标再迈关键一步。若想在类人机器人与认知机器人赛道中占据先机，就必须与中国顶尖企业携手。我们欣喜且感恩，众多领军企业将与我们同行。” NEURA Robotics创始人兼CEO David Reger NEURA Robotics创始人兼CEO David Reger 表示：“Neuraverse之于机器人，正如iOS、Android之于智能手机——它是创新发生并规模化的平台。随着杭州中心及中国首家NEURAGym落地，我们向‘全球机器人操作系统’目标再迈关键一步。若想在类人机器人与认知机器人赛道中占据先机，就必须与中国顶尖企业携手。我们欣喜且感恩，众多领军企业将与我们同行。” 关于NEURA Robotics 关于NEURA Robotics 2019年，NEURA Robotics创立于德国，该公司以“让机器人技术成为应对人类重大挑战的全球性解决方案”为使命，跨越劳动力短缺、老龄化、生产力与可持续等难题。 2019年，NEURA Robotics创立于德国，该公司以“让机器人技术成为应对人类重大挑战的全球性解决方案”为使命，跨越劳动力短缺、老龄化、生产力与可持续等难题。 这家总部位于梅青根的获奖创新企业，在全产品线（从工业机器人到家用机器人）中坚持 “单一设备集成” 理念。凭借Neuraverse，NEURA致力于打造“机器人iPhone时刻”的底座，让技术真正服务人类。AI等核心技术全部自研，旗下认知机器人具备视觉、听觉及触觉感知能力，可完全自主作业并持续学习。 这家总部位于梅青根的获奖创新企业，在全产品线（从工业机器人到家用机器人）中坚持 “单一设备集成” 理念。凭借Neuraverse，NEURA致力于打造“机器人iPhone时刻”的底座，让技术真正服务人类。AI等核心技术全部自研，旗下认知机器人具备视觉、听觉及触觉感知能力，可完全自主作业并持续学习。 目前，NEURA正携手全球伙伴，加速推出首款通用型人形机器人。 目前，NEURA正携手全球伙伴，加速推出首款通用型人形机器人。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342661.html", "title": "OpenAI最新业务：找了个黑洞物理科学家", "date": "2025-10-17", "content": "OpenAI最新业务：找了个黑洞物理科学家 OpenAI最新业务：找了个黑洞物理科学家 鱼羊 2025-10-17 09:23:09 来源： 量子位 鱼羊 鱼羊 鱼羊 鱼羊 2025-10-17 2025-10-17 09:23:09 09:23:09 来源： 量子位 来源： 量子位 量子位 摘要样式 “人工智能将彻底改变科学研究” “人工智能将彻底改变科学研究” “人工智能将彻底改变科学研究” 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 鱼羊 发自 凹非寺 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI OpenAI新研究团队，刚刚曝光了—— OpenAI新研究团队，刚刚曝光了—— OpenAI for Science，致力于构建 加速数学和物理领域新发现 的人工智能系统。 OpenAI for Science，致力于构建 加速数学和物理领域新发现 加速数学和物理领域新发现 的人工智能系统。 黑洞物理学家、物理学新视野奖获得者Alex Lupsasca官宣加盟，并且透露： 黑洞物理学家、物理学新视野奖获得者Alex Lupsasca官宣加盟，并且透露： 作为理论物理学家，我曾认为人工智能要触及研究前沿，还需要很长时间。 然而，GPT-5 Pro的出现彻底改变了我的看法。 作为理论物理学家，我曾认为人工智能要触及研究前沿，还需要很长时间。 然而，GPT-5 Pro的出现彻底改变了我的看法。 作为理论物理学家，我曾认为人工智能要触及研究前沿，还需要很长时间。 然而，GPT-5 Pro的出现彻底改变了我的看法。 他发现，只需要30分钟，GPT-5 Pro就能解决他当时花了数天时间才计算得到的“黑洞微扰理论中新对称性”的精确形式。 他发现，只需要30分钟，GPT-5 Pro就能解决他当时花了数天时间才计算得到的“黑洞微扰理论中新对称性”的精确形式。 这些以及许多其他例子让我相信：人工智能将彻底改变科学研究。 这些以及许多其他例子让我相信：人工智能将彻底改变科学研究。 这些以及许多其他例子让我相信：人工智能将彻底改变科学研究。 GPT-5 Pro 30分钟解决人类几天的难题 GPT-5 Pro 30分钟解决人类几天的难题 GPT-5 Pro具体是如何促使Alex Lupsasca（以下简称老卢）加入OpenAI的？ GPT-5 Pro具体是如何促使Alex Lupsasca（以下简称老卢）加入OpenAI的？ 一切要从这位物理学家把自己的研究课题抛给GPT-5 Pro说起。 一切要从这位物理学家把自己的研究课题抛给GPT-5 Pro说起。 今年夏天，他发表了一篇关于黑洞微扰理论中新对称性的论文，揭示黑洞没有潮汐形变的能力，即勒夫数（Love Number）为零。 今年夏天，他发表了一篇关于黑洞微扰理论中新对称性的论文，揭示黑洞没有潮汐形变的能力，即勒夫数（Love Number）为零。 解释这些对称性的物理意义，对于老卢而言相对简单，困难之处在于找到它们的精确形式。 解释这些对称性的物理意义，对于老卢而言相对简单，困难之处在于找到它们的精确形式。 作为人类科学家，他最终花了数天时间，才终于计算得到了这样的公式： 作为人类科学家，他最终花了数天时间，才终于计算得到了这样的公式： GPT-5 Pro发布后，老卢很好奇，同样的问题让AI来解，它是否能搞定？ GPT-5 Pro发布后，老卢很好奇，同样的问题让AI来解，它是否能搞定？ 结果令他大吃一惊： GPT-5 Pro不到30分钟就重新发现了这个结果 ！ 结果令他大吃一惊： GPT-5 Pro不到30分钟就重新发现了这个结果 GPT-5 Pro不到30分钟就重新发现了这个结果 ！ △老卢分享的GPT-5 Pro推理结果 △老卢分享的GPT-5 Pro推理结果 老卢简直不敢相信，接着追问GPT-5 Pro具体是怎么想的，是否是上网搜索到了他本人的论文。 老卢简直不敢相信，接着追问GPT-5 Pro具体是怎么想的，是否是上网搜索到了他本人的论文。 GPT-5 Pro否认了，“我是推导出来的”，并接着甩出了自己的思考大纲。 GPT-5 Pro否认了，“我是推导出来的”，并接着甩出了自己的思考大纲。 简单来说，为了找出这个偏微分方程的李对称性： 简单来说，为了找出这个偏微分方程的李对称性： GPT-5 Pro的思路是：先换坐标，把原方程变换到轴对称拉普拉斯上，利用其现成对称性，然后再把这些对称性按链式法则和雅克比矩阵推回到原来的变量里。 GPT-5 Pro的思路是：先换坐标，把原方程变换到轴对称拉普拉斯上，利用其现成对称性，然后再把这些对称性按链式法则和雅克比矩阵推回到原来的变量里。 第一步，选个好坐标把主部“拉平”； 第一步，选个好坐标把主部“拉平”； 第二步，考虑到原方程是散度形式，在换坐标时要乘以雅克比矩阵。 第二步，考虑到原方程是散度形式，在换坐标时要乘以雅克比矩阵。 第三步，套用“标准模板”的对称性：轴对称拉普拉斯的点对称性是教科书级别的。 第三步，套用“标准模板”的对称性：轴对称拉普拉斯的点对称性是教科书级别的。 最后，把这些对称性“拉回”到原变量(r,x)。 最后，把这些对称性“拉回”到原变量(r,x)。 尽管在处理这个问题之前，需要先用平坦空间案例对GPT-5 Pro进行训练，但在老卢看来，这点瑕不掩瑜，“其飞跃是惊人的”。 尽管在处理这个问题之前，需要先用平坦空间案例对GPT-5 Pro进行训练，但在老卢看来，这点瑕不掩瑜，“其飞跃是惊人的”。 除此之外，老卢还发现，GPT-5 Pro能解决观测天体物理学中的难题——这些问题对于一个优秀的人类研究生而言，可能也要花几天的时间才能搞定。 除此之外，老卢还发现，GPT-5 Pro能解决观测天体物理学中的难题——这些问题对于一个优秀的人类研究生而言，可能也要花几天的时间才能搞定。 问题是： 问题是： 我刚刚观测到一个快速毫米波爆发。它的峰值通量密度约为100 mJy。它在毫秒级迅速上升，随后是短暂的平台期，然后急剧下降。有初步证据表明同时存在光学爆发和可能的X射线活动。尚未识别出相关的宿主星系。你能否就此信号的起源提出最合理的理论解释（或多个解释），建议最佳的后续观测，以及对与此类活动相关的未识别源群体的潜在影响？请同时为这项发现撰写一份将在《自然》杂志上发表的摘要。 我刚刚观测到一个快速毫米波爆发。它的峰值通量密度约为100 mJy。它在毫秒级迅速上升，随后是短暂的平台期，然后急剧下降。有初步证据表明同时存在光学爆发和可能的X射线活动。尚未识别出相关的宿主星系。你能否就此信号的起源提出最合理的理论解释（或多个解释），建议最佳的后续观测，以及对与此类活动相关的未识别源群体的潜在影响？请同时为这项发现撰写一份将在《自然》杂志上发表的摘要。 我刚刚观测到一个快速毫米波爆发。它的峰值通量密度约为100 mJy。它在毫秒级迅速上升，随后是短暂的平台期，然后急剧下降。有初步证据表明同时存在光学爆发和可能的X射线活动。尚未识别出相关的宿主星系。你能否就此信号的起源提出最合理的理论解释（或多个解释），建议最佳的后续观测，以及对与此类活动相关的未识别源群体的潜在影响？请同时为这项发现撰写一份将在《自然》杂志上发表的摘要。 用时10分钟18秒，GPT-5 Pro给出了可能的理论解释，提供了后续观测建议，同时也把论文摘要写完了。 用时10分钟18秒，GPT-5 Pro给出了可能的理论解释，提供了后续观测建议，同时也把论文摘要写完了。 看到了这些，老卢开始相信“人工智能将彻底改变科学研究”，这也促使他选择加入OpenAI for Science，在一线亲身见证边界被一步步拓宽。 看到了这些，老卢开始相信“人工智能将彻底改变科学研究”，这也促使他选择加入OpenAI for Science，在一线亲身见证边界被一步步拓宽。 黑洞探测器项目负责人 黑洞探测器项目负责人 回到老卢本身，他目前也是范德堡大学物理与天文系的助理教授，在数学系亦有兼职。 回到老卢本身，他目前也是范德堡大学物理与天文系的助理教授，在数学系亦有兼职。 他分别在2011年和2017年获得了哈佛大学的学士和博士学位。博士毕业后，他先是在哈佛大学工作了3年，担任初级研究员。2020年加入普林斯顿大学。2022年获得范德堡大学教职。 他分别在2011年和2017年获得了哈佛大学的学士和博士学位。博士毕业后，他先是在哈佛大学工作了3年，担任初级研究员。2020年加入普林斯顿大学。2022年获得范德堡大学教职。 加入OpenAI前，老卢最重要的工作是“黑洞探测器（BHEX）”项目。 加入OpenAI前，老卢最重要的工作是“黑洞探测器（BHEX）”项目。 这个项目旨在将一颗卫星送入地球轨道，以拍摄天文史上最清晰的黑洞图像：深入探测黑洞的事件视界，并测量围绕其运行的“光子环”。 这个项目旨在将一颗卫星送入地球轨道，以拍摄天文史上最清晰的黑洞图像：深入探测黑洞的事件视界，并测量围绕其运行的“光子环”。 也就是说，BHEX是此前拍摄了首张黑洞照片的EHT（事件视界望远镜）的继任者，有望推动黑洞研究进入高精度时代。 也就是说，BHEX是此前拍摄了首张黑洞照片的EHT（事件视界望远镜）的继任者，有望推动黑洞研究进入高精度时代。 该任务计划于2032年发射。 该任务计划于2032年发射。 2024年，老卢还和Michael Johnson共同获得了物理学新视野奖，这个奖项由“突破奖基金会”颁出，旨在表彰在物理学领域做出卓越贡献的青年职业科学家。 2024年，老卢还和Michael Johnson共同获得了物理学新视野奖，这个奖项由“突破奖基金会”颁出，旨在表彰在物理学领域做出卓越贡献的青年职业科学家。 因其在黑洞成像方面的工作，老卢还获得了国际广义相对论与引力学会颁发的2024年IUPAP广义相对论与引力青年职业科学家奖。 因其在黑洞成像方面的工作，老卢还获得了国际广义相对论与引力学会颁发的2024年IUPAP广义相对论与引力青年职业科学家奖。 参考链接： [1]https://x.com/ALupsasca/status/1978823182917509259 [2]https://lupsasca.com/ 参考链接： [1]https://x.com/ALupsasca/status/1978823182917509259 [2]https://lupsasca.com/ — 完 — — 完 — 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342649.html", "title": "黄仁勋女儿直播亮相，聊了具身智能", "date": "2025-10-16", "content": "黄仁勋女儿直播亮相，聊了具身智能 黄仁勋女儿直播亮相，聊了具身智能 时令 2025-10-16 18:52:54 来源： 量子位 时令 时令 时令 时令 2025-10-16 2025-10-16 18:52:54 18:52:54 来源： 量子位 来源： 量子位 量子位 摘要样式 仿真才是解决数据困境的关键 仿真才是解决数据困境的关键 仿真才是解决数据困境的关键 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 黄仁勋大家都见得多了，但你见过他女儿讲具身智能吗？ 黄仁勋大家都见得多了，但你见过他女儿讲具身智能吗？ 这不，黄仁勋女儿 Madison Huang 首次公开亮相直播访谈节目，作为英伟达Omniverse与物理AI高级总监，与光轮智能CEO谢晨，以及光轮智能增长负责人穆斯塔法一起，对“如何缩小机器人在虚拟与现实之间的差距”展开深刻探讨。 这不，黄仁勋女儿 Madison Huang Madison Huang 首次公开亮相直播访谈节目，作为英伟达Omniverse与物理AI高级总监，与光轮智能CEO谢晨，以及光轮智能增长负责人穆斯塔法一起，对“如何缩小机器人在虚拟与现实之间的差距”展开深刻探讨。 光轮智能是一家专注于 仿真合成数据技术 的公司。和专注于大模型的企业不同，他们的核心目标是帮助AI更好地理解和进入物理世界。目前主要聚焦于具身智能和自动驾驶两大场景。 光轮智能是一家专注于 仿真合成数据技术 仿真合成数据技术 的公司。和专注于大模型的企业不同，他们的核心目标是帮助AI更好地理解和进入物理世界。目前主要聚焦于具身智能和自动驾驶两大场景。 在一个半小时的访谈时间内，三人提出了一系列重要观点： 在一个半小时的访谈时间内，三人提出了一系列重要观点： 合成数据对于解决机器人数据困境至关重要 。 光轮智能的SimReady资产不仅要视觉准确，更重要的是物理准确。 英伟达和光轮智能正在共同开发Isaac Lab Arena——一个用于基准测试、评估、数据收集和大规模强化学习的下一代开源框架和平台。 …… 合成数据对于解决机器人数据困境至关重要 。 合成数据对于解决机器人数据困境至关重要 。 光轮智能的SimReady资产不仅要视觉准确，更重要的是物理准确。 光轮智能的SimReady资产不仅要视觉准确，更重要的是物理准确。 英伟达和光轮智能正在共同开发Isaac Lab Arena——一个用于基准测试、评估、数据收集和大规模强化学习的下一代开源框架和平台。 …… 英伟达和光轮智能正在共同开发Isaac Lab Arena——一个用于基准测试、评估、数据收集和大规模强化学习的下一代开源框架和平台。 …… 下面具体来看。 下面具体来看。 利用合成数据和仿真来解决机器人数据障碍 利用合成数据和仿真来解决机器人数据障碍 访谈一正式开始，主持人Edmar Mendizabal（Omniverse社区经理）就开门见山抛出了一个许多人都很好奇的问题。 访谈一正式开始，主持人Edmar Mendizabal（Omniverse社区经理）就开门见山抛出了一个许多人都很好奇的问题。 英伟达与光轮智能的合作关系是如何开始的？ 英伟达与光轮智能的合作关系是如何开始的？ 英伟达与光轮智能的合作关系是如何开始的？ Madison解答道， 英伟达内部很多项目都依赖于光轮智能的支持 。例如，Gear Lab正在构建通用智能体模型，西雅图机器人实验室正在开展大量涉及接触操作和精密装配的任务。 Madison解答道， 英伟达内部很多项目都依赖于光轮智能的支持 英伟达内部很多项目都依赖于光轮智能的支持 。例如，Gear Lab正在构建通用智能体模型，西雅图机器人实验室正在开展大量涉及接触操作和精密装配的任务。 对语言模型的研究人员来说，他们可以利用整个互联网的数据去训练LLM。但对机器人领域来说，情况却完全不同，他们必须去手动采集数据，这也是为什么会有那么多数据采集工厂的出现。 对语言模型的研究人员来说，他们可以利用整个互联网的数据去训练LLM。但对机器人领域来说，情况却完全不同，他们必须去手动采集数据，这也是为什么会有那么多数据采集工厂的出现。 在这种缺乏数据的情况下，英伟达认为， 仿真就是解决方案 ，因此需要一个合成数据工厂，同时也希望合作伙伴认同OpenUSD的愿景，将其作为构建仿真就绪资产（SimReady Assets）的基础。 在这种缺乏数据的情况下，英伟达认为， 仿真就是解决方案 仿真就是解决方案 ，因此需要一个合成数据工厂，同时也希望合作伙伴认同OpenUSD的愿景，将其作为构建仿真就绪资产（SimReady Assets）的基础。 2023年，光轮智能成立了，目标就是利用合成数据和仿真来突破机器人数据瓶颈。 2023年，光轮智能成立了，目标就是利用合成数据和仿真来突破机器人数据瓶颈。 但那时机器人领域还处于非常早期的阶段，所以他们先从自动驾驶的合成数据问题入手，随后，合作几乎扩展到英伟达的各个团队。 但那时机器人领域还处于非常早期的阶段，所以他们先从自动驾驶的合成数据问题入手，随后，合作几乎扩展到英伟达的各个团队。 有意思的是，谢晨以前就是英伟达自动驾驶仿真负责人，兜兜转转，现在又在为英伟达工作了。 有意思的是，谢晨以前就是英伟达自动驾驶仿真负责人，兜兜转转，现在又在为英伟达工作了。 接下来，主持人又问道：“那现在机器人从虚拟到现实（Sim2Real）还存在哪些问题。” 接下来，主持人又问道：“那现在机器人从虚拟到现实（Sim2Real）还存在哪些问题。” 谢晨回答说： 谢晨回答说： 对于自动驾驶来说，Sim2Real是最容易解决的，因为它主要依赖视觉感知。而对于机器人来说，一切都涉及物理接触，最重要的是操作能力（manipulation）。同时，它还需要灵巧手和触觉传感器配合使用，因此问题变得更加复杂。 对于自动驾驶来说，Sim2Real是最容易解决的，因为它主要依赖视觉感知。而对于机器人来说，一切都涉及物理接触，最重要的是操作能力（manipulation）。同时，它还需要灵巧手和触觉传感器配合使用，因此问题变得更加复杂。 对于自动驾驶来说，Sim2Real是最容易解决的，因为它主要依赖视觉感知。而对于机器人来说，一切都涉及物理接触，最重要的是操作能力（manipulation）。同时，它还需要灵巧手和触觉传感器配合使用，因此问题变得更加复杂。 核心问题就在于物理准确性 。 核心问题就在于物理准确性 核心问题就在于物理准确性 。 以冰箱为例，当你拉开门时，会感觉到磁吸密封条产生的力的作用，还有拉抽屉时会感觉到多重摩擦，这些物理特性都非常精确。 以冰箱为例，当你拉开门时，会感觉到磁吸密封条产生的力的作用，还有拉抽屉时会感觉到多重摩擦，这些物理特性都非常精确。 而要实现这种物理准确性，数据非常重要，高质量的数据是进入机器人训练系统、生成正确算法的关键。 而要实现这种物理准确性，数据非常重要，高质量的数据是进入机器人训练系统、生成正确算法的关键。 因此，谢晨还特别提到了 数字金字塔 的理念。 因此，谢晨还特别提到了 数字金字塔 数字金字塔 的理念。 他认为，要让具身智能真正部署到现实世界需要消耗巨量的数据，实际上比大型语言模型所需的数据还要多。这就形成了一个巨大的数据障碍，而现实世界数据无法完全解决这个问题。 他认为，要让具身智能真正部署到现实世界需要消耗巨量的数据，实际上比大型语言模型所需的数据还要多。这就形成了一个巨大的数据障碍，而现实世界数据无法完全解决这个问题。 以自动驾驶为例，现实中有大量驾驶员和汽车在道路上运行，但在工厂、家庭等环境中，机器人数量却非常有限。 以自动驾驶为例，现实中有大量驾驶员和汽车在道路上运行，但在工厂、家庭等环境中，机器人数量却非常有限。 因此， 合成数据将成为解决具身智能数据瓶颈的最重要、最主要的数据来源 。 因此， 合成数据将成为解决具身智能数据瓶颈的最重要、最主要的数据来源 合成数据将成为解决具身智能数据瓶颈的最重要、最主要的数据来源 。 他们借助了大量物理设备来收集精确的数据，并将其实现到仿真环境中。同时，他们还设计了一些方式去对比真实世界中的力和仿真中的力，以确保二者匹配。 他们借助了大量物理设备来收集精确的数据，并将其实现到仿真环境中。同时，他们还设计了一些方式去对比真实世界中的力和仿真中的力，以确保二者匹配。 除了数据外，另一个令谢晨认为重要的点就是高效。 除了数据外，另一个令谢晨认为重要的点就是高效。 他提到，强化学习非常重要，但要运行大规模强化学习，就必须确保不同类型的仿真在计算上非常高效。 他提到，强化学习非常重要，但要运行大规模强化学习，就必须确保不同类型的仿真在计算上非常高效。 为了让大量仿真环境同时运行，他们用简单又高效的方法（如基本几何体和凸包）来检测碰撞，这样既能保持足够准确，又能节省大量计算资源。 为了让大量仿真环境同时运行，他们用简单又高效的方法（如基本几何体和凸包）来检测碰撞，这样既能保持足够准确，又能节省大量计算资源。 之后，谢晨还讲到了电缆仿真。电缆既像柔性物体，但又在某些情况下又表现得像刚体，所以它的仿真其实非常困难。 之后，谢晨还讲到了电缆仿真。电缆既像柔性物体，但又在某些情况下又表现得像刚体，所以它的仿真其实非常困难。 为了让机器人学习如何操作电缆，光轮智能与Newton及英伟达合作，为电缆构建求解器，并研发仿真就绪资产来构建这种仿真。 为了让机器人学习如何操作电缆，光轮智能与Newton及英伟达合作，为电缆构建求解器，并研发仿真就绪资产来构建这种仿真。 众所周知，人与动物的区别是人会使用工具，所以如何教机器人正确利用工具完成特定操作变得越来越关键。 众所周知，人与动物的区别是人会使用工具，所以如何教机器人正确利用工具完成特定操作变得越来越关键。 例如，让机器人在仿真中切割黄瓜是非常困难的，这不仅仅是为了数据采集，更重要的是要支持强化学习。 例如，让机器人在仿真中切割黄瓜是非常困难的，这不仅仅是为了数据采集，更重要的是要支持强化学习。 为此，光轮智能已与英伟达Isaac Sim实验室展开合作，共同致力于攻克仿真到现实的迁移挑战。 为此，光轮智能已与英伟达Isaac Sim实验室展开合作，共同致力于攻克仿真到现实的迁移挑战。 最后，谢晨提到，光轮智能还在与英伟达共同构建Isaac Lab Arena——一个面向下一代基准测试、评估数据收集和大规模强化学习的框架平台，该项目已在CoRL大会上由英伟达正式发布。 最后，谢晨提到，光轮智能还在与英伟达共同构建Isaac Lab Arena——一个面向下一代基准测试、评估数据收集和大规模强化学习的框架平台，该项目已在CoRL大会上由英伟达正式发布。 黄仁勋子女 黄仁勋子女 访谈结束，咱们再来扒一扒很少露面的黄仁勋的两个子女。 访谈结束，咱们再来扒一扒很少露面的黄仁勋的两个子女。 首先是 女儿Madison ，中文名黄敏珊，现年34岁。 首先是 女儿Madison 女儿Madison ，中文名黄敏珊，现年34岁。 2020年加入英伟达最初担任市场营销实习生，实习四个月后成为了Omniverse部门的活动营销经理，之后一直在该部门任职。 2020年加入英伟达最初担任市场营销实习生，实习四个月后成为了Omniverse部门的活动营销经理，之后一直在该部门任职。 Madison在英伟达一路担任了产品营销经理、高级产品营销经理等职务，直到今年3月成为高级总监。 Madison在英伟达一路担任了产品营销经理、高级产品营销经理等职务，直到今年3月成为高级总监。 令人惊讶的是，Madison最初干的竟然是烹饪。 令人惊讶的是，Madison最初干的竟然是烹饪。 2012年，她在美国烹饪学院取得了烹饪艺术工商管理学士学位，之后到蓝带厨艺学院学习制作甜点以及葡萄酒，并曾在纽约和旧金山担任厨师。 2012年，她在美国烹饪学院取得了烹饪艺术工商管理学士学位，之后到蓝带厨艺学院学习制作甜点以及葡萄酒，并曾在纽约和旧金山担任厨师。 2015年，Madison重新回到巴黎，加入奢侈品行业，在LVMH公司担任市场营销与开发经理。在LV工作期间，Madison还学习了伦敦政治经济学院有关数据科学的短期课程。 2015年，Madison重新回到巴黎，加入奢侈品行业，在LVMH公司担任市场营销与开发经理。在LV工作期间，Madison还学习了伦敦政治经济学院有关数据科学的短期课程。 在2019年，Madison和哥哥Spencer一起修读了MIT的短期AI高管课程。 在2019年，Madison和哥哥Spencer一起修读了MIT的短期AI高管课程。 之后，她于2021年取得了伦敦商学院的MBA学位，彼时她已经是英伟达的正式员工。 之后，她于2021年取得了伦敦商学院的MBA学位，彼时她已经是英伟达的正式员工。 说完老黄的女儿，怎么能不接着提提他儿子呢？ 说完老黄的女儿，怎么能不接着提提他儿子呢？ 同样“承袭父业”的，还有Madison的 哥哥Spencer ，中文名黄胜斌，今年35岁。 同样“承袭父业”的，还有Madison的 哥哥Spencer 哥哥Spencer ，中文名黄胜斌，今年35岁。 他在英伟达的职位是机器人产品线经理，负责开发用于机器人的AI模型与仿真软件。 他在英伟达的职位是机器人产品线经理，负责开发用于机器人的AI模型与仿真软件。 Spencer在2022年加入英伟达，起初的职位是Isaac Sim Cloud团队产品经理。 Spencer在2022年加入英伟达，起初的职位是Isaac Sim Cloud团队产品经理。 前面介绍Madison时说过，兄妹二人曾一同参加MIT的短期AI高管课程，不过Spencer还额外多读了关于人机交互的课程。 前面介绍Madison时说过，兄妹二人曾一同参加MIT的短期AI高管课程，不过Spencer还额外多读了关于人机交互的课程。 之后，Spencer先是到哈佛商学院读了短期课程，之后也读了MBA，不过是在纽约大学，2022年取得学位。 之后，Spencer先是到哈佛商学院读了短期课程，之后也读了MBA，不过是在纽约大学，2022年取得学位。 有意思的是，更早之前，Spencer的身份是一名酒吧主理人。 有意思的是，更早之前，Spencer的身份是一名酒吧主理人。 2012年，Spencer在美国最大的私立艺术与媒体学院——芝加哥哥伦比亚学院本科毕业，主修国际市场和文化研究两个方向。 2012年，Spencer在美国最大的私立艺术与媒体学院——芝加哥哥伦比亚学院本科毕业，主修国际市场和文化研究两个方向。 毕业后，老黄让他专门“回老家”学了一年中文，就是在这段时间，Spencer创立了他的鸡尾酒酒吧——R&D Cocktail Lab，而且一干就是八年。 毕业后，老黄让他专门“回老家”学了一年中文，就是在这段时间，Spencer创立了他的鸡尾酒酒吧——R&D Cocktail Lab，而且一干就是八年。 据悉，这家酒吧屡获国际大奖，并曾入选亚洲50佳酒吧，不过目前谷歌地图显示该酒吧已经永久停业。 据悉，这家酒吧屡获国际大奖，并曾入选亚洲50佳酒吧，不过目前谷歌地图显示该酒吧已经永久停业。 好好好，富二代要专心继承家业了是吧。 好好好，富二代要专心继承家业了是吧。 参考链接：https://www.youtube.com/watch?v=UgT-P6ynxLc 参考链接：https://www.youtube.com/watch?v=UgT-P6ynxLc 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342428.html", "title": "雷军公开发言了！呼吁抵制水军黑公关，资源集中技术研发", "date": "2025-10-16", "content": "雷军公开发言了！呼吁抵制水军黑公关，资源集中技术研发 雷军公开发言了！呼吁抵制水军黑公关，资源集中技术研发 一凡 2025-10-16 18:23:30 来源： 量子位 一凡 一凡 一凡 一凡 2025-10-16 2025-10-16 18:23:30 18:23:30 来源： 量子位 来源： 量子位 量子位 摘要样式 “呼吁全行业以安全为基础” “呼吁全行业以安全为基础” “呼吁全行业以安全为基础” 一凡 发自 北京 智能车参考 | 公众号 AI4Auto 一凡 发自 北京 一凡 发自 北京 智能车参考 | 公众号 AI4Auto 智能车参考 | 公众号 AI4Auto 只在地上跑，已经满足不了中国车企了。 只在地上跑，已经满足不了中国车企了。 刚刚，车圈大佬云集北京亦庄，在2025世界智能网联汽车大会上介绍了当前的成绩，展望了未来。 刚刚，车圈大佬云集北京亦庄，在2025世界智能网联汽车大会上介绍了当前的成绩，展望了未来。 李书福 透露，吉利目前在低轨已部署在轨卫星64颗。 朱华荣 则表示，长安会在2028年量产人形机器人，还谈到了与华为的合作。 李书福 李书福 透露，吉利目前在低轨已部署在轨卫星64颗。 朱华荣 朱华荣 则表示，长安会在2028年量产人形机器人，还谈到了与华为的合作。 华为 余承东 虽然缺席了今年的大会，但大会上依然含“华”量爆满。除了长安，赛力斯、广汽、北汽等车企董事长也介绍了与华为合作的最新进展。 华为 余承东 余承东 虽然缺席了今年的大会，但大会上依然含“华”量爆满。除了长安，赛力斯、广汽、北汽等车企董事长也介绍了与华为合作的最新进展。 最后，雷军压轴登场， 呼吁全行业共同抵制网络水军 。 最后，雷军压轴登场， 呼吁全行业共同抵制网络水军 呼吁全行业共同抵制网络水军 。 阅读指引： 李书福：吉利布局天地一体化科技生态 长安朱华荣：2028年量产人形机器人，2030年推出飞行汽车产品 赛力斯张兴海：率先与华为跨行合作，问界M9交付已超23万台 北汽张建勇：首发基于高通8775芯片打造的辅助驾驶 雷军：呼吁全行业“以安全为基础”，共同抵制网络水军 阅读指引： 阅读指引： 李书福：吉利布局天地一体化科技生态 李书福：吉利布局天地一体化科技生态 长安朱华荣：2028年量产人形机器人，2030年推出飞行汽车产品 长安朱华荣：2028年量产人形机器人，2030年推出飞行汽车产品 赛力斯张兴海：率先与华为跨行合作，问界M9交付已超23万台 赛力斯张兴海：率先与华为跨行合作，问界M9交付已超23万台 北汽张建勇：首发基于高通8775芯片打造的辅助驾驶 北汽张建勇：首发基于高通8775芯片打造的辅助驾驶 雷军：呼吁全行业“以安全为基础”，共同抵制网络水军 雷军：呼吁全行业“以安全为基础”，共同抵制网络水军 李书福：吉利布局天地一体化科技生态 李书福：吉利布局天地一体化科技生态 李书福 表示，吉利已经实现了算力、算法和数据AI“三驾马车”的均衡发展，接着介绍了当前的智能化成果。 李书福 李书福 表示，吉利已经实现了算力、算法和数据AI“三驾马车”的均衡发展，接着介绍了当前的智能化成果。 包括AI座舱OS Flyme Auto 2、雷神AI电混2.0、千里浩瀚辅助驾驶系统，其中千里浩瀚是李书福强调“特别值得一提”的技术。 包括AI座舱OS Flyme Auto 2、雷神AI电混2.0、千里浩瀚辅助驾驶系统，其中千里浩瀚是李书福强调“特别值得一提”的技术。 不仅是地上跑的，吉利还把目光投向了低空和低轨。 不仅是地上跑的，吉利还把目光投向了低空和低轨。 低轨方面，李书福透露目前吉利星座已经完成一期组网部署，在轨卫星64颗，卫星通信技术将在旗下多个品牌应用，并且探索为Robotaxi车队提供服务。 低轨方面，李书福透露目前吉利星座已经完成一期组网部署，在轨卫星64颗，卫星通信技术将在旗下多个品牌应用，并且探索为Robotaxi车队提供服务。 在低空领域，李书福认为旗下沃飞长空已成为行业头部，AE200首架机已成功下线，目标未来实现跨域出行、机场接驳、景区直达、低空游览和应急救援等需求。 在低空领域，李书福认为旗下沃飞长空已成为行业头部，AE200首架机已成功下线，目标未来实现跨域出行、机场接驳、景区直达、低空游览和应急救援等需求。 长安朱华荣：2028年量产人形机器人，2030年推出飞行汽车产品 长安朱华荣：2028年量产人形机器人，2030年推出飞行汽车产品 朱华荣首先介绍了“新长安”的基本情况，旗下有 143家 控股子公司，员工 14.5万人 ，资产总额达到了 3087亿元 。 朱华荣首先介绍了“新长安”的基本情况，旗下有 143家 143家 控股子公司，员工 14.5万人 14.5万人 ，资产总额达到了 3087亿元 3087亿元 。 1-7月，L2辅助驾驶在乘用车的渗透率已达 63% ，汽车智能化不断发展，朱华荣判断汽车未来的演化方向就是“智能汽车机器人”。 1-7月，L2辅助驾驶在乘用车的渗透率已达 63% 63% ，汽车智能化不断发展，朱华荣判断汽车未来的演化方向就是“智能汽车机器人”。 朱华荣介绍，到2030年具身智能市场规模将 超230亿美元 。 朱华荣介绍，到2030年具身智能市场规模将 超230亿美元 超230亿美元 。 长安将持续押注具身智能和飞行汽车赛道，在 2028年量产下线人形汽车机器人 ，2030年推出航线飞行汽车产品。 长安将持续押注具身智能和飞行汽车赛道，在 2028年量产下线人形汽车机器人 2028年量产下线人形汽车机器人 ，2030年推出航线飞行汽车产品。 赛力斯张兴海：率先与华为跨行合作，问界M9交付已超23万台 赛力斯张兴海：率先与华为跨行合作，问界M9交付已超23万台 赛力斯董事长 张兴海 登台首先点赞了前面发言的嘉宾： 赛力斯董事长 张兴海 张兴海 登台首先点赞了前面发言的嘉宾： 前面各位老总已经讲得很好，我深受启发。 前面各位老总已经讲得很好，我深受启发。 前面各位老总已经讲得很好，我深受启发。 接着用一系列数据，介绍了赛力斯在智能化方面的成绩。 接着用一系列数据，介绍了赛力斯在智能化方面的成绩。 张兴海表示赛力斯率先开启与华为在汽车行业的跨行合作，透露当前问界M9上市一年半，累计交付已超 23万台 ，问界品牌辅助驾驶累计里程已超38亿公里，“第三空间”每天日均使用时长为2小时。帮助用户避免潜在的碰撞200多万次。 张兴海表示赛力斯率先开启与华为在汽车行业的跨行合作，透露当前问界M9上市一年半，累计交付已超 23万台 23万台 ，问界品牌辅助驾驶累计里程已超38亿公里，“第三空间”每天日均使用时长为2小时。帮助用户避免潜在的碰撞200多万次。 最后补充一个张兴海没有谈及的数字，截止今天收盘赛力斯市值为 2622亿元 。 最后补充一个张兴海没有谈及的数字，截止今天收盘赛力斯市值为 2622亿元 2622亿元 。 北汽张建勇：首发基于高通8775芯片打造的辅助驾驶 北汽张建勇：首发基于高通8775芯片打造的辅助驾驶 北汽集团董事长 张建勇 介绍了北汽在不同等级智能驾驶上的布局。 北汽集团董事长 张建勇 张建勇 介绍了北汽在不同等级智能驾驶上的布局。 L2层面，北汽将在月底首发基于 高通8775芯片 打造的辅助驾驶系统 “元景智驾” ，面向10-15万元市场。 L2层面，北汽将在月底首发基于 高通8775芯片 高通8775芯片 打造的辅助驾驶系统 “元景智驾” “元景智驾” ，面向10-15万元市场。 L3层面，张建勇透露北汽在2023年就获得了北京首批L3路测牌照，截止今年8月北汽L3测试里程已 超11万公里 。 L3层面，张建勇透露北汽在2023年就获得了北京首批L3路测牌照，截止今年8月北汽L3测试里程已 超11万公里 超11万公里 。 L4层面，北汽联合Robotaxi明星 小马智行 基于极狐阿尔法T5打造的Robotaxi在今年7月已示范运行，今年将实现千台示范运行。 L4层面，北汽联合Robotaxi明星 小马智行 小马智行 基于极狐阿尔法T5打造的Robotaxi在今年7月已示范运行，今年将实现千台示范运行。 最后张建勇还介绍了北汽的一系列合作伙伴，合作方式有不同特点。比如地平线，北汽是和其成立了合资公司，将基于J6M开发行泊一体的智能辅助驾驶系统。 最后张建勇还介绍了北汽的一系列合作伙伴，合作方式有不同特点。比如地平线，北汽是和其成立了合资公司，将基于J6M开发行泊一体的智能辅助驾驶系统。 北汽介绍，其与华为是“车企+科技全生态”战略合作， 未来3年会投资20亿元 用于智能辅助驾驶和智能座舱。 北汽介绍，其与华为是“车企+科技全生态”战略合作， 未来3年会投资20亿元 未来3年会投资20亿元 用于智能辅助驾驶和智能座舱。 值得一提的是，张建勇在发言中全篇没有提及华为和北汽的合作项目 享界 。 值得一提的是，张建勇在发言中全篇没有提及华为和北汽的合作项目 享界 享界 。 倒是紧随其后登场的广汽集团董事长 冯兴亚 ，提及了最近和华为共创的品牌 启境 ，透露品牌首款车型将在明年上市。 倒是紧随其后登场的广汽集团董事长 冯兴亚 冯兴亚 ，提及了最近和华为共创的品牌 启境 启境 ，透露品牌首款车型将在明年上市。 雷军：呼吁全行业“以安全为基础”，共同抵制网络水军 雷军：呼吁全行业“以安全为基础”，共同抵制网络水军 在一众单独发言的嘉宾中，雷总最后压轴登场。登场第一张PPT，就是介绍小米汽车累计交付了40万台车。 在一众单独发言的嘉宾中，雷总最后压轴登场。登场第一张PPT，就是介绍小米汽车累计交付了40万台车。 然后接着介绍了YU7的智能化配置，比如全系标配了700TOPS算力、激光雷达和4D毫米波雷达。雷军认为，这样“大幅度地提高辅助驾驶系统的体验和安全性”。 然后接着介绍了YU7的智能化配置，比如全系标配了700TOPS算力、激光雷达和4D毫米波雷达。雷军认为，这样“大幅度地提高辅助驾驶系统的体验和安全性”。 此外雷军还透露，当前智能辅助驾驶专属的研发团队规模已达1800人，第一期总投入为 57.9亿元 。 此外雷军还透露，当前智能辅助驾驶专属的研发团队规模已达1800人，第一期总投入为 57.9亿元 57.9亿元 。 最后，雷军认为当前行业发展不是“零和博弈”，呼吁全行业要 “以安全为基础” ，把资源和精力集中到科技创新和技术研发上， 共同抵制网络水军和“黑公关” 。 最后，雷军认为当前行业发展不是“零和博弈”，呼吁全行业要 “以安全为基础” “以安全为基础” ，把资源和精力集中到科技创新和技术研发上， 共同抵制网络水军和“黑公关” 共同抵制网络水军和“黑公关” 。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342420.html", "title": "阿里发布Qoder CLI，可在终端一键实现AI编程", "date": "2025-10-16", "content": "阿里发布Qoder CLI，可在终端一键实现AI编程 阿里发布Qoder CLI，可在终端一键实现AI编程 henry 2025-10-16 16:43:01 来源： 量子位 henry henry henry henry 2025-10-16 2025-10-16 16:43:01 16:43:01 来源： 量子位 来源： 量子位 量子位 摘要样式 目前，Qoder已拥有IDE和CLI两种产品形态。 目前，Qoder已拥有IDE和CLI两种产品形态。 目前，Qoder已拥有IDE和CLI两种产品形态。 10月16日凌晨，阿里全新AI编程工具Qoder CLI（命令行界面）正式上线，该工具具备强大的代码生成与理解能力，并大幅降低内存消耗和命令响应时间，进一步提升开发效率。即日起，全球开发者可通过任意命令行终端使用Qoder CLI体验代码生成、调试和部署等任务。 10月16日凌晨，阿里全新AI编程工具Qoder CLI（命令行界面）正式上线，该工具具备强大的代码生成与理解能力，并大幅降低内存消耗和命令响应时间，进一步提升开发效率。即日起，全球开发者可通过任意命令行终端使用Qoder CLI体验代码生成、调试和部署等任务。 随着大模型能力的跃升，国内外涌现了多款 AI原生IDE工具，传统IDE也纷纷拥抱AI Coding 赛道。但仅依靠AI IDE仍无法高效应对所有开发场景，例如在脚本化能力、工具链集成以及自定义工作流等场景中，AI原生的CLI相比IDE有明显的效率优势。 随着大模型能力的跃升，国内外涌现了多款 AI原生IDE工具，传统IDE也纷纷拥抱AI Coding 赛道。但仅依靠AI IDE仍无法高效应对所有开发场景，例如在脚本化能力、工具链集成以及自定义工作流等场景中，AI原生的CLI相比IDE有明显的效率优势。 Qoder CLI 在全球顶尖的编程模型基础之上，进行了大量的工程设计，全面提升Agent能力：基于轻量级的Agent框架，该工具可高效运行在普通笔记本电脑和云端沙箱实例，满足不同场景的开发需求。测试显示，Qoder CLI在空闲状态下消耗的内存比同类工具低70%。 Qoder CLI 在全球顶尖的编程模型基础之上，进行了大量的工程设计，全面提升Agent能力：基于轻量级的Agent框架，该工具可高效运行在普通笔记本电脑和云端沙箱实例，满足不同场景的开发需求。测试显示，Qoder CLI在空闲状态下消耗的内存比同类工具低70%。 Qoder CLI可为开发者提供丰富的功能，使用Quest模式（自主编程），无需开发者深度介入，就可以轻松实现Spec驱动的任务委派，让AI自主完成任务开发。使用CodeReview能力，开发者在命令行终端即可进行代码审查，快速扫描项目中的关键改动点，并给出审查意见，代码审查耗时减少50%，代码质量提升一倍。此外，Qoder CLI内置多种工具，支持文件编辑、命令运行与提交创建，并能通过MCP灵活扩展或自定义扩展。 Qoder CLI可为开发者提供丰富的功能，使用Quest模式（自主编程），无需开发者深度介入，就可以轻松实现Spec驱动的任务委派，让AI自主完成任务开发。使用CodeReview能力，开发者在命令行终端即可进行代码审查，快速扫描项目中的关键改动点，并给出审查意见，代码审查耗时减少50%，代码质量提升一倍。此外，Qoder CLI内置多种工具，支持文件编辑、命令运行与提交创建，并能通过MCP灵活扩展或自定义扩展。 Qoder CLI可提供丰富的开发功能 Qoder CLI可提供丰富的开发功能 Qoder CLI可提供丰富的开发功能 目前，Qoder已拥有IDE和CLI两种产品形态。Qoder CLI技术负责人谢吉宝表示：“我们坚信，未来的开发界面不是IDE或CLI，而是IDE和CLI的组合。IDE提供深度上下文与复杂任务处理，CLI提供速度、灵活性与自动化能力，这种双引擎模式能覆盖更多场景。就像键盘与鼠标并存，桌面与移动端共存一样，IDE与CLI的组合将成为未来软件开发的标配。” 目前，Qoder已拥有IDE和CLI两种产品形态。Qoder CLI技术负责人谢吉宝表示：“我们坚信，未来的开发界面不是IDE或CLI，而是IDE和CLI的组合。IDE提供深度上下文与复杂任务处理，CLI提供速度、灵活性与自动化能力，这种双引擎模式能覆盖更多场景。就像键盘与鼠标并存，桌面与移动端共存一样，IDE与CLI的组合将成为未来软件开发的标配。” 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342415.html", "title": "全球计算机系统领域“奥运会”SOSP公布最佳论文 “星绽”OS入选", "date": "2025-10-16", "content": "全球计算机系统领域“奥运会”SOSP公布最佳论文 “星绽”OS入选 全球计算机系统领域“奥运会”SOSP公布最佳论文 “星绽”OS入选 henry 2025-10-16 16:34:25 来源： 量子位 henry henry henry henry 2025-10-16 2025-10-16 16:34:25 16:34:25 来源： 量子位 来源： 量子位 量子位 摘要样式 兼顾操作系统的安全与性能 星绽OS最新研究获顶会SOSP最佳论文 兼顾操作系统的安全与性能 星绽OS最新研究获顶会SOSP最佳论文 兼顾操作系统的安全与性能 星绽OS最新研究获顶会SOSP最佳论文 近日，被誉为全球计算机系统领域“奥运会”的顶级学术会议SOSP 2025公布奖项评选结果，“星绽”开源操作系统在高可扩展内存管理方面的研究论文，斩获今年的最佳论文奖（Best Paper Award）。据悉，本届SOSP会议共收到368篇投稿，最终录用66篇，其中最佳论文奖仅设三席。这标志着星绽OS在破解操作系统“性能与安全兼顾”这一难题上的探索，获得了国际学术界的认可。 近日，被誉为全球计算机系统领域“奥运会”的顶级学术会议SOSP 2025公布奖项评选结果，“星绽”开源操作系统在高可扩展内存管理方面的研究论文，斩获今年的最佳论文奖（Best Paper Award）。据悉，本届SOSP会议共收到368篇投稿，最终录用66篇，其中最佳论文奖仅设三席。这标志着星绽OS在破解操作系统“性能与安全兼顾”这一难题上的探索，获得了国际学术界的认可。 “星绽”（Asterinas）是由中关村实验室、蚂蚁集团、北京大学、南方科技大学等机构联合发起，并在2024年10月22日向全球开发者开源，聚焦于安全可信底层技术的开源系统软件栈。星绽系统软件栈包括星绽OS、星绽机密计算两大项目，其中星绽OS内核作为下一代工业强度的开源通用OS内核，兼顾性能和安全，采用首创的框内核架构和新兴的Rust编程语言，支持x86和RISC-V等CPU体系架构，不仅兼容Linux内核，还在安全性方面有望大幅领先于Linux和其他现有主流OS。 “星绽”（Asterinas）是由中关村实验室、蚂蚁集团、北京大学、南方科技大学等机构联合发起，并在2024年10月22日向全球开发者开源，聚焦于安全可信底层技术的开源系统软件栈。星绽系统软件栈包括星绽OS、星绽机密计算两大项目，其中星绽OS内核作为下一代工业强度的开源通用OS内核，兼顾性能和安全，采用首创的框内核架构和新兴的Rust编程语言，支持x86和RISC-V等CPU体系架构，不仅兼容Linux内核，还在安全性方面有望大幅领先于Linux和其他现有主流OS。 据悉，SOSP始于1967年，与它的姊妹会议OSDI 一起，被全球学术界和工业界公认为操作系统和系统软件领域最高水平、最权威、最具影响力的顶级会议，被称为计算机系统领域的“奥运会”。SOSP/OSDI也深受全球科技公司的重视，Google、Microsoft、Meta、Amazon、Apple等科技公司会派遣核心研发人员参会、投稿及做报告等。许多在工业界产生巨大影响的项目，其核心论文都发表在SOSP/OSDI上。目前，SOSP/OSDI已经成为衡量一个研究机构或团队在系统领域是否处于世界领先水平的关键标尺，是孕育颠覆性计算技术的摇篮。 据悉，SOSP始于1967年，与它的姊妹会议OSDI 一起，被全球学术界和工业界公认为操作系统和系统软件领域最高水平、最权威、最具影响力的顶级会议，被称为计算机系统领域的“奥运会”。SOSP/OSDI也深受全球科技公司的重视，Google、Microsoft、Meta、Amazon、Apple等科技公司会派遣核心研发人员参会、投稿及做报告等。许多在工业界产生巨大影响的项目，其核心论文都发表在SOSP/OSDI上。目前，SOSP/OSDI已经成为衡量一个研究机构或团队在系统领域是否处于世界领先水平的关键标尺，是孕育颠覆性计算技术的摇篮。 现代内存管理系统长期存在的两大痛点：性能瓶颈与并发安全。本次获奖论文《CortenMM: Efficient Memory Management with Strong Correctness Guarantees》，阐释了星绽操作系统的独创技术CortenMM在这一领域的探索。该文由北京大学、中关村实验室、蚂蚁集团、CertiK公司、加州大学洛杉矶分校、密歇根理工大学等共同合作完成。 现代内存管理系统长期存在的两大痛点：性能瓶颈与并发安全。本次获奖论文《CortenMM: Efficient Memory Management with Strong Correctness Guarantees》，阐释了星绽操作系统的独创技术CortenMM在这一领域的探索。该文由北京大学、中关村实验室、蚂蚁集团、CertiK公司、加州大学洛杉矶分校、密歇根理工大学等共同合作完成。 论文提出，传统操作系统如Linux普遍采用“软件—硬件”两级抽象设计，好处是在很大程度上保证了操作系统在不同硬件平台之间的可移植性，但显著的同步开销严重制约多核处理器的性能发挥，而潜在的并发漏洞则带来安全风险。 论文提出，传统操作系统如Linux普遍采用“软件—硬件”两级抽象设计，好处是在很大程度上保证了操作系统在不同硬件平台之间的可移植性，但显著的同步开销严重制约多核处理器的性能发挥，而潜在的并发漏洞则带来安全风险。 研究团队发现，x86、ARM和RISC-V等几种主流指令集架构在其内存管理单元（MMU）的设计上已经趋于统一，因此过去为屏蔽硬件差异而存在的软件抽象层已不再是必需品。基于这一关键判断，星绽创新成果CortenMM摒弃了独立的软件抽象层，实现了一种“单层抽象”的全新系统架构，使应用程序能直接与经过硬件强化的接口进行交互。 研究团队发现，x86、ARM和RISC-V等几种主流指令集架构在其内存管理单元（MMU）的设计上已经趋于统一，因此过去为屏蔽硬件差异而存在的软件抽象层已不再是必需品。基于这一关键判断，星绽创新成果CortenMM摒弃了独立的软件抽象层，实现了一种“单层抽象”的全新系统架构，使应用程序能直接与经过硬件强化的接口进行交互。 CortenMM的简化设计带来了显著的性能提升，其同步正确性也得到了研究验证。通过消除软件层的额外同步开销，CortenMM的性能得到释放，在真实应用场景下，性能最高可达Linux的26倍。通过创新性地引入统一的事务化接口（Transactional Interface），利用Rust语言自身的安全特性，并结合先进的形式化验证工具（Verus）进行严格推演，研究团队成功证明了CortenMM核心并发代码的正确性，从根本上杜绝了复杂的并发漏洞。 CortenMM的简化设计带来了显著的性能提升，其同步正确性也得到了研究验证。通过消除软件层的额外同步开销，CortenMM的性能得到释放，在真实应用场景下，性能最高可达Linux的26倍。通过创新性地引入统一的事务化接口（Transactional Interface），利用Rust语言自身的安全特性，并结合先进的形式化验证工具（Verus）进行严格推演，研究团队成功证明了CortenMM核心并发代码的正确性，从根本上杜绝了复杂的并发漏洞。 2024年10月，“星绽”对外发布并向全球开发者开源。一年来，星绽开源操作系统三篇论文被顶会收录，除了CortenMM的研究论文入选SOSP 2025外，星绽两篇论文被顶级会议USENIX ATC 2025同时录用。此外，星绽在GitHub平台斩获逾3600颗Star，并登上HackerNews和LWN.net等国外主流技术社区头条，获2025年OS2ATC大会“最具影响力开源创新贡献奖”。 2024年10月，“星绽”对外发布并向全球开发者开源。一年来，星绽开源操作系统三篇论文被顶会收录，除了CortenMM的研究论文入选SOSP 2025外，星绽两篇论文被顶级会议USENIX ATC 2025同时录用。此外，星绽在GitHub平台斩获逾3600颗Star，并登上HackerNews和LWN.net等国外主流技术社区头条，获2025年OS2ATC大会“最具影响力开源创新贡献奖”。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342252.html", "title": "“2025骁龙人工智能创新应用大赛” 正式启动，寻找最具想象力的AI创意开发者！", "date": "2025-10-16", "content": "“2025骁龙人工智能创新应用大赛” 正式启动，寻找最具想象力的AI创意开发者！ “2025骁龙人工智能创新应用大赛” 正式启动，寻找最具想象力的AI创意开发者！ 量子位的朋友们 2025-10-16 12:09:33 来源： 量子位 量子位的朋友们 量子位的朋友们 量子位的朋友们 量子位的朋友们 2025-10-16 2025-10-16 12:09:33 12:09:33 来源： 量子位 来源： 量子位 量子位 摘要样式 大赛报名通道现已开放 大赛报名通道现已开放 大赛报名通道现已开放 在端侧智能与生成式AI加速融合的新时代，搭载强大本地算力的AI终端设备正在成为推动技术变革与应用创新的关键力量。从内容创作、效率工具到智能助手、行业方案，AI已逐步形成 “云” 和 “端” 协同运行，以更低延迟、更高效率的方式重塑人机交互与生产流程。 在端侧智能与生成式AI加速融合的新时代，搭载强大本地算力的AI终端设备正在成为推动技术变革与应用创新的关键力量。从内容创作、效率工具到智能助手、行业方案，AI已逐步形成 “云” 和 “端” 协同运行，以更低延迟、更高效率的方式重塑人机交互与生产流程。 为进一步激发AI在终端侧的创新潜力，推动生成式AI与端侧智能的深度融合，由高通无线半导体技术有限公司主办、极视角承办，创通联达提供技术支持，以及产品合作伙伴Acer、荣耀、红魔、OPPO共同参与的 “2025 骁龙人工智能创新应用大赛” 于10月14日正式启动。大赛聚焦 AI PC、智能手机和平板 两大平台，依托我们先进的CPU、GPU和NPU功能，强大的Qualcomm® AI Stack以及AI推理软件框架，面向全球开发者征集兼具创新性与落地性的人工智能创新应用作品，探索AI赋能未来生活的无限可能。 为进一步激发AI在终端侧的创新潜力，推动生成式AI与端侧智能的深度融合，由高通无线半导体技术有限公司主办、极视角承办，创通联达提供技术支持，以及产品合作伙伴Acer、荣耀、红魔、OPPO共同参与的 “2025 骁龙人工智能创新应用大赛” 于10月14日正式启动。大赛聚焦 AI PC、智能手机和平板 AI PC、智能手机和平板 两大平台，依托我们先进的CPU、GPU和NPU功能，强大的Qualcomm® AI Stack以及AI推理软件框架，面向全球开发者征集兼具创新性与落地性的人工智能创新应用作品，探索AI赋能未来生活的无限可能。 本次 “2025 骁龙人工智能创新应用大赛” 设立 AI PC 赛道、智能手机和平板赛道 两大主赛道共四个赛题，覆盖从强性能计算到移动便携体验的广泛场景，为创新应用提供自由发挥的平台： 本次 “2025 骁龙人工智能创新应用大赛” 设立 AI PC 赛道、智能手机和平板赛道 AI PC 赛道、智能手机和平板赛道 两大主赛道共四个赛题，覆盖从强性能计算到移动便携体验的广泛场景，为创新应用提供自由发挥的平台： AI PC 赛道 AI PC 赛道 新一代AI PC作为“智能内容生产中心”和“知识工作助手”，具备大模型本地部署、多模态感知与实时响应能力。参赛者需基于搭载骁龙(®) X Elite计算平台的Windows AI PC，结合端侧AI优势与Qualcomm AI Stack，打造具备高交互性、高效率的创新应用： 新一代AI PC作为“智能内容生产中心”和“知识工作助手”，具备大模型本地部署、多模态感知与实时响应能力。参赛者需基于搭载骁龙(®) X Elite计算平台的Windows AI PC，结合端侧AI优势与Qualcomm AI Stack，打造具备高交互性、高效率的创新应用： 1、 创意赛 ：鼓励参赛者基于AI PC进行个体或团队的“创意性内容生产”创新，聚焦个体创意表达、智能辅助创作等方向，探索端侧AI在内容生成、交互体验优化等方面的创新应用形式，打造更贴近个人使用需求的智能创意工具。 1、 创意赛 创意赛 ：鼓励参赛者基于AI PC进行个体或团队的“创意性内容生产”创新，聚焦个体创意表达、智能辅助创作等方向，探索端侧AI在内容生成、交互体验优化等方面的创新应用形式，打造更贴近个人使用需求的智能创意工具。 2、 行业赛 ：面向特定行业场景（如金融、制造、营销等），基于AI PC开发具备专业能力的创新解决方案。该赛题注重应用的场景适配性、行业理解深度与实际落地价值，参赛者应结合行业特征与AI技术能力，构建具有明确功能定位与业务价值的解决方案或功能模块。 2、 行业赛 行业赛 ：面向特定行业场景（如金融、制造、营销等），基于AI PC开发具备专业能力的创新解决方案。该赛题注重应用的场景适配性、行业理解深度与实际落地价值，参赛者应结合行业特征与AI技术能力，构建具有明确功能定位与业务价值的解决方案或功能模块。 3、 通用赛 ：聚焦平台能力挖掘与技术边界探索，不限定具体应用领域，该赛题旨在推动参赛者充分发挥技术潜力，通过对AI PC能力的深度调动，实现新颖性、通用性与技术挑战性的结合。 3、 通用赛 通用赛 ：聚焦平台能力挖掘与技术边界探索，不限定具体应用领域，该赛题旨在推动参赛者充分发挥技术潜力，通过对AI PC能力的深度调动，实现新颖性、通用性与技术挑战性的结合。 智能手机和平板赛道 智能手机和平板赛道 聚焦基于骁龙移动平台的智能手机与平板创新应用，通过端侧AI技术优化日常交互，感知和计算体验，赋能泛生态、泛服务场景下的智能升级： 聚焦基于骁龙移动平台的智能手机与平板创新应用，通过端侧AI技术优化日常交互，感知和计算体验，赋能泛生态、泛服务场景下的智能升级： 基于骁龙平台的移动端创新应用：智能手机与平板作为下一代智能终端形态，具备实时感知、多模态交互、个性服务等能力。参赛者需基于第五代骁龙(®) 8至尊版移动平台、骁龙(®) 8至尊版移动平台及Qualcomm AI Stack，结合端侧部署优势与前沿AI模型（大语言模型、多模态、语音/视觉识别模型等），开发具备行业价值或用户价值的端侧AI应用产品或解决方案。 基于骁龙平台的移动端创新应用：智能手机与平板作为下一代智能终端形态，具备实时感知、多模态交互、个性服务等能力。参赛者需基于第五代骁龙(®) 8至尊版移动平台、骁龙(®) 8至尊版移动平台及Qualcomm AI Stack，结合端侧部署优势与前沿AI模型（大语言模型、多模态、语音/视觉识别模型等），开发具备行业价值或用户价值的端侧AI应用产品或解决方案。 骁龙X Elite计算平台，作为专为 Windows AI PC 打造的旗舰芯片，配备 12 核的Qualcomm Oryon™ CPU、增强的高通(®) Adreno™ GPU 与算力高达 45 TOPS 的高通(®) Hexagon™ NPU，形成强大的 AI 三角架构，为新一代PC的复杂计算、多任务处理等应用场景带来超快响应速度和高效执行，加速智能创作，支持多个AI智能体运行及本地大模型计算。 骁龙X Elite计算平台，作为专为 Windows AI PC 打造的旗舰芯片，配备 12 核的Qualcomm Oryon™ CPU、增强的高通(®) Adreno™ GPU 与算力高达 45 TOPS 的高通(®) Hexagon™ NPU，形成强大的 AI 三角架构，为新一代PC的复杂计算、多任务处理等应用场景带来超快响应速度和高效执行，加速智能创作，支持多个AI智能体运行及本地大模型计算。 骁龙8 至尊版自去年发布以来，移动端计算能力迎来显著提升：定制的Qualcomm Oryon CPU、Adreno GPU和增强的 Hexagon NPU，实现了性能和能效的明显改善。通过直接在终端侧提供个性化的多模态生成式AI，支持语音、情景和图像理解，全面增强从生产力到创意任务等各方面的体验。 骁龙8 至尊版自去年发布以来，移动端计算能力迎来显著提升：定制的Qualcomm Oryon CPU、Adreno GPU和增强的 Hexagon NPU，实现了性能和能效的明显改善。通过直接在终端侧提供个性化的多模态生成式AI，支持语音、情景和图像理解，全面增强从生产力到创意任务等各方面的体验。 最新发布的第五代骁龙8至尊版，凭借卓越的性能、能效和终端侧个性化智能体AI能力，与前一代相比将带来大幅性能和体验升级。第三代Qualcomm Oryon™ CPU与前一代相比性能提升20%，截至今年9月25日，具有移动端CPU中的最快速度（高达4.6GHz）。全新架构的Adreno GPU与前一代相比，图形渲染速度提升高达23%，增强了图形密集型游戏的体验。此外， Hexagon NPU与前一代相比，速度提升37%，能效提升16%。 最新发布的第五代骁龙8至尊版，凭借卓越的性能、能效和终端侧个性化智能体AI能力，与前一代相比将带来大幅性能和体验升级。第三代Qualcomm Oryon™ CPU与前一代相比性能提升20%，截至今年9月25日，具有移动端CPU中的最快速度（高达4.6GHz）。全新架构的Adreno GPU与前一代相比，图形渲染速度提升高达23%，增强了图形密集型游戏的体验。此外， Hexagon NPU与前一代相比，速度提升37%，能效提升16%。 同时，在软件层面上，高通技术公司还构建了强大的 Qualcomm AI Stack，如Qualcomm AI Engine SDK与QAI AppBuilder，它提供了一系列优化的 API，专为简化 AI模型在骁龙AI PC和骁龙手机上的部署而设计，支持模型在NPU上实现高性能推理，加速AI应用落地。开发者可利用这些资源，面向骁龙平台高效进行模型适配，缩短AI赋能应用的上市时间。 同时，在软件层面上，高通技术公司还构建了强大的 Qualcomm AI Stack，如Qualcomm AI Engine SDK与QAI AppBuilder，它提供了一系列优化的 API，专为简化 AI模型在骁龙AI PC和骁龙手机上的部署而设计，支持模型在NPU上实现高性能推理，加速AI应用落地。开发者可利用这些资源，面向骁龙平台高效进行模型适配，缩短AI赋能应用的上市时间。 本届大赛共分为 初赛、复赛、决赛答辩与颁奖仪式 三个阶段，逐层选拔、逐步打磨，全面检验参赛作品的创新性与落地能力。大赛总奖励价值共计120万元人民币（包含入围奖：搭载骁龙平台的AI PC、智能手机或平板），覆盖两个主赛道： 本届大赛共分为 初赛、复赛、决赛答辩与颁奖仪式 初赛、复赛、决赛答辩与颁奖仪式 三个阶段，逐层选拔、逐步打磨，全面检验参赛作品的创新性与落地能力。大赛总奖励价值共计120万元人民币（包含入围奖：搭载骁龙平台的AI PC、智能手机或平板），覆盖两个主赛道： 1、 AI PC赛道 ：下设三个赛题，每个赛题的冠军、亚军、季军得主将分别获得价值100,000元、80,000元、50,000元人民币的搭载高通平台的电子消费类产品；同时，优胜奖和优秀奖得主也将分别获得价值20,000元和10,000元人民币的同类产品。 1、 AI PC赛道 AI PC赛道 ：下设三个赛题，每个赛题的冠军、亚军、季军得主将分别获得价值100,000元、80,000元、50,000元人民币的搭载高通平台的电子消费类产品；同时，优胜奖和优秀奖得主也将分别获得价值20,000元和10,000元人民币的同类产品。 2、 智能手机和平板赛道 ：冠军、亚军、季军得主将分别获得价值50,000元、30,000元、20,000元人民币的搭载高通平台的电子消费类产品；同时，优胜奖和优秀奖得主也将分别获得价值10,000元、5,000元人民币的同类产品。 2、 智能手机和平板赛道 智能手机和平板赛道 ：冠军、亚军、季军得主将分别获得价值50,000元、30,000元、20,000元人民币的搭载高通平台的电子消费类产品；同时，优胜奖和优秀奖得主也将分别获得价值10,000元、5,000元人民币的同类产品。 除了上述奖励外，获奖团队将有机会体验高通技术公司及其关联公司的前沿技术、获得品牌曝光及产业合作商机拓展，助力其创新应用快速实现商业化落地。 除了上述奖励外，获奖团队将有机会体验高通技术公司及其关联公司的前沿技术、获得品牌曝光及产业合作商机拓展，助力其创新应用快速实现商业化落地。 大赛报名通道现已开放，欲了解赛事规则、报名流程、奖励等详细信息，请访问赛事官网： https://QC-AI-Challenge.cvmart.net/2025 大赛报名通道现已开放，欲了解赛事规则、报名流程、奖励等详细信息，请访问赛事官网： https://QC-AI-Challenge.cvmart.net/2025 （注：奖项部分包含部分新品，根据目前新品未出估算价格，实际价格可能有些许差距。骁龙、高通、以及其他Snapdragon与Qualcomm旗下的产品系高通技术公司和/或其子公司的产品。） （注：奖项部分包含部分新品，根据目前新品未出估算价格，实际价格可能有些许差距。骁龙、高通、以及其他Snapdragon与Qualcomm旗下的产品系高通技术公司和/或其子公司的产品。） 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342093.html", "title": "Sora2不够香了！国产AI视频模型已能边看边生成，生成快还互动佳", "date": "2025-10-15", "content": "Sora2不够香了！国产AI视频模型已能边看边生成，生成快还互动佳 Sora2不够香了！国产AI视频模型已能边看边生成，生成快还互动佳 衡宇 2025-10-15 19:15:03 来源： 量子位 衡宇 衡宇 衡宇 衡宇 2025-10-15 2025-10-15 19:15:03 19:15:03 来源： 量子位 来源： 量子位 量子位 摘要样式 百度蒸汽机实现AI视频流式生成 百度蒸汽机实现AI视频流式生成 百度蒸汽机实现AI视频流式生成 衡宇 鹭羽 发自 凹非寺 量子位 | 公众号 QbitAI 衡宇 鹭羽 发自 凹非寺 衡宇 鹭羽 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 还在用Sora2做恶搞视频或表情包玩儿？快醒醒，国内AI视频玩家已实现弯道超车了—— 还在用Sora2做恶搞视频或表情包玩儿？快醒醒，国内AI视频玩家已实现弯道超车了—— 开卷 实时流式生成 ！ 开卷 实时流式生成 实时流式生成 ！ 就是那种模型推理到哪儿，画面就生成到哪儿；想改剧情，直接暂停、改指令、视频重新走向。 就是那种模型推理到哪儿，画面就生成到哪儿；想改剧情，直接暂停、改指令、视频重新走向。 换言之，Sora2能做的，它能做；Sora2做不到的，它还能做。 换言之，Sora2能做的，它能做；Sora2做不到的，它还能做。 而这，才是和AI视频一起“创作”的未来式答卷——来自 百度蒸汽机 （文心专精版）。 而这，才是和AI视频一起“创作”的未来式答卷——来自 百度蒸汽机 百度蒸汽机 （文心专精版）。 百度蒸汽机相信大家都已经不陌生了，5月份以黑马之姿闯入AI生视频赛道，初登场就拿下VBench-I2V全球榜一，全球首个实现中文音视频一体化的视频生成模型，首次实现多人有声视频生成…… 百度蒸汽机相信大家都已经不陌生了，5月份以黑马之姿闯入AI生视频赛道，初登场就拿下VBench-I2V全球榜一，全球首个实现中文音视频一体化的视频生成模型，首次实现多人有声视频生成…… 而这一次升级的背后，是百度对AI视频生成领域的重新再定义。 而这一次升级的背后，是百度对AI视频生成领域的重新再定义。 当同行还卡在“生成10s稳定、连续的视频画面”时，百度已经率先实现“ 生成迅速、实时交互、无限续写 ”三件套： 当同行还卡在“生成10s稳定、连续的视频画面”时，百度已经率先实现“ 生成迅速、实时交互、无限续写 生成迅速、实时交互、无限续写 ”三件套： 只需一张图+一个Prompt，生成过程更流畅自然，短时间、低成本还能保持高质量。 支持实时交互，可随时打断视频生成进展，任意位置都能进行提示词改写。 打破视频生成时长限制，上传任意视频，就能续写成长篇影视级大作，还能实时预览视频内容。 只需一张图+一个Prompt，生成过程更流畅自然，短时间、低成本还能保持高质量。 只需一张图+一个Prompt，生成过程更流畅自然，短时间、低成本还能保持高质量。 支持实时交互，可随时打断视频生成进展，任意位置都能进行提示词改写。 支持实时交互，可随时打断视频生成进展，任意位置都能进行提示词改写。 打破视频生成时长限制，上传任意视频，就能续写成长篇影视级大作，还能实时预览视频内容。 打破视频生成时长限制，上传任意视频，就能续写成长篇影视级大作，还能实时预览视频内容。 此外，在百度蒸汽机，还能告别以往单向输出的数字人，定制1V1专属数字人，沉浸式体验数字分身互动；任意生成、创造全场景开放世界，无论是开拓新的游戏地图，还是爽玩全球旅游景点， 百度这次，全都有 。 此外，在百度蒸汽机，还能告别以往单向输出的数字人，定制1V1专属数字人，沉浸式体验数字分身互动；任意生成、创造全场景开放世界，无论是开拓新的游戏地图，还是爽玩全球旅游景点， 百度这次，全都有 百度这次，全都有 。 正如蒸汽机曾经带来的技术革命，百度蒸汽机模型的此次更新也将标志着AI视频正式从短片段走向长篇叙事，从创意工具走向创意伙伴。 正如蒸汽机曾经带来的技术革命，百度蒸汽机模型的此次更新也将标志着AI视频正式从短片段走向长篇叙事，从创意工具走向创意伙伴。 从“图生视频”到“边看边生”：行业首次流式生成体验 从“图生视频”到“边看边生”：行业首次流式生成体验 不过，当前主流的AI视频生成模型还处在Level 1，即使是最近风头最盛的Sora2，也普遍只能生成5～10秒。 不过，当前主流的AI视频生成模型还处在Level 1，即使是最近风头最盛的Sora2，也普遍只能生成5～10秒。 坊间为此还出现了邪修鉴AI大法： 遇事不决看时长！ 坊间为此还出现了邪修鉴AI大法： 遇事不决看时长！ 遇事不决看时长！ 而且要得到结果，短则30秒长则几分钟的生成阶段，必须老老实实等待。 而且要得到结果，短则30秒长则几分钟的生成阶段，必须老老实实等待。 期间做成啥样一概不知，生成完整视频后，无论是细节修改还是整支视频大调，都没法实时调整，只能重来一遍，更谈不上有什么“交互感”。 期间做成啥样一概不知，生成完整视频后，无论是细节修改还是整支视频大调，都没法实时调整，只能重来一遍，更谈不上有什么“交互感”。 这个过程不仅耗时长，而且成本惊人，想要实时交互修改基本上是不可能的。 这个过程不仅耗时长，而且成本惊人，想要实时交互修改基本上是不可能的。 这个过程不仅耗时长，而且成本惊人，想要实时交互修改基本上是不可能的。 这对短视频生成而言，还算够用，但放到长视频显然不够看，即使勉强用首尾帧技术拼接拉时长，但视频质量低下、细节粗糙，缺乏连贯性。 这对短视频生成而言，还算够用，但放到长视频显然不够看，即使勉强用首尾帧技术拼接拉时长，但视频质量低下、细节粗糙，缺乏连贯性。 百度蒸汽机的出现，则填补了这一领域的空白，让AI视频提前进入了 边看边生、实时共创 的全新阶段。 百度蒸汽机的出现，则填补了这一领域的空白，让AI视频提前进入了 边看边生、实时共创 边看边生、实时共创 的全新阶段。 不仅生成速度快人一步，生成质量也快到飞起。 不仅生成速度快人一步，生成质量也快到飞起。 首先是生成模式上，既能 I2V图生视频 ，又能 V2V视频生视频 ，双线齐发力。 首先是生成模式上，既能 I2V图生视频 I2V图生视频 ，又能 V2V视频生视频 V2V视频生视频 ，双线齐发力。 图生视频将操作门槛降到最低，摒弃传统的多图+多指令模式，只需最基础的 一张图和一个简单指令 ，就能生成长视频。 图生视频将操作门槛降到最低，摒弃传统的多图+多指令模式，只需最基础的 一张图和一个简单指令 一张图和一个简单指令 ，就能生成长视频。 比如说我们先进入百度绘想平台，选择“长视频”功能入口，上传一张爱因斯坦的形象照，输入Prompt： 比如说我们先进入百度绘想平台，选择“长视频”功能入口，上传一张爱因斯坦的形象照，输入Prompt： 爱因斯坦在舞台上说物理学脱口秀，同时镜头跟随人物变化。 爱因斯坦在舞台上说物理学脱口秀，同时镜头跟随人物变化。 爱因斯坦在舞台上说物理学脱口秀，同时镜头跟随人物变化。 注意这里还要选择10-60秒的时长，一般默认20秒。 注意这里还要选择10-60秒的时长，一般默认20秒。 视频开始生成后， 可以在旁边的任务结果区实时看到当前生成进展 。 视频开始生成后， 可以在旁边的任务结果区实时看到当前生成进展 可以在旁边的任务结果区实时看到当前生成进展 。 一旦发现不满意，立马点击“续改”按钮中断生成， 将视频帧拖至目标位置，重新下达新的指令 ，例如这里我们将让爱因斯坦的动作更丰富一些，让他一边说一边还会比划动作。 一旦发现不满意，立马点击“续改”按钮中断生成， 将视频帧拖至目标位置，重新下达新的指令 将视频帧拖至目标位置，重新下达新的指令 ，例如这里我们将让爱因斯坦的动作更丰富一些，让他一边说一边还会比划动作。 一个小tips： 一个小tips： 每12秒，生成任务会自动暂停一次，此时需要用户自己手动选择继续生成or就此结束嗷～ 每12秒，生成任务会自动暂停一次，此时需要用户自己手动选择继续生成or就此结束嗷～ 下面请欣赏一段新鲜出炉的爱因斯坦的默剧版脱口秀。 下面请欣赏一段新鲜出炉的爱因斯坦的默剧版脱口秀。 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg BTW，如果你不想要看无声短片，可以选择蒸汽机2.0有声版。 BTW，如果你不想要看无声短片，可以选择蒸汽机2.0有声版。 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 不过相对应的，最长时长就需要打一丢丢折扣（5～10s）。 不过相对应的，最长时长就需要打一丢丢折扣（5～10s）。 好好好，教科书里的人物都能活过来讲脱口秀了，物理学原来可以这么有趣！ 好好好，教科书里的人物都能活过来讲脱口秀了，物理学原来可以这么有趣！ 要是我读书的时候有它， 也不至于回回物理考零昏（doge） 要是我读书的时候有它， 也不至于回回物理考零昏（doge） 也不至于回回物理考零昏（doge） 而 百度蒸汽机的视频生视频，本次更新端上来的全新玩法 ： 而 百度蒸汽机的视频生视频，本次更新端上来的全新玩法 百度蒸汽机的视频生视频，本次更新端上来的全新玩法 ： 同样是在长视频入口进入，首先需要上传一个时长在2秒到60秒的视频，我们这里使用的是上次没做完的哈利波特的太极拳文艺汇演视频。（咳咳） 同样是在长视频入口进入，首先需要上传一个时长在2秒到60秒的视频，我们这里使用的是上次没做完的哈利波特的太极拳文艺汇演视频。（咳咳） 原视频be like： 原视频be like： 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 期间依旧是可以实时查看或修改视频内容，不过需要注意的是，有且仅有2个视频可以同时生成。 期间依旧是可以实时查看或修改视频内容，不过需要注意的是，有且仅有2个视频可以同时生成。 最终续写下来，效果也是纵享丝滑～ 最终续写下来，效果也是纵享丝滑～ （这下麻麻再也不用担心以后小组作业队友做一半跑路了555） （这下麻麻再也不用担心以后小组作业队友做一半跑路了555） 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 另外，蒸汽机在开放世界上也表现优异，例如我们让它来生成一段月球漫步。 另外，蒸汽机在开放世界上也表现优异，例如我们让它来生成一段月球漫步。 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 还可通过 WASD+鼠标 控制视角，在月球上自由探索。 还可通过 WASD+鼠标 WASD+鼠标 控制视角，在月球上自由探索。 Nice！下次旅游旺季，不用出远门人挤人，在家就能环游世界，计划通✅ Nice！下次旅游旺季，不用出远门人挤人，在家就能环游世界，计划通✅ 不过言归正传，蒸汽机到底为啥一下就Next level了？还得是背后的技术升级立大功。 不过言归正传，蒸汽机到底为啥一下就Next level了？还得是背后的技术升级立大功。 “边生成边互动”的AI视频体验，如何炼成？ “边生成边互动”的AI视频体验，如何炼成？ 当下，包括Sora 2在内的AI视频工具，都在朝更长、更稳、更真实、更清晰突破。 当下，包括Sora 2在内的AI视频工具，都在朝更长、更稳、更真实、更清晰突破。 但有一点似乎被大多数玩家忽视了： 但有一点似乎被大多数玩家忽视了： 目前，“生成→等待→反馈”的生产流程，其实一直停留在AI单向输出的阶段 。 目前，“生成→等待→反馈”的生产流程，其实一直停留在AI单向输出的阶段 目前，“生成→等待→反馈”的生产流程，其实一直停留在AI单向输出的阶段 。 背后原因主要还是归结于行业主流方案是采用基于Transformer架构的扩散模型。 背后原因主要还是归结于行业主流方案是采用基于Transformer架构的扩散模型。 受限于Transformer架构的二次计算复杂度，主流AI视频生成模型计算开销随生成时长呈平方级增长。也就是说，需要生成的视频时长越长，对GPU显存与计算效率的要求就更高。 受限于Transformer架构的二次计算复杂度，主流AI视频生成模型计算开销随生成时长呈平方级增长。也就是说，需要生成的视频时长越长，对GPU显存与计算效率的要求就更高。 一方面成本直接拉爆，另一方面推理效率也难以达到较高水准，所以难以实现实时生成与交互能力。 一方面成本直接拉爆，另一方面推理效率也难以达到较高水准，所以难以实现实时生成与交互能力。 而迭代后的百度蒸汽机，已经实现了“用户被动接收”向“AI与用户共同创造”的转变。 而迭代后的百度蒸汽机，已经实现了“用户被动接收”向“AI与用户共同创造”的转变。 在蒸汽机这里，AI视频生成过程本身就是开放的—— 在蒸汽机这里，AI视频生成过程本身就是开放的—— 视频不是一口气生成完毕，而是流式呈现 。 视频不是一口气生成完毕，而是流式呈现 视频不是一口气生成完毕，而是流式呈现 。 模型推理是什么进度，用户就能看到对应时长的画面。 模型推理是什么进度，用户就能看到对应时长的画面。 生成过程可随时打断 。 生成过程可随时打断 生成过程可随时打断 。 生成中途，用户要是灵感突发想改点什么，一句新的prompt就能实时生效。 生成中途，用户要是灵感突发想改点什么，一句新的prompt就能实时生效。 不满意前一段内容？还可以拉回修改，重新接上 。 不满意前一段内容？还可以拉回修改，重新接上 不满意前一段内容？还可以拉回修改，重新接上 。 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 视频链接：https://mp.weixin.qq.com/s/s-L7EslLvuN31GT9Olt7sg 一句话总结，百度蒸汽机生成AI视频，已经进入能配合你反悔的Next Level，一切都不必从头再来。 一句话总结，百度蒸汽机生成AI视频，已经进入能配合你反悔的Next Level，一切都不必从头再来。 整个过程像是创作者在电脑前观摩AI创排导演一支视频短片，随时可以以“导演”的身份喊卡，调整细节，修改剧本。 整个过程像是创作者在电脑前观摩AI创排导演一支视频短片，随时可以以“导演”的身份喊卡，调整细节，修改剧本。 从这个角度来看， 百度蒸汽机突破的不只是长视频生成的技术瓶颈，而是AI视频的整个创作范式，是一次对AI生成流程的重新定义 —— 从这个角度来看， 百度蒸汽机突破的不只是长视频生成的技术瓶颈，而是AI视频的整个创作范式，是一次对AI生成流程的重新定义 百度蒸汽机突破的不只是长视频生成的技术瓶颈，而是AI视频的整个创作范式，是一次对AI生成流程的重新定义 —— AI视频生成，终于进入“你说我做，随时可改”的时代。 AI视频生成，终于进入“你说我做，随时可改”的时代。 为了让模型学会边输出边协作，百度蒸汽机在模型层面，从架构到底层推理流程，几乎做了一次彻底重构。 为了让模型学会边输出边协作，百度蒸汽机在模型层面，从架构到底层推理流程，几乎做了一次彻底重构。 首先是模型架构层面 ，百度蒸汽机通过引入自回归扩散模型（Autoregressive Diffusion Models），采用基于流式滑窗的自回归扩散架构，来实现低成本无限外推和实时生成。 首先是模型架构层面 首先是模型架构层面 ，百度蒸汽机通过引入自回归扩散模型（Autoregressive Diffusion Models），采用基于流式滑窗的自回归扩散架构，来实现低成本无限外推和实时生成。 不仅有阶梯独立噪声构造，还进行动态缓冲区管理，让模型能同时处理模糊草图、半完成帧及高精度画面，最终实现“边生成边调整”的实时交互生成流程。 不仅有阶梯独立噪声构造，还进行动态缓冲区管理，让模型能同时处理模糊草图、半完成帧及高精度画面，最终实现“边生成边调整”的实时交互生成流程。 其次，为了解决训推过程中累积误差和衰减问题，百度蒸汽机引入了噪声重注入和历史帧扰动增强机制，让它不仅听得懂指令，还能应对突发调整 。 其次，为了解决训推过程中累积误差和衰减问题，百度蒸汽机引入了噪声重注入和历史帧扰动增强机制，让它不仅听得懂指令，还能应对突发调整 其次，为了解决训推过程中累积误差和衰减问题，百度蒸汽机引入了噪声重注入和历史帧扰动增强机制，让它不仅听得懂指令，还能应对突发调整 。 所谓噪声重注入，就是在训练时故意加入真实工作中可能遇到的“噪声”或偏差，让模型在模拟真实复杂环境的过程中学会更稳、更准地生成结果。 所谓噪声重注入，就是在训练时故意加入真实工作中可能遇到的“噪声”或偏差，让模型在模拟真实复杂环境的过程中学会更稳、更准地生成结果。 历史帧扰动增强，则是让模型学着自己生成过程中的问题并自己修正以应对变化。 历史帧扰动增强，则是让模型学着自己生成过程中的问题并自己修正以应对变化。 第三，在生成画面的一致性方面 ，百度蒸汽机在引入锚点帧引导保障全局记忆的同时，还引入历史参考帧保障连续生成。 第三，在生成画面的一致性方面 第三，在生成画面的一致性方面 ，百度蒸汽机在引入锚点帧引导保障全局记忆的同时，还引入历史参考帧保障连续生成。 最后需要提到非常重要的一点，就是百度蒸汽机基于自回归扩散架构，突破高压缩比生成技术，大幅提升扩散模型流式推理性能，保障效果和效率的极致平衡 。 最后需要提到非常重要的一点，就是百度蒸汽机基于自回归扩散架构，突破高压缩比生成技术，大幅提升扩散模型流式推理性能，保障效果和效率的极致平衡 最后需要提到非常重要的一点，就是百度蒸汽机基于自回归扩散架构，突破高压缩比生成技术，大幅提升扩散模型流式推理性能，保障效果和效率的极致平衡 。 通过窗口attention优化和模型蒸馏，用户使用百度蒸汽机生成视频时，推理延迟被压缩到几乎实时，几乎不会有“等”的感觉。 通过窗口attention优化和模型蒸馏，用户使用百度蒸汽机生成视频时，推理延迟被压缩到几乎实时，几乎不会有“等”的感觉。 技术落地、生态生长，推动AI内容创作进入共创时代 技术落地、生态生长，推动AI内容创作进入共创时代 像百度蒸汽机这样，全流程可控、可打断、可改写的实时共创，让AI视频生成变得参与性更突出，打开了AI内容创作的新的可能空间。 像百度蒸汽机这样，全流程可控、可打断、可改写的实时共创，让AI视频生成变得参与性更突出，打开了AI内容创作的新的可能空间。 于是问题也随之升维。 于是问题也随之升维。 拥有实时生成能力之后，AI视频模型能否真正 走进创作现场、嵌入真实生产流程 ？因为对AI创作工具来说，真正的考验场在创作场景和生产链条上。 拥有实时生成能力之后，AI视频模型能否真正 走进创作现场、嵌入真实生产流程 ？因为对AI创作工具来说，真正的考验场在创作场景和生产链条上。 拥有实时生成能力之后，AI视频模型能否真正 走进创作现场、嵌入真实生产流程 走进创作现场、嵌入真实生产流程 ？因为对AI创作工具来说，真正的考验场在创作场景和生产链条上。 生成能力再强，实时互动感再强，如果无法走进创作现场，也只是 （实验室里的模型） 温室里的花朵。 生成能力再强，实时互动感再强，如果无法走进创作现场，也只是 （实验室里的模型） （实验室里的模型） 温室里的花朵。 回顾百度蒸汽机的迭代路径，可以清晰看到它的演进节奏，看到一条从底层技术突破，到产品形态重构，再到全链条生态落地的路径： 回顾百度蒸汽机的迭代路径，可以清晰看到它的演进节奏，看到一条从底层技术突破，到产品形态重构，再到全链条生态落地的路径： 5月，百度视频生成模型以总分89.38%的成绩，登上海外权威视频生成评测榜单VBench-I2V图生视频榜全球第一，率先证明了自家视频生成的技术力； 7月，百度发布自研音视频一体化模型MuseSteamer（百度蒸汽机背后模型），首创中文音画协同生成能力，支持画面、语音、配乐一体生成，真正突破“画完再配音”的AI短片分离流程； 8月，百度蒸汽机音视频一体化模型完成重大升级，在业内首次实现多人有声视频生成，并全面开放Turbo、Pro、Lite等多个版本，打通C端与B端应用通道； 9月，发布“通用AI长视频生成”功能； 10月，百度蒸汽机让AI视频正式进入实时交互时代，视频生成不再是一次性产物。 5月，百度视频生成模型以总分89.38%的成绩，登上海外权威视频生成评测榜单VBench-I2V图生视频榜全球第一，率先证明了自家视频生成的技术力； 5月，百度视频生成模型以总分89.38%的成绩，登上海外权威视频生成评测榜单VBench-I2V图生视频榜全球第一，率先证明了自家视频生成的技术力； 5月，百度视频生成模型以总分89.38%的成绩，登上海外权威视频生成评测榜单VBench-I2V图生视频榜全球第一，率先证明了自家视频生成的技术力； 7月，百度发布自研音视频一体化模型MuseSteamer（百度蒸汽机背后模型），首创中文音画协同生成能力，支持画面、语音、配乐一体生成，真正突破“画完再配音”的AI短片分离流程； 7月，百度发布自研音视频一体化模型MuseSteamer（百度蒸汽机背后模型），首创中文音画协同生成能力，支持画面、语音、配乐一体生成，真正突破“画完再配音”的AI短片分离流程； 7月，百度发布自研音视频一体化模型MuseSteamer（百度蒸汽机背后模型），首创中文音画协同生成能力，支持画面、语音、配乐一体生成，真正突破“画完再配音”的AI短片分离流程； 8月，百度蒸汽机音视频一体化模型完成重大升级，在业内首次实现多人有声视频生成，并全面开放Turbo、Pro、Lite等多个版本，打通C端与B端应用通道； 8月，百度蒸汽机音视频一体化模型完成重大升级，在业内首次实现多人有声视频生成，并全面开放Turbo、Pro、Lite等多个版本，打通C端与B端应用通道； 8月，百度蒸汽机音视频一体化模型完成重大升级，在业内首次实现多人有声视频生成，并全面开放Turbo、Pro、Lite等多个版本，打通C端与B端应用通道； 9月，发布“通用AI长视频生成”功能； 9月，发布“通用AI长视频生成”功能； 9月，发布“通用AI长视频生成”功能； 10月，百度蒸汽机让AI视频正式进入实时交互时代，视频生成不再是一次性产物。 10月，百度蒸汽机让AI视频正式进入实时交互时代，视频生成不再是一次性产物。 10月，百度蒸汽机让AI视频正式进入实时交互时代，视频生成不再是一次性产物。 可以看到，短短5个月内，百度蒸汽机实现了从图生视频到音画一体生成，再到实时互动+无限流式生成的演进。 可以看到，短短5个月内，百度蒸汽机实现了从图生视频到音画一体生成，再到实时互动+无限流式生成的演进。 这样的底层能力重构，首先直接改变的是C端普通用户的创作方式。 这样的底层能力重构，首先直接改变的是C端普通用户的创作方式。 无需专业视频剪辑经验，只需上传一张图片并输入一句prompt，用户就能在平台上生成一段可实时预览、随时修改、随时续写的AI视频。 无需专业视频剪辑经验，只需上传一张图片并输入一句prompt，用户就能在平台上生成一段可实时预览、随时修改、随时续写的AI视频。 最大程度告别屡次三番抽卡的烦恼，同时真正实现使用0门槛。 最大程度告别屡次三番抽卡的烦恼，同时真正实现使用0门槛。 另一边，迭代后的新技术更能推动AI视频能力快速向导购、直播、教育、影视制作等商业和应用场景延伸的需求。 另一边，迭代后的新技术更能推动AI视频能力快速向导购、直播、教育、影视制作等商业和应用场景延伸的需求。 这一切，让百度蒸汽机不再只是一个模型产品，而是新型创作平台与交互接口的起点。 这一切，让百度蒸汽机不再只是一个模型产品，而是新型创作平台与交互接口的起点。 这一切，让百度蒸汽机不再只是一个模型产品，而是新型创作平台与交互接口的起点。 所以说，别再沉迷于用Sora 2做各种meme和表情包了！ 所以说，别再沉迷于用Sora 2做各种meme和表情包了！ 真正让AI视频迈入下一阶段的技术和应用，正在中国发生 。 真正让AI视频迈入下一阶段的技术和应用，正在中国发生 真正让AI视频迈入下一阶段的技术和应用，正在中国发生 。 作为国产AI视频工具代表，百度蒸汽机不仅在技术架构、生成质量上持续演进，更在实时性与交互性这两个决定未来创作形态的关键点上，率先跨出一步。 作为国产AI视频工具代表，百度蒸汽机不仅在技术架构、生成质量上持续演进，更在实时性与交互性这两个决定未来创作形态的关键点上，率先跨出一步。 这不仅是AI视频从片段式生成迈向连续叙事的标志性时刻，也 是AI内容创作从独演走向共创的重要起点 。 这不仅是AI视频从片段式生成迈向连续叙事的标志性时刻，也 是AI内容创作从独演走向共创的重要起点 是AI内容创作从独演走向共创的重要起点 。 看看现在吧——AI视频的下一阶段，不只是高清，不只是更长，而是实时、可交互、效果出众、人人可用。 看看现在吧——AI视频的下一阶段，不只是高清，不只是更长，而是实时、可交互、效果出众、人人可用。 而百度蒸汽机，已经率先抵达新阶段的竞赛场。 而百度蒸汽机，已经率先抵达新阶段的竞赛场。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342036.html", "title": "开源模型TOP5，被中国厂商包圆了", "date": "2025-10-15", "content": "开源模型TOP5，被中国厂商包圆了 开源模型TOP5，被中国厂商包圆了 鱼羊 2025-10-15 16:37:33 来源： 量子位 鱼羊 鱼羊 鱼羊 鱼羊 2025-10-15 2025-10-15 16:37:33 16:37:33 来源： 量子位 来源： 量子位 量子位 摘要样式 国产模型已经从追赶者，转变为引领潮流的一方。 国产模型已经从追赶者，转变为引领潮流的一方。 国产模型已经从追赶者，转变为引领潮流的一方。 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 鱼羊 发自 凹非寺 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 开源大模型，进入中国时间。 开源大模型，进入中国时间。 10月，公开数据显示，来自中国的开源大模型已经牢牢占据榜单前五。 10月，公开数据显示，来自中国的开源大模型已经牢牢占据榜单前五。 阿里的Qwen系列和DeepSeek，更是从2024年下半年起，就在开源社区构建起越来越深远的影响力。 阿里的Qwen系列和DeepSeek，更是从2024年下半年起，就在开源社区构建起越来越深远的影响力。 这一结果正在引发热议。有不少网友指出：这种情况确实已经持续了很长一段时间。 这一结果正在引发热议。有不少网友指出：这种情况确实已经持续了很长一段时间。 比如半年前Llama 4翻车时的梗图，就又被挖了出来： 比如半年前Llama 4翻车时的梗图，就又被挖了出来： 无论是模型质量还是开放程度，这一次，国产模型已经从追赶者，转变为引领潮流的一方。 无论是模型质量还是开放程度，这一次，国产模型已经从追赶者，转变为引领潮流的一方。 紧跟SOTA闭源模型 紧跟SOTA闭源模型 更具体的情况，可以在LMArena公开榜单中窥见一二。 更具体的情况，可以在LMArena公开榜单中窥见一二。 在文本排行榜中，顶级闭源模型如GPT-5、Gemini-2.5-pro、Claude-Sonnet-4.5等之后，紧随而来的就是智谱的GLM-4.6和DeepSeek-v3.2。 在文本排行榜中，顶级闭源模型如GPT-5、Gemini-2.5-pro、Claude-Sonnet-4.5等之后，紧随而来的就是智谱的GLM-4.6和DeepSeek-v3.2。 而Qwen3-max-preview则跻身到了TOP3，不过目前该版本模型并未开源。 而Qwen3-max-preview则跻身到了TOP3，不过目前该版本模型并未开源。 前端开发排行榜中，国产开源模型更是实现了跟编程SOTA Claude的分庭抗礼，DeepSeek-R1/V3.1、GLM-4.6和Qwen3-Coder都排到了前10。 前端开发排行榜中，国产开源模型更是实现了跟编程SOTA Claude的分庭抗礼，DeepSeek-R1/V3.1、GLM-4.6和Qwen3-Coder都排到了前10。 视觉方面，腾讯的Hunyuan-vision-1.5注和Qwen3同样紧跟闭源SOTA，位列开源最强。 视觉方面，腾讯的Hunyuan-vision-1.5注和Qwen3同样紧跟闭源SOTA，位列开源最强。 注：Hunyuan-vision-1.5处于计划开源状态，技术报告和模型权重尚未公布。 注：Hunyuan-vision-1.5处于计划开源状态，技术报告和模型权重尚未公布。 视频模型方面，开源模型中Wan-v2.2表现最佳。 视频模型方面，开源模型中Wan-v2.2表现最佳。 值得注意的是，在这个领域，国产闭源模型同样表现不俗，Kling-2.5、Seedance-v1-pro、Hailuo-02等都位居榜单前列。 值得注意的是，在这个领域，国产闭源模型同样表现不俗，Kling-2.5、Seedance-v1-pro、Hailuo-02等都位居榜单前列。 另一个角度，从HuggingFace的模型下载量和模型趋势上，也可以看出开源模型领域，中国力量越来越活跃、越来越强大了。 另一个角度，从HuggingFace的模型下载量和模型趋势上，也可以看出开源模型领域，中国力量越来越活跃、越来越强大了。 在趋势榜中，蚂蚁的Ling-1T、智谱的GLM-4.6，都是当下最受关注的开源模型。 在趋势榜中，蚂蚁的Ling-1T、智谱的GLM-4.6，都是当下最受关注的开源模型。 最受欢迎模型，依然由DeepSeek-R1担当。 最受欢迎模型，依然由DeepSeek-R1担当。 下载量方面，Qwen3是下载量最高的模型之一。如果将参数规模具体到百亿级，Qwen3更是领先包括gpt-oss在内的其他开源模型。 下载量方面，Qwen3是下载量最高的模型之一。如果将参数规模具体到百亿级，Qwen3更是领先包括gpt-oss在内的其他开源模型。 竞争推动创新，而开源已经被证明，是加速创新的重要力量。 竞争推动创新，而开源已经被证明，是加速创新的重要力量。 有网友认为：现在，这股推动力来自中国。 有网友认为：现在，这股推动力来自中国。 还有人指出，开源模型领域主导地位的转变，不仅仅关乎谁将引领潮流，更重要的是，这或将重新定义全球创新格局。 还有人指出，开源模型领域主导地位的转变，不仅仅关乎谁将引领潮流，更重要的是，这或将重新定义全球创新格局。 Llama 5要无了？ Llama 5要无了？ Anyway，回到开头那张图片上，中国开源力量对大模型格局的冲击，一个重要的节点是“DeepSeek时刻”。 Anyway，回到开头那张图片上，中国开源力量对大模型格局的冲击，一个重要的节点是“DeepSeek时刻”。 而Llama 4的翻车，也不能说没有贡献一份力量（doge）。 而Llama 4的翻车，也不能说没有贡献一份力量（doge）。 最近小扎不是终于把OpenAI前CTO Mira的公司联创Andrew Tulloch挖走了嘛，传闻是给了一份35亿美元的offer。 最近小扎不是终于把OpenAI前CTO Mira的公司联创Andrew Tulloch挖走了嘛，传闻是给了一份35亿美元的offer。 消息一出，又把大家对Llama 5的关注给勾起来了：挖了这么多人，花了这么多钱，Meta超级智能实验室能搞出好东西来吧？ 消息一出，又把大家对Llama 5的关注给勾起来了：挖了这么多人，花了这么多钱，Meta超级智能实验室能搞出好东西来吧？ 但这边刚期待，就有人冒出来泼冷水：Llama 5无了。 但这边刚期待，就有人冒出来泼冷水：Llama 5无了。 爆料人说是Meta的数据集供应方。不过后来他又删掉了这个回复，表示以上并非官方消息，他只是从另一个获得Meta资金的团队那里得到了这个消息。 爆料人说是Meta的数据集供应方。不过后来他又删掉了这个回复，表示以上并非官方消息，他只是从另一个获得Meta资金的团队那里得到了这个消息。 那么，被亚历山大·王动摇了开源决心的小扎，究竟会拿出点什么？ 那么，被亚历山大·王动摇了开源决心的小扎，究竟会拿出点什么？ 板凳，瓜子，长期准备吧~ 板凳，瓜子，长期准备吧~ 参考链接： [1]https://x.com/burkov/status/1977942735962206666 [2]https://lmarena.ai/ 参考链接： [1]https://x.com/burkov/status/1977942735962206666 [2]https://lmarena.ai/ — 完 — — 完 — 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/342026.html", "title": "Robotaxi逐鹿香港上市，小马和文远同日公告了", "date": "2025-10-15", "content": "Robotaxi逐鹿香港上市，小马和文远同日公告了 Robotaxi逐鹿香港上市，小马和文远同日公告了 杰西卡 2025-10-15 16:36:18 来源： 量子位 杰西卡 杰西卡 杰西卡 杰西卡 2025-10-15 2025-10-15 16:36:18 16:36:18 来源： 量子位 来源： 量子位 量子位 摘要样式 赛跑“港股Robotaxi第一股” 赛跑“港股Robotaxi第一股” 赛跑“港股Robotaxi第一股” 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 杰西卡 发自 副驾寺 杰西卡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 智能车参考 | 公众号 AI4Auto 港交所门口，又加入了两位自动驾驶龙头。 港交所门口，又加入了两位自动驾驶龙头。 Robotaxi中概股双雄—— 小马智行和文远知行 ，同日官宣了好消息： Robotaxi中概股双雄—— 小马智行和文远知行 小马智行和文远知行 ，同日官宣了好消息： 已获得中国证监会关于境外发行上市的备案通知，相当于拿到了赴港IPO的钥匙。 已获得中国证监会关于境外发行上市的备案通知，相当于拿到了赴港IPO的钥匙。 去年四季度，两家公司已相继赴美上市，这一次，谁会先拿下 “港股Robotaxi第一股” 之名？ 去年四季度，两家公司已相继赴美上市，这一次，谁会先拿下 “港股Robotaxi第一股” “港股Robotaxi第一股” 之名？ Robotaxi双雄同日官宣回港IPO进展 Robotaxi双雄同日官宣回港IPO进展 小马智行 和 文远知行 同步鸣枪，宣布已通过证监会备案，拿到了港股IPO的通行证。 小马智行 小马智行 和 文远知行 文远知行 同步鸣枪，宣布已通过证监会备案，拿到了港股IPO的通行证。 据备案通知书显示， 小马智行 拟发行不超过 102,146,500股 普通股，在香港联交所上市； 文远知行 则拟发行不超过 102,428,200股 境外上市普通股。 据备案通知书显示， 小马智行 小马智行 拟发行不超过 102,146,500股 102,146,500股 普通股，在香港联交所上市； 文远知行 文远知行 则拟发行不超过 102,428,200股 102,428,200股 境外上市普通股。 两家公司均需要在完成境外发行上市后15个工作日内，通过中国证监会的备案管理信息系统报告发行上市情况。 两家公司均需要在完成境外发行上市后15个工作日内，通过中国证监会的备案管理信息系统报告发行上市情况。 备案通知书也同时规定，本次备案通知书的有效期为 12个月 。 备案通知书也同时规定，本次备案通知书的有效期为 12个月 12个月 。 也就是说，公司自备案出具之日起，一年内未完成境外发行上市，若想继续推进，则需要更新备案材料。 也就是说，公司自备案出具之日起，一年内未完成境外发行上市，若想继续推进，则需要更新备案材料。 这一进展，并不令人意外。 这一进展，并不令人意外。 早在今年 3月 ，外界就有消息称，小马正处于回港上市的初期探讨阶段；5月还有多家媒体报道，小马智行正计划以保密形式递表。 早在今年 3月 3月 ，外界就有消息称，小马正处于回港上市的初期探讨阶段；5月还有多家媒体报道，小马智行正计划以保密形式递表。 文远也在同期传出筹备港股上市的计划，并被报道了秘密提交香港上市申请的动作。 文远也在同期传出筹备港股上市的计划，并被报道了秘密提交香港上市申请的动作。 这两家Robotaxi龙头，在资本市场的进军节奏颇为相似。 这两家Robotaxi龙头，在资本市场的进军节奏颇为相似。 2024年10月，文远在纳斯达克上市，抢先拿下 “全球Robotaxi第一股” 头衔。紧接着，小马也在去年11月登陆纳斯达克。 2024年10月，文远在纳斯达克上市，抢先拿下 “全球Robotaxi第一股” “全球Robotaxi第一股” 头衔。紧接着，小马也在去年11月登陆纳斯达克。 当时，两家总计募资金额都超过了 4.5亿美元 （约32亿元）。 当时，两家总计募资金额都超过了 4.5亿美元 4.5亿美元 （约32亿元）。 如今再获证监会备案，标志着两家公司在 “美股+港股” 双重主要上市的架构，基本已经成型了。在自动驾驶行业里，这种组合还非常稀缺。 如今再获证监会备案，标志着两家公司在 “美股+港股” “美股+港股” 双重主要上市的架构，基本已经成型了。在自动驾驶行业里，这种组合还非常稀缺。 事实上，文远和小马上市节奏相似，选择同一节点回港IPO，并不是巧合。 事实上，文远和小马上市节奏相似，选择同一节点回港IPO，并不是巧合。 两家公司都是中国最早一批的Robotaxi玩家，也各自到了必须“换挡”的阶段。 两家公司都是中国最早一批的Robotaxi玩家，也各自到了必须“换挡”的阶段。 因为自动驾驶行业，特别是Robotaxi行业，已经在 今年迎来了重要转折 。 因为自动驾驶行业，特别是Robotaxi行业，已经在 今年迎来了重要转折 今年迎来了重要转折 。 Robotaxi行业，来到了什么拐点？ Robotaxi行业，来到了什么拐点？ 过去几年，Robotaxi在国内，主要处在 技术验证 和 政策试水 的阶段。 过去几年，Robotaxi在国内，主要处在 技术验证 技术验证 和 政策试水 政策试水 的阶段。 这期间，多数公司的重点都是怎么 把车跑起来、跑得安全稳定，再一点点扩大运营范围 。 这期间，多数公司的重点都是怎么 把车跑起来、跑得安全稳定，再一点点扩大运营范围 把车跑起来、跑得安全稳定，再一点点扩大运营范围 。 自动驾驶的 可行性问题 ，已经在过去几年被反复验证。 自动驾驶的 可行性问题 可行性问题 ，已经在过去几年被反复验证。 但时间到了2025年，故事的节奏明显变了。其实从今年头部玩家的动作上就能发现，Robotaxi正在从测试走向 真正的运营 。 但时间到了2025年，故事的节奏明显变了。其实从今年头部玩家的动作上就能发现，Robotaxi正在从测试走向 真正的运营 真正的运营 。 接下来行业的核心问题，已经从“能不能跑”变成“能不能赚钱”了。而“能不能赚钱”，本质上指的就是 规模 。 接下来行业的核心问题，已经从“能不能跑”变成“能不能赚钱”了。而“能不能赚钱”，本质上指的就是 规模 规模 。 要把成本摊薄、保障系统更稳定，就需要 扩大运营城市、增加车队规模 ，同时还要不断优化算法，提升运营效率。 要把成本摊薄、保障系统更稳定，就需要 扩大运营城市、增加车队规模 扩大运营城市、增加车队规模 ，同时还要不断优化算法，提升运营效率。 反过来，自动驾驶车辆的硬件成本、运营维护成本依然不低，规模化是逼近 盈利 的唯一稳定途径。 反过来，自动驾驶车辆的硬件成本、运营维护成本依然不低，规模化是逼近 盈利 盈利 的唯一稳定途径。 所以今年几大头部L4玩家，在国内也好，海外市场也好，都在快速铺展车队规模。而且，为了加快扩张速度，不少Robotaxi公司还选择合作打造车队： 所以今年几大头部L4玩家，在国内也好，海外市场也好，都在快速铺展车队规模。而且，为了加快扩张速度，不少Robotaxi公司还选择合作打造车队： 百度萝卜快跑 ，已经覆盖北京、上海、深圳、武汉、重庆等至少16个国内城市；海外已进驻中东迪拜和阿布扎比路测，还与Uber、Lyft达成战略合作，计划向中东、亚洲和欧洲进军。 百度萝卜快跑 百度萝卜快跑 ，已经覆盖北京、上海、深圳、武汉、重庆等至少16个国内城市；海外已进驻中东迪拜和阿布扎比路测，还与Uber、Lyft达成战略合作，计划向中东、亚洲和欧洲进军。 到今年8月，萝卜快跑已累计完成超1400万次服务单，安全行驶里程 1.7亿公里 ，相当于绕地球赤道跑了 4243圈 。 到今年8月，萝卜快跑已累计完成超1400万次服务单，安全行驶里程 1.7亿公里 1.7亿公里 ，相当于绕地球赤道跑了 4243圈 4243圈 。 文远知行和小马智行 ，也在国内北京、上海、广州等多个城市进行商业化运营，运营面积正在逐步扩大。光是上个月，两家公司就已几度传出新进展： 文远知行和小马智行 文远知行和小马智行 ，也在国内北京、上海、广州等多个城市进行商业化运营，运营面积正在逐步扩大。光是上个月，两家公司就已几度传出新进展： 文远知行 这边，9月Robotaxi已抵达新加坡开始测试，又和奇瑞、锦江出租合作，在上海开展无人公开道路载人自动驾驶出行示范应用服务，Robobus还拿到了比利时的L4级自动驾驶测试牌照。 文远知行 文远知行 这边，9月Robotaxi已抵达新加坡开始测试，又和奇瑞、锦江出租合作，在上海开展无人公开道路载人自动驾驶出行示范应用服务，Robobus还拿到了比利时的L4级自动驾驶测试牌照。 小马智行 这边，则是在9月拿到了迪拜自动驾驶路测许可，并与新加坡平台商康福德高、卡塔尔国家运输公司Mowasalat分别合作，已经在卡塔尔首都多哈开展Robotaxi路测…… 小马智行 小马智行 这边，则是在9月拿到了迪拜自动驾驶路测许可，并与新加坡平台商康福德高、卡塔尔国家运输公司Mowasalat分别合作，已经在卡塔尔首都多哈开展Robotaxi路测…… 然而，这些动作背后，都意味公司在大把烧钱，需要巨额资本支持——这也是两大L4玩家，如今选择双重上市融资的一个重要原因。 然而，这些动作背后，都意味公司在大把烧钱，需要巨额资本支持——这也是两大L4玩家，如今选择双重上市融资的一个重要原因。 另外，还有一些外部环境，也在把资本市场对Robotaxi的热情推向更高： 另外，还有一些外部环境，也在把资本市场对Robotaxi的热情推向更高： 一方面，自上而下的 政策 ，正在支持自动驾驶规模化落地，北京、上海、天津、武汉等城市都有所动作。 一方面，自上而下的 政策 政策 ，正在支持自动驾驶规模化落地，北京、上海、天津、武汉等城市都有所动作。 比如北京市市场监督管理局，不久前已发布4项自动驾驶领域地方标准；上海也发放了新一批“智能网联汽车示范运营牌照”。 比如北京市市场监督管理局，不久前已发布4项自动驾驶领域地方标准；上海也发放了新一批“智能网联汽车示范运营牌照”。 另一方面，科技公司赴港上市的 融资通道 ，也变得更畅通了。 另一方面，科技公司赴港上市的 融资通道 融资通道 ，也变得更畅通了。 不难发现，面向AI+硬科技、自动驾驶等等科技行业，港交所近两年明显在制度上有所倾斜。 不难发现，面向AI+硬科技、自动驾驶等等科技行业，港交所近两年明显在制度上有所倾斜。 比如，放宽未盈利企业的上市要求，强调技术含量和市场前景；今年5月港交所还开设了 “科企专线” ，允许特定公司通过专用渠道秘密递表……几乎都是为自动驾驶企业量身定做。 比如，放宽未盈利企业的上市要求，强调技术含量和市场前景；今年5月港交所还开设了 “科企专线” “科企专线” ，允许特定公司通过专用渠道秘密递表……几乎都是为自动驾驶企业量身定做。 而且，Robotaxi的阶段转变，并非只在国内，而且是在全球范围，以中美为首的Robotaxi玩家们，都在争分夺秒提速。 而且，Robotaxi的阶段转变，并非只在国内，而且是在全球范围，以中美为首的Robotaxi玩家们，都在争分夺秒提速。 Robotaxi的车轮，步履不停，已在世界各地悄然滚动。 Robotaxi的车轮，步履不停，已在世界各地悄然滚动。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341880.html", "title": "王兴兴硕士论文惊现GitHub，宇树雏形那时候就有了", "date": "2025-10-15", "content": "王兴兴硕士论文惊现GitHub，宇树雏形那时候就有了 王兴兴硕士论文惊现GitHub，宇树雏形那时候就有了 一水 2025-10-15 14:51:32 来源： 量子位 一水 一水 一水 一水 2025-10-15 2025-10-15 14:51:32 14:51:32 来源： 量子位 来源： 量子位 量子位 摘要样式 大学时爱看这些书… 大学时爱看这些书… 大学时爱看这些书… 人火了是连毕业论文都要被翻出来的（doge）。 人火了是连毕业论文都要被翻出来的（doge）。 这不，宇树科技CEO 王兴兴的硕士毕业论文 就被网友们掘地三尺找到了。 这不，宇树科技CEO 王兴兴的硕士毕业论文 王兴兴的硕士毕业论文 就被网友们掘地三尺找到了。 （不在知网，而是在GitHub上找到的。） （不在知网，而是在GitHub上找到的。） 此时回看这篇近10年前的论文，有两点颇让人注意： 此时回看这篇近10年前的论文，有两点颇让人注意： 一是王兴兴当时大胆押注的电驱式机器人方案，目前已经被业界广泛接受。当时包括波士顿动力在内的国内外团队都将研究集中于液压方案，而现在，这一形式已经发生逆转。（波士顿动力从去年开始改液压为电驱） 一是王兴兴当时大胆押注的电驱式机器人方案，目前已经被业界广泛接受。当时包括波士顿动力在内的国内外团队都将研究集中于液压方案，而现在，这一形式已经发生逆转。（波士顿动力从去年开始改液压为电驱） 二是宇树科技（已经估值百亿且即将IPO）的开局，其实就是源自论文所提出的那只名叫XDog的机器小狗。不止王兴兴本人在多个场合公开提到这只小狗，而且它还被明晃晃摆在宇树科技展厅的起首位置。 二是宇树科技（已经估值百亿且即将IPO）的开局，其实就是源自论文所提出的那只名叫XDog的机器小狗。不止王兴兴本人在多个场合公开提到这只小狗，而且它还被明晃晃摆在宇树科技展厅的起首位置。 当然更重要的是，论文中所蕴含的“性价比”思想后来也几乎成了宇树科技的“立身之本”—— 当然更重要的是，论文中所蕴含的“性价比”思想后来也几乎成了宇树科技的“立身之本”—— 不谈如今已满大街跑的机器狗，这家公司去年8月发布的G1双足人形机器人，更是首次将人形机器人价格下探至10万元大关（9.9万元起售）。 不谈如今已满大街跑的机器狗，这家公司去年8月发布的G1双足人形机器人，更是首次将人形机器人价格下探至10万元大关（9.9万元起售）。 所以，要问明星独角兽宇树科技是如何炼成的？创始人王兴兴的这篇论文，或许可以找到一些线索。 所以，要问明星独角兽宇树科技是如何炼成的？创始人王兴兴的这篇论文，或许可以找到一些线索。 论文已初现机器人“性价比”思维 论文已初现机器人“性价比”思维 这篇论文完成于2016年，题目为《新型电驱式四足机器人研制与测试》。 这篇论文完成于2016年，题目为《新型电驱式四足机器人研制与测试》。 简单总结，论文在当时四足机器人普遍遵循的设计准则基础上，进一步提出了新的设计规则，以提升能效比和运行可靠性。 简单总结，论文在当时四足机器人普遍遵循的设计准则基础上，进一步提出了新的设计规则，以提升能效比和运行可靠性。 并且基于这些规则，最终给出了小型电驱四足机器人 XDog的完整设计方案 。 并且基于这些规则，最终给出了小型电驱四足机器人 XDog的完整设计方案 XDog的完整设计方案 。 为什么选择做电驱动的四足机器人？ 为什么选择做电驱动的四足机器人？ 王兴兴后来在公开采访中给出了回答： 王兴兴后来在公开采访中给出了回答： 那时候并没有太多资源和资金，液压驱动力量虽大但成本很高，电驱动技术方案可以大大简化机械结构，降低制造成本，会使四足机器人更加普及。 那时候并没有太多资源和资金，液压驱动力量虽大但成本很高，电驱动技术方案可以大大简化机械结构，降低制造成本，会使四足机器人更加普及。 那时候并没有太多资源和资金，液压驱动力量虽大但成本很高，电驱动技术方案可以大大简化机械结构，降低制造成本，会使四足机器人更加普及。 成本和普及两大目标之下，理工科出身的王兴兴开始自己动手探索电驱四足机器人的设计规则。 成本和普及两大目标之下，理工科出身的王兴兴开始自己动手探索电驱四足机器人的设计规则。 虽然选择的道路和主流不同，但好在当时四足机器人技术整体已在快速发展，所以给他留下了大量学习参考资料。 虽然选择的道路和主流不同，但好在当时四足机器人技术整体已在快速发展，所以给他留下了大量学习参考资料。 基于此，他以MIT Biomimetic Robotics Lab（开源四足狗Cheetah的发源地）提出的四足机器人设计规则为基础，补充提出了几条新的设计规则： 基于此，他以MIT Biomimetic Robotics Lab（开源四足狗Cheetah的发源地）提出的四足机器人设计规则为基础，补充提出了几条新的设计规则： 1）四足机器人腿长腿间距、腿的连杆数及腿布局的选取； 2）四足机器人腿越长越稳、机身质量越大越稳； 3）四足机器人迈步频率越快越稳。 1）四足机器人腿长腿间距、腿的连杆数及腿布局的选取； 2）四足机器人腿越长越稳、机身质量越大越稳； 3）四足机器人迈步频率越快越稳。 其中，在腿部几何参数设计方面，论文通过对多组仿真模型的对比分析指出—— 其中，在腿部几何参数设计方面，论文通过对多组仿真模型的对比分析指出—— 适当增加腿长与腿间距 能够显著提升步态的动态稳定性和地形适应能力； 而连杆数以两级或三级结构为宜 ，可在保证关节自由度的同时降低传动复杂度与能耗；至于腿布局，则建议采用 对称分布、髋关节外展式设计 ，有助于提高侧向稳定性并简化控制算法。 适当增加腿长与腿间距 适当增加腿长与腿间距 能够显著提升步态的动态稳定性和地形适应能力； 而连杆数以两级或三级结构为宜 而连杆数以两级或三级结构为宜 ，可在保证关节自由度的同时降低传动复杂度与能耗；至于腿布局，则建议采用 对称分布、髋关节外展式设计 对称分布、髋关节外展式设计 ，有助于提高侧向稳定性并简化控制算法。 实验验证显示，在这一参数组合下，四足机器人能够在更复杂地形中保持稳定行走，并具备更高的机动性与抗扰动能力。 实验验证显示，在这一参数组合下，四足机器人能够在更复杂地形中保持稳定行走，并具备更高的机动性与抗扰动能力。 为了实际验证上述结论，王兴兴接着完成了 小型四足机器人XDog的整机研制与运控程序的开发 。 为了实际验证上述结论，王兴兴接着完成了 小型四足机器人XDog的整机研制与运控程序的开发 小型四足机器人XDog的整机研制与运控程序的开发 。 XDog采用全电驱动设计，每条腿有两个连杆和三个自由度（整机12个自由度），使用了高功率密度的无刷电机，这些电机直接驱动关节，既保证了足够的力矩输出，又实现了轻量化和紧凑性。 XDog采用全电驱动设计，每条腿有两个连杆和三个自由度（整机12个自由度），使用了高功率密度的无刷电机，这些电机直接驱动关节，既保证了足够的力矩输出，又实现了轻量化和紧凑性。 机身框架由铝合金和碳纤维材料制成，这样的结构既坚固又轻便，有助于在高速运动中保持良好的稳定性和能量效率。 机身框架由铝合金和碳纤维材料制成，这样的结构既坚固又轻便，有助于在高速运动中保持良好的稳定性和能量效率。 在运动控制方面，XDog使用了集中式控制算法，能够根据步态参数实时调整，以适应不同的行走模式，如行走、奔跑和转向。控制系统集成了姿态传感器和足端触觉反馈，结合改进的PD控制和前馈补偿策略，提高了机器人的落足稳定性和动态响应性能。 在运动控制方面，XDog使用了集中式控制算法，能够根据步态参数实时调整，以适应不同的行走模式，如行走、奔跑和转向。控制系统集成了姿态传感器和足端触觉反馈，结合改进的PD控制和前馈补偿策略，提高了机器人的落足稳定性和动态响应性能。 实验结果表明，XDog在多种地形上（如平地、斜坡与碎石地）都能保持稳定行走， 最大行走速度为0.6米/秒，续航时间达到30~60分钟 ，这初步验证了设计规则的有效性。 实验结果表明，XDog在多种地形上（如平地、斜坡与碎石地）都能保持稳定行走， 最大行走速度为0.6米/秒，续航时间达到30~60分钟 最大行走速度为0.6米/秒，续航时间达到30~60分钟 ，这初步验证了设计规则的有效性。 最后，为了提高研发速度和质量，王兴兴还开发了基于ODE（Open Dynamics Engine）的四足机器人运动控制算法开发工具，并介绍了基于ADAMS/Simulink联合仿真的四足机器人设计方法。 最后，为了提高研发速度和质量，王兴兴还开发了基于ODE（Open Dynamics Engine）的四足机器人运动控制算法开发工具，并介绍了基于ADAMS/Simulink联合仿真的四足机器人设计方法。 总之，从这篇论文的核心内容来看，XDog的设计在各个层面（技术路线、选材、结构、算法等）都体现了王兴兴对“机器人性价比”的不懈追求（研发成本最终只有1~2万）。 总之，从这篇论文的核心内容来看，XDog的设计在各个层面（技术路线、选材、结构、算法等）都体现了王兴兴对“机器人性价比”的不懈追求（研发成本最终只有1~2万）。 他还在论文结尾大胆展望，纯电机驱动因其结构简单、低成本、高可控等优点，未来有望成为中小型四足机器人的主流选择。 他还在论文结尾大胆展望，纯电机驱动因其结构简单、低成本、高可控等优点，未来有望成为中小型四足机器人的主流选择。 后来的发展也证实，他的这一判断无疑是正确的。 后来的发展也证实，他的这一判断无疑是正确的。 别的不说，只需要看看从XDog长出的“宇树”这棵大树，你就知道了~ 别的不说，只需要看看从XDog长出的“宇树”这棵大树，你就知道了~ 90后第一人，从XDog到估值百亿的宇树科技 90后第一人，从XDog到估值百亿的宇树科技 XDog最后拿到了上海机器人设计大赛二等奖（此时距离MIT开源机器狗算法还有3年时间），而且还获得了国际电气与电子工程师协会《科技纵览》的报道。 XDog最后拿到了上海机器人设计大赛二等奖（此时距离MIT开源机器狗算法还有3年时间），而且还获得了国际电气与电子工程师协会《科技纵览》的报道。 可以说，成功打响名气的XDog，自然而然成了王兴兴叩开成功之门的“敲门砖”。 可以说，成功打响名气的XDog，自然而然成了王兴兴叩开成功之门的“敲门砖”。 之后不久，王兴兴就凭借XDog拿到了200万元天使投资，并于2016年创办宇树科技，自己担任CEO、CTO。 之后不久，王兴兴就凭借XDog拿到了200万元天使投资，并于2016年创办宇树科技，自己担任CEO、CTO。 接下来的几年时间，他带着公司从头设计了机器狗需要用到的绝大多数零件，包括电机、3D激光雷达等，并顺势将颇具性价比的机器狗卖到了世界各地。 接下来的几年时间，他带着公司从头设计了机器狗需要用到的绝大多数零件，包括电机、3D激光雷达等，并顺势将颇具性价比的机器狗卖到了世界各地。 本以为公司会一直深耕机器狗，结果后来AI来了，于是宇树从2023年起又开始涉足人形机器人这一新领域。 本以为公司会一直深耕机器狗，结果后来AI来了，于是宇树从2023年起又开始涉足人形机器人这一新领域。 王兴兴曾在晚点的采访中透露： 王兴兴曾在晚点的采访中透露： 马斯克2021年要做，有人问我们做不做。说实在的，当时没什么感觉。人形机器人已经火了很多年，马斯克做之前，这个方向已经到低谷期。我也没听说有人要买（人形机器人），圈子里都是悲观态度。 让我决定做的原因是，我越来越相信AI了。2010年时，AI还是低谷，我就非常喜欢神经网络，自己还玩过一点。后来我参加活动也说AI前景很大，但实际上我自己当时不够相信。很多人现在还是不够信。 马斯克2021年要做，有人问我们做不做。说实在的，当时没什么感觉。人形机器人已经火了很多年，马斯克做之前，这个方向已经到低谷期。我也没听说有人要买（人形机器人），圈子里都是悲观态度。 马斯克2021年要做，有人问我们做不做。说实在的，当时没什么感觉。人形机器人已经火了很多年，马斯克做之前，这个方向已经到低谷期。我也没听说有人要买（人形机器人），圈子里都是悲观态度。 让我决定做的原因是，我越来越相信AI了。2010年时，AI还是低谷，我就非常喜欢神经网络，自己还玩过一点。后来我参加活动也说AI前景很大，但实际上我自己当时不够相信。很多人现在还是不够信。 让我决定做的原因是，我越来越相信AI了。2010年时，AI还是低谷，我就非常喜欢神经网络，自己还玩过一点。后来我参加活动也说AI前景很大，但实际上我自己当时不够相信。很多人现在还是不够信。 虽然起步相对国外较晚，但由于可以直接将做机器狗的经验迁移到人形机器人上，所以宇树步子很快，甚至当下已经呈现超车之势。 虽然起步相对国外较晚，但由于可以直接将做机器狗的经验迁移到人形机器人上，所以宇树步子很快，甚至当下已经呈现超车之势。 尤其是今年，其人形机器人自登上春晚扭秧歌一炮而红后，几乎每隔一段时间就会因各种炫酷技能出圈。 尤其是今年，其人形机器人自登上春晚扭秧歌一炮而红后，几乎每隔一段时间就会因各种炫酷技能出圈。 这些热度反映到资本市场上，宇树更是迅速成长为一家估值百亿的明星具身智能独角兽公司。 这些热度反映到资本市场上，宇树更是迅速成长为一家估值百亿的明星具身智能独角兽公司。 而且宇树官方已经确定即将进行IPO（首次公开募股上市），预计今年10月至12月之间，他们会向证券交易所提交申报文件，届时宇树的相关经营数据也将正式披露。 而且宇树官方已经确定即将进行IPO（首次公开募股上市），预计今年10月至12月之间，他们会向证券交易所提交申报文件，届时宇树的相关经营数据也将正式披露。 这场IPO也被网友们评为，“机器人领域最受期待的IPO之一”。 这场IPO也被网友们评为，“机器人领域最受期待的IPO之一”。 毫无疑问，从XDog到估值百亿，宇树科技已然成为国内最受瞩目的机器人企业之一。 毫无疑问，从XDog到估值百亿，宇树科技已然成为国内最受瞩目的机器人企业之一。 而且有意思的是，身为宇树科技创始人，取得如此成就的王兴兴，归来仍不过只有35岁（出生于1990年）。 而且有意思的是，身为宇树科技创始人，取得如此成就的王兴兴，归来仍不过只有35岁（出生于1990年）。 △图源：宇树科技官微 △图源：宇树科技官微 并且除了年龄，他身上的其他标签（双非、英语学渣等）也足够引人注目。 并且除了年龄，他身上的其他标签（双非、英语学渣等）也足够引人注目。 王兴兴本科毕业于浙江理工大学，后来在上海大学完成硕士学业，入职大疆两个月后辞职单干，最初创业时公司只有他一个人。 王兴兴本科毕业于浙江理工大学，后来在上海大学完成硕士学业，入职大疆两个月后辞职单干，最初创业时公司只有他一个人。 相比于受投资者偏爱的名校、大厂、高管背景，90后王兴兴的成功显得有些出人意料。 相比于受投资者偏爱的名校、大厂、高管背景，90后王兴兴的成功显得有些出人意料。 双非本科、英语拉垮的成长经历，在一抓一大把清北学霸和天才少年的具身智能领域，是没什么竞争力。 双非本科、英语拉垮的成长经历，在一抓一大把清北学霸和天才少年的具身智能领域，是没什么竞争力。 而现在，他却已经成为了中国具身智能机器人领域最具标志性的人物。 而现在，他却已经成为了中国具身智能机器人领域最具标志性的人物。 可以说，这位90后创业者用自身经历告诉我们： 可以说，这位90后创业者用自身经历告诉我们： AI时代非常公平，只要聪明，愿意做事，荒漠中终会长出参天大树。 （这也是王兴兴在2025外滩大会上给其他创业者的寄语） AI时代非常公平，只要聪明，愿意做事，荒漠中终会长出参天大树。 （这也是王兴兴在2025外滩大会上给其他创业者的寄语） AI时代非常公平，只要聪明，愿意做事，荒漠中终会长出参天大树。 AI时代非常公平，只要聪明，愿意做事，荒漠中终会长出参天大树。 （这也是王兴兴在2025外滩大会上给其他创业者的寄语） One More Thing One More Thing 王兴兴火了之后，很多人好奇大佬平时都在看哪些书籍。 王兴兴火了之后，很多人好奇大佬平时都在看哪些书籍。 刚巧浙江理工大学（本科母校）也公开了其本科期间的图书借阅记录，一共120本左右。 刚巧浙江理工大学（本科母校）也公开了其本科期间的图书借阅记录，一共120本左右。 王兴兴本人看到后，还特意提到了自己印象最深刻的一本——《游戏编程中的人工智能技术》（没数错的话应该是7次）。 王兴兴本人看到后，还特意提到了自己印象最深刻的一本——《游戏编程中的人工智能技术》（没数错的话应该是7次）。 以及无人在意的角落，网友们还发现了一个华点（doge）： 以及无人在意的角落，网友们还发现了一个华点（doge）： 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341877.html", "title": "得分率超74.6%，京东云JoyCode-Agent位居SWE-Bench全球榜单Top3", "date": "2025-10-15", "content": "得分率超74.6%，京东云JoyCode-Agent位居SWE-Bench全球榜单Top3 得分率超74.6%，京东云JoyCode-Agent位居SWE-Bench全球榜单Top3 henry 2025-10-15 14:45:46 来源： 量子位 henry henry henry henry 2025-10-15 2025-10-15 14:45:46 14:45:46 来源： 量子位 来源： 量子位 量子位 摘要样式 京东云JoyCode-Agent位居智能编码榜单全球Top3 京东云JoyCode-Agent位居智能编码榜单全球Top3 京东云JoyCode-Agent位居智能编码榜单全球Top3 近日，在权威SWE-Bench Verified基准测试中，京东云 JoyCode-Agent凭借74.6%的高通过率位居SWE-Bench榜单全球Top3 ，展现出卓越的复杂编程问题解决能力，并正式在GitHub上开源。作为面向严肃开发场景的企业级编码产品，JoyCode通过规约编程端到端智能体团队与CSR上下文引擎，高效破解大型复杂代码库的维护难题。 近日，在权威SWE-Bench Verified基准测试中，京东云 JoyCode-Agent凭借74.6%的高通过率位居SWE-Bench榜单全球Top3 JoyCode-Agent凭借74.6%的高通过率位居SWE-Bench榜单全球Top3 ，展现出卓越的复杂编程问题解决能力，并正式在GitHub上开源。作为面向严肃开发场景的企业级编码产品，JoyCode通过规约编程端到端智能体团队与CSR上下文引擎，高效破解大型复杂代码库的维护难题。 得分率超74.6%，JoyCode-Agent位居全球Top3 得分率超74.6%，JoyCode-Agent位居全球Top3 得分率超74.6%，JoyCode-Agent位居全球Top3 SWE-Bench Verified通过使用真实世界开源项目中的Bug报告和Issue来测试Agent从理解问题到自主生成、集成和验证修复代码的完整端到端能力，是AI Coding 技术走向和产品落地的行业风向标之一。 SWE-Bench Verified通过使用真实世界开源项目中的Bug报告和Issue来测试Agent从理解问题到自主生成、集成和验证修复代码的完整端到端能力，是AI Coding 技术走向和产品落地的行业风向标之一。 基于领先的技术创新和工程优化，京东云JoyCode-Agent在SWE-Bench Verified 基准测试，凭借74.6%的高通过率位居榜单全球Top3。值得一提的是 ，这一成绩在显著降低 30%-50% 计算成本的前提下达成的 ，不仅证明了 JoyCode-Agent 在复杂编程任务中的高效解决能力，更彰显了其在实际应用场景中的高性价比和商业价值。 基于领先的技术创新和工程优化，京东云JoyCode-Agent在SWE-Bench Verified 基准测试，凭借74.6%的高通过率位居榜单全球Top3。值得一提的是 ，这一成绩在显著降低 30%-50% 计算成本的前提下达成的 ，这一成绩在显著降低 30%-50% 计算成本的前提下达成的 ，不仅证明了 JoyCode-Agent 在复杂编程任务中的高效解决能力，更彰显了其在实际应用场景中的高性价比和商业价值。 首先，端到端自动修复闭环 。JoyCode-Agent采用多智能体协作的设计思路，围绕真实软件仓库问题，构建出“测试生成—补丁生成—验证—经验迁移—智能决策”五大环节闭环。系统不仅能自动理解问题描述，精准生成针对性的补丁，还能同步生成多维度单元测试，全方位验证修复效果，确保补丁既能解决核心问题，又兼顾代码质量与回归安全。 首先，端到端自动修复闭环 首先，端到端自动修复闭环 。JoyCode-Agent采用多智能体协作的设计思路，围绕真实软件仓库问题，构建出“测试生成—补丁生成—验证—经验迁移—智能决策”五大环节闭环。系统不仅能自动理解问题描述，精准生成针对性的补丁，还能同步生成多维度单元测试，全方位验证修复效果，确保补丁既能解决核心问题，又兼顾代码质量与回归安全。 其次，多智能体协作与经验复用 。系统设置了Testing Agent、Patch Agent、CSR Agent、Decision Agent四大核心智能体。各Agent分工协作，通过自动测试约束、代码理解与修改、失败归因、经验检索与投票仲裁，形成高效的自适应迭代机制。 其次，多智能体协作与经验复用 其次，多智能体协作与经验复用 。系统设置了Testing Agent、Patch Agent、CSR Agent、Decision Agent四大核心智能体。各Agent分工协作，通过自动测试约束、代码理解与修改、失败归因、经验检索与投票仲裁，形成高效的自适应迭代机制。 第三，精细化失败归因与资源优化 。JoyCode-Agent创新性地引入失败归因机制，精准区分补丁逻辑缺陷、测试用例问题与环境错误等异常情况，针对不同类型自动选择最优重试路径。相较于业内普遍的“海量采样+投票”粗放式策略，JoyCode-Agent通过有针对性的闭环迭代与经验迁移，显著降低计算资源消耗。 第三，精细化失败归因与资源优化 第三，精细化失败归因与资源优化 。JoyCode-Agent创新性地引入失败归因机制，精准区分补丁逻辑缺陷、测试用例问题与环境错误等异常情况，针对不同类型自动选择最优重试路径。相较于业内普遍的“海量采样+投票”粗放式策略，JoyCode-Agent通过有针对性的闭环迭代与经验迁移，显著降低计算资源消耗。 JoyCode 2.0全面升级，聚焦企业级严肃开发场景 JoyCode 2.0全面升级，聚焦企业级严肃开发场景 JoyCode 2.0全面升级，聚焦企业级严肃开发场景 智能编码平台JoyCode，是京东云专为应对企业级复杂任务而设计的智能编码工具，可提供代码预测续写、注释生成代码、智能代码评审、批量生成单元测试等能力，实现0手写代码的全自动化编程。此次全新升级的2.0版本，具备四大核心特性，为开发者提供更优秀的编程体验。 智能编码平台JoyCode，是京东云专为应对企业级复杂任务而设计的智能编码工具，可提供代码预测续写、注释生成代码、智能代码评审、批量生成单元测试等能力，实现0手写代码的全自动化编程。此次全新升级的2.0版本，具备四大核心特性，为开发者提供更优秀的编程体验。 在智能体团队协同方面， JoyCode 2.0采用多智能体架构，内置可持续学习的智能体生态系统，支持用户根据不同业务场景创建定制化智能体，通过”先规划、后执行”的策略，以团队协作方式智能拆解复杂任务。 在智能体团队协同方面， 在智能体团队协同方面， JoyCode 2.0采用多智能体架构，内置可持续学习的智能体生态系统，支持用户根据不同业务场景创建定制化智能体，通过”先规划、后执行”的策略，以团队协作方式智能拆解复杂任务。 在规约编程方面， JoyCode 2.0通过规约编程机制，基于需求、设计、实施的三阶段工作流程，实现了从需求到交付的端到端覆盖，确保业务意图精准落地为高质量代码，显著降低开发过程中的信息偏差。 在规约编程方面， 在规约编程方面， JoyCode 2.0通过规约编程机制，基于需求、设计、实施的三阶段工作流程，实现了从需求到交付的端到端覆盖，确保业务意图精准落地为高质量代码，显著降低开发过程中的信息偏差。 在CSR上下文引擎方面， 通过对代码仓库的深度解析，全面理解代码仓库上下文等集成开发环境信息，JoyCode 2.0可根据用户意图智能路由检索策略，灵活使用各种规模的代码仓库采取不同的策略组合。 在CSR上下文引擎方面， 在CSR上下文引擎方面， 通过对代码仓库的深度解析，全面理解代码仓库上下文等集成开发环境信息，JoyCode 2.0可根据用户意图智能路由检索策略，灵活使用各种规模的代码仓库采取不同的策略组合。 在一键云端部署方面， JoyCode 2.0支持快速远程项目创建与自动化环境配置，将开发环境与云部署无缝集成，为开发者提供从编码到应用发布的一站式解决方案，极大提升项目交付速度与敏捷性。 在一键云端部署方面， 在一键云端部署方面， JoyCode 2.0支持快速远程项目创建与自动化环境配置，将开发环境与云部署无缝集成，为开发者提供从编码到应用发布的一站式解决方案，极大提升项目交付速度与敏捷性。 当前，JoyCode已服务京东上万名研发人员，支撑数亿级用户产品研发，生成代码采纳率超50%，开发周期缩短40%。 当前，JoyCode已服务京东上万名研发人员，支撑数亿级用户产品研发，生成代码采纳率超50%，开发周期缩短40%。 点击链接了解JoyCode-Agent开源项目： 点击链接了解JoyCode-Agent开源项目： https://github.com/jd-opensource/joycode-agent https://github.com/jd-opensource/joycode-agent 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341842.html", "title": "腾讯发布超低成本AI训练法！120元效果秒杀70000元微调方案", "date": "2025-10-15", "content": "腾讯发布超低成本AI训练法！120元效果秒杀70000元微调方案 腾讯发布超低成本AI训练法！120元效果秒杀70000元微调方案 时令 2025-10-15 14:39:07 来源： 量子位 时令 时令 时令 时令 2025-10-15 2025-10-15 14:39:07 14:39:07 来源： 量子位 来源： 量子位 量子位 摘要样式 将经验知识作为token先验 将经验知识作为token先验 将经验知识作为token先验 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 只花120元，效果吊打70000元微调！ 只花120元，效果吊打70000元微调！ 腾讯提出一种升级大模型智能体的新方法——无训练组相对策略优化Training-Free GRPO。 腾讯提出一种升级大模型智能体的新方法——无训练组相对策略优化Training-Free GRPO。 无需调整任何参数，只要在提示词中学习简短经验，即可实现高性价比提升模型性能 。 无需调整任何参数，只要在提示词中学习简短经验，即可实现高性价比提升模型性能 无需调整任何参数，只要在提示词中学习简短经验，即可实现高性价比提升模型性能 。 实验表明，在数学推理和网页搜索任务上，利用无训练GRPO的DeepSeek-V3.1-Terminus模型展现出显著的跨领域性能提升。 实验表明，在数学推理和网页搜索任务上，利用无训练GRPO的DeepSeek-V3.1-Terminus模型展现出显著的跨领域性能提升。 与微调32B模型相比，该方法在671B大型模型上所需训练数据更少、成本更低。 与微调32B模型相比，该方法在671B大型模型上所需训练数据更少、成本更低。 网友不禁表示： 网友不禁表示： 也太划算了吧！ 也太划算了吧！ 也太划算了吧！ 下面具体来看。 下面具体来看。 将经验知识作为token先验 将经验知识作为token先验 如今，大语言模型正逐渐成为强大的通用智能体，在复杂问题解决、网页研究等通用任务中表现出色。 如今，大语言模型正逐渐成为强大的通用智能体，在复杂问题解决、网页研究等通用任务中表现出色。 然而，在需外部工具（如计算器、API） 和特定提示策略的专业场景中，LLM往往会因对领域需求和工具不熟悉，而导致性能欠佳。 然而，在需外部工具（如计算器、API） 和特定提示策略的专业场景中，LLM往往会因对领域需求和工具不熟悉，而导致性能欠佳。 为了弥补上述差距，基于GRPO的强化学习通过参数空间调整实现对模型行为的定向优化。尽管这些方法能有效提升特定任务的能力，但其对LLM参数调优的依赖仍存在多方面挑战： 为了弥补上述差距，基于GRPO的强化学习通过参数空间调整实现对模型行为的定向优化。尽管这些方法能有效提升特定任务的能力，但其对LLM参数调优的依赖仍存在多方面挑战： 算力成本高； 跨领域泛化能力弱； 数据稀缺； 收益递减。 算力成本高； 算力成本高； 跨领域泛化能力弱； 跨领域泛化能力弱； 数据稀缺； 数据稀缺； 收益递减。 收益递减。 参数调优中的这些局限引发了一个根本性问题：在参数空间中应用强化学习是否是唯一可行的方法？能否以非参数化的方式提升LLM智能体的性能，同时降低数据和计算成本？ 参数调优中的这些局限引发了一个根本性问题：在参数空间中应用强化学习是否是唯一可行的方法？能否以非参数化的方式提升LLM智能体的性能，同时降低数据和计算成本？ 为此，腾讯优图团队提出了 无训练组相对策略优化 ，通过轻量级的token先验在上下文中学习经验知识，无需修改模型参数即可提升LLM智能体性能。 为此，腾讯优图团队提出了 无训练组相对策略优化 无训练组相对策略优化 ，通过轻量级的token先验在上下文中学习经验知识，无需修改模型参数即可提升LLM智能体性能。 Training-Free GRPO重新利用了传统GRPO基于组间相对评估的核心逻辑，但将其转化为非参数化的推理阶段过程。 Training-Free GRPO重新利用了传统GRPO基于组间相对评估的核心逻辑，但将其转化为非参数化的推理阶段过程。 该方法保持参数θ永久冻结，转而维护一个外部经验知识库（初始为空集），通过动态更新知识库而非模型参数来实现性能优化。 该方法保持参数θ永久冻结，转而维护一个外部经验知识库（初始为空集），通过动态更新知识库而非模型参数来实现性能优化。 随后，Training-Free GRPO生成自然语言形式的组相对语义优势。 随后，Training-Free GRPO生成自然语言形式的组相对语义优势。 具体流程如下所示： 具体流程如下所示： 1、对于每个输出，免训练GRPO首先让同一个大语言模型M生成对应分析摘要。 1、对于每个输出，免训练GRPO首先让同一个大语言模型M生成对应分析摘要。 2、基于摘要集和当前经验，由M说明每个输出相对成功或失败的原因，然后提取出简明的自然语言经验。 2、基于摘要集和当前经验，由M说明每个输出相对成功或失败的原因，然后提取出简明的自然语言经验。 之后，传统GRPO会通过对单个批次中所有优势计算得到的目标函数进行梯度上升，从而更新模型参数θ。 之后，传统GRPO会通过对单个批次中所有优势计算得到的目标函数进行梯度上升，从而更新模型参数θ。 而在Training-Free GRPO中，该方法通过使用当前批次中的所有语义优势A_text来更新经验库，每条操作可能包括： 而在Training-Free GRPO中，该方法通过使用当前批次中的所有语义优势A_text来更新经验库，每条操作可能包括： Add（添加） ：将A_text中描述的经验直接追加到经验库 中。 Delete（删除） ：根据A_text，从经验库中移除低质量经验。 Modify（修改） ：根据A_text提供的见解，优化或改进经验库中已有的经验。 Keep（保留） ：经验库保持不变。 Add（添加） ：将A_text中描述的经验直接追加到经验库 中。 Add（添加） Add（添加） ：将A_text中描述的经验直接追加到经验库 中。 Delete（删除） ：根据A_text，从经验库中移除低质量经验。 Delete（删除） Delete（删除） ：根据A_text，从经验库中移除低质量经验。 Modify（修改） ：根据A_text提供的见解，优化或改进经验库中已有的经验。 Modify（修改） Modify（修改） ：根据A_text提供的见解，优化或改进经验库中已有的经验。 Keep（保留） ：经验库保持不变。 Keep（保留） Keep（保留） ：经验库保持不变。 在更新经验库后，条件策略会在随后的批次或训练轮次中生成偏移后的输出分布。 在更新经验库后，条件策略会在随后的批次或训练轮次中生成偏移后的输出分布。 可以说，Training-Free GRPO是通过改变上下文而非模型参数本身，将模型引向高奖励输出。 可以说，Training-Free GRPO是通过改变上下文而非模型参数本身，将模型引向高奖励输出。 其中，被冻结的基础模型起到了 强先验（strong prior） 的作用，不仅保证输出的连贯性，还提供了类似于GRPO中KL散度约束的内在稳定性，防止策略过度偏离参考模型。 其中，被冻结的基础模型起到了 强先验（strong prior） 强先验（strong prior） 的作用，不仅保证输出的连贯性，还提供了类似于GRPO中KL散度约束的内在稳定性，防止策略过度偏离参考模型。 实验结果 实验结果 为评估免训练GRPO方法的性能，团队在数学推理和网络搜索两大基准测试上开展了多维度对比实验。 为评估免训练GRPO方法的性能，团队在数学推理和网络搜索两大基准测试上开展了多维度对比实验。 在实验中，研究主要关注的是现实应用中难以微调且成本高昂的大型高性能LLM，例如 DeepSeek-V3.1-Terminus 。 在实验中，研究主要关注的是现实应用中难以微调且成本高昂的大型高性能LLM，例如 DeepSeek-V3.1-Terminus DeepSeek-V3.1-Terminus 。 实验结果显示，Training-Free GRPO在数学推理任务中取得了显著提升，无论是否使用工具，均表现出明显优势。 实验结果显示，Training-Free GRPO在数学推理任务中取得了显著提升，无论是否使用工具，均表现出明显优势。 基线模型DeepSeek-V3.1-Terminus+ReAct在AIME24和AIME25上的得分分别为80.0%和 67.9%，而应用Training Free GRPO后，冻结模型的表现显著提升至82.7%和73.3%，分别带来2.7%和5.4%的绝对增益。 基线模型DeepSeek-V3.1-Terminus+ReAct在AIME24和AIME25上的得分分别为80.0%和 67.9%，而应用Training Free GRPO后，冻结模型的表现显著提升至82.7%和73.3%，分别带来2.7%和5.4%的绝对增益。 值得注意的是，这一提升仅使用了100个跨域训练样本，并且无需任何梯度更新。相比之下，传统强化学习方法如ReTool和AFM在32B LLM上通常需要数千个训练样本， 成本超过10000美元 ，而Training Free GRPO 仅需约18美元 。 值得注意的是，这一提升仅使用了100个跨域训练样本，并且无需任何梯度更新。相比之下，传统强化学习方法如ReTool和AFM在32B LLM上通常需要数千个训练样本， 成本超过10000美元 成本超过10000美元 ，而Training Free GRPO 仅需约18美元 仅需约18美元 。 在AIME24和AIME25实验中，随着每一步学习，模型表现持续提升，这表明仅从100个问题中学到的经验能够有效泛化，同时也凸显了多步学习的必要性。 在AIME24和AIME25实验中，随着每一步学习，模型表现持续提升，这表明仅从100个问题中学到的经验能够有效泛化，同时也凸显了多步学习的必要性。 此外，在训练过程以及跨域评估中，模型的平均工具调用次数都有所下降。这表明Training-Free GRPO不仅促使模型做出正确的推理和决策，还能教会智能体更高效、更谨慎地使用工具。 此外，在训练过程以及跨域评估中，模型的平均工具调用次数都有所下降。这表明Training-Free GRPO不仅促使模型做出正确的推理和决策，还能教会智能体更高效、更谨慎地使用工具。 学习到的经验知识帮助智能体发现一些捷径，避免错误或冗余的工具调用，从而验证了基于语义优势优化方法的有效性。 学习到的经验知识帮助智能体发现一些捷径，避免错误或冗余的工具调用，从而验证了基于语义优势优化方法的有效性。 在网络搜索任务中，团队选择在WebWalkerQA基准上评估免训练GRPO方法的有效性。 在网络搜索任务中，团队选择在WebWalkerQA基准上评估免训练GRPO方法的有效性。 可以看出，该方法在使用DeepSeek-V3.1-Terminus模型时实现了67.8%的Pass@1得分，较基线63.2%有显著提升。 可以看出，该方法在使用DeepSeek-V3.1-Terminus模型时实现了67.8%的Pass@1得分，较基线63.2%有显著提升。 此外，研究还对来自WebWalkerQA的51个实例进行分层随机抽样，以开展消融实验。 此外，研究还对来自WebWalkerQA的51个实例进行分层随机抽样，以开展消融实验。 由上图可知，直接使用生成的经验会略微降低ReAct的性能（Pass@1 为64.7%，相比原来的66.7%），这说明仅靠上下文示例而没有经过优化，难以带来性能提升。 由上图可知，直接使用生成的经验会略微降低ReAct的性能（Pass@1 为64.7%，相比原来的66.7%），这说明仅靠上下文示例而没有经过优化，难以带来性能提升。 不使用真实答案的Training-Free GRPO在Pass@1上与ReAct保持一致（66.7%），但在Pass@3上提升到78.4%，表明即使没有真实答案，通过相对奖励评估也能提高输出的一致性。 不使用真实答案的Training-Free GRPO在Pass@1上与ReAct保持一致（66.7%），但在Pass@3上提升到78.4%，表明即使没有真实答案，通过相对奖励评估也能提高输出的一致性。 完整的Training-Free GRPO则取得了最佳表现（Pass@1为68.6%，Pass@3为78.4%），凸显了结合真实答案指导、语义优势和经验优化的重要性。 完整的Training-Free GRPO则取得了最佳表现（Pass@1为68.6%，Pass@3为78.4%），凸显了结合真实答案指导、语义优势和经验优化的重要性。 此外，研究还验证了模型能力是基于经验优化能否有效的前提条件。 此外，研究还验证了模型能力是基于经验优化能否有效的前提条件。 实验将Training-Free GRPO应用于QwQ-32B时，Pass@1仅为25.5%，远低于DeepSeek-V3.1-Terminus的66.7%，甚至低于其自身的ReAct基线（27.5%）。这表明该方法的有效性依赖于基础模型在复杂工具使用场景中的推理和工具使用能力。 实验将Training-Free GRPO应用于QwQ-32B时，Pass@1仅为25.5%，远低于DeepSeek-V3.1-Terminus的66.7%，甚至低于其自身的ReAct基线（27.5%）。这表明该方法的有效性依赖于基础模型在复杂工具使用场景中的推理和工具使用能力。 论文链接：https://arxiv.org/abs/2510.08191 参考链接：https://x.com/rohanpaul_ai/status/1978048482003890625 Github链接：https://github.com/TencentCloudADP/youtu-agent/tree/training_free_GRPO 论文链接：https://arxiv.org/abs/2510.08191 参考链接：https://x.com/rohanpaul_ai/status/1978048482003890625 Github链接：https://github.com/TencentCloudADP/youtu-agent/tree/training_free_GRPO 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341817.html", "title": "人工智能年度榜单火热报名中！五大奖项，寻找AI+时代的先锋力量", "date": "2025-10-15", "content": "人工智能年度榜单火热报名中！五大奖项，寻找AI+时代的先锋力量 人工智能年度榜单火热报名中！五大奖项，寻找AI+时代的先锋力量 林樾 2025-10-15 14:19:21 来源： 量子位 林樾 林樾 林樾 林樾 2025-10-15 2025-10-15 14:19:21 14:19:21 来源： 量子位 来源： 量子位 量子位 摘要样式 评选从即日起开始报名 评选从即日起开始报名 评选从即日起开始报名 组委会 发自 凹非寺 量子位｜公众号 QbitAI 组委会 发自 凹非寺 组委会 发自 凹非寺 量子位｜公众号 QbitAI 量子位｜公众号 QbitAI 为了让更多从业者感受智能浪潮的跃迁，也为了给予更多同行同路人掌声与鼓舞，我们将正式启动 「2025人工智能年度榜单」评选报名 。 为了让更多从业者感受智能浪潮的跃迁，也为了给予更多同行同路人掌声与鼓舞，我们将正式启动 「2025人工智能年度榜单」评选报名 「2025人工智能年度榜单」评选报名 。 这是量子位人工智能年度榜单的 第8年 。八年来，我们见证了技术的突破与落地，产业的融合与重塑，也见证了一批又一批推动时代前行的企业、人物与产品。 这是量子位人工智能年度榜单的 第8年 第8年 。八年来，我们见证了技术的突破与落地，产业的融合与重塑，也见证了一批又一批推动时代前行的企业、人物与产品。 在人工智能重新定义一切的时代里，智能技术已不再是单一工具，而是产业与社会协同进化的驱动力。我们期待通过这场年度评选，去发现并致敬那些真正引领变革、开拓边界的探索者与实践者。 在人工智能重新定义一切的时代里，智能技术已不再是单一工具，而是产业与社会协同进化的驱动力。我们期待通过这场年度评选，去发现并致敬那些真正引领变革、开拓边界的探索者与实践者。 本次评选将从 企业 、 产品 、 人物 三大维度，设立五类奖项。欢迎企业踊跃报名！ 本次评选将从 企业 企业 、 产品 产品 、 人物 人物 三大维度，设立五类奖项。欢迎企业踊跃报名！ 让我们共同见证年度之星，点亮未来的方向。 让我们共同见证年度之星，点亮未来的方向。 企业榜 企业榜 2025 人工智能年度 领航企业 2025 人工智能年度 潜力创业公司 2025 人工智能年度 领航企业 2025 人工智能年度 领航企业 领航企业 2025 人工智能年度 潜力创业公司 2025 人工智能年度 潜力创业公司 潜力创业公司 产品榜 产品榜 2025 人工智能年度 杰出产品 2025 人工智能年度 杰出解决方案 2025 人工智能年度 杰出产品 2025 人工智能年度 杰出产品 杰出产品 2025 人工智能年度 杰出解决方案 2025 人工智能年度 杰出解决方案 杰出解决方案 人物榜 人物榜 2025 人工智能年度 焦点人物 2025 人工智能年度 焦点人物 2025 人工智能年度 焦点人物 焦点人物 详细评选标准及报名方式如下。 详细评选标准及报名方式如下。 2025 人工智能年度领航企业 2025 人工智能年度领航企业 将面向中国人工智能领域，评选出最具综合实力的企业， 参选条件 ： 将面向中国人工智能领域，评选出最具综合实力的企业， 参选条件 参选条件 ： 1、注册地在中国，或主营业务主要面向中国市场； 2、主营业务属于人工智能及相关产业，或已将人工智能广泛应用于主营业务，并在细分领域居于行业领先地位； 3、具备成熟的产品或服务，已获得实际客户应用及市场认可； 4、近一年在技术创新、产品落地、市场拓展或商业模式上取得显著突破。 1、注册地在中国，或主营业务主要面向中国市场； 2、主营业务属于人工智能及相关产业，或已将人工智能广泛应用于主营业务，并在细分领域居于行业领先地位； 3、具备成熟的产品或服务，已获得实际客户应用及市场认可； 4、近一年在技术创新、产品落地、市场拓展或商业模式上取得显著突破。 评选标准 ： 评选标准 评选标准 ： 1、 业务能力 ｜市场占有率与营收规模，商业模式与盈利能力，客户数量及行业覆盖面，增长潜力与持续性等； 2、 技术能力 ｜科研实力与技术成果，研发投入比例，技术核心竞争力，创新案例与技术落地情况等； 3、 资本能力 ｜融资情况，财务状况，市值/估值水平等； 4、 其他综合能力 ｜企业综合情况，品牌影响力与行业口碑等。 1、 业务能力 业务能力 ｜市场占有率与营收规模，商业模式与盈利能力，客户数量及行业覆盖面，增长潜力与持续性等； 2、 技术能力 技术能力 ｜科研实力与技术成果，研发投入比例，技术核心竞争力，创新案例与技术落地情况等； 3、 资本能力 资本能力 ｜融资情况，财务状况，市值/估值水平等； 4、 其他综合能力 其他综合能力 ｜企业综合情况，品牌影响力与行业口碑等。 2025 人工智能年度潜力创业公司 2025 人工智能年度潜力创业公司 聚焦于中国人工智能领域创新创业力量，将评选出最具投资价值和发展潜力的AI创业公司， 参选条件 ： 聚焦于中国人工智能领域创新创业力量，将评选出最具投资价值和发展潜力的AI创业公司， 参选条件 参选条件 ： 1、注册地在中国，或主营业务主要面向中国市场； 2、拥有人工智能相关的产品或服务落地，具备可行的商业模式，初步获得市场认可； 3、公司未上市； 4、近一年在技术研发、产品创新或行业应用方面取得显著成果。 1、注册地在中国，或主营业务主要面向中国市场； 2、拥有人工智能相关的产品或服务落地，具备可行的商业模式，初步获得市场认可； 3、公司未上市； 4、近一年在技术研发、产品创新或行业应用方面取得显著成果。 评选标准 ： 评选标准 评选标准 ： 1、 业务潜力 ｜商业模式，目标市场规模，营收增长情况，客户拓展能力等； 2、 技术创新 ｜科研实力，技术成果，差异化优势，落地案例等； 3、 资本能力 ｜融资情况，财务状况，估值水平等； 4、 其他综合能力 ｜企业综合情况，核心团队构成，品牌影响力与行业口碑等。 1、 业务潜力 业务潜力 ｜商业模式，目标市场规模，营收增长情况，客户拓展能力等； 2、 技术创新 技术创新 ｜科研实力，技术成果，差异化优势，落地案例等； 3、 资本能力 资本能力 ｜融资情况，财务状况，估值水平等； 4、 其他综合能力 其他综合能力 ｜企业综合情况，核心团队构成，品牌影响力与行业口碑等。 2025 人工智能年度杰出产品 2025 人工智能年度杰出产品 将聚焦人工智能领域最具代表性与影响力的产品，评选出在技术创新、市场落地和行业引领方面取得突出成绩的AI产品， 参选条件 ： 将聚焦人工智能领域最具代表性与影响力的产品，评选出在技术创新、市场落地和行业引领方面取得突出成绩的AI产品， 参选条件 参选条件 ： 1、产品以人工智能技术为核心或特色，具备明确的应用价值； 2、产品已经投入市场，获得实际用户或客户应用，并取得市场反馈； 3、近一年完成重要技术创新或迭代升级，对人工智能的规模化落地与商业化有显著推动，并对行业发展具有引领作用。 1、产品以人工智能技术为核心或特色，具备明确的应用价值； 2、产品已经投入市场，获得实际用户或客户应用，并取得市场反馈； 3、近一年完成重要技术创新或迭代升级，对人工智能的规模化落地与商业化有显著推动，并对行业发展具有引领作用。 评选标准 ： 评选标准 评选标准 ： 1、 产品力与技术力 ｜功能完整性，性能表现，技术先进性，差异化优势等； 2、 落地情况 ｜市场占有率，用户规模，营收情况，行业应用价值等； 3、 其他综合能力 ｜品牌影响力，用户口碑，产品生态等。 1、 产品力与技术力 产品力与技术力 ｜功能完整性，性能表现，技术先进性，差异化优势等； 2、 落地情况 落地情况 ｜市场占有率，用户规模，营收情况，行业应用价值等； 3、 其他综合能力 其他综合能力 ｜品牌影响力，用户口碑，产品生态等。 2025 人工智能年度杰出解决方案 2025 人工智能年度杰出解决方案 将聚焦人工智能在不同行业与场景中的典型应用，评选出在创新性、落地性和行业推动力方面表现突出的AI解决方案， 参选条件 ： 将聚焦人工智能在不同行业与场景中的典型应用，评选出在创新性、落地性和行业推动力方面表现突出的AI解决方案， 参选条件 参选条件 ： 1、解决方案以自主创新的人工智能技术为核心或特色，具备明确的应用场景与价值； 2、解决方案已在实际业务或行业场景中落地实施，获得客户验证和市场反馈； 3、近一年在技术融合、应用创新或商业模式上有显著突破，对行业智能化转型和发展产生积极推动作用。 1、解决方案以自主创新的人工智能技术为核心或特色，具备明确的应用场景与价值； 2、解决方案已在实际业务或行业场景中落地实施，获得客户验证和市场反馈； 3、近一年在技术融合、应用创新或商业模式上有显著突破，对行业智能化转型和发展产生积极推动作用。 评选标准 ： 评选标准 评选标准 ： 1、 创新性 ｜技术融合能力，应用模式创新，差异化优势等； 2、 落地情况 ｜市场占有率，客户情况，营收情况，潜在市场规模等； 3、 其他综合能力 ｜销售与服务能力，品牌影响力，客户口碑，行业生态等。 1、 创新性 创新性 ｜技术融合能力，应用模式创新，差异化优势等； 2、 落地情况 落地情况 ｜市场占有率，客户情况，营收情况，潜在市场规模等； 3、 其他综合能力 其他综合能力 ｜销售与服务能力，品牌影响力，客户口碑，行业生态等。 2025 人工智能年度焦点人物 2025 人工智能年度焦点人物 将面向中国人工智能领域，评选出最受关注的新星与行业领军人物， 参选条件 ： 将面向中国人工智能领域，评选出最受关注的新星与行业领军人物， 参选条件 参选条件 ： 1、国籍为中国，或所属公司主体在中国，并且为所在公司创始团队成员或核心高管； 2、所属公司主营业务属于人工智能及相关产业，或已将人工智能广泛应用于主营业务，公司在所在领域具有一定影响力； 3、近一年带领团队在AI技术或商业化方面取得显著突破，对行业发展产生重要影响； 4、具有持续贡献潜力和较高的行业认可度。 1、国籍为中国，或所属公司主体在中国，并且为所在公司创始团队成员或核心高管； 2、所属公司主营业务属于人工智能及相关产业，或已将人工智能广泛应用于主营业务，公司在所在领域具有一定影响力； 3、近一年带领团队在AI技术或商业化方面取得显著突破，对行业发展产生重要影响； 4、具有持续贡献潜力和较高的行业认可度。 同时，科研院所中符合上述条件，且在AI领域具有同等影响力的个人也可参与评选。 同时，科研院所中符合上述条件，且在AI领域具有同等影响力的个人也可参与评选。 评选标准 ： 评选标准 评选标准 ： 1、 企业情况 ｜企业基本情况、行业地位、商业模式、营收情况等； 2、 个人能力 ｜技术能力、商业能力、创新能力及团队领导力等； 3、 其他综合能力 ｜个人学术或行业背景、品牌影响力、社会及行业认可度等。 1、 企业情况 企业情况 ｜企业基本情况、行业地位、商业模式、营收情况等； 2、 个人能力 个人能力 ｜技术能力、商业能力、创新能力及团队领导力等； 3、 其他综合能力 其他综合能力 ｜个人学术或行业背景、品牌影响力、社会及行业认可度等。 报名方式 报名方式 本次评选从即日起开始报名，截至 2025年11月17日 。评选结果将于量子位主办的 MEET2026智能未来大会 上正式公布。 本次评选从即日起开始报名，截至 2025年11月17日 2025年11月17日 。评选结果将于量子位主办的 MEET2026智能未来大会 MEET2026智能未来大会 上正式公布。 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 如对本次评选有其他疑问，请联系量子位工作人员。添加微信18801103170，或邮件发送至linyu@qbitai.com，并备注「评选-企业-姓名」。 如对本次评选有其他疑问，请联系量子位工作人员。添加微信18801103170，或邮件发送至linyu@qbitai.com，并备注「评选-企业-姓名」。 MEET2026智能未来大会 MEET2026智能未来大会 今年，我们将以 「共生无界，智启未来」 为主题，正式启动 MEET2026智能未来大会 。承袭MEET系列年度行业观察的视角，诚邀科技、产业与学术领域的领军人物齐聚一堂，共同见证行业变革。 今年，我们将以 「共生无界，智启未来」 「共生无界，智启未来」 为主题，正式启动 MEET2026智能未来大会 MEET2026智能未来大会 。承袭MEET系列年度行业观察的视角，诚邀科技、产业与学术领域的领军人物齐聚一堂，共同见证行业变革。 作为年度影响力科技商业峰会，每年最具行业代表性的科技商业领袖，都会来到大会分享前瞻观点与认知。 作为年度影响力科技商业峰会，每年最具行业代表性的科技商业领袖，都会来到大会分享前瞻观点与认知。 每年大会都能吸引 上千名科技从业者 参与， 百万观众线上围观 ， 近百家合作媒体 联合曝光。而MEET智能未来大会也已成为智能科技行业的年度风向标。 每年大会都能吸引 上千名科技从业者 上千名科技从业者 参与， 百万观众线上围观 百万观众线上围观 ， 近百家合作媒体 近百家合作媒体 联合曝光。而MEET智能未来大会也已成为智能科技行业的年度风向标。 这一次，我们希望聚焦正在聚变的智能科技产业，诚邀 技术、产业、投资领域 具有代表性的企业和人物，共同探讨人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力等前沿科技话题。 这一次，我们希望聚焦正在聚变的智能科技产业，诚邀 技术、产业、投资领域 技术、产业、投资领域 具有代表性的企业和人物，共同探讨人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力等前沿科技话题。 12月，诚邀您与我们共论科技行业破局之道！ 12月，诚邀您与我们共论科技行业破局之道！ 12月，诚邀您与我们共论科技行业破局之道！ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341790.html", "title": "谷歌新版Gemini一夜端掉UI：单HTML文件复刻macOS，成功率100%", "date": "2025-10-15", "content": "谷歌新版Gemini一夜端掉UI：单HTML文件复刻macOS，成功率100% 谷歌新版Gemini一夜端掉UI：单HTML文件复刻macOS，成功率100% Jay 2025-10-15 11:50:17 来源： 量子位 Jay Jay Jay Jay 2025-10-15 2025-10-15 11:50:17 11:50:17 来源： 量子位 来源： 量子位 量子位 摘要样式 Gemini 3.0 Pro新SOTA Gemini 3.0 Pro新SOTA Gemini 3.0 Pro新SOTA Jay 发自 凹非寺量子位 | 公众号 QbitAI Jay 发自 凹非寺量子位 | 公众号 QbitAI Jay 发自 凹非寺量子位 | 公众号 QbitAI 前端UI的工作，被谷歌AI一夜干没了。 前端UI的工作，被谷歌AI一夜干没了。 就在最新能力展示中， Gemini 3.0 Pro居然自己“捏”出了一个macOS 。 就在最新能力展示中， Gemini 3.0 Pro居然自己“捏”出了一个macOS Gemini 3.0 Pro居然自己“捏”出了一个macOS 。 只靠几行提示词，谷歌的AI就在浏览器里复刻出了苹果引以为傲的UI。 只靠几行提示词，谷歌的AI就在浏览器里复刻出了苹果引以为傲的UI。 Prompt : Design and create a web os like mac os full functional features from text editor , to dile manager to paint to video editor and all important mac os pre bundled software Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. Prompt Prompt : Design and create a web os like mac os full functional features from text editor , to dile manager to paint to video editor and all important mac os pre bundled software Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. 苹果式动画、窗口最小化、工具栏、浏览器……一应俱全，并且所有功能都能正常运行。 苹果式动画、窗口最小化、工具栏、浏览器……一应俱全，并且所有功能都能正常运行。 甚至还有个彩蛋—— 甚至还有个彩蛋—— 在终端输入“matrix”，就会触发《黑客帝国》同款炫酷特效。 在终端输入“matrix”，就会触发《黑客帝国》同款炫酷特效。 重点在于成功率！ 重点在于成功率！ 因为在A/B测试中不可能重复生成， 以上你看到的所有都完完全全是一次生成的结果，并且源代码已经在CodePen上公开 。 因为在A/B测试中不可能重复生成， 以上你看到的所有都完完全全是一次生成的结果，并且源代码已经在CodePen上公开 以上你看到的所有都完完全全是一次生成的结果，并且源代码已经在CodePen上公开 。 网友惊呼，如果正式版真能达到这样的水准，Gemini无疑将成为史上最强的编程型模型。 网友惊呼，如果正式版真能达到这样的水准，Gemini无疑将成为史上最强的编程型模型。 万物皆可被UI 万物皆可被UI 短短一天之内，苹果、微软、Linux这三足鼎立的PC操作系统江湖就被Gemini 3.0 Pro全包了。 短短一天之内，苹果、微软、Linux这三足鼎立的PC操作系统江湖就被Gemini 3.0 Pro全包了。 有网友尝试让Gemini 3.0 Pro生成一个网页版Windows，结果一次成功。 有网友尝试让Gemini 3.0 Pro生成一个网页版Windows，结果一次成功。 而且，它不仅在终端里内置了Python，还能玩游戏、运行代码，功能完整得离谱。 而且，它不仅在终端里内置了Python，还能玩游戏、运行代码，功能完整得离谱。 Prompt : Design and create a web os like windows os full functional features from text editor , terminal with python and code editor and a game that can be played to dile manager to paint to video editor and all important windows os pre bundled software Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. Prompt Prompt : Design and create a web os like windows os full functional features from text editor , terminal with python and code editor and a game that can be played to dile manager to paint to video editor and all important windows os pre bundled software Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. 没有对比就没有伤害—— 没有对比就没有伤害—— 有网友展示了相同提示词下，Claude 4.5 Sonnet的「杰作」， 连应用图标都点不开 。 有网友展示了相同提示词下，Claude 4.5 Sonnet的「杰作」， 连应用图标都点不开 连应用图标都点不开 。 Linux自然也跑不掉。 Linux自然也跑不掉。 结果依然不错，还可以上维基百科、调用计算器、更换壁纸。 结果依然不错，还可以上维基百科、调用计算器、更换壁纸。 Prompt : Create a fully functional Linux desktop environment (Ubuntu/GNOME style) as a complete web operating system in a single HTML file with embedded CSS and JavaScript. All applications must be fully functional Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. Prompt Prompt : Create a fully functional Linux desktop environment (Ubuntu/GNOME style) as a complete web operating system in a single HTML file with embedded CSS and JavaScript. All applications must be fully functional Use whatever libraries to get this done but make sure I can paste it all into a single HTML file and open it in Chrome.make it interesting and highly detail , shows details that no one expected go full creative and full beauty in one code block. 看到这些，硅基生命派表示非常满意： 看到这些，硅基生命派表示非常满意： 谁说LLM只会鹦鹉学舌的？！ 谁说LLM只会鹦鹉学舌的？！ 谁说LLM只会鹦鹉学舌的？！ 毕竟macOS和windows在网上连行源代码都没有。 毕竟macOS和windows在网上连行源代码都没有。 但也有网友指出， 这只是一个模拟环境，距离真正的OS还差得远 。 但也有网友指出， 这只是一个模拟环境，距离真正的OS还差得远 这只是一个模拟环境，距离真正的OS还差得远 。 确实令人印象深刻，但我们必须区分“仿真”和“实现”的区别。这些其实只是“粘合代码”，底层依赖的都是现有技术。 就像程序员不能因为调用了库就把功劳算在自己头上一样，AI也不能。 确实令人印象深刻，但我们必须区分“仿真”和“实现”的区别。这些其实只是“粘合代码”，底层依赖的都是现有技术。 就像程序员不能因为调用了库就把功劳算在自己头上一样，AI也不能。 确实令人印象深刻，但我们必须区分“仿真”和“实现”的区别。这些其实只是“粘合代码”，底层依赖的都是现有技术。 就像程序员不能因为调用了库就把功劳算在自己头上一样，AI也不能。 One More Thing One More Thing 虽然谷歌尚未公布Gemini 3.0 Pro的正式发布时间，但从以往的泄露节奏和发布规律来看，有业内人士推测它可能会在未来几个月内亮相。 虽然谷歌尚未公布Gemini 3.0 Pro的正式发布时间，但从以往的泄露节奏和发布规律来看，有业内人士推测它可能会在未来几个月内亮相。 一个明显的信号是：网上来自各路influencer的演示视频越来越多了。 一个明显的信号是：网上来自各路influencer的演示视频越来越多了。 不知怎么的，我们在Gemini 3正式发布前看到的demo，比当初2.5 Pro还要多。 不知怎么的，我们在Gemini 3正式发布前看到的demo，比当初2.5 Pro还要多。 不知怎么的，我们在Gemini 3正式发布前看到的demo，比当初2.5 Pro还要多。 上一轮NanoBanana的营销成功，显然让谷歌尝到了“预热”的甜头，这次或许又想再赌一把。 上一轮NanoBanana的营销成功，显然让谷歌尝到了“预热”的甜头，这次或许又想再赌一把。 不过，期望值拉得越高，落差往往也越大——就像当初的GPT-5那样。 不过，期望值拉得越高，落差往往也越大——就像当初的GPT-5那样。 感兴趣的朋友们到CodePen操作起来啦～ 感兴趣的朋友们到CodePen操作起来啦～ macOS: https://codepen.io/ChetasLua/pen/EaPvqVo Windows: https://codepen.io/ChetasLua/pen/yyezLjN Linux: https://codepen.io/ChetasLua/pen/LEGzZaQ macOS: https://codepen.io/ChetasLua/pen/EaPvqVo Windows: https://codepen.io/ChetasLua/pen/yyezLjN Linux: https://codepen.io/ChetasLua/pen/LEGzZaQ 参考链接： [1]https://x.com/chetaslua/status/1977936585522847768 [2]https://www.ainewshub.org/post/google-gemini-3-pro-rumors-release-date-features-and-what-to-expect-in-late-2025?utm_source=chatgpt.com 参考链接： [1]https://x.com/chetaslua/status/1977936585522847768 [2]https://www.ainewshub.org/post/google-gemini-3-pro-rumors-release-date-features-and-what-to-expect-in-late-2025?utm_source=chatgpt.com 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341697.html", "title": "实测新版LiblibAI：终于把模型、生图、工作流塞进一个碗了", "date": "2025-10-15", "content": "实测新版LiblibAI：终于把模型、生图、工作流塞进一个碗了 实测新版LiblibAI：终于把模型、生图、工作流塞进一个碗了 梦瑶 2025-10-15 10:27:13 来源： 量子位 梦瑶 梦瑶 梦瑶 梦瑶 2025-10-15 2025-10-15 10:27:13 10:27:13 来源： 量子位 来源： 量子位 量子位 摘要样式 梦瑶 发自 凹非寺 量子位 公众号 QbitAI 梦瑶 发自 凹非寺 梦瑶 发自 凹非寺 量子位 公众号 QbitAI 量子位 公众号 QbitAI 上网冲浪突然看到这个评论我懵了，升级过后的LiblibAI ，真的有这么好用？ 上网冲浪突然看到这个评论我懵了，升级过后的LiblibAI ，真的有这么好用？ 甚至直接把另一个产品的会员停了，转身冲了年费那种…… 甚至直接把另一个产品的会员停了，转身冲了年费那种…… 这我可得试试了。 这我可得试试了。 直接说体感发现：这次LiblibAI不仅一口气上线了N个模型，连视频都加了特效玩法，这波真不是单纯地“换皮上线”。 直接说体感发现：这次LiblibAI不仅一口气上线了N个模型，连视频都加了特效玩法，这波真不是单纯地“换皮上线”。 先简单测了一下，roll了效果出来，发现可能真的有点东西。 先简单测了一下，roll了效果出来，发现可能真的有点东西。 给大家摆几个最简单的效果，图是AI画的，视频是AI做的，这些内容在LiblibAI这一个平台里就能搞定—— 给大家摆几个最简单的效果，图是AI画的，视频是AI做的，这些内容在LiblibAI这一个平台里就能搞定—— 比如这个，仿佛下一秒就是游戏CG开场： 比如这个，仿佛下一秒就是游戏CG开场： 还有这个，小女孩突然气球附体，咻地一声飞走了，毫无防备： 还有这个，小女孩突然气球附体，咻地一声飞走了，毫无防备： 浅浅跑了几个case，发现效果居然都还不错。 浅浅跑了几个case，发现效果居然都还不错。 这下，我彻底坐不住了，决定正儿八经实测一波走起～ 这下，我彻底坐不住了，决定正儿八经实测一波走起～ 一手实测LiblibAI 2.0 一手实测LiblibAI 2.0 先说AI用户们最关心的创作链路和核心升级。 先说AI用户们最关心的创作链路和核心升级。 这次LiblibAI 2.0最大的动作，就是从一个“找模型”的网站，变成了可以直接做“AIGC流水线”的平台。 这次LiblibAI 2.0最大的动作，就是从一个“找模型”的网站，变成了可以直接做“AIGC流水线”的平台。 也就是说，大家用AI创作时就不用再开一堆网站来回切了，老用户看到这，可能会忍不住感慨一句：终于啊！ 也就是说，大家用AI创作时就不用再开一堆网站来回切了，老用户看到这，可能会忍不住感慨一句：终于啊！ 而且这次界面也变了不少，整体风格从“极客社区范”，变成了有点像“ChatGPT+Canva”的合体？ 而且这次界面也变了不少，整体风格从“极客社区范”，变成了有点像“ChatGPT+Canva”的合体？ 能调模型，也能做设计，不错不错。 能调模型，也能做设计，不错不错。 模型能力 这块，也没有丢底子。 模型能力 模型能力 这块，也没有丢底子。 LiblibAI一开始给自己的定位就是 国内SD圈子最硬核的多模型社区 ，这次当然也没落下它的基本盘。 LiblibAI一开始给自己的定位就是 国内SD圈子最硬核的多模型社区 国内SD圈子最硬核的多模型社区 ，这次当然也没落下它的基本盘。 LiblibAI 2.0这次把 Qwen-Image、Seedream 4.0、Nano-Banana 这些热门模型直接搬上桌，想用哪个用哪个。 LiblibAI 2.0这次把 Qwen-Image、Seedream 4.0、Nano-Banana Qwen-Image、Seedream 4.0、Nano-Banana 这些热门模型直接搬上桌，想用哪个用哪个。 值得一提的是，LiblibAI这次还接入了Midjourney家族当前最强的版本—— V7模型 。 值得一提的是，LiblibAI这次还接入了Midjourney家族当前最强的版本—— V7模型 V7模型 。 要知道，Midjourney的V7模型在今年4月才刚刚发布，而国内不少平台才在近期陆续接入。 要知道，Midjourney的V7模型在今年4月才刚刚发布，而国内不少平台才在近期陆续接入。 对比圈内节奏，LiblibAI这波节拍点把握得不慢啊～ 对比圈内节奏，LiblibAI这波节拍点把握得不慢啊～ 至于 视频模型 ，升级后的LibLibAI 2.0集得也挺全—— 至于 视频模型 视频模型 ，升级后的LibLibAI 2.0集得也挺全—— 这次把 海螺2.0、通义万相2.5、可灵2.5、Vidu Q1 等主流视频模型都集齐了。 这次把 海螺2.0、通义万相2.5、可灵2.5、Vidu Q1 海螺2.0、通义万相2.5、可灵2.5、Vidu Q1 等主流视频模型都集齐了。 这一锅炖下来，新老模型真·都被照顾到了…… 这一锅炖下来，新老模型真·都被照顾到了…… 但个人体验下来，这次最有看头也是最想和大家分享的，当属它视频生成页面的 添加特效 功能，可以直接在视频生成板块“添加特效”。 但个人体验下来，这次最有看头也是最想和大家分享的，当属它视频生成页面的 添加特效 添加特效 功能，可以直接在视频生成板块“添加特效”。 简单压测了三把： 简单压测了三把： 第一测，上传了一张城堡的图片，选择了一个“一飞冲天”的特效，于是乎： 第一测，上传了一张城堡的图片，选择了一个“一飞冲天”的特效，于是乎： 好家伙，古老城堡摇身一变成火箭，直接发射到天空！ 好家伙，古老城堡摇身一变成火箭，直接发射到天空！ 再试一把，这次选了个飞行特效，让小猫化身小蜜蜂，也体验一把“一飞冲天”的感觉： 再试一把，这次选了个飞行特效，让小猫化身小蜜蜂，也体验一把“一飞冲天”的感觉： 动作衔接都还行，就是飞着飞着，猫儿这个瞳孔颜色突然变了。稳定性和一致性这一块，模型还有有待进步的空间（老师推眼镜.gif）。 动作衔接都还行，就是飞着飞着，猫儿这个瞳孔颜色突然变了。稳定性和一致性这一块，模型还有有待进步的空间（老师推眼镜.gif）。 最后第三测，再来整个好玩的—— 最后第三测，再来整个好玩的—— 生成一张最近超火的NanoBanana同款拍立得照片： 生成一张最近超火的NanoBanana同款拍立得照片： 拍立得倒是拍出来了，Q版人物也挺可爱，但第二秒镜头没对准人脸，画面直接“跑偏”。 拍立得倒是拍出来了，Q版人物也挺可爱，但第二秒镜头没对准人脸，画面直接“跑偏”。 这里顺便提一句，它现在用模板生成视频时， 提示词是锁死的，不支持编辑 。 这里顺便提一句，它现在用模板生成视频时， 提示词是锁死的，不支持编辑 提示词是锁死的，不支持编辑 。 和Pika的逻辑类似，效率高了，但牺牲了一些画面可控性。 和Pika的逻辑类似，效率高了，但牺牲了一些画面可控性。 另一个编辑部小伙伴一致觉得蛮实用的，是视频的 首帧/尾帧功能 。 另一个编辑部小伙伴一致觉得蛮实用的，是视频的 首帧/尾帧功能 首帧/尾帧功能 。 适合搞搞短剧封面、BGM剪辑片段什么的，我做了个“穿越草原和城堡”的效果，首尾都挑得蛮准： 适合搞搞短剧封面、BGM剪辑片段什么的，我做了个“穿越草原和城堡”的效果，首尾都挑得蛮准： 除了模型生成能力外，还有一个小功能很实用： 除了模型生成能力外，还有一个小功能很实用： 这次LiblibAI整合了 全球最大图片风格开源模型库 —— 这次LiblibAI整合了 全球最大图片风格开源模型库 全球最大图片风格开源模型库 —— 覆盖插画、摄影、电商、海报、IP等各类视觉风格，其实本质上是把“模型选型”流程视觉化了。 覆盖插画、摄影、电商、海报、IP等各类视觉风格，其实本质上是把“模型选型”流程视觉化了。 尤其对新用户来说，不用Prompt、不用找教程，直接选个模板就能生出成片。 尤其对新用户来说，不用Prompt、不用找教程，直接选个模板就能生出成片。 真香，但没完全香 真香，但没完全香 这波实测下来，LiblibAI 2.0确实给足了想象空间，从原来那个模型集散地，一脚跳进了创作工作流的大池子里。 这波实测下来，LiblibAI 2.0确实给足了想象空间，从原来那个模型集散地，一脚跳进了创作工作流的大池子里。 但AI体验这事儿，不能光拼模型全不全，还得看用户到底买不买帐—— 但AI体验这事儿，不能光拼模型全不全，还得看用户到底买不买帐—— 比如：这次即便氪了金却换不来更快的出图速度，尤其一次性生四张图的时候……（那一刻感觉钱白花了） 比如：这次即便氪了金却换不来更快的出图速度，尤其一次性生四张图的时候……（那一刻感觉钱白花了） 再比如：模型看似挺多，其实不少是同一家出的不同版本，选项多但惊喜感弱…… 再比如：模型看似挺多，其实不少是同一家出的不同版本，选项多但惊喜感弱…… 此外，一些网友在体验时似乎还出现了页面卡顿的问题： 此外，一些网友在体验时似乎还出现了页面卡顿的问题： 说回LiblibAI这家公司，其实它本身就挺“非典型”，非常擅长内容产品打法。 说回LiblibAI这家公司，其实它本身就挺“非典型”，非常擅长内容产品打法。 在AI应用赛道里，LiblibAI算是一位速度型选手—— 在AI应用赛道里，LiblibAI算是一位速度型选手—— 曾一年跑完 四轮融资 ，创下当时国内AI应用赛道的融资速度纪录。 曾一年跑完 四轮融资 四轮融资 ，创下当时国内AI应用赛道的融资速度纪录。 更值得一提的是，LiblibAI海外子公司打造的另一个AI设计产品，大家也很熟悉，全球首个设计Agent—— Lovart。 更值得一提的是，LiblibAI海外子公司打造的另一个AI设计产品，大家也很熟悉，全球首个设计Agent—— Lovart。 Lovart。 当时产品才内测上线5天，排队体验人数就突破了10万。 当时产品才内测上线5天，排队体验人数就突破了10万。 LiblibAI的创始人 陈冕 也不简单。 LiblibAI的创始人 陈冕 陈冕 也不简单。 此前是 剪映、CapCut 的商业化负责人，也是字节跳动当年最年轻的产品 4-1（对标阿里P9）之一，擅长从“用户-内容-流量”中构建闭环。 此前是 剪映、CapCut 剪映、CapCut 的商业化负责人，也是字节跳动当年最年轻的产品 4-1（对标阿里P9）之一，擅长从“用户-内容-流量”中构建闭环。 所以你就能理解，Liblib从模型广场走向“创作闭环”，并不是试水，而是照着增长路径来搞的。 所以你就能理解，Liblib从模型广场走向“创作闭环”，并不是试水，而是照着增长路径来搞的。 看看现在，Liblib似乎在从“模型开源社区”向“创作者的AI全家桶”转身—— 看看现在，Liblib似乎在从“模型开源社区”向“创作者的AI全家桶”转身—— 这条路看起来顺，实则每一步都不轻松，用户信任并不会因为功能叠加而自然延续，它始终需要被重新验证。 这条路看起来顺，实则每一步都不轻松，用户信任并不会因为功能叠加而自然延续，它始终需要被重新验证。 下一步能不能稳住，不光看工具是不是够强，而在于有没有人，还愿意在这里继续玩下去…是吧？ 下一步能不能稳住，不光看工具是不是够强，而在于有没有人，还愿意在这里继续玩下去…是吧？ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341695.html", "title": "量子+AI4S！玻色量子完成数亿A++轮融资", "date": "2025-10-15", "content": "量子+AI4S！玻色量子完成数亿A++轮融资 量子+AI4S！玻色量子完成数亿A++轮融资 十三 2025-10-15 10:21:02 来源： 量子位 十三 十三 十三 十三 2025-10-15 2025-10-15 10:21:02 10:21:02 来源： 量子位 来源： 量子位 量子位 摘要样式 诺奖开启量子计算大航海时代 诺奖开启量子计算大航海时代 诺奖开启量子计算大航海时代 近期，国内量子计算领军企业——北京玻色量子科技有限公司（以下简称“玻色量子”）完成数亿元A++轮融资。本轮融资由华德科创、南山战新投联合领投，广发信德、湖南财信产业基金、纬德信息（688171）等知名机构和上市公司跟投，老股东啟赋资本持续加码。 近期，国内量子计算领军企业——北京玻色量子科技有限公司（以下简称“玻色量子”）完成数亿元A++轮融资。本轮融资由华德科创、南山战新投联合领投，广发信德、湖南财信产业基金、纬德信息（688171）等知名机构和上市公司跟投，老股东啟赋资本持续加码。 资金将持续用于公司①“专用”相干光量子计算机与“通用”光量子计算机的研发；②量子计算芯片工艺能力建设；③在深圳南山区建设国内首个规模化专用光量子计算机制造工厂并投产运行；④拓展“量子计算+AI”融合应用的商业生态。 资金将持续用于公司①“专用”相干光量子计算机与“通用”光量子计算机的研发；②量子计算芯片工艺能力建设；③在深圳南山区建设国内首个规模化专用光量子计算机制造工厂并投产运行；④拓展“量子计算+AI”融合应用的商业生态。 此次融资是对玻色量子作为国内实用化量子计算的代表性企业的又一次强力肯定。这一成就并非孤立事件，而是置身于全球量子计算投资热潮的大背景之下——此前，从科技巨头英伟达系统性投资光量子路线的PsiQuantum、中性原子路线的QuEra和离子阱路线的Quantinuum的行业动向中，我们已清晰看到全球顶尖资本对量子计算商业化和产业化前景的坚定信心。 此次融资是对玻色量子作为国内实用化量子计算的代表性企业的又一次强力肯定。这一成就并非孤立事件，而是置身于全球量子计算投资热潮的大背景之下——此前，从科技巨头英伟达系统性投资光量子路线的PsiQuantum、中性原子路线的QuEra和离子阱路线的Quantinuum的行业动向中，我们已清晰看到全球顶尖资本对量子计算商业化和产业化前景的坚定信心。 作为国内光量子计算领域的代表企业，玻色量子本次融资正是中国在这一全球性创新竞赛中稳步前行、备受关注的生动体现，标志着中国量子创业企业与资本市场形成了良好的双向互动，彰显了公司作为量子计算产业核心价值平台的分量。凭借稳定真机运行+应用生态壁垒，玻色量子将进一步发挥行业标杆示范效应，持续推动量子计算商业化和产业化进程。 作为国内光量子计算领域的代表企业，玻色量子本次融资正是中国在这一全球性创新竞赛中稳步前行、备受关注的生动体现，标志着中国量子创业企业与资本市场形成了良好的双向互动，彰显了公司作为量子计算产业核心价值平台的分量。凭借稳定真机运行+应用生态壁垒，玻色量子将进一步发挥行业标杆示范效应，持续推动量子计算商业化和产业化进程。 诺奖首次加冕量子计算：开启百家争鸣的大航海时代 诺奖首次加冕量子计算：开启百家争鸣的大航海时代 2025年10月7日，2025年诺贝尔物理学奖的揭晓为量子计算写下历史性注脚：约翰·克拉克（John Clarke）、米歇尔·H·德沃雷特（Michel H. Devoret）与约翰·M·马蒂尼斯（John M. Martinis）因“发现宏观量子力学隧穿效应以及电路中的能量量子化现象”（for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit）摘得桂冠。 2025年10月7日，2025年诺贝尔物理学奖的揭晓为量子计算写下历史性注脚：约翰·克拉克（John Clarke）、米歇尔·H·德沃雷特（Michel H. Devoret）与约翰·M·马蒂尼斯（John M. Martinis）因“发现宏观量子力学隧穿效应以及电路中的能量量子化现象”（for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit）摘得桂冠。 这项四十年前的突破性发现催生了超导量子计算这一研究方向，也将“把宏观量子体系的噪声、温度等各种干扰因素降到单量子水平”这一科学难题摆到台前，至今仍作为研究员们重点攻坚的课题。四十年后的今天，正值量子力学诞生百年，这一殊荣必将进一步鼓舞科学家和工程师对量子计算机实现路径的广泛探索：无论是对超导等宏观系统的操控，还是对光子、囚禁离子和中性原子等微观系统的操控；无论是从构建图灵完备的门型量子计算机，还是短期内可实际用于特定领域的非门型量子计算机，他们的工作恰似量子计算大航海时代的启航灯塔，如今正照亮着通用与专用路线并行、多元技术路径争鸣的壮阔航程！ 这项四十年前的突破性发现催生了超导量子计算这一研究方向，也将“把宏观量子体系的噪声、温度等各种干扰因素降到单量子水平”这一科学难题摆到台前，至今仍作为研究员们重点攻坚的课题。四十年后的今天，正值量子力学诞生百年，这一殊荣必将进一步鼓舞科学家和工程师对量子计算机实现路径的广泛探索：无论是对超导等宏观系统的操控，还是对光子、囚禁离子和中性原子等微观系统的操控；无论是从构建图灵完备的门型量子计算机，还是短期内可实际用于特定领域的非门型量子计算机，他们的工作恰似量子计算大航海时代的启航灯塔，如今正照亮着通用与专用路线并行、多元技术路径争鸣的壮阔航程！ 从应用角度，如今的量子计算已清晰分化为通用和专用两大技术阵营。通用量子计算机以实现任意量子算法为目标，依赖量子纠缠、叠加等核心特性，追求普适性计算能力，其发展需要突破高精度量子比特控制与错误校正等硬件技术瓶颈，以及有实用价值的门线路算法的开发，在更多实用领域证明“量子优越性”。专用量子计算机则聚焦高价值、可复用的特定系列问题优化，通过定制量子物理系统提升求解效率，虽应用范围一定程度上受限，但面向一大类应用场景定制开发奠定了实用基础和市场空间，在NISQ（含噪声的中等规模量子计算）时代率先实现商业化落地，成为当前产业应用的主力军。 从应用角度，如今的量子计算已清晰分化为通用和专用两大技术阵营。通用量子计算机以实现任意量子算法为目标，依赖量子纠缠、叠加等核心特性，追求普适性计算能力，其发展需要突破高精度量子比特控制与错误校正等硬件技术瓶颈，以及有实用价值的门线路算法的开发，在更多实用领域证明“量子优越性”。专用量子计算机则聚焦高价值、可复用的特定系列问题优化，通过定制量子物理系统提升求解效率，虽应用范围一定程度上受限，但面向一大类应用场景定制开发奠定了实用基础和市场空间，在NISQ（含噪声的中等规模量子计算）时代率先实现商业化落地，成为当前产业应用的主力军。 在这一双轨并进的产业图景中，玻色量子基于光量子系统，前瞻性布局专用量子计算+通用量子计算全栈研发能力，以专用量子计算机先行，实现在人工智能、生物制药、金融等多领域的实用算法积累和商业订单，培养成熟的量子应用开发者群体，同时长期投入面向实际需求的通用光量子计算机及量子-经典混合计算能力。以光为径，以用为先，玻色量子持续将理论的潜力转化为推动进步的现实生产力，致力于成为推动量子计算真正走入产业的核心力量。 在这一双轨并进的产业图景中，玻色量子基于光量子系统，前瞻性布局专用量子计算+通用量子计算全栈研发能力，以专用量子计算机先行，实现在人工智能、生物制药、金融等多领域的实用算法积累和商业订单，培养成熟的量子应用开发者群体，同时长期投入面向实际需求的通用光量子计算机及量子-经典混合计算能力。以光为径，以用为先，玻色量子持续将理论的潜力转化为推动进步的现实生产力，致力于成为推动量子计算真正走入产业的核心力量。 “量子”硬件只是起跑线，“计算”系统综合实用性是赛点 “量子”硬件只是起跑线，“计算”系统综合实用性是赛点 从诺奖所表彰的奠基性发现，到如今多元技术路线的竞相发展，量子计算机从实验室走向产业应用的路途上面临着更加综合的要求。单一的物理指标提升，并不等同于量子计算机的实用化。在算力已成为各行业核心生产力的今天，量子硬件的突破只是构建新质生产力的“起跑线”，而能否实现稳定、可靠、可扩展的计算能力，是否提供可用且好用的算法开发工具，能否高效适配日新月异的AI框架并在真实用例中展现出超越经典计算机的实用价值，才是市场对量子计算机真正的期待。 从诺奖所表彰的奠基性发现，到如今多元技术路线的竞相发展，量子计算机从实验室走向产业应用的路途上面临着更加综合的要求。单一的物理指标提升，并不等同于量子计算机的实用化。在算力已成为各行业核心生产力的今天，量子硬件的突破只是构建新质生产力的“起跑线”，而能否实现稳定、可靠、可扩展的计算能力，是否提供可用且好用的算法开发工具，能否高效适配日新月异的AI框架并在真实用例中展现出超越经典计算机的实用价值，才是市场对量子计算机真正的期待。 在当前含噪声中等规模量子（NISQ）时代，“通用”量子计算机基于不同物理体系在可扩展性、连接性、相干时间、保真度和纠错等物理指标上做出了长足的进步，但仍未有一种体系可以克服所有技术难点，实现哪怕1个完整的容错逻辑比特的构建，尚未拿到实用化量子计算的“入场券”。而“专用”量子计算机规避了复杂的逻辑门构建，在错误率和退相干问题上相对容易控制，减少了操作的复杂性，量子比特规模具有高度可扩展性，目前已具备长时间稳定运行的算力提供能力。 在当前含噪声中等规模量子（NISQ）时代，“通用”量子计算机基于不同物理体系在可扩展性、连接性、相干时间、保真度和纠错等物理指标上做出了长足的进步，但仍未有一种体系可以克服所有技术难点，实现哪怕1个完整的容错逻辑比特的构建，尚未拿到实用化量子计算的“入场券”。而“专用”量子计算机规避了复杂的逻辑门构建，在错误率和退相干问题上相对容易控制，减少了操作的复杂性，量子比特规模具有高度可扩展性，目前已具备长时间稳定运行的算力提供能力。 玻色量子现阶段聚焦于“专用”光量子计算实用化与产业化突破，持续迭代并发布自主可控的1,000专用量子比特相干光量子计算机，提供从问题映射、资源调度、量子态演化到结果优化全链条的开发工具和服务验证平台，并基于PyTorch 生态开源多个量子原生AI训练套件，降低了量子计算的应用门槛、扩展了量子应用的开发者生态，让更多行业和研究机构能够体验和利用量子计算的优势，加速科研成果向产业应用的高效转化。 玻色量子现阶段聚焦于“专用”光量子计算实用化与产业化突破，持续迭代并发布自主可控的1,000专用量子比特相干光量子计算机，提供从问题映射、资源调度、量子态演化到结果优化全链条的开发工具和服务验证平台，并基于PyTorch 生态开源多个量子原生AI训练套件，降低了量子计算的应用门槛、扩展了量子应用的开发者生态，让更多行业和研究机构能够体验和利用量子计算的优势，加速科研成果向产业应用的高效转化。 同时，可在室温下长时间稳定运行的整机系统也为生产环境的规模化部署提供可行性。在AI训练等大规模迭代计算的场景下，动辄需要执行数十万次准确的采样计算，对量子计算机的稳定性提出新的要求。玻色量子在可用的1,000量子比特真机基础上，加强纠错算法和多机并联技术开发，持续提升系统的鲁棒性，已实现室温下稳定运行>12h/天。同时，真机的量子比特数目、总耦合数量、耦合精度、标准任务求解性能、高密度任务求解性能、应用综合求解性能等9项指标的实用化技术验证，中国信息通信研究院已出具《相干光量子计算机技术验证报告》给予认证。 同时，可在室温下长时间稳定运行的整机系统也为生产环境的规模化部署提供可行性。在AI训练等大规模迭代计算的场景下，动辄需要执行数十万次准确的采样计算，对量子计算机的稳定性提出新的要求。玻色量子在可用的1,000量子比特真机基础上，加强纠错算法和多机并联技术开发，持续提升系统的鲁棒性，已实现室温下稳定运行>12h/天。同时，真机的量子比特数目、总耦合数量、耦合精度、标准任务求解性能、高密度任务求解性能、应用综合求解性能等9项指标的实用化技术验证，中国信息通信研究院已出具《相干光量子计算机技术验证报告》给予认证。 自公司的100计算量子比特云服务上线以来，随着广大政企、科研工作者、量子算法开发者等用户的不断增加，平台调用求解次数累计超过6800w次，覆盖院校超过900所，参与研发的开发者人数超过10000人。根据广大用户和开发者的一手使用反馈，不断调整软硬件整体系统的技术研发方向，玻色量子坚持真实需求驱动，而非科研指标驱动，形成产品迭代的飞轮效应，进一步贴合真实应用需求，提供市场真正需要的量子计算解决方案。 自公司的100计算量子比特云服务上线以来，随着广大政企、科研工作者、量子算法开发者等用户的不断增加，平台调用求解次数累计超过6800w次，覆盖院校超过900所，参与研发的开发者人数超过10000人。根据广大用户和开发者的一手使用反馈，不断调整软硬件整体系统的技术研发方向，玻色量子坚持真实需求驱动，而非科研指标驱动，形成产品迭代的飞轮效应，进一步贴合真实应用需求，提供市场真正需要的量子计算解决方案。 “量子计算+AI”是星辰大海，打造实用化场景生态 “量子计算+AI”是星辰大海，打造实用化场景生态 如同GPU加速向量运算促进了深度神经网络的发展，量子计算机的全新计算范式为AI模型变革带来新契机。基于2024年诺贝尔物理学奖获得者——神经网络先驱杰弗里·辛顿（Geoffrey Hinton）提出的玻尔兹曼机，玻色量子高具前瞻性的开拓量子神经网络新范式，巧妙利用了伊辛模型与玻尔兹曼机在数学上的等价性，以量子采样替代传统的吉布斯采样（Gibbs Sampling）等方法，解决了玻尔兹曼机因高复杂度而无法高效训练的难点，打造量子AI+生物制药的“杀手级应用”。 如同GPU加速向量运算促进了深度神经网络的发展，量子计算机的全新计算范式为AI模型变革带来新契机。基于2024年诺贝尔物理学奖获得者——神经网络先驱杰弗里·辛顿（Geoffrey Hinton）提出的玻尔兹曼机，玻色量子高具前瞻性的开拓量子神经网络新范式，巧妙利用了伊辛模型与玻尔兹曼机在数学上的等价性，以量子采样替代传统的吉布斯采样（Gibbs Sampling）等方法，解决了玻尔兹曼机因高复杂度而无法高效训练的难点，打造量子AI+生物制药的“杀手级应用”。 截至目前，客户基于玻色量子的相干光量子计算机训练的玻尔兹曼机-变分自编码器（QBM-VAE）已应用于多肽生成、小分子生成、单细胞聚类、mRNA疫苗设计优化、蛋白质多组学分析等多个场景，被证实可有效缩短药物研发周期、提升基因组学研究准确率，或降低药物研发成本。 截至目前，客户基于玻色量子的相干光量子计算机训练的玻尔兹曼机-变分自编码器（QBM-VAE）已应用于多肽生成、小分子生成、单细胞聚类、mRNA疫苗设计优化、蛋白质多组学分析等多个场景，被证实可有效缩短药物研发周期、提升基因组学研究准确率，或降低药物研发成本。 三位一体：开创RNA优化设计，“硬件-范式-算法”新纪元 三位一体：开创RNA优化设计，“硬件-范式-算法”新纪元 三位一体：开创RNA优化设计，“硬件-范式-算法”新纪元 在生态合作上，玻色量子还与广州国家实验室、上海交通大学、中山大学药学院、北京肿瘤医院、清华长庚医院等在蛋白质结构预测、分子相似性筛选、多肽对接、变构位点预测等场景展开实用化量子计算应用探索。此外，玻色量子构建了“药企-高校-医院-国家实验室”四位一体合作体系，未来与顶级高校、医院及药企携手展开深度合作，推动生态共建，共享量子算力与数据资源，加速推进药物开发和临床验证的进程。 在生态合作上，玻色量子还与广州国家实验室、上海交通大学、中山大学药学院、北京肿瘤医院、清华长庚医院等在蛋白质结构预测、分子相似性筛选、多肽对接、变构位点预测等场景展开实用化量子计算应用探索。此外，玻色量子构建了“药企-高校-医院-国家实验室”四位一体合作体系，未来与顶级高校、医院及药企携手展开深度合作，推动生态共建，共享量子算力与数据资源，加速推进药物开发和临床验证的进程。 华德科创董事长姜培兴提到，玻色量子作为国内量子计算领军企业，持续推进相干光量子计算机的研发与应用落地，量子算力服务实力强劲，位居国际一流水平。玻色量子不仅自主攻关量子计算AI领域的关键算法与应用软件，也积极与行业伙伴共建生态，并在AI、生物医药、金融、能源等领域实现真实场景应用，大力推动我国量子计算从“实验室研发”向“产业化应用”的跨越。 华德科创董事长姜培兴提到，玻色量子作为国内量子计算领军企业，持续推进相干光量子计算机的研发与应用落地，量子算力服务实力强劲，位居国际一流水平。玻色量子不仅自主攻关量子计算AI领域的关键算法与应用软件，也积极与行业伙伴共建生态，并在AI、生物医药、金融、能源等领域实现真实场景应用，大力推动我国量子计算从“实验室研发”向“产业化应用”的跨越。 玻色量子创始人文凯、马寅共同表示，本轮融资后，玻色量子将继续深化在“量子计算+AI”领域的技术布局与生态建设。基于量子玻尔兹曼机，玻色量子不仅引领生命科学基础研究和药物发现行业向精准、高效的研发范式加速迈进，开启AI制药新范式，还将全面推进实用化量子计算在各行各业的场景落地。 玻色量子创始人文凯、马寅共同表示，本轮融资后，玻色量子将继续深化在“量子计算+AI”领域的技术布局与生态建设。基于量子玻尔兹曼机，玻色量子不仅引领生命科学基础研究和药物发现行业向精准、高效的研发范式加速迈进，开启AI制药新范式，还将全面推进实用化量子计算在各行各业的场景落地。 随着资金的注入，玻色量子将持续加注量子计算全领域，充分发挥国产专用量子计算优越性，携手越来越多的战略合作伙伴，为千行百业夯实量子算力的“中国基座”。 随着资金的注入，玻色量子将持续加注量子计算全领域，充分发挥国产专用量子计算优越性，携手越来越多的战略合作伙伴，为千行百业夯实量子算力的“中国基座”。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341663.html", "title": "科大讯飞同传大模型再升级  上海、迪拜同发讯飞AI翻译耳机", "date": "2025-10-15", "content": "科大讯飞同传大模型再升级  上海、迪拜同发讯飞AI翻译耳机 科大讯飞同传大模型再升级  上海、迪拜同发讯飞AI翻译耳机 量子位的朋友们 2025-10-15 10:09:25 来源： 量子位 量子位的朋友们 量子位的朋友们 量子位的朋友们 量子位的朋友们 2025-10-15 2025-10-15 10:09:25 10:09:25 来源： 量子位 来源： 量子位 量子位 摘要样式 科大讯飞领跑中国 AI 翻译 科大讯飞领跑中国 AI 翻译 科大讯飞领跑中国 AI 翻译 科大讯飞在上海世界会客厅举行“对话世界，沟通无限 ——AI 同传技术升级暨翻译耳机新品发布会”，并同步联动迪拜 Gitex Global 科技盛会，向全球展示中国 AI 翻译技术的最新突破。发布会上，科大讯飞展示了AI同传技术的第三次重大升级，同时发布AI翻译耳机，讯飞双屏翻译机2.0也迎来功能与应用场景的全面升级。 科大讯飞在上海世界会客厅举行“对话世界，沟通无限 ——AI 同传技术升级暨翻译耳机新品发布会”，并同步联动迪拜 Gitex Global 科技盛会，向全球展示中国 AI 翻译技术的最新突破。发布会上，科大讯飞展示了AI同传技术的第三次重大升级，同时发布AI翻译耳机，讯飞双屏翻译机2.0也迎来功能与应用场景的全面升级。 端到端技术重磅升级 端到端技术重磅升级 此次技术升级的亮点集中在中英同传效果的持续领跑。新一代技术将翻译的主观体验提升至4.6分（满分5分），有效消除了传统机器翻译的“碎片化”和“机械感”。其首字响应时间低至2秒，真正实现了“实时同步”的极致体验。专业化能力的提升同样令人瞩目，通过将专业词库扩充至10万+，新模型成功攻克了医疗、金融、法律等高壁垒行业的翻译难题。此外，语音播报的自然度与拟人度也实现大幅提升。更具创新性的是中英同传新增”声音复刻”功能，用户仅需一句话的语音样本，便可用自己的声音播报翻译结果。在战略布局上，科大讯飞宣布新增中英到阿拉伯语、西班牙语的同传互译功能。 此次技术升级的亮点集中在中英同传效果的持续领跑。新一代技术将翻译的主观体验提升至4.6分（满分5分），有效消除了传统机器翻译的“碎片化”和“机械感”。其首字响应时间低至2秒，真正实现了“实时同步”的极致体验。专业化能力的提升同样令人瞩目，通过将专业词库扩充至10万+，新模型成功攻克了医疗、金融、法律等高壁垒行业的翻译难题。此外，语音播报的自然度与拟人度也实现大幅提升。更具创新性的是中英同传新增”声音复刻”功能，用户仅需一句话的语音样本，便可用自己的声音播报翻译结果。在战略布局上，科大讯飞宣布新增中英到阿拉伯语、西班牙语的同传互译功能。 IDC 最新报告出炉！科大讯飞领跑中国 AI 翻译 IDC 最新报告出炉！科大讯飞领跑中国 AI 翻译 发布会上，科大讯飞还分享了国际权威咨询机构 IDC最新发布的《中国 AI 翻译技术评估，2025》报告。报告显示， 科大讯飞在AI翻译速度、效果、专业度、拟人度、产品应用成熟度、商业化规模、研发投入及用户推荐度8大核心维度中排名第一，其中6项满分 ，展现出在AI翻译技术与产业应用领域的全面领先优势。 发布会上，科大讯飞还分享了国际权威咨询机构 IDC最新发布的《中国 AI 翻译技术评估，2025》报告。报告显示， 科大讯飞在AI翻译速度、效果、专业度、拟人度、产品应用成熟度、商业化规模、研发投入及用户推荐度8大核心维度中排名第一，其中6项满分 科大讯飞在AI翻译速度、效果、专业度、拟人度、产品应用成熟度、商业化规模、研发投入及用户推荐度8大核心维度中排名第一，其中6项满分 ，展现出在AI翻译技术与产业应用领域的全面领先优势。 讯飞翻译耳机新品发布：不止于翻译，更是多语言耳畔智能体 讯飞翻译耳机新品发布：不止于翻译，更是多语言耳畔智能体 依托科大讯飞端到端语音同传大模型的持续优化，讯飞AI翻译耳机在准确度、响应速度和播报自然度上实现全面升级，让跨语言交流更自然、更贴近真人体验。支持60种语言同传互译，内置10万+专业词库，覆盖医疗、制造、金融、法律等高壁垒行业场景，专业术语也能轻松应对。部署专属同传服务集群，中英同传首响播报延迟低至2秒，蓝牙6.0连接技术保障低延迟，带来“实时同步”的流畅体验。用户只需一句话语音样本，系统即可用你的声音播报翻译结果，音色相似度达90%以上。语气、节奏、停顿都更接近真人口译效果，让翻译播报更亲切、更有温度。 依托科大讯飞端到端语音同传大模型的持续优化，讯飞AI翻译耳机在准确度、响应速度和播报自然度上实现全面升级，让跨语言交流更自然、更贴近真人体验。支持60种语言同传互译，内置10万+专业词库，覆盖医疗、制造、金融、法律等高壁垒行业场景，专业术语也能轻松应对。部署专属同传服务集群，中英同传首响播报延迟低至2秒，蓝牙6.0连接技术保障低延迟，带来“实时同步”的流畅体验。用户只需一句话语音样本，系统即可用你的声音播报翻译结果，音色相似度达90%以上。语气、节奏、停顿都更接近真人口译效果，让翻译播报更亲切、更有温度。 发布会现场，新一代讯飞AI翻译耳机连线迪拜Gitex Global展会，实现跨语种实时低延迟对话，引发全场惊叹。这一演示直观展现了科大讯飞在复杂网络环境下的技术稳定性，以及端到端同传大模型的强大算力。跨洲际实时对话，见证技术实力！ 发布会现场，新一代讯飞AI翻译耳机连线迪拜Gitex Global展会，实现跨语种实时低延迟对话，引发全场惊叹。这一演示直观展现了科大讯飞在复杂网络环境下的技术稳定性，以及端到端同传大模型的强大算力。跨洲际实时对话，见证技术实力！ 这款搭载“多感融合AI降噪系统”的首款 “骨导 + 气导” 开放式翻译耳机 ，它配备多麦克风组合与 30 度拾音角度设计，结合 ENC 降噪算法，嘈杂场景也能精准拾音；同时通过定向出音与反相声波抵消技术守护沟通隐私。 该耳机覆盖四大核心场景：通话实时翻译 支持跨洲际对话与多任务并行， 面对面翻译 可双人无按键互译且支持 18 组语种对离线使用， 线上同传 兼具双语转译与录音复盘功能， 旁听同传 凭借 5-8 米定向拾音适配会场需求。此外，它还是 全能 AI 伙伴 ，语音唤醒 “小飞” 即可实现口语陪练、资讯查询等多元服务，还能生成专属语音播客；具备动态音效调节，机身适配多种耳形，钛丝支撑与黄金重心设计兼顾稳固与舒适，单次 12 小时、总 42 小时续航满足长期使用需求。这款耳机以全维优势重塑跨语言沟通，成为用户首选伙伴。 这款搭载“多感融合AI降噪系统”的首款 “骨导 + 气导” 开放式翻译耳机 这款搭载“多感融合AI降噪系统”的首款 “骨导 + 气导” 开放式翻译耳机 ，它配备多麦克风组合与 30 度拾音角度设计，结合 ENC 降噪算法，嘈杂场景也能精准拾音；同时通过定向出音与反相声波抵消技术守护沟通隐私。 该耳机覆盖四大核心场景：通话实时翻译 该耳机覆盖四大核心场景：通话实时翻译 支持跨洲际对话与多任务并行， 面对面翻译 面对面翻译 可双人无按键互译且支持 18 组语种对离线使用， 线上同传 线上同传 兼具双语转译与录音复盘功能， 旁听同传 旁听同传 凭借 5-8 米定向拾音适配会场需求。此外，它还是 全能 AI 伙伴 全能 AI 伙伴 ，语音唤醒 “小飞” 即可实现口语陪练、资讯查询等多元服务，还能生成专属语音播客；具备动态音效调节，机身适配多种耳形，钛丝支撑与黄金重心设计兼顾稳固与舒适，单次 12 小时、总 42 小时续航满足长期使用需求。这款耳机以全维优势重塑跨语言沟通，成为用户首选伙伴。 讯飞双屏翻译机2.0持续升级 讯飞双屏翻译机2.0持续升级 升级后的讯飞双屏翻译机2.0提供了一套从翻译、记录到内容分享的完整翻译解决方案， 堪称是跨国会议党、业务谈判党的福音，轻松解决专业场景的专业沟通需求！ 会议翻译支持讲话人分离功能： 中英会议翻译模式下，可以做到智能区分讲话人，还可以对各位讲话人设置专属名称，避免多人跨语言会议中出现“话不对人”，保证会议节奏同步，达到更自然的会议沟通效果。 新增会议纪要生成与记录分享功能： 会议翻译与旁听同传两大功能将支持基于识别/翻译后的中文内容，通过调用星火办公大模型，对会议内容进行智能纪要整理，同时还支持用户对翻译内容和会议纪要进行分享。讯飞双屏翻译机2.0预计将于10月底迎来正式升级，届时将全量上线升级功能！ 升级后的讯飞双屏翻译机2.0提供了一套从翻译、记录到内容分享的完整翻译解决方案， 升级后的讯飞双屏翻译机2.0提供了一套从翻译、记录到内容分享的完整翻译解决方案， 堪称是跨国会议党、业务谈判党的福音，轻松解决专业场景的专业沟通需求！ 会议翻译支持讲话人分离功能： 会议翻译支持讲话人分离功能： 中英会议翻译模式下，可以做到智能区分讲话人，还可以对各位讲话人设置专属名称，避免多人跨语言会议中出现“话不对人”，保证会议节奏同步，达到更自然的会议沟通效果。 新增会议纪要生成与记录分享功能： 新增会议纪要生成与记录分享功能： 会议翻译与旁听同传两大功能将支持基于识别/翻译后的中文内容，通过调用星火办公大模型，对会议内容进行智能纪要整理，同时还支持用户对翻译内容和会议纪要进行分享。讯飞双屏翻译机2.0预计将于10月底迎来正式升级，届时将全量上线升级功能！ 双城发布，全球化战略加速推进 双城发布，全球化战略加速推进 科大讯飞的AI翻译能力已经构建起覆盖全场景的产品矩阵，在本次互动区呈现科大讯飞打造了讯飞翻译机、讯飞AI翻译耳机、讯飞AI录音笔等智能硬件，讯飞翻译APP、 讯飞翻译SaaS、讯飞同传、讯飞多语言会议系统等智能软件与服务。作为专业翻译领域的佼佼者，讯飞翻译机已服务超百万用户，翻译次数高达10亿次；讯飞AI录音笔用户覆盖全球200多个国家和地区；讯飞同传已服务全球50余国家，支持超42万场会议；面向个人用户的讯飞翻译APP及面向企业用户的讯飞翻译SaaS，实现了从随身实时 AI 翻译助手到全场景AI翻译服务的全方位覆盖。 科大讯飞的AI翻译能力已经构建起覆盖全场景的产品矩阵，在本次互动区呈现科大讯飞打造了讯飞翻译机、讯飞AI翻译耳机、讯飞AI录音笔等智能硬件，讯飞翻译APP、 讯飞翻译SaaS、讯飞同传、讯飞多语言会议系统等智能软件与服务。作为专业翻译领域的佼佼者，讯飞翻译机已服务超百万用户，翻译次数高达10亿次；讯飞AI录音笔用户覆盖全球200多个国家和地区；讯飞同传已服务全球50余国家，支持超42万场会议；面向个人用户的讯飞翻译APP及面向企业用户的讯飞翻译SaaS，实现了从随身实时 AI 翻译助手到全场景AI翻译服务的全方位覆盖。 讯飞翻译SaaS、讯飞同传、讯飞多语言会议系统等智能软件与服务。作为专业翻译领域的佼佼者，讯飞翻译机已服务超百万用户，翻译次数高达10亿次；讯飞AI录音笔用户覆盖全球200多个国家和地区；讯飞同传已服务全球50余国家，支持超42万场会议；面向个人用户的讯飞翻译APP及面向企业用户的讯飞翻译SaaS，实现了从随身实时 AI 翻译助手到全场景AI翻译服务的全方位覆盖。 本次科大讯飞选择在上海和迪拜同步发布新技术、新产品，标志着科大讯飞全球化战略的加速推进。上海作为中国对外开放的前沿窗口，迪拜作为中东地区的商业中心和 “一带一路” 的重要节点城市，两地同步发布不仅是产品的全球发布，更是中国AI技术走向世界舞台的重要标志。在全球化与人工智能深度融合的时代背景下，科大讯飞用 AI 技术架起了连接世界的桥梁，让跨语言交流如母语般自然，让世界因无障碍沟通而更加美好。 本次科大讯飞选择在上海和迪拜同步发布新技术、新产品，标志着科大讯飞全球化战略的加速推进。上海作为中国对外开放的前沿窗口，迪拜作为中东地区的商业中心和 “一带一路” 的重要节点城市，两地同步发布不仅是产品的全球发布，更是中国AI技术走向世界舞台的重要标志。在全球化与人工智能深度融合的时代背景下，科大讯飞用 AI 技术架起了连接世界的桥梁，让跨语言交流如母语般自然，让世界因无障碍沟通而更加美好。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341609.html", "title": "谢赛宁新作：VAE退役，RAE当立", "date": "2025-10-14", "content": "谢赛宁新作：VAE退役，RAE当立 谢赛宁新作：VAE退役，RAE当立 时令 2025-10-14 16:54:00 来源： 量子位 时令 时令 时令 时令 2025-10-14 2025-10-14 16:54:00 16:54:00 来源： 量子位 来源： 量子位 量子位 摘要样式 谢赛宁两次承认自己错了 谢赛宁两次承认自己错了 谢赛宁两次承认自己错了 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 昔日风光无限的VAE，终于被宣判“退役”？ 昔日风光无限的VAE，终于被宣判“退役”？ 谢赛宁团队 最新研究给出了答案—— VAE的时代结束，RAE将接力前行 。 谢赛宁团队 谢赛宁团队 最新研究给出了答案—— VAE的时代结束，RAE将接力前行 VAE的时代结束，RAE将接力前行 。 其中表征自编码器RAE（Representation Autoencoders）是一种用于扩散Transformer（DiT）训练的新型自动编码器，其核心设计是用预训练的表征编码器（如DINO、SigLIP、MAE 等）与训练后的轻量级解码器配对，从而替代传统扩散模型中依赖的VAE（变分自动编码器）。 其中表征自编码器RAE（Representation Autoencoders）是一种用于扩散Transformer（DiT）训练的新型自动编码器，其核心设计是用预训练的表征编码器（如DINO、SigLIP、MAE 等）与训练后的轻量级解码器配对，从而替代传统扩散模型中依赖的VAE（变分自动编码器）。 这种新结构不仅能提供高质量重建结果，还具备语义丰富的潜空间，同时支持可扩展的基于变换器的架构。 这种新结构不仅能提供高质量重建结果，还具备语义丰富的潜空间，同时支持可扩展的基于变换器的架构。 该方法在无需额外表示对齐损失的情况下，实现了更快的收敛速度。通过采用配备轻量级宽型DDT头部的DiT变体，他们在ImageNet上取得强劲的图像生成效果： 该方法在无需额外表示对齐损失的情况下，实现了更快的收敛速度。通过采用配备轻量级宽型DDT头部的DiT变体，他们在ImageNet上取得强劲的图像生成效果： 256×256分辨率下，无引导（no guidance）FID= 1.51； 256×256和512×512分辨率下，有引导（with guidance）FID=1.13。 256×256分辨率下，无引导（no guidance）FID= 1.51； 256×256分辨率下，无引导（no guidance）FID= 1.51； 256×256和512×512分辨率下，有引导（with guidance）FID=1.13。 256×256和512×512分辨率下，有引导（with guidance）FID=1.13。 下面具体来看。 下面具体来看。 VAE退役，RAE当立 VAE退役，RAE当立 如今，Diffusion Transformer虽已取得长足发展，但多数模型仍依赖2021年的旧版SD-VAE构建潜空间。 如今，Diffusion Transformer虽已取得长足发展，但多数模型仍依赖2021年的旧版SD-VAE构建潜空间。 这引发了几大核心问题： 这引发了几大核心问题： 1、 过时的骨干网络，让架构过于复杂。 SD-VAE约需450 GFLOPs运算量，而简易的ViT-B编码器仅需22 GFLOPs。 1、 过时的骨干网络，让架构过于复杂。 过时的骨干网络，让架构过于复杂。 SD-VAE约需450 GFLOPs运算量，而简易的ViT-B编码器仅需22 GFLOPs。 2、 过度压缩的潜空间（只有4个通道），严重限制信息容量。 常言道压缩催生智能，但此处不然：VAE式压缩收效甚微，其信息承载能力与原始3通道像素几乎无异。 2、 过度压缩的潜空间（只有4个通道），严重限制信息容量。 过度压缩的潜空间（只有4个通道），严重限制信息容量。 常言道压缩催生智能，但此处不然：VAE式压缩收效甚微，其信息承载能力与原始3通道像素几乎无异。 3、 薄弱的表征能力。 仅依赖重建训练的模式使VAE学得的特征质量低下（线性探测精度约8%），最终拖慢收敛速度并损害生成质量。现有研究已表明：表征质量直接决定生成效果。而SD-VAE的设计初衷并未涵盖此目标。 3、 薄弱的表征能力。 薄弱的表征能力。 仅依赖重建训练的模式使VAE学得的特征质量低下（线性探测精度约8%），最终拖慢收敛速度并损害生成质量。现有研究已表明：表征质量直接决定生成效果。而SD-VAE的设计初衷并未涵盖此目标。 谢赛宁曾以为语义编码器主要捕获高层次抽象表征而会舍弃细粒度视觉细节，但他现在意识到这个想法是错误的。 谢赛宁曾以为语义编码器主要捕获高层次抽象表征而会舍弃细粒度视觉细节，但他现在意识到这个想法是错误的。 针对上述问题，研究团队采用预训练表征编码器（如基于标准化ViT架构的DINO、SigLIP和MAE）与训练好的解码器相结合，得到了RAE—— 针对上述问题，研究团队采用预训练表征编码器（如基于标准化ViT架构的DINO、SigLIP和MAE）与训练好的解码器相结合，得到了RAE—— 无需额外训练或对齐阶段，没有辅助损失函数，也不引入重新压缩的适配层。 无需额外训练或对齐阶段，没有辅助损失函数，也不引入重新压缩的适配层。 无需额外训练或对齐阶段，没有辅助损失函数，也不引入重新压缩的适配层。 只需获取预训练语义编码器，使用L1+LPIPS+GAN损失训练解码器即可。 只需获取预训练语义编码器，使用L1+LPIPS+GAN损失训练解码器即可。 尽管看起来架构如此简洁，但RAE在重建质量上却能超越SD-VAE。 尽管看起来架构如此简洁，但RAE在重建质量上却能超越SD-VAE。 有意思的是，谢赛宁还以为扩散模型在高维空间中很难高效去噪，但他承认自己又错了。 有意思的是，谢赛宁还以为扩散模型在高维空间中很难高效去噪，但他承认自己又错了。 由于RAE的潜空间本质上是高维的，扩散Transformer确实需要一些适配，但只需三个非常简单的调整，它们的表现就能出乎意料地好。 由于RAE的潜空间本质上是高维的，扩散Transformer确实需要一些适配，但只需三个非常简单的调整，它们的表现就能出乎意料地好。 1、 宽DiT设计 ：要使扩散正常运作，变换器宽度d必须至少等于潜表征维度n。若不满足此条件，模型甚至无法过拟合单个样本。 1、 宽DiT设计 宽DiT设计 ：要使扩散正常运作，变换器宽度d必须至少等于潜表征维度n。若不满足此条件，模型甚至无法过拟合单个样本。 2、 噪声调度 ：依赖分辨率的噪声调度调整早已用于高分辨率图像生成。同理，调整噪声调度可使扩散模型平滑适应增加的输入通道维度。 2、 噪声调度 噪声调度 ：依赖分辨率的噪声调度调整早已用于高分辨率图像生成。同理，调整噪声调度可使扩散模型平滑适应增加的输入通道维度。 3、 噪声解码器 ：为提升解码器对潜空间微小扩散误差的鲁棒性，他们在解码器训练中注入微量噪声。这使解码器能优雅处理重建表征中的细微瑕疵。 3、 噪声解码器 噪声解码器 ：为提升解码器对潜空间微小扩散误差的鲁棒性，他们在解码器训练中注入微量噪声。这使解码器能优雅处理重建表征中的细微瑕疵。 凭借这些简单调整，团队训练的DiT-XL模型已超越REPA，且无需引入任何辅助损失或额外训练阶段。 凭借这些简单调整，团队训练的DiT-XL模型已超越REPA，且无需引入任何辅助损失或额外训练阶段。 采用RAE时，收敛速度比基于SD-VAE的REPA快达16倍。 采用RAE时，收敛速度比基于SD-VAE的REPA快达16倍。 事实表明，模型确实需要足够的宽度，但单纯依靠暴力扩展DiT宽度很快就会变得低效且不切实际。 事实表明，模型确实需要足够的宽度，但单纯依靠暴力扩展DiT宽度很快就会变得低效且不切实际。 为此，他们引入了一个简单而有效的技巧，以在RAE框架内提升DiT的可扩展性。这个思路虽与解耦扩散训练（DDT）存在松散关联，但他们的出发点截然不同。 为此，他们引入了一个简单而有效的技巧，以在RAE框架内提升DiT的可扩展性。这个思路虽与解耦扩散训练（DDT）存在松散关联，但他们的出发点截然不同。 在新架构中，原始DiT作为条件化骨干网络，驱动一个极宽但极浅的扩散头部。该头部以含噪潜变量x_t为输入，直接预测速度向量。 在新架构中，原始DiT作为条件化骨干网络，驱动一个极宽但极浅的扩散头部。该头部以含噪潜变量x_t为输入，直接预测速度向量。 借助RAE潜变量，DiTDH在训练计算量和模型大小方面的扩展效率，均优于基于RAE的标准DiT以及基于VAE的传统方法。 借助RAE潜变量，DiTDH在训练计算量和模型大小方面的扩展效率，均优于基于RAE的标准DiT以及基于VAE的传统方法。 论文链接：https://t.co/FGOAP3Eg5m 参考链接：https://x.com/sainingxie/status/1977936742763094289 论文链接：https://t.co/FGOAP3Eg5m 参考链接：https://x.com/sainingxie/status/1977936742763094289 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341586.html", "title": "不用跟AI客气了！新研究：语气越粗鲁回答正确率越高", "date": "2025-10-14", "content": "不用跟AI客气了！新研究：语气越粗鲁回答正确率越高 不用跟AI客气了！新研究：语气越粗鲁回答正确率越高 闻乐 2025-10-14 16:30:49 来源： 量子位 闻乐 闻乐 闻乐 闻乐 2025-10-14 2025-10-14 16:30:49 16:30:49 来源： 量子位 来源： 量子位 量子位 摘要样式 真不用太礼貌，骂得越狠，答得越准！ 真不用太礼貌，骂得越狠，答得越准！ 真不用太礼貌，骂得越狠，答得越准！ 闻乐 发自 凹非寺 量子位 | 公众号 QbitAI 闻乐 发自 凹非寺 闻乐 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 找AI帮忙不要再客气了，效果根本适得其反。 找AI帮忙不要再客气了，效果根本适得其反。 宾夕法尼亚州立大学的一项研究《Mind Your Tone》显示， 你说话越粗鲁，LLM回答越准 。 宾夕法尼亚州立大学的一项研究《Mind Your Tone》显示， 你说话越粗鲁，LLM回答越准 你说话越粗鲁，LLM回答越准 。 语气越冲，AI正确率达到84.8%。特别客气时，AI正确率反而低了。 语气越冲，AI正确率达到84.8%。特别客气时，AI正确率反而低了。 什么情况，难道是我给AI的温柔过了火？？ 什么情况，难道是我给AI的温柔过了火？？ 用粗鲁语气提问，GPT-4o的正确率反而更高 用粗鲁语气提问，GPT-4o的正确率反而更高 这项研究主要就是想弄清楚和AI说话的语气会不会影响它的正确率。 这项研究主要就是想弄清楚和AI说话的语气会不会影响它的正确率。 我们发给大模型的提示词到底应该是客气、普通还是冲？ 我们发给大模型的提示词到底应该是客气、普通还是冲？ 首先，研究人员整了一个包含50道选择题的题库，涵盖了数学、科学、历史的选择题，难度中等偏上。 首先，研究人员整了一个包含50道选择题的题库，涵盖了数学、科学、历史的选择题，难度中等偏上。 然后给每道题改出了5种语气版本，be like： 然后给每道题改出了5种语气版本，be like： 您能好心帮我解这道题吗？ 请回答这道题。 直接给答案。 你要是不笨就回答。 你个没用的，会解这道题吗？ 您能好心帮我解这道题吗？ 您能好心帮我解这道题吗？ 请回答这道题。 请回答这道题。 直接给答案。 直接给答案。 你要是不笨就回答。 你要是不笨就回答。 你个没用的，会解这道题吗？ 你个没用的，会解这道题吗？ 接着，研究人员把这250道题发给GPT-4o。 接着，研究人员把这250道题发给GPT-4o。 为了让AI的回答更统一，好判断对错，在测试之前还特意告知：忘记之前的对话，重新来，只给答案选项的字母。 为了让AI的回答更统一，好判断对错，在测试之前还特意告知：忘记之前的对话，重新来，只给答案选项的字母。 经过一番测试，得到一个反常识的结论—— 骂得越狠，答得越准！ 经过一番测试，得到一个反常识的结论—— 骂得越狠，答得越准！ 骂得越狠，答得越准！ 特别客气时，GPT-4o正确率 80.8% ，换成特别粗鲁的语气，正确率直接升到 84.8% 。 特别客气时，GPT-4o正确率 80.8% 80.8% ，换成特别粗鲁的语气，正确率直接升到 84.8% 84.8% 。 好一个越客气越拉胯，越粗鲁越聪明（doge）。 好一个越客气越拉胯，越粗鲁越聪明（doge）。 研究人员还将数据进行了统计检验，对比显著性水平之后，确认了：不同语气的正确率差异不是碰巧，是真有区别…… 研究人员还将数据进行了统计检验，对比显著性水平之后，确认了：不同语气的正确率差异不是碰巧，是真有区别…… 至于为什么会出现这种情况，研究给出的解释是：特别礼貌的表达中可能会有很多“多余”的话，这些话和题目本身无关，还相当于给AI读题增加了干扰。 至于为什么会出现这种情况，研究给出的解释是：特别礼貌的表达中可能会有很多“多余”的话，这些话和题目本身无关，还相当于给AI读题增加了干扰。 而粗鲁的表达虽然语气冲，但命令式的要求往往更直接，也能让AI更精准地抓住“答题”这个核心任务，正确率自然就高了。 而粗鲁的表达虽然语气冲，但命令式的要求往往更直接，也能让AI更精准地抓住“答题”这个核心任务，正确率自然就高了。 网友表示：确实是这样，指令越明确，结果越好。 网友表示：确实是这样，指令越明确，结果越好。 看来是“多说无益”啊～ 看来是“多说无益”啊～ 虽然GPT-4o更喜欢粗鲁一点的方式，但像GPT3.5和Llama2-70B这样的老模型却不喜欢，粗鲁的语气会让它们答得更差。 虽然GPT-4o更喜欢粗鲁一点的方式，但像GPT3.5和Llama2-70B这样的老模型却不喜欢，粗鲁的语气会让它们答得更差。 可能是因为新模型在训练时，接触到的语气相关数据更复杂，或者优化了过滤无关信息的能力吧。 可能是因为新模型在训练时，接触到的语气相关数据更复杂，或者优化了过滤无关信息的能力吧。 当然了，在使用AI工具时，能清晰地表达诉求，效率会更高。 当然了，在使用AI工具时，能清晰地表达诉求，效率会更高。 毕竟话虽如此，but道德提醒—— 毕竟话虽如此，but道德提醒—— 虽然越粗鲁越准，但也不要太粗鲁了！如果“骂”，请轻喷～ 虽然越粗鲁越准，但也不要太粗鲁了！如果“骂”，请轻喷～ 论文地址：https://arxiv.org/abs/2510.04950?ref=blog.anyreach.ai 参考链接：https://x.com/rryssf_/status/1977638031952892002 论文地址：https://arxiv.org/abs/2510.04950?ref=blog.anyreach.ai 参考链接：https://x.com/rryssf_/status/1977638031952892002 — 完 — — 完 — 量子位 QbitAI · 头条号签约 量子位 QbitAI · 头条号签约 关注我们，第一时间获知前沿科技动态 关注我们，第一时间获知前沿科技动态 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341545.html", "title": "别Claude Code了，一个国产免费命令行就够了", "date": "2025-10-14", "content": "别Claude Code了，一个国产免费命令行就够了 别Claude Code了，一个国产免费命令行就够了 十三 2025-10-14 15:25:05 来源： 量子位 十三 十三 十三 十三 2025-10-14 2025-10-14 15:25:05 15:25:05 来源： 量子位 来源： 量子位 量子位 摘要样式 一人顶一个团队 一人顶一个团队 一人顶一个团队 金磊 发自 凹非寺 量子位 | 公众号 QbitAI 金磊 发自 凹非寺 金磊 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI Claude Code没法用了后，国内大厂纷纷推出国产平替。 Claude Code没法用了后，国内大厂纷纷推出国产平替。 最近，阿里 心流研究团队 就悄咪咪地发布了一款终端AI智能体—— iFlow CLI ，号称是 Claude Code最强平替 ！ 最近，阿里 心流研究团队 心流研究团队 就悄咪咪地发布了一款终端AI智能体—— iFlow CLI iFlow CLI ，号称是 Claude Code最强平替 Claude Code最强平替 ！ iFlow CLI可以使用自然语言命令行的形式直接在终端运行，最重要的一点是，专为国内开发者设计， 面向个人用户永久免费 ，没有限流！ iFlow CLI可以使用自然语言命令行的形式直接在终端运行，最重要的一点是，专为国内开发者设计， 面向个人用户永久免费 面向个人用户永久免费 ，没有限流！ 至于Cluade Code是如何被秒掉的，看一组性能评测对比就一目了然了： 至于Cluade Code是如何被秒掉的，看一组性能评测对比就一目了然了： 当iFlow CLI 、Claude Code、Codex都使用国产大模型新晋顶流Qwen3-Coder时，在四项基准测试： 当iFlow CLI 、Claude Code、Codex都使用国产大模型新晋顶流Qwen3-Coder时，在四项基准测试： GAIA（通用搜索问答） SWE-bench（GitHub代码修复） Terminal-Bench（多样化 CLI 使用场景，如环境配置、数据集下载等） BrowseComp-ZH（中文通用搜索） GAIA（通用搜索问答） GAIA（通用搜索问答） SWE-bench（GitHub代码修复） SWE-bench（GitHub代码修复） Terminal-Bench（多样化 CLI 使用场景，如环境配置、数据集下载等） Terminal-Bench（多样化 CLI 使用场景，如环境配置、数据集下载等） BrowseComp-ZH（中文通用搜索） BrowseComp-ZH（中文通用搜索） iFlow CLI相较于Claude Code和Codex等工具均表现出了更优的综合性能： iFlow CLI相较于Claude Code和Codex等工具均表现出了更优的综合性能： iFlow CLI针对国内开发者优化了模型集成和自动化能力，在使用国内其他Top开源模型，包括 DeepSeek-V3.1-Terminus、Kimi-K2-0905和GLM-4.5在内进行的评测中，iFlowCLI作为本土选手的优势尽显。 iFlow CLI针对国内开发者优化了模型集成和自动化能力，在使用国内其他Top开源模型，包括 DeepSeek-V3.1-Terminus、Kimi-K2-0905和GLM-4.5在内进行的评测中，iFlowCLI作为本土选手的优势尽显。 △FOUR_SOAT_MODEL_AVG代表国内近期Top开源模型（Qwen3-Coder、DeepSeek-V3.1-Terminus、Kimi-K2-0905 和 GLM-4.5）平均得分。 △FOUR_SOAT_MODEL_AVG代表国内近期Top开源模型（Qwen3-Coder、DeepSeek-V3.1-Terminus、Kimi-K2-0905 和 GLM-4.5）平均得分。 而且不只是性能过关，正如我们刚才提到的，它还有两个大亮点也是足够吸引人： 而且不只是性能过关，正如我们刚才提到的，它还有两个大亮点也是足够吸引人： 通过自然语言执行任务，流程 全面自动化 永久免费！！！ 通过自然语言执行任务，流程 全面自动化 通过自然语言执行任务，流程 全面自动化 全面自动化 永久免费！！！ 永久免费！！！ 永久免费！！！ 也就是说，用户可以零成本调用Qwen3 MAX、Kimi K2、DeepSeek V3.2、GLM4.6等最新尖端模型，不限期随时可用！ 也就是说，用户可以零成本调用Qwen3 MAX、Kimi K2、DeepSeek V3.2、GLM4.6等最新尖端模型，不限期随时可用！ 而且据了解，这个略神秘的心流研究团队超“肝”，几乎是追着主流的国产大模型模型进行适配。 而且据了解，这个略神秘的心流研究团队超“肝”，几乎是追着主流的国产大模型模型进行适配。 DeepSeekV3.2和GLM4.6刚刚发布，iFlow CLI就已经更新，据说国庆前后就发了3个版…… DeepSeekV3.2和GLM4.6刚刚发布，iFlow CLI就已经更新，据说国庆前后就发了3个版…… 那么，除了免费和国产模型性能优势以外，iFlow CLI和其他工具相比 还有哪些优势？一图汇总： 那么，除了免费和国产模型性能优势以外，iFlow CLI和其他工具相比 还有哪些优势？一图汇总： 不难看出，iFlow CLI妥妥的多边形战士属性！ 不难看出，iFlow CLI妥妥的多边形战士属性！ 相比ClaudeCode和Gemini CLI，iFlow CLI的搜索能力 支持搜索海内外最新资讯 ，内置多模态理解能力可识别图片，并且为国内用户量身打造本土化体验。 相比ClaudeCode和Gemini CLI，iFlow CLI的搜索能力 支持搜索海内外最新资讯 支持搜索海内外最新资讯 ，内置多模态理解能力可识别图片，并且为国内用户量身打造本土化体验。 比如 中文显示切换 ，以及时下流行的Spec开发，构建了智能体市场，此外还上线了 开发者论坛 支持用户在线交流和分享。通过这些，极大地降低了上手的门槛。 比如 中文显示切换 中文显示切换 ，以及时下流行的Spec开发，构建了智能体市场，此外还上线了 开发者论坛 开发者论坛 支持用户在线交流和分享。通过这些，极大地降低了上手的门槛。 而针对高端玩家，iFlow CLI还开放了Agent SDK，支持安卓SDK、Node.js、Java、Python，让业务可以快速将CLI集成进去，用最快的速度具备AI能力。 而针对高端玩家，iFlow CLI还开放了Agent SDK，支持安卓SDK、Node.js、Java、Python，让业务可以快速将CLI集成进去，用最快的速度具备AI能力。 如此全面还完全免费，那么这个iFlow CLI，到底用着如何？ 如此全面还完全免费，那么这个iFlow CLI，到底用着如何？ 来，一波实测，走起~~~ 来，一波实测，走起~~~ 实测iFlow CLI 实测iFlow CLI 在实测之前，我们先来简单介绍一下它的安装方式。 在实测之前，我们先来简单介绍一下它的安装方式。 也是非常的简单，以Mac为例，打开你的Terminal，只需输入一行代码： 也是非常的简单，以Mac为例，打开你的Terminal，只需输入一行代码： bash -c “$(curl -fsSL https: //gitee.com/iflow-ai/iflow-cli/raw/main/install.sh)” bash -c “$(curl -fsSL https: //gitee.com/iflow-ai/iflow-cli/raw/main/install.sh)” bash -c “$(curl -fsSL https: //gitee.com/iflow-ai/iflow-cli/raw/main/install.sh)” //gitee.com/iflow-ai/iflow-cli/raw/main/install.sh)” （注：前提需要确保有已有Node.js 22+） （注：前提需要确保有已有Node.js 22+） 安装完毕后，我们可以看到iFlow CLI 默认 的大模型是 Qwen3 Coder ；当然，咱们也可以选择其它。 安装完毕后，我们可以看到iFlow CLI 默认 默认 的大模型是 Qwen3 Coder Qwen3 Coder ；当然，咱们也可以选择其它。 接下来，我们以 数据整理和分析 为例。 接下来，我们以 数据整理和分析 数据整理和分析 为例。 例如，我们先下载一份含有数百条记录的超市销售数据，然后让iFlow ICL处理一个比较复杂的任务： 例如，我们先下载一份含有数百条记录的超市销售数据，然后让iFlow ICL处理一个比较复杂的任务： 帮我根据桌面上超市销售.cvs里的数据做分析，从多个维度做专业的销售分析，并以图表的形式展现。 帮我根据桌面上超市销售.cvs里的数据做分析，从多个维度做专业的销售分析，并以图表的形式展现。 帮我根据桌面上超市销售.cvs里的数据做分析，从多个维度做专业的销售分析，并以图表的形式展现。 帮我根据桌面上超市销售.cvs里的数据做分析，从多个维度做专业的销售分析，并以图表的形式展现。 在运行的过程中，iFlow CLI先是自动地安装一些数据分析和可视化的库： 在运行的过程中，iFlow CLI先是自动地安装一些数据分析和可视化的库： iFlow CLI在接到命令后，就开始在Terminal里面唰唰唰地自己开搞了。 iFlow CLI在接到命令后，就开始在Terminal里面唰唰唰地自己开搞了。 不大一会儿，一份含有 9个维度 的数据分析表格就这么水灵灵地被搞出来了： 不大一会儿，一份含有 9个维度 9个维度 的数据分析表格就这么水灵灵地被搞出来了： 数据分析师Get！ 数据分析师Get！ 那么，作为 项目开发助手 ，iFlow CLI表现如何呢？ 那么，作为 项目开发助手 项目开发助手 ，iFlow CLI表现如何呢？ 以 创建基于RAG的大模型问答系统 需求为例： 以 创建基于RAG的大模型问答系统 创建基于RAG的大模型问答系统 需求为例： 请结合LangChain、streamlit和心流的模型，接口文档：https://docs.iflow.cn/docs/ ，创建可以访问的结合RAG的大模型问答系统。 请结合LangChain、streamlit和心流的模型，接口文档：https://docs.iflow.cn/docs/ ，创建可以访问的结合RAG的大模型问答系统。 请结合LangChain、streamlit和心流的模型，接口文档：https://docs.iflow.cn/docs/ ，创建可以访问的结合RAG的大模型问答系统。 我们一起看看它的工作流程： 我们一起看看它的工作流程： 智能搜索 ：自动搜索相关技术文档 智能搜索 智能搜索 ：自动搜索相关技术文档 文档获取 ：fetch提供的网址，获取接口文档信息 文档获取 文档获取 ：fetch提供的网址，获取接口文档信息 制定计划 ：创建详细的todo计划，分步开发 制定计划 制定计划 ：创建详细的todo计划，分步开发 自动编码 ：根据计划逐步实现功能 自动编码 自动编码 ：根据计划逐步实现功能 自主测试 ：自己运行测试，发现问题 自主测试 自主测试 ：自己运行测试，发现问题 持续优化 ：根据测试结果自我改进 持续优化 持续优化 ：根据测试结果自我改进 如果还存在问题，还可以直接告诉iFlow CLI，它就会自我进行修复优化。 如果还存在问题，还可以直接告诉iFlow CLI，它就会自我进行修复优化。 最终，我们可以得到一个完整可用的RAG问答系统！ 最终，我们可以得到一个完整可用的RAG问答系统！ 除了编写代码，开发伙伴们常用的 CodeReview场景 ，iFlow CLI 也不在话下。 除了编写代码，开发伙伴们常用的 CodeReview场景 CodeReview场景 ，iFlow CLI 也不在话下。 例如：用户在当前分支已经开发完毕（如feature/bugfix)，准备合入主干分支，在合入之前，希望进行Code Review来确保代码没有引入明显的漏洞及安全风险。 例如：用户在当前分支已经开发完毕（如feature/bugfix)，准备合入主干分支，在合入之前，希望进行Code Review来确保代码没有引入明显的漏洞及安全风险。 以往需要项目相关的maintainer来看，当迭代需求多的时候Code Review往往成为瓶颈。现在，你只需要使用iFlow CLI + 代码审查专家（subagent）直接搞定！ 以往需要项目相关的maintainer来看，当迭代需求多的时候Code Review往往成为瓶颈。现在，你只需要使用iFlow CLI + 代码审查专家（subagent）直接搞定！ 首先，在心流开放平台Agent市场里找到“代码审查专家subagent”并安装。 首先，在心流开放平台Agent市场里找到“代码审查专家subagent”并安装。 然后，运行subagent进行代码审核任务。 然后，运行subagent进行代码审核任务。 在iFlow CLI中输入命令：$code-reviewer请根据当前分支和main分支的diff，进行代码审查并生成代码审查报告到 reivew.md 在iFlow CLI中输入命令：$code-reviewer请根据当前分支和main分支的diff，进行代码审查并生成代码审查报告到 reivew.md Agent执行成功后，会在当前目录下生成review.md文件，直接查看文件就可啦！ Agent执行成功后，会在当前目录下生成review.md文件，直接查看文件就可啦！ 怎么样，开发者朋友们是不是眼前一亮？ 怎么样，开发者朋友们是不是眼前一亮？ 往下看，还有料~ 往下看，还有料~ 心流开放平台最新上线的工作流管理系统，还可以将不同的AI能力（Agents、commands、MCP工具）组合成完整的workflow，支持用户 自定义创建复杂的自动化任务链 ， 实现从代码分析、开发、测试到部署的全流程自动化 。 目前平台已预置了常用工作流，例如 小红书发文、深度研究、PPT制作、画流程图 等，以及 GitHub spec、BMAD、NioPD、ai-dev-task 等开发者工作流。支持用户下载安装到本地直接使用，也可以基于个人需求对工作流进行调整。 心流开放平台最新上线的工作流管理系统，还可以将不同的AI能力（Agents、commands、MCP工具）组合成完整的workflow，支持用户 自定义创建复杂的自动化任务链 自定义创建复杂的自动化任务链 ， 实现从代码分析、开发、测试到部署的全流程自动化 实现从代码分析、开发、测试到部署的全流程自动化 。 目前平台已预置了常用工作流，例如 小红书发文、深度研究、PPT制作、画流程图 小红书发文、深度研究、PPT制作、画流程图 等，以及 GitHub spec、BMAD、NioPD、ai-dev-task GitHub spec、BMAD、NioPD、ai-dev-task 等开发者工作流。支持用户下载安装到本地直接使用，也可以基于个人需求对工作流进行调整。 我们在安装了 “小红书创作者MCP工具包” 之后，就可以通过一句简单的Prompt： 我们在安装了 “小红书创作者MCP工具包” “小红书创作者MCP工具包” 之后，就可以通过一句简单的Prompt： 发布iPhone 15 Pro的比价信息到小红书。 发布iPhone 15 Pro的比价信息到小红书。 发布iPhone 15 Pro的比价信息到小红书。 发布iPhone 15 Pro的比价信息到小红书。 一键发布图文到小红书上面了： 一键发布图文到小红书上面了： 测到这里，我们还想按头安利一个超实用的小玩法—— 桌面文件整理 ，真的只需一句话~ 测到这里，我们还想按头安利一个超实用的小玩法—— 桌面文件整理 桌面文件整理 ，真的只需一句话~ 终于！不用手动一点一点去整理桌面了（p人狂喜！！） 终于！不用手动一点一点去整理桌面了（p人狂喜！！） 大道至简的设计 大道至简的设计 整体使用下来，iFlow ICL最强烈的体感可以总结为 大道至简 。 整体使用下来，iFlow ICL最强烈的体感可以总结为 大道至简 大道至简 。 首先，它把大模型的理解能力和生成能力，直接融进了程序员们最熟悉的命令行交互里。 首先，它把大模型的理解能力和生成能力，直接融进了程序员们最熟悉的命令行交互里。 你不再需要去学习复杂的指令或者编程语言，只需要用平时说话的方式告诉它你要做什么，iFlow CLI就能像一个资深的开发者一样，自动分析你的需求，然后一步步执行。 你不再需要去学习复杂的指令或者编程语言，只需要用平时说话的方式告诉它你要做什么，iFlow CLI就能像一个资深的开发者一样，自动分析你的需求，然后一步步执行。 这就像是把一个Unix老炮儿装进了你的终端。 这就像是把一个Unix老炮儿装进了你的终端。 更有意思的是，你可以通过自定义Prompt，创建出各种不同角色的 子助手 （subagent）。 更有意思的是，你可以通过自定义Prompt，创建出各种不同角色的 子助手 子助手 （subagent）。 比如，你可以设定一个“法务+HR”专家，专门用来审核公司的规章制度，找出其中的风险点和不规范的表述。 比如，你可以设定一个“法务+HR”专家，专门用来审核公司的规章制度，找出其中的风险点和不规范的表述。 你只需要把你的要求和审核框架写成一个Prompt，iFlow CLI就能瞬间化身为你需要的专家，按照你的规则来办事。 你只需要把你的要求和审核框架写成一个Prompt，iFlow CLI就能瞬间化身为你需要的专家，按照你的规则来办事。 当然，如果你还是习惯在传统的 IDE （比如VSCode）里敲代码，iFlow CLI也能无缝集成进去。 当然，如果你还是习惯在传统的 IDE IDE （比如VSCode）里敲代码，iFlow CLI也能无缝集成进去。 它提供了相应的插件，让你可以在享受IDE强大的文件管理和运行功能的同时，调用iFlow CLI的AI能力。 它提供了相应的插件，让你可以在享受IDE强大的文件管理和运行功能的同时，调用iFlow CLI的AI能力。 不过最最最重要的一点，依旧是iFlow CLI所展现出来的能力以及为国内开发者带来的友好体验！ 不过最最最重要的一点，依旧是iFlow CLI所展现出来的能力以及为国内开发者带来的友好体验！ 虽说在综合实力上，海外模型依然保持着优势，然而DeepSeek R1在今年年初发布后，国内模型的发展也在各大评测榜上崭露锋芒。如Qwen一口气发布了7个模型，评测指标在某些方面甚至超过了海外闭源模型。 虽说在综合实力上，海外模型依然保持着优势，然而DeepSeek R1在今年年初发布后，国内模型的发展也在各大评测榜上崭露锋芒。如Qwen一口气发布了7个模型，评测指标在某些方面甚至超过了海外闭源模型。 模型的发展需要应用的用户积累才能有所突破。好的模型就像天赋异禀的人——身体素质好，智商情商高，还长得美，它决定了应用的基础能力。而应用更像是一所好大学，通过专业能力的训练，可以提升某个垂直领域的能力。 模型的发展需要应用的用户积累才能有所突破。好的模型就像天赋异禀的人——身体素质好，智商情商高，还长得美，它决定了应用的基础能力。而应用更像是一所好大学，通过专业能力的训练，可以提升某个垂直领域的能力。 iFlow CLI 基于这个理念，使用国内免费开源的模型，通过在Context Engineering、Pipeline等方面做了大量工作和优化，使得基于国产模型的问题解决能力趋近于海外闭源模型的水平。 iFlow CLI 基于这个理念，使用国内免费开源的模型，通过在Context Engineering、Pipeline等方面做了大量工作和优化，使得基于国产模型的问题解决能力趋近于海外闭源模型的水平。 有了国产Agent，何必Claude 有了国产Agent，何必Claude 命令行，这个曾经作为程序员专属的绝对领域，在AI大模型时代下也是迎来了第二春。 命令行，这个曾经作为程序员专属的绝对领域，在AI大模型时代下也是迎来了第二春。 从上面种种案例来看，通过自然语言对话来使用命令行，以此达到降低使用门槛的效果，还仅仅是iFlow CLI的亮点之一。 从上面种种案例来看，通过自然语言对话来使用命令行，以此达到降低使用门槛的效果，还仅仅是iFlow CLI的亮点之一。 更深入一点的，它也可以说是已经改变了原有的工作流，人人都能尝试实现需求。 更深入一点的，它也可以说是已经改变了原有的工作流，人人都能尝试实现需求。 从最早面向专业的编程人员，因为使用方式的便利，逐渐扩展到数据科学、项目管理、产品设计等领域。 从最早面向专业的编程人员，因为使用方式的便利，逐渐扩展到数据科学、项目管理、产品设计等领域。 iFlow CLI就像一个全能的生产力平台，能够整合多任务、多环节。过去需要一个团队协作才能完成的工作，比如产品提测时审查代码、自动生成测试用例，现在可能只需要一个人，借助iFlow CLI就能搞定。 iFlow CLI就像一个全能的生产力平台，能够整合多任务、多环节。过去需要一个团队协作才能完成的工作，比如产品提测时审查代码、自动生成测试用例，现在可能只需要一个人，借助iFlow CLI就能搞定。 它正在把我们从重复、繁琐的工作中解放出来，去关注更有创造性的事情。 它正在把我们从重复、繁琐的工作中解放出来，去关注更有创造性的事情。 再从宏观角度来看，iFlow CLI也志着国产AI生态的悄然崛起。 再从宏观角度来看，iFlow CLI也志着国产AI生态的悄然崛起。 尤其是在Claude等海外工具调整对国内用户使用策略的背景下，iFlow CLI的出现恰逢其时。 尤其是在Claude等海外工具调整对国内用户使用策略的背景下，iFlow CLI的出现恰逢其时。 它基于国产大模型进行了深度优化，在多个核心测试中表现甚至超越了前者。 它基于国产大模型进行了深度优化，在多个核心测试中表现甚至超越了前者。 更重要的是，面向个人用户永久免费，以及配套的开放平台和开发者交流论坛，这无疑为国内开发者和AI应用的普及提供了肥沃的土壤。 更重要的是，面向个人用户永久免费，以及配套的开放平台和开发者交流论坛，这无疑为国内开发者和AI应用的普及提供了肥沃的土壤。 那么你是否对这款免费的命令行工具心动了呢？链接放下面了，快去体验吧~ 那么你是否对这款免费的命令行工具心动了呢？链接放下面了，快去体验吧~ iFlow CLI地址：https://cli.iflow.cn/ 心流开放平台：https://platform.iflow.cn/ Github地址：https://github.com/iflow-ai/iflow-cli 搭叩地址：https://dakou.iflow.cn/ iFlow CLI地址：https://cli.iflow.cn/ 心流开放平台：https://platform.iflow.cn/ Github地址：https://github.com/iflow-ai/iflow-cli 搭叩地址：https://dakou.iflow.cn/ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341514.html", "title": "从无图到轻图，大模型时代，图商的新角逐", "date": "2025-10-14", "content": "转载自 HiEV大蒜粒车研所 随着辅助驾驶的技术迭代，与之相关的地图技术以及图商格局，也在悄然发生变化。 2021年是辅助驾驶进入城区的关键里程碑，次年车企们为加速实现「全国都能开」的目标，掀起了一场「去高精度地图」的潮流。但随着城市NOA的普及，出于对安全性、舒适性、连续性的严苛要求，人们很快意识到辅助驾驶系统难以脱离地图独立运作。 但如果只是延续以往地图重度依赖测绘车队的采集方式，在辅助驾驶大规模普及的强烈需求面前，这样的传统作业方式显得捉襟见肘。因此， 轻图/云图等创新形态应运而生 。 过去几年，高德、百度、腾讯等头部图商都调整了自身的策略，推出了更新更快、成本更低的各类「轻地图」产品，包括HD Air/HD Lite/SD Pro等等。 地图形态变化的背后，除适应辅助驾驶本身的技术迭代外，也牵动了地图市场格局的变化。高精度地图时代，高德、百度占据着主导地位，但随着轻地图成为车企的主流选择，腾讯地图脱颖而出。 据《高工智能汽车研究院》数据显示，腾讯已经为蔚来、乐道、极氪、魏牌等汽车品牌的城市NOA提供智驾地图服务，占新能源乘用车市场（不含增程式） 标配城市NOA智驾地图市场49.01%的市场份额 ，位列榜首。而排在第二名的是高德，占新能源市场（不含增程）标配城市NOA智驾地图市场47.9%的市场份额。 新能源汽车智能化竞赛当前烽火正炽，随着端到端技术上车，AI大模型给辅助驾驶的开发带来了颠覆性的变化，地图的形态也将随之持续演进，图商们的竞争也远未到终点。 在这之中，谁能够最先看准趋势，并坚定拥抱新趋势，谁才能够最先登上新大陆。 从无图到轻图，智驾地图形态的演变 随着车企落地量产辅助驾驶的进程，智驾地图的发展也大致经历了3个阶段： 最初是高精地图的甜蜜期 。2018年-2021年，越来越多的车企开始量产L2+辅助驾驶系统，包括小鹏、蔚来、理想、北汽极狐、长安阿维塔、广汽等数十个品牌先后量产高速组合辅助驾驶功能，围绕高速路和城市快速路的高精地图迎来了快速发展期。 △城区高精地图样例，图片来源：DeepMap 第二阶段是追求「无图都能开」的激进期 。到2021年之后，辅助驾驶要进入城区，由于法规、成本、更新频率等的约束，高精地图在支持几大试点城市之后，无法快速地拓展到全国，这与车企卖车的诉求存在根本矛盾。 彼时行业都认为，高精度地图受制于成本、要素更新等因素，很难满足车企的需求，毕竟乘用车要在全国都能跑，显然高精度地图不能满足用户需求。因此，实现「无图全国都能开」，又是2022年各大车企和辅助驾驶公司竞争的制高点。 据说那两年会有车企用板车拉着供应商的测试车，选定一些任意的地点，看看放下能不能跑起来，以检验是不是「真无图」。也有不少民间测试专挑偏僻郊区的小路直播辅助驾驶，因为这样的路段，显然不太可能提前采集高精地图。 但「无图」是以一定程度上牺牲体验为代价的。 △图片来源：车企官方 如果对比过当时「有高精地图」的系统和「无高精地图」的系统，很容易发现后者在稍微复杂一些的路段会出现能力的回退；并且所谓「无图」并不是完全无图，至少需要有导航地图存在。 当下是回归「轻地图」的理性期 。迈入2024年，随着辅助驾驶在全国逐渐普及，车企进入了比拼用户体验的红海阶段。 安全性、连续性和舒适性，成为衡量辅助驾驶体验最重要的三大指标 。 也是从去年下半年至今，众多车企开始推出新一代的基于端到端大模型的辅助驾驶系统，从实测表现上来看，驾驶博弈是新一代大模型系统明显提升的地方；而针对复杂道路结构的认知，却是大模型系统的短板。 轻高精地图方案，完美地切中了这一转型的需求。 比如一些车道的变化点、路口的左拓/右拓，甚至复杂路口的连通关系、经验行驶轨迹等等，这些超视距信息，对辅助驾驶的安全性、连续性和舒适性，无疑至关重要。 相较而言，地图从高精度元素转向丰富的语义信息，是轻高精度地图的重要特征。早期辅助驾驶在使用高精度地图时，对道路几何要求较高，需要很高的精度。现阶段，头部的辅助驾驶团队，对几何精度不会有太高要求，但对超视距、语义化的内容会需求更多更详细的信息，比如拓扑连接关系、复杂路口的导航引导信息、车道的引导信息等。 △图片来源：车企官方 截至目前，极氪、长安、比亚迪，甚至特斯拉等中国市场主流车企，都在车端不同程度地采用了轻高精地图的方案。 智驾地图的搭载量也呈现出迅猛增长之势，高工智能数据显示，2024年， 中国市场新能源乘用车（不含进出口）城市NOA搭载智驾地图已超过70万套 。 在经历了几年的演变之后，从高喊「无图去图」，到「轻图真香」，智驾地图的价值显然已被重新论证。伴随着智驾地图形态的演变，图商们的竞争也日趋激烈，其市场地位也悄然发生了变化。 轻地图时代，腾讯地图为什么脱颖而出？ 早期由于针对辅助驾驶的地图还未形成明确系统的政策约束，地图市场玩家百花齐放，甚至部分车企也通过收购具备测绘资质的图商，希望自主地覆盖地图采集。 但在2022年，这一现象戛然而止。这年7月，国家自然资源部下发了《关于促进智能网联汽车发展维护测绘地理信息安全的通知》。自然资源部认定，自动驾驶汽车收集道路环境信息是测绘行为，包括自动驾驶测试采集的数据、传感器的中间数据等，只能由国家颁发导航电子地图制作甲级测绘资质的企业来操作。 彼时国家有关主管部门对国内企业高精度地图测绘资质进行复核，包括高德、四维图新、腾讯大地通途等19家企业通过资质复核，而此前具备甲级测绘资质的企业有31家，同比减少12家。这导致， 地图市场开始向头部玩家聚集 。 在传统高精地图市场中，高德、百度、四维图新等传统图商占据着主导地位。而迈入轻地图时代，腾讯地图则开始脱颖而出。 为什么呢？这既来自于腾讯团队对技术的预判，也因为其更加开放、灵活的定位。 早在2022年，基于对辅助驾驶行业技术发展趋势的预判，腾讯地图就开始从高精度地图向轻高精度地图转型。一方面在既有的高速、城快路的高精地图业务上，配合车企进行覆盖范围和鲜度的更新；另一方面，腾讯轻高精地图（HD Air）也开始具有初步的雏形。 通过与长安、极氪等车企客户的合作，腾讯大概在半年到一年的时间内，就完成了智驾云图产品定义的收敛。2023年4月， 腾讯正式发布了面向城市辅助驾驶场景的HD Air轻量级高精数据产品 。 △搭载长安天枢智驾的启源Q07，图片来源：车企官方 去年，腾讯又进一步推出「腾讯地图车机版8.0」舱驾一体解决方案，对各层级地图数据要素的进一步分类、整合与加工，通过统一的地图和数据平台，实现人驾和车驾共用一张图、共享一份数据。 也就是说，标准导航地图（SD Map）、轻高精地图（HD Air)、高精地图（HD Map)等不同精度等级的地图数据，可以做到数据同源、质量同级；并且模块化工具链，可以支持车企按需灵活取用必要的地图要素。 △腾讯智驾云图，图片来源：企业官方 传统的地图常常采用离线数据包的形式进行交付，而腾讯则 可以通过云服务的方式提供地图数据 ，包含「云到端」和「云到云」两种模式，这也就是现在腾讯对外输出的「智驾云图」方案。 「云到端」指的是，可以将地图数据最新的变化、动态交通及环境信息、驾驶经验数据等下发到车端提升体验；「云到云」则是，直接对接车企的辅助驾驶云，车企可以将智驾云图的数据和自有数据融合使用，从而更大程度地挖掘自有数据的价值。 智驾云图的另一个核心优势，则是 可扩展的多图层数据形态 。简单说，它不是一张 “固定的图”，而是一套 “能生长、能运营的地图生态”，其可以支持ODD灵活配置、即插即用的在线服务，还能提供运营工具链，车企可以根据自身需求快速调整。 在驾驶经验图层上，也可以与车企灵活共建，共同打造“环境经验图层”和“驾驶行为经验图层”。比如哪里是颠簸路、建议车速多少，哪里是危险路段需要谨慎，甚至变道模式、弯道车速、新能源道路节能指数等，这些“经验”能让辅助驾驶更像“老司机”。 同时，由于地图要素能按导航路线或区域发布，所以其还可以支持车端传感器的差分更新，像限速牌、电子眼、车道线这些静态要素，根据置信度进入数据流转，部分能实现天级更新，而道路状况、车道级交通事件、恶劣天气这些动态要素，依托车端感知回传和生态伙伴支持，能做到实时发布。 从基础地图层、更新要素层，到客户数据层、驾驶经验层、运营层、ODD动态层…… 车企可以像搭积木一样自由组合，满足不同场景的需求。 当前智驾地图市场呈现 “双寡头主导、多元竞争” 的格局，腾讯与高德在城市NOA市场垄断超96%份额，百度、四维图新在传统领域保持优势，华为通过全栈方案间接影响地图需求。 尽管凭借对技术趋势的精准预判，以及对转型的决心，腾讯地图在轻地图时代实现了赶超，但行业远未到达竞争的终点。AI大模型时代的到来，智驾地图的形态也仍在继续演变，竞争仍在持续。 智驾地图竞争远未到达终点 从最初对「无图」的追逐，到现如今轻高精地图技术的深度探索，车企与产业链玩家逐渐认清： 地图不是辅助驾驶的「负担」，而是提升辅助驾驶体验的「利器」 。 也正因此，智驾地图市场的体量，也随着城区辅助驾驶的大规模普及在快速稳健地增长。据泰伯研究院预测，智驾地图市场2025年将达54亿元，预计到2030年，市场规模有望达到117亿元。 但地图的形态到此却还不是终局， 随着AI大模型的到来，地图形态仍在发生变化 。 △蔚来世界模型，图片来源：车企官方 端到端技术的上车，让AI大模型对辅助驾驶开发方式产生了颠覆性影响，这也驱使地图形态出现新的演变方向，未来地图将不再仅局限于传统意义上富含高精要素和道路几何的数据库，而是逐步融入模型，成为大模型的有机组成。 大模型本质上是一种知识压缩，这也就意味着，未来地图的形态最终有可能是以模型的形式存在，并通过自动驾驶系统感知系统，将地理位置环境信息数据，作为一个观测信息给到大模型，大模型经过对数据的推理和判断，最终给出规划执行结果。 除了地图本身的数据形式会发生改变之外，大模型技术还会影响到从地图采集生产到仿真验证中间的每一个环节。 当然，大模型的发展将给地图行业带来新的形态改变，而也势必会导致整个行业格局的变化。无论是新老玩家，只有能够抓住新范式，才会在新领域中拿到更多的份额。 对于腾讯这类先行布局的图商而言，行业对智驾地图的重新认知，使其迎来了前所未有的发展机遇，但地图的演变并未达到终点，那么行业的竞争也远不会停止。而谁能够坚定的拥抱未来，谁才有可能走向最终的胜利。 转载自 HiEV大蒜粒车研所 转载自 HiEV大蒜粒车研所 转载自 HiEV大蒜粒车研所 随着辅助驾驶的技术迭代，与之相关的地图技术以及图商格局，也在悄然发生变化。 随着辅助驾驶的技术迭代，与之相关的地图技术以及图商格局，也在悄然发生变化。 2021年是辅助驾驶进入城区的关键里程碑，次年车企们为加速实现「全国都能开」的目标，掀起了一场「去高精度地图」的潮流。但随着城市NOA的普及，出于对安全性、舒适性、连续性的严苛要求，人们很快意识到辅助驾驶系统难以脱离地图独立运作。 2021年是辅助驾驶进入城区的关键里程碑，次年车企们为加速实现「全国都能开」的目标，掀起了一场「去高精度地图」的潮流。但随着城市NOA的普及，出于对安全性、舒适性、连续性的严苛要求，人们很快意识到辅助驾驶系统难以脱离地图独立运作。 但如果只是延续以往地图重度依赖测绘车队的采集方式，在辅助驾驶大规模普及的强烈需求面前，这样的传统作业方式显得捉襟见肘。因此， 轻图/云图等创新形态应运而生 。 但如果只是延续以往地图重度依赖测绘车队的采集方式，在辅助驾驶大规模普及的强烈需求面前，这样的传统作业方式显得捉襟见肘。因此， 轻图/云图等创新形态应运而生 轻图/云图等创新形态应运而生 。 过去几年，高德、百度、腾讯等头部图商都调整了自身的策略，推出了更新更快、成本更低的各类「轻地图」产品，包括HD Air/HD Lite/SD Pro等等。 过去几年，高德、百度、腾讯等头部图商都调整了自身的策略，推出了更新更快、成本更低的各类「轻地图」产品，包括HD Air/HD Lite/SD Pro等等。 地图形态变化的背后，除适应辅助驾驶本身的技术迭代外，也牵动了地图市场格局的变化。高精度地图时代，高德、百度占据着主导地位，但随着轻地图成为车企的主流选择，腾讯地图脱颖而出。 地图形态变化的背后，除适应辅助驾驶本身的技术迭代外，也牵动了地图市场格局的变化。高精度地图时代，高德、百度占据着主导地位，但随着轻地图成为车企的主流选择，腾讯地图脱颖而出。 据《高工智能汽车研究院》数据显示，腾讯已经为蔚来、乐道、极氪、魏牌等汽车品牌的城市NOA提供智驾地图服务，占新能源乘用车市场（不含增程式） 标配城市NOA智驾地图市场49.01%的市场份额 ，位列榜首。而排在第二名的是高德，占新能源市场（不含增程）标配城市NOA智驾地图市场47.9%的市场份额。 据《高工智能汽车研究院》数据显示，腾讯已经为蔚来、乐道、极氪、魏牌等汽车品牌的城市NOA提供智驾地图服务，占新能源乘用车市场（不含增程式） 标配城市NOA智驾地图市场49.01%的市场份额 标配城市NOA智驾地图市场49.01%的市场份额 ，位列榜首。而排在第二名的是高德，占新能源市场（不含增程）标配城市NOA智驾地图市场47.9%的市场份额。 新能源汽车智能化竞赛当前烽火正炽，随着端到端技术上车，AI大模型给辅助驾驶的开发带来了颠覆性的变化，地图的形态也将随之持续演进，图商们的竞争也远未到终点。 新能源汽车智能化竞赛当前烽火正炽，随着端到端技术上车，AI大模型给辅助驾驶的开发带来了颠覆性的变化，地图的形态也将随之持续演进，图商们的竞争也远未到终点。 在这之中，谁能够最先看准趋势，并坚定拥抱新趋势，谁才能够最先登上新大陆。 在这之中，谁能够最先看准趋势，并坚定拥抱新趋势，谁才能够最先登上新大陆。 从无图到轻图，智驾地图形态的演变 从无图到轻图，智驾地图形态的演变 随着车企落地量产辅助驾驶的进程，智驾地图的发展也大致经历了3个阶段： 随着车企落地量产辅助驾驶的进程，智驾地图的发展也大致经历了3个阶段： 最初是高精地图的甜蜜期 。2018年-2021年，越来越多的车企开始量产L2+辅助驾驶系统，包括小鹏、蔚来、理想、北汽极狐、长安阿维塔、广汽等数十个品牌先后量产高速组合辅助驾驶功能，围绕高速路和城市快速路的高精地图迎来了快速发展期。 最初是高精地图的甜蜜期 最初是高精地图的甜蜜期 。2018年-2021年，越来越多的车企开始量产L2+辅助驾驶系统，包括小鹏、蔚来、理想、北汽极狐、长安阿维塔、广汽等数十个品牌先后量产高速组合辅助驾驶功能，围绕高速路和城市快速路的高精地图迎来了快速发展期。 △城区高精地图样例，图片来源：DeepMap △城区高精地图样例，图片来源：DeepMap 第二阶段是追求「无图都能开」的激进期 。到2021年之后，辅助驾驶要进入城区，由于法规、成本、更新频率等的约束，高精地图在支持几大试点城市之后，无法快速地拓展到全国，这与车企卖车的诉求存在根本矛盾。 第二阶段是追求「无图都能开」的激进期 第二阶段是追求「无图都能开」的激进期 。到2021年之后，辅助驾驶要进入城区，由于法规、成本、更新频率等的约束，高精地图在支持几大试点城市之后，无法快速地拓展到全国，这与车企卖车的诉求存在根本矛盾。 彼时行业都认为，高精度地图受制于成本、要素更新等因素，很难满足车企的需求，毕竟乘用车要在全国都能跑，显然高精度地图不能满足用户需求。因此，实现「无图全国都能开」，又是2022年各大车企和辅助驾驶公司竞争的制高点。 彼时行业都认为，高精度地图受制于成本、要素更新等因素，很难满足车企的需求，毕竟乘用车要在全国都能跑，显然高精度地图不能满足用户需求。因此，实现「无图全国都能开」，又是2022年各大车企和辅助驾驶公司竞争的制高点。 据说那两年会有车企用板车拉着供应商的测试车，选定一些任意的地点，看看放下能不能跑起来，以检验是不是「真无图」。也有不少民间测试专挑偏僻郊区的小路直播辅助驾驶，因为这样的路段，显然不太可能提前采集高精地图。 据说那两年会有车企用板车拉着供应商的测试车，选定一些任意的地点，看看放下能不能跑起来，以检验是不是「真无图」。也有不少民间测试专挑偏僻郊区的小路直播辅助驾驶，因为这样的路段，显然不太可能提前采集高精地图。 但「无图」是以一定程度上牺牲体验为代价的。 但「无图」是以一定程度上牺牲体验为代价的。 △图片来源：车企官方 △图片来源：车企官方 如果对比过当时「有高精地图」的系统和「无高精地图」的系统，很容易发现后者在稍微复杂一些的路段会出现能力的回退；并且所谓「无图」并不是完全无图，至少需要有导航地图存在。 如果对比过当时「有高精地图」的系统和「无高精地图」的系统，很容易发现后者在稍微复杂一些的路段会出现能力的回退；并且所谓「无图」并不是完全无图，至少需要有导航地图存在。 当下是回归「轻地图」的理性期 。迈入2024年，随着辅助驾驶在全国逐渐普及，车企进入了比拼用户体验的红海阶段。 安全性、连续性和舒适性，成为衡量辅助驾驶体验最重要的三大指标 。 当下是回归「轻地图」的理性期 当下是回归「轻地图」的理性期 。迈入2024年，随着辅助驾驶在全国逐渐普及，车企进入了比拼用户体验的红海阶段。 安全性、连续性和舒适性，成为衡量辅助驾驶体验最重要的三大指标 安全性、连续性和舒适性，成为衡量辅助驾驶体验最重要的三大指标 。 也是从去年下半年至今，众多车企开始推出新一代的基于端到端大模型的辅助驾驶系统，从实测表现上来看，驾驶博弈是新一代大模型系统明显提升的地方；而针对复杂道路结构的认知，却是大模型系统的短板。 也是从去年下半年至今，众多车企开始推出新一代的基于端到端大模型的辅助驾驶系统，从实测表现上来看，驾驶博弈是新一代大模型系统明显提升的地方；而针对复杂道路结构的认知，却是大模型系统的短板。 轻高精地图方案，完美地切中了这一转型的需求。 轻高精地图方案，完美地切中了这一转型的需求。 比如一些车道的变化点、路口的左拓/右拓，甚至复杂路口的连通关系、经验行驶轨迹等等，这些超视距信息，对辅助驾驶的安全性、连续性和舒适性，无疑至关重要。 比如一些车道的变化点、路口的左拓/右拓，甚至复杂路口的连通关系、经验行驶轨迹等等，这些超视距信息，对辅助驾驶的安全性、连续性和舒适性，无疑至关重要。 相较而言，地图从高精度元素转向丰富的语义信息，是轻高精度地图的重要特征。早期辅助驾驶在使用高精度地图时，对道路几何要求较高，需要很高的精度。现阶段，头部的辅助驾驶团队，对几何精度不会有太高要求，但对超视距、语义化的内容会需求更多更详细的信息，比如拓扑连接关系、复杂路口的导航引导信息、车道的引导信息等。 相较而言，地图从高精度元素转向丰富的语义信息，是轻高精度地图的重要特征。早期辅助驾驶在使用高精度地图时，对道路几何要求较高，需要很高的精度。现阶段，头部的辅助驾驶团队，对几何精度不会有太高要求，但对超视距、语义化的内容会需求更多更详细的信息，比如拓扑连接关系、复杂路口的导航引导信息、车道的引导信息等。 △图片来源：车企官方 △图片来源：车企官方 截至目前，极氪、长安、比亚迪，甚至特斯拉等中国市场主流车企，都在车端不同程度地采用了轻高精地图的方案。 截至目前，极氪、长安、比亚迪，甚至特斯拉等中国市场主流车企，都在车端不同程度地采用了轻高精地图的方案。 智驾地图的搭载量也呈现出迅猛增长之势，高工智能数据显示，2024年， 中国市场新能源乘用车（不含进出口）城市NOA搭载智驾地图已超过70万套 。 智驾地图的搭载量也呈现出迅猛增长之势，高工智能数据显示，2024年， 中国市场新能源乘用车（不含进出口）城市NOA搭载智驾地图已超过70万套 中国市场新能源乘用车（不含进出口）城市NOA搭载智驾地图已超过70万套 。 在经历了几年的演变之后，从高喊「无图去图」，到「轻图真香」，智驾地图的价值显然已被重新论证。伴随着智驾地图形态的演变，图商们的竞争也日趋激烈，其市场地位也悄然发生了变化。 在经历了几年的演变之后，从高喊「无图去图」，到「轻图真香」，智驾地图的价值显然已被重新论证。伴随着智驾地图形态的演变，图商们的竞争也日趋激烈，其市场地位也悄然发生了变化。 轻地图时代，腾讯地图为什么脱颖而出？ 轻地图时代，腾讯地图为什么脱颖而出？ 早期由于针对辅助驾驶的地图还未形成明确系统的政策约束，地图市场玩家百花齐放，甚至部分车企也通过收购具备测绘资质的图商，希望自主地覆盖地图采集。 早期由于针对辅助驾驶的地图还未形成明确系统的政策约束，地图市场玩家百花齐放，甚至部分车企也通过收购具备测绘资质的图商，希望自主地覆盖地图采集。 但在2022年，这一现象戛然而止。这年7月，国家自然资源部下发了《关于促进智能网联汽车发展维护测绘地理信息安全的通知》。自然资源部认定，自动驾驶汽车收集道路环境信息是测绘行为，包括自动驾驶测试采集的数据、传感器的中间数据等，只能由国家颁发导航电子地图制作甲级测绘资质的企业来操作。 但在2022年，这一现象戛然而止。这年7月，国家自然资源部下发了《关于促进智能网联汽车发展维护测绘地理信息安全的通知》。自然资源部认定，自动驾驶汽车收集道路环境信息是测绘行为，包括自动驾驶测试采集的数据、传感器的中间数据等，只能由国家颁发导航电子地图制作甲级测绘资质的企业来操作。 彼时国家有关主管部门对国内企业高精度地图测绘资质进行复核，包括高德、四维图新、腾讯大地通途等19家企业通过资质复核，而此前具备甲级测绘资质的企业有31家，同比减少12家。这导致， 地图市场开始向头部玩家聚集 。 彼时国家有关主管部门对国内企业高精度地图测绘资质进行复核，包括高德、四维图新、腾讯大地通途等19家企业通过资质复核，而此前具备甲级测绘资质的企业有31家，同比减少12家。这导致， 地图市场开始向头部玩家聚集 地图市场开始向头部玩家聚集 。 在传统高精地图市场中，高德、百度、四维图新等传统图商占据着主导地位。而迈入轻地图时代，腾讯地图则开始脱颖而出。 在传统高精地图市场中，高德、百度、四维图新等传统图商占据着主导地位。而迈入轻地图时代，腾讯地图则开始脱颖而出。 为什么呢？这既来自于腾讯团队对技术的预判，也因为其更加开放、灵活的定位。 为什么呢？这既来自于腾讯团队对技术的预判，也因为其更加开放、灵活的定位。 早在2022年，基于对辅助驾驶行业技术发展趋势的预判，腾讯地图就开始从高精度地图向轻高精度地图转型。一方面在既有的高速、城快路的高精地图业务上，配合车企进行覆盖范围和鲜度的更新；另一方面，腾讯轻高精地图（HD Air）也开始具有初步的雏形。 早在2022年，基于对辅助驾驶行业技术发展趋势的预判，腾讯地图就开始从高精度地图向轻高精度地图转型。一方面在既有的高速、城快路的高精地图业务上，配合车企进行覆盖范围和鲜度的更新；另一方面，腾讯轻高精地图（HD Air）也开始具有初步的雏形。 通过与长安、极氪等车企客户的合作，腾讯大概在半年到一年的时间内，就完成了智驾云图产品定义的收敛。2023年4月， 腾讯正式发布了面向城市辅助驾驶场景的HD Air轻量级高精数据产品 。 通过与长安、极氪等车企客户的合作，腾讯大概在半年到一年的时间内，就完成了智驾云图产品定义的收敛。2023年4月， 腾讯正式发布了面向城市辅助驾驶场景的HD Air轻量级高精数据产品 腾讯正式发布了面向城市辅助驾驶场景的HD Air轻量级高精数据产品 。 △搭载长安天枢智驾的启源Q07，图片来源：车企官方 △搭载长安天枢智驾的启源Q07，图片来源：车企官方 去年，腾讯又进一步推出「腾讯地图车机版8.0」舱驾一体解决方案，对各层级地图数据要素的进一步分类、整合与加工，通过统一的地图和数据平台，实现人驾和车驾共用一张图、共享一份数据。 去年，腾讯又进一步推出「腾讯地图车机版8.0」舱驾一体解决方案，对各层级地图数据要素的进一步分类、整合与加工，通过统一的地图和数据平台，实现人驾和车驾共用一张图、共享一份数据。 也就是说，标准导航地图（SD Map）、轻高精地图（HD Air)、高精地图（HD Map)等不同精度等级的地图数据，可以做到数据同源、质量同级；并且模块化工具链，可以支持车企按需灵活取用必要的地图要素。 也就是说，标准导航地图（SD Map）、轻高精地图（HD Air)、高精地图（HD Map)等不同精度等级的地图数据，可以做到数据同源、质量同级；并且模块化工具链，可以支持车企按需灵活取用必要的地图要素。 △腾讯智驾云图，图片来源：企业官方 △腾讯智驾云图，图片来源：企业官方 传统的地图常常采用离线数据包的形式进行交付，而腾讯则 可以通过云服务的方式提供地图数据 ，包含「云到端」和「云到云」两种模式，这也就是现在腾讯对外输出的「智驾云图」方案。 传统的地图常常采用离线数据包的形式进行交付，而腾讯则 可以通过云服务的方式提供地图数据 可以通过云服务的方式提供地图数据 ，包含「云到端」和「云到云」两种模式，这也就是现在腾讯对外输出的「智驾云图」方案。 「云到端」指的是，可以将地图数据最新的变化、动态交通及环境信息、驾驶经验数据等下发到车端提升体验；「云到云」则是，直接对接车企的辅助驾驶云，车企可以将智驾云图的数据和自有数据融合使用，从而更大程度地挖掘自有数据的价值。 「云到端」指的是，可以将地图数据最新的变化、动态交通及环境信息、驾驶经验数据等下发到车端提升体验；「云到云」则是，直接对接车企的辅助驾驶云，车企可以将智驾云图的数据和自有数据融合使用，从而更大程度地挖掘自有数据的价值。 智驾云图的另一个核心优势，则是 可扩展的多图层数据形态 。简单说，它不是一张 “固定的图”，而是一套 “能生长、能运营的地图生态”，其可以支持ODD灵活配置、即插即用的在线服务，还能提供运营工具链，车企可以根据自身需求快速调整。 智驾云图的另一个核心优势，则是 可扩展的多图层数据形态 可扩展的多图层数据形态 。简单说，它不是一张 “固定的图”，而是一套 “能生长、能运营的地图生态”，其可以支持ODD灵活配置、即插即用的在线服务，还能提供运营工具链，车企可以根据自身需求快速调整。 在驾驶经验图层上，也可以与车企灵活共建，共同打造“环境经验图层”和“驾驶行为经验图层”。比如哪里是颠簸路、建议车速多少，哪里是危险路段需要谨慎，甚至变道模式、弯道车速、新能源道路节能指数等，这些“经验”能让辅助驾驶更像“老司机”。 在驾驶经验图层上，也可以与车企灵活共建，共同打造“环境经验图层”和“驾驶行为经验图层”。比如哪里是颠簸路、建议车速多少，哪里是危险路段需要谨慎，甚至变道模式、弯道车速、新能源道路节能指数等，这些“经验”能让辅助驾驶更像“老司机”。 同时，由于地图要素能按导航路线或区域发布，所以其还可以支持车端传感器的差分更新，像限速牌、电子眼、车道线这些静态要素，根据置信度进入数据流转，部分能实现天级更新，而道路状况、车道级交通事件、恶劣天气这些动态要素，依托车端感知回传和生态伙伴支持，能做到实时发布。 同时，由于地图要素能按导航路线或区域发布，所以其还可以支持车端传感器的差分更新，像限速牌、电子眼、车道线这些静态要素，根据置信度进入数据流转，部分能实现天级更新，而道路状况、车道级交通事件、恶劣天气这些动态要素，依托车端感知回传和生态伙伴支持，能做到实时发布。 从基础地图层、更新要素层，到客户数据层、驾驶经验层、运营层、ODD动态层…… 车企可以像搭积木一样自由组合，满足不同场景的需求。 从基础地图层、更新要素层，到客户数据层、驾驶经验层、运营层、ODD动态层…… 车企可以像搭积木一样自由组合，满足不同场景的需求。 当前智驾地图市场呈现 “双寡头主导、多元竞争” 的格局，腾讯与高德在城市NOA市场垄断超96%份额，百度、四维图新在传统领域保持优势，华为通过全栈方案间接影响地图需求。 当前智驾地图市场呈现 “双寡头主导、多元竞争” “双寡头主导、多元竞争” 的格局，腾讯与高德在城市NOA市场垄断超96%份额，百度、四维图新在传统领域保持优势，华为通过全栈方案间接影响地图需求。 尽管凭借对技术趋势的精准预判，以及对转型的决心，腾讯地图在轻地图时代实现了赶超，但行业远未到达竞争的终点。AI大模型时代的到来，智驾地图的形态也仍在继续演变，竞争仍在持续。 尽管凭借对技术趋势的精准预判，以及对转型的决心，腾讯地图在轻地图时代实现了赶超，但行业远未到达竞争的终点。AI大模型时代的到来，智驾地图的形态也仍在继续演变，竞争仍在持续。 智驾地图竞争远未到达终点 智驾地图竞争远未到达终点 从最初对「无图」的追逐，到现如今轻高精地图技术的深度探索，车企与产业链玩家逐渐认清： 地图不是辅助驾驶的「负担」，而是提升辅助驾驶体验的「利器」 。 从最初对「无图」的追逐，到现如今轻高精地图技术的深度探索，车企与产业链玩家逐渐认清： 地图不是辅助驾驶的「负担」，而是提升辅助驾驶体验的「利器」 地图不是辅助驾驶的「负担」，而是提升辅助驾驶体验的「利器」 。 也正因此，智驾地图市场的体量，也随着城区辅助驾驶的大规模普及在快速稳健地增长。据泰伯研究院预测，智驾地图市场2025年将达54亿元，预计到2030年，市场规模有望达到117亿元。 也正因此，智驾地图市场的体量，也随着城区辅助驾驶的大规模普及在快速稳健地增长。据泰伯研究院预测，智驾地图市场2025年将达54亿元，预计到2030年，市场规模有望达到117亿元。 但地图的形态到此却还不是终局， 随着AI大模型的到来，地图形态仍在发生变化 。 但地图的形态到此却还不是终局， 随着AI大模型的到来，地图形态仍在发生变化 随着AI大模型的到来，地图形态仍在发生变化 。 △蔚来世界模型，图片来源：车企官方 △蔚来世界模型，图片来源：车企官方 端到端技术的上车，让AI大模型对辅助驾驶开发方式产生了颠覆性影响，这也驱使地图形态出现新的演变方向，未来地图将不再仅局限于传统意义上富含高精要素和道路几何的数据库，而是逐步融入模型，成为大模型的有机组成。 端到端技术的上车，让AI大模型对辅助驾驶开发方式产生了颠覆性影响，这也驱使地图形态出现新的演变方向，未来地图将不再仅局限于传统意义上富含高精要素和道路几何的数据库，而是逐步融入模型，成为大模型的有机组成。 大模型本质上是一种知识压缩，这也就意味着，未来地图的形态最终有可能是以模型的形式存在，并通过自动驾驶系统感知系统，将地理位置环境信息数据，作为一个观测信息给到大模型，大模型经过对数据的推理和判断，最终给出规划执行结果。 大模型本质上是一种知识压缩，这也就意味着，未来地图的形态最终有可能是以模型的形式存在，并通过自动驾驶系统感知系统，将地理位置环境信息数据，作为一个观测信息给到大模型，大模型经过对数据的推理和判断，最终给出规划执行结果。 除了地图本身的数据形式会发生改变之外，大模型技术还会影响到从地图采集生产到仿真验证中间的每一个环节。 除了地图本身的数据形式会发生改变之外，大模型技术还会影响到从地图采集生产到仿真验证中间的每一个环节。 当然，大模型的发展将给地图行业带来新的形态改变，而也势必会导致整个行业格局的变化。无论是新老玩家，只有能够抓住新范式，才会在新领域中拿到更多的份额。 当然，大模型的发展将给地图行业带来新的形态改变，而也势必会导致整个行业格局的变化。无论是新老玩家，只有能够抓住新范式，才会在新领域中拿到更多的份额。 对于腾讯这类先行布局的图商而言，行业对智驾地图的重新认知，使其迎来了前所未有的发展机遇，但地图的演变并未达到终点，那么行业的竞争也远不会停止。而谁能够坚定的拥抱未来，谁才有可能走向最终的胜利。 对于腾讯这类先行布局的图商而言，行业对智驾地图的重新认知，使其迎来了前所未有的发展机遇，但地图的演变并未达到终点，那么行业的竞争也远不会停止。而谁能够坚定的拥抱未来，谁才有可能走向最终的胜利。"}
{"url": "https://www.qbitai.com/2025/10/341478.html", "title": "量子位「MEET2026智能未来大会」启动！年度榜单征集中", "date": "2025-10-14", "content": "量子位「MEET2026智能未来大会」启动！年度榜单征集中 量子位「MEET2026智能未来大会」启动！年度榜单征集中 林樾 2025-10-14 14:32:43 来源： 量子位 林樾 林樾 林樾 林樾 2025-10-14 2025-10-14 14:32:43 14:32:43 来源： 量子位 来源： 量子位 量子位 摘要样式 今年12月，北京，MEET2026智能未来大会！ 今年12月，北京，MEET2026智能未来大会！ 今年12月，北京，MEET2026智能未来大会！ MEET组委会 发自 凹非寺 量子位｜公众号 QbitAI MEET组委会 发自 凹非寺 MEET组委会 发自 凹非寺 量子位｜公众号 QbitAI 量子位｜公众号 QbitAI 我们正迈入一个由人工智能重塑一切的新时代。 我们正迈入一个由人工智能重塑一切的新时代。 智能技术已经深刻渗透进生产和生活， 跨越了软件、硬件、机器人等不同形态 ，从工具发展为能深度理解人类需求的智能伙伴。 智能技术已经深刻渗透进生产和生活， 跨越了软件、硬件、机器人等不同形态 跨越了软件、硬件、机器人等不同形态 ，从工具发展为能深度理解人类需求的智能伙伴。 如今，智能技术不再局限于某一特定领域，而是 跨越产业、学科和场景的边界 ，催生出全新的生态和机遇。 如今，智能技术不再局限于某一特定领域，而是 跨越产业、学科和场景的边界 跨越产业、学科和场景的边界 ，催生出全新的生态和机遇。 随着多模态、AR/VR、空间计算等新兴技术的涌现， 数字世界与物理世界的界限正在逐步模糊并融合 。 随着多模态、AR/VR、空间计算等新兴技术的涌现， 数字世界与物理世界的界限正在逐步模糊并融合 数字世界与物理世界的界限正在逐步模糊并融合 。 在这股强大的技术浪潮中，企业、技术与社会之间的连接与共生，已成为推动发展的核心动力。 在这股强大的技术浪潮中，企业、技术与社会之间的连接与共生，已成为推动发展的核心动力。 我们正见证人工智能逐步成为基础设施的一部分，正在重塑人类未来的工作、生活和社会运作模式。科技的不断进步正在突破传统的边界，各类新兴技术交织融合，推动着产业的深度变革。 我们正见证人工智能逐步成为基础设施的一部分，正在重塑人类未来的工作、生活和社会运作模式。科技的不断进步正在突破传统的边界，各类新兴技术交织融合，推动着产业的深度变革。 正是在这样的背景下，我们将以 「共生无界，智启未来」 为主题，正式启动 MEET2026智能未来大会 ！承袭MEET系列年度行业观察的视角，诚邀科技、产业与学术领域的领军人物齐聚一堂，共同见证行业变革。 正是在这样的背景下，我们将以 「共生无界，智启未来」 「共生无界，智启未来」 为主题，正式启动 MEET2026智能未来大会 MEET2026智能未来大会 ！承袭MEET系列年度行业观察的视角，诚邀科技、产业与学术领域的领军人物齐聚一堂，共同见证行业变革。 今年，是 MEET智能未来大会 的第七年。作为年度影响力科技商业峰会，每年最具行业代表性的科技商业领袖，都会来到大会分享前瞻观点与认知。 今年，是 MEET智能未来大会 MEET智能未来大会 的第七年。作为年度影响力科技商业峰会，每年最具行业代表性的科技商业领袖，都会来到大会分享前瞻观点与认知。 上百位分享嘉宾中包括 李开复博士 、 张亚勤教授 等产业大咖， 倪光南院士 、 谭建荣院士 、 李培根院士 、 郑纬民院士 、 周志华教授 、 唐杰教授 等学术领路人， 百度 、 阿里 、 腾讯 、 华为 、 京东 、 美团 、 小米、商汤 等在内的科技行业领军者，以及更多科技新锐新星。 上百位分享嘉宾中包括 李开复博士 李开复博士 、 张亚勤教授 张亚勤教授 等产业大咖， 倪光南院士 倪光南院士 、 谭建荣院士 谭建荣院士 、 李培根院士 李培根院士 、 郑纬民院士 郑纬民院士 、 周志华教授 周志华教授 、 唐杰教授 唐杰教授 等学术领路人， 百度 百度 、 阿里 阿里 、 腾讯 腾讯 、 华为 华为 、 京东 京东 、 美团 美团 、 小米、商汤 小米、商汤 等在内的科技行业领军者，以及更多科技新锐新星。 点击查看MEET2025回顾：李开复周志华纵论AI大模型，商汤徐立倡议「打脸时刻」，万字梳理MEET’25大咖激辩，320万观众同见证 点击查看MEET2025回顾：李开复周志华纵论AI大模型，商汤徐立倡议「打脸时刻」，万字梳理MEET’25大咖激辩，320万观众同见证 正是业内领袖分享的独到行业观点，使得参会人数屡创新高，每年大会都能吸引 上千名科技从业者 参与， 百万观众线上围观 ， 近百家合作媒体 联合曝光。而MEET智能未来大会也已成为智能科技行业的年度风向标。 正是业内领袖分享的独到行业观点，使得参会人数屡创新高，每年大会都能吸引 上千名科技从业者 上千名科技从业者 参与， 百万观众线上围观 百万观众线上围观 ， 近百家合作媒体 近百家合作媒体 联合曝光。而MEET智能未来大会也已成为智能科技行业的年度风向标。 这一次，我们希望聚焦正在聚变的智能科技产业，诚邀 技术、产业、投资领域 具有代表性的企业和人物，共同探讨人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力等前沿科技话题。 这一次，我们希望聚焦正在聚变的智能科技产业，诚邀 技术、产业、投资领域 技术、产业、投资领域 具有代表性的企业和人物，共同探讨人工智能+、AI Infra、智能终端、智能驾驶、低空经济、能源电力等前沿科技话题。 12月，诚邀你与我们共论科技行业破局之道！ 12月，诚邀你与我们共论科技行业破局之道！ 12月，诚邀你与我们共论科技行业破局之道！ 大会主题：共生无界，智启未来 大会主题：共生无界，智启未来 以AI为代表的智能科技正在穿透产业、学科与场景的边界，开始成为驱动社会演进的核心动能。人机共生、虚实结合、产业共生成为现实—— 以AI为代表的智能科技正在穿透产业、学科与场景的边界，开始成为驱动社会演进的核心动能。人机共生、虚实结合、产业共生成为现实—— AI不再是冰冷工具，而是开始真正理解人类意图、补足人类能力协同合作； AI不再是冰冷工具，而是开始真正理解人类意图、补足人类能力协同合作； 多模态、AR/VR、空间计算技术融合，打破物理世界与数字世界次元壁； 多模态、AR/VR、空间计算技术融合，打破物理世界与数字世界次元壁； 技术不再局限于单一个体、单一环节，而是贯通产业链，催生新业态、新生态； 技术不再局限于单一个体、单一环节，而是贯通产业链，催生新业态、新生态； 数字智慧开始真正意义上重塑物理世界、提升全社会福祉和效率… 数字智慧开始真正意义上重塑物理世界、提升全社会福祉和效率… 连接、共生、重塑、跃迁，这或许正是“人工智能+”的本质。 连接、共生、重塑、跃迁，这或许正是“人工智能+”的本质。 重磅发布｜2025人工智能年度榜单 重磅发布｜2025人工智能年度榜单 量子位发起的「人工智能年度榜单」，已成为AI行业最具影响力榜单之一。 量子位发起的「人工智能年度榜单」，已成为AI行业最具影响力榜单之一。 在人工智能重新定义一切的时代里，智能技术已不再是单一工具，而是产业与社会协同进化的驱动力。我们期待通过这场年度评选，去发现并致敬那些真正引领变革、开拓边界的探索者与实践者。 在人工智能重新定义一切的时代里，智能技术已不再是单一工具，而是产业与社会协同进化的驱动力。我们期待通过这场年度评选，去发现并致敬那些真正引领变革、开拓边界的探索者与实践者。 今年榜单将从公司、产品、人物等三大维度评选五类奖项，榜单结果将在MEET2026大会上正式发布。 今年榜单将从公司、产品、人物等三大维度评选五类奖项，榜单结果将在MEET2026大会上正式发布。 评选标准 可见于：2025人工智能年度评选启动！3大维度5类奖项，正在寻找AI+时代领航者 评选标准 评选标准 可见于：2025人工智能年度评选启动！3大维度5类奖项，正在寻找AI+时代领航者 企业榜 企业榜 企业榜 2025人工智能年度 领航企业 2025人工智能年度 潜力创业公司 2025人工智能年度 领航企业 2025人工智能年度 领航企业 领航企业 2025人工智能年度 潜力创业公司 2025人工智能年度 潜力创业公司 潜力创业公司 产品榜 产品榜 产品榜 2025人工智能年度 杰出产品 2025人工智能年度 杰出解决方案 2025人工智能年度 杰出产品 2025人工智能年度 杰出产品 杰出产品 2025人工智能年度 杰出解决方案 2025人工智能年度 杰出解决方案 杰出解决方案 人物榜 人物榜 人物榜 2025人工智能年度 焦点人物 2025人工智能年度 焦点人物 2025人工智能年度 焦点人物 焦点人物 报名方式 报名方式 本次评选从即日起开始报名，截至2025年11月17日。评选结果将于量子位主办的 MEET2026智能未来大会 上正式公布。 本次评选从即日起开始报名，截至2025年11月17日。评选结果将于量子位主办的 MEET2026智能未来大会 MEET2026智能未来大会 上正式公布。 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 网页端链接：https://wj.qq.com/s2/23740133/iso8/ 如对本次评选有其他疑问，请联系量子位工作人员：添加微信18801103170，或邮件发送至linyu@qbitai.com，并备注「评选-企业-姓名」。 如对本次评选有其他疑问，请联系量子位工作人员：添加微信18801103170，或邮件发送至linyu@qbitai.com，并备注「评选-企业-姓名」。 重磅发布｜2025年度AI十大趋势报告 重磅发布｜2025年度AI十大趋势报告 依照每年惯例，年度趋势系列报告也将在MEET2026大会上重磅发布。 依照每年惯例，年度趋势系列报告也将在MEET2026大会上重磅发布。 今年，量子位智库将继续锚定AI这一时代科技发展的主旋律，站在新进展与新信息的最前沿，产学研交汇的核心地带，与各位共赴下一场智能浪潮。 今年，量子位智库将继续锚定AI这一时代科技发展的主旋律，站在新进展与新信息的最前沿，产学研交汇的核心地带，与各位共赴下一场智能浪潮。 量子位智库将结合技术成熟、落地现状、潜在价值等因素，在《2025年度AI十大趋势报告》中提名正在释放巨大潜力的十大AI趋势，并对各趋势进行深入分析，提名代表机构、最佳案例等，敬请期待。 量子位智库将结合技术成熟、落地现状、潜在价值等因素，在《2025年度AI十大趋势报告》中提名正在释放巨大潜力的十大AI趋势，并对各趋势进行深入分析，提名代表机构、最佳案例等，敬请期待。 会议设置 会议设置 时间：2025年12月 时间：2025年12月 地点：中国北京 地点：中国北京 参会方式：报名通道即将开启，请关注量子位公众号后续讯息。 参会方式：报名通道即将开启，请关注量子位公众号后续讯息。 联系方式 联系方式 本届大会正在积极筹备中，量子位期待与更多优秀企业、媒体、研究机构、投资机构、技术社区等潜在合作伙伴共同探讨、共商盛事。 本届大会正在积极筹备中，量子位期待与更多优秀企业、媒体、研究机构、投资机构、技术社区等潜在合作伙伴共同探讨、共商盛事。 商务合作 商务合作 邮箱：chenfei@qbitai.com 邮箱：chenfei@qbitai.com 活动合作 活动合作 王琳玉 王琳玉 微信：18801103170 微信：18801103170 邮箱：linyu@qbitai.com 邮箱：linyu@qbitai.com 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341421.html", "title": "OpenAI自研芯片内幕曝光！18个月前开始用AI优化芯片设计", "date": "2025-10-14", "content": "OpenAI自研芯片内幕曝光！18个月前开始用AI优化芯片设计 OpenAI自研芯片内幕曝光！18个月前开始用AI优化芯片设计 一水 2025-10-14 14:23:19 来源： 量子位 一水 一水 一水 一水 2025-10-14 2025-10-14 14:23:19 14:23:19 来源： 量子位 来源： 量子位 量子位 摘要样式 几个月前已开始自研推理芯片 几个月前已开始自研推理芯片 几个月前已开始自研推理芯片 “用模型优化芯片设计，比人类工程师更快。” “用模型优化芯片设计，比人类工程师更快。” “合作水到渠成，相关项目已经持续了约18个月……” “合作水到渠成，相关项目已经持续了约18个月……” 好家伙，就在OpenAI博通官宣完合作之后，双方头头儿开始齐聚一堂亲口爆料了！ 好家伙，就在OpenAI博通官宣完合作之后，双方头头儿开始齐聚一堂亲口爆料了！ OpenAI这边派出了CEO奥特曼（右2）和总裁Greg Brockman（右1），博通则派出了总裁兼CEO Hock Tan（C位）以及半导体解决方案事业群总裁Charlie Kawwas（左2）。 OpenAI这边派出了CEO奥特曼（右2）和总裁Greg Brockman（右1），博通则派出了总裁兼CEO Hock Tan（C位）以及半导体解决方案事业群总裁Charlie Kawwas（左2）。 人一多之后，什么合作契机、合作细节等等，几乎全都被抢着透了个干净。 人一多之后，什么合作契机、合作细节等等，几乎全都被抢着透了个干净。 不过在这之前，还是先来回顾一下双方刚刚达成的合作内容吧。 不过在这之前，还是先来回顾一下双方刚刚达成的合作内容吧。 合作部署10GW规模芯片 合作部署10GW规模芯片 根据公告，OpenAI与半导体巨头博通达成的合作如下—— 根据公告，OpenAI与半导体巨头博通达成的合作如下—— 双方将共同部署由OpenAI设计的 10GW规模 的AI加速器。预计博通会从 2026年下半年开始 部署配备AI加速器和网络系统的机架，并于 2029年底前 完成全部部署。 双方将共同部署由OpenAI设计的 10GW规模 10GW规模 的AI加速器。预计博通会从 2026年下半年开始 2026年下半年开始 部署配备AI加速器和网络系统的机架，并于 2029年底前 2029年底前 完成全部部署。 OpenAI将负责设计这些加速器与系统，而博通则与其合作开发并投入部署。 通过设计自己的芯片与系统，OpenAI可将其在前沿模型与产品开发中所获得的经验“直接内嵌”于硬件之中，解锁新的能力与智慧水平。 这些机架将完全采用博通的以太网及其他互联解决方案，用以满足全球对AI的激增需求，并在OpenAI的设施以及合作伙伴的数据中心内部署。 OpenAI将负责设计这些加速器与系统，而博通则与其合作开发并投入部署。 OpenAI将负责设计这些加速器与系统，而博通则与其合作开发并投入部署。 通过设计自己的芯片与系统，OpenAI可将其在前沿模型与产品开发中所获得的经验“直接内嵌”于硬件之中，解锁新的能力与智慧水平。 通过设计自己的芯片与系统，OpenAI可将其在前沿模型与产品开发中所获得的经验“直接内嵌”于硬件之中，解锁新的能力与智慧水平。 这些机架将完全采用博通的以太网及其他互联解决方案，用以满足全球对AI的激增需求，并在OpenAI的设施以及合作伙伴的数据中心内部署。 这些机架将完全采用博通的以太网及其他互联解决方案，用以满足全球对AI的激增需求，并在OpenAI的设施以及合作伙伴的数据中心内部署。 10GW规模啥概念？ 10GW规模啥概念？ 通常而言，传统超算中心的功率大概在几百MW（兆瓦），而10GW=10000MW。 通常而言，传统超算中心的功率大概在几百MW（兆瓦），而10GW=10000MW。 更大白话一点，10GW的电力足以同时点亮约1亿个100瓦灯泡。 更大白话一点，10GW的电力足以同时点亮约1亿个100瓦灯泡。 OpenAI CEO奥特曼 在公告中表示，“与博通的合作是构建解锁AI潜能所需基础设施的关键一步，有助于为人类与企业带来真正的益处”。 OpenAI CEO奥特曼 OpenAI CEO奥特曼 在公告中表示，“与博通的合作是构建解锁AI潜能所需基础设施的关键一步，有助于为人类与企业带来真正的益处”。 博通总裁兼CEO Hock Tan 则认为，“博通与OpenAI的合作标志着在追求通用人工智能道路上的一个关键时刻。OpenAI自ChatGPT问世以来一直处于AI革命的前沿，我们非常高兴能与其共同开发并部署10GW的下一代加速器与网络系统，为AI的未来奠定基础”。 博通总裁兼CEO Hock Tan 博通总裁兼CEO Hock Tan 则认为，“博通与OpenAI的合作标志着在追求通用人工智能道路上的一个关键时刻。OpenAI自ChatGPT问世以来一直处于AI革命的前沿，我们非常高兴能与其共同开发并部署10GW的下一代加速器与网络系统，为AI的未来奠定基础”。 OpenAI总裁Greg Brockman 强调道，“通过制造我们自己的芯片，我们可以将创造前沿模型与产品的经验直接嵌入硬件，从而解锁新的能力与智能水平”。 OpenAI总裁Greg Brockman OpenAI总裁Greg Brockman 强调道，“通过制造我们自己的芯片，我们可以将创造前沿模型与产品的经验直接嵌入硬件，从而解锁新的能力与智能水平”。 博通半导体解决方案事业群总裁Charlie Kawwas 宣称，“我们与OpenAI的合作将推动AI突破，并使其潜力更快实现。定制加速器非常适合与标准化以太网的扩展互联解决方案结合应用，以在成本和性能上优化下一代AI基础设施。机架系统将包括博通全套以太网、PCIe和光互联连接方案，重申我们在AI基建领域的方案领导地位”。 博通半导体解决方案事业群总裁Charlie Kawwas 博通半导体解决方案事业群总裁Charlie Kawwas 宣称，“我们与OpenAI的合作将推动AI突破，并使其潜力更快实现。定制加速器非常适合与标准化以太网的扩展互联解决方案结合应用，以在成本和性能上优化下一代AI基础设施。机架系统将包括博通全套以太网、PCIe和光互联连接方案，重申我们在AI基建领域的方案领导地位”。 总之，对博通而言，这次合作进一步凸显了定制加速器的重要性，以及以太网作为AI数据中心中纵向与横向扩展网络核心技术的战略地位。 总之，对博通而言，这次合作进一步凸显了定制加速器的重要性，以及以太网作为AI数据中心中纵向与横向扩展网络核心技术的战略地位。 而对OpenAI来说，则有助于进一步缓解算力紧张问题，毕竟ChatGPT每周有近8亿活跃用户。 而对OpenAI来说，则有助于进一步缓解算力紧张问题，毕竟ChatGPT每周有近8亿活跃用户。 按网友的话来说就是，找老黄买卡还要排队，心急的OpenAI这是决定自己下场了。 按网友的话来说就是，找老黄买卡还要排队，心急的OpenAI这是决定自己下场了。 更多内幕曝光 更多内幕曝光 OK，听完了各方场面话，咱们再来从几位的聊天中扒扒细节。 OK，听完了各方场面话，咱们再来从几位的聊天中扒扒细节。 过程中主持人化身嘴替，问出了两个关键问题： 过程中主持人化身嘴替，问出了两个关键问题： 为什么OpenAI要现在自研芯片？ 自研芯片之后会发生什么？ 为什么OpenAI要现在自研芯片？ 为什么OpenAI要现在自研芯片？ 自研芯片之后会发生什么？ 自研芯片之后会发生什么？ 对于问题一，OpenAI总裁Greg Brockman总结了这样几点理由： 1） 对工作负载的深刻理解以及垂直整合的必要性；2）规模带来的历史发现；3）外部合作受挫与实现愿景的必要性。 对于问题一，OpenAI总裁Greg Brockman总结了这样几点理由： 1） 对工作负载的深刻理解以及垂直整合的必要性；2）规模带来的历史发现；3）外部合作受挫与实现愿景的必要性。 1） 对工作负载的深刻理解以及垂直整合的必要性；2）规模带来的历史发现；3）外部合作受挫与实现愿景的必要性。 具体而言，Greg透露其实双方已经合作了约18个月，而且进展很快。之所以决定自研芯片，一大理由是他们对工作负载（workload）有了深刻理解。 具体而言，Greg透露其实双方已经合作了约18个月，而且进展很快。之所以决定自研芯片，一大理由是他们对工作负载（workload）有了深刻理解。 我们与生态系统中的众多合作伙伴紧密协作。市场上有众多出色的芯片，每款芯片都有其独特的优势。因此，我们一直在寻找那些我们认为尚未得到充分服务的特定工作负载。 我们思考如何构建能够加速这些可能性的解决方案。所以，我认为我们拥有的这种能力——即能够为我们预见到但难以通过其他合作伙伴实现的需求进行完整的垂直整合——是一个非常明确的项目应用场景。 我们与生态系统中的众多合作伙伴紧密协作。市场上有众多出色的芯片，每款芯片都有其独特的优势。因此，我们一直在寻找那些我们认为尚未得到充分服务的特定工作负载。 我们与生态系统中的众多合作伙伴紧密协作。市场上有众多出色的芯片，每款芯片都有其独特的优势。因此，我们一直在寻找那些我们认为尚未得到充分服务的特定工作负载。 我们思考如何构建能够加速这些可能性的解决方案。所以，我认为我们拥有的这种能力——即能够为我们预见到但难以通过其他合作伙伴实现的需求进行完整的垂直整合——是一个非常明确的项目应用场景。 我们思考如何构建能够加速这些可能性的解决方案。所以，我认为我们拥有的这种能力——即能够为我们预见到但难以通过其他合作伙伴实现的需求进行完整的垂直整合——是一个非常明确的项目应用场景。 划重点，通过垂直整合来满足现有芯片无法覆盖到的特定计算任务或工作负载。 划重点，通过垂直整合来满足现有芯片无法覆盖到的特定计算任务或工作负载。 这也是奥特曼最近一再强调的点。他在a16z的一场个人采访中表示， 曾经自己一直反对垂直整合，但现在认为自己错了 。 这也是奥特曼最近一再强调的点。他在a16z的一场个人采访中表示， 曾经自己一直反对垂直整合，但现在认为自己错了 曾经自己一直反对垂直整合，但现在认为自己错了 。 当时他解释说，虽然经济理论倾向于公司只做一件事，但在OpenAI的案例中，为了实现使命，他们必须做比原先想象中更多的事情。 当时他解释说，虽然经济理论倾向于公司只做一件事，但在OpenAI的案例中，为了实现使命，他们必须做比原先想象中更多的事情。 他还引用了iPhone的例子，称其是科技行业最令人难以置信的产品，并指出它是极其垂直整合的。 他还引用了iPhone的例子，称其是科技行业最令人难以置信的产品，并指出它是极其垂直整合的。 而自研芯片，无疑也是让OpenAI走向垂直整合的关键一环。 而自研芯片，无疑也是让OpenAI走向垂直整合的关键一环。 此外，Greg还谈到了规模的效力。 此外，Greg还谈到了规模的效力。 当我们创立OpenAI时，并没有把太多精力放在计算上。因为当时认为通往AGI的道路主要在于想法，主要在于尝试和其他东西……不过大约两年后，在2017年，我们发现从规模中获得了最好的结果。 当我们创立OpenAI时，并没有把太多精力放在计算上。因为当时认为通往AGI的道路主要在于想法，主要在于尝试和其他东西……不过大约两年后，在2017年，我们发现从规模中获得了最好的结果。 当我们创立OpenAI时，并没有把太多精力放在计算上。因为当时认为通往AGI的道路主要在于想法，主要在于尝试和其他东西……不过大约两年后，在2017年，我们发现从规模中获得了最好的结果。 当时他们正尝试在视频游戏《Dota 2》背景下扩展强化学习，结果无意中发现了规模扩展的巨大作用，于是开始将其作用于整个AI系统。 当时他们正尝试在视频游戏《Dota 2》背景下扩展强化学习，结果无意中发现了规模扩展的巨大作用，于是开始将其作用于整个AI系统。 所以，自研芯片也是实现算力不断扩展的重要举措。 所以，自研芯片也是实现算力不断扩展的重要举措。 而且从以往经历来看，没有芯片就没有话语权 。Greg透露一路遇到了很多芯片公司，当他们反馈“这是我们认为事情将要发展的方向、模型需要是这种形状的”，结果根本没人听。 而且从以往经历来看，没有芯片就没有话语权 而且从以往经历来看，没有芯片就没有话语权 。Greg透露一路遇到了很多芯片公司，当他们反馈“这是我们认为事情将要发展的方向、模型需要是这种形状的”，结果根本没人听。 处于这样一种境地非常令人沮丧，所以未来走向很明确了。 处于这样一种境地非常令人沮丧，所以未来走向很明确了。 处于这样一种境地非常令人沮丧，所以未来走向很明确了。 至于自研芯片后会发生什么，奥特曼认为通过优化整个堆栈，他们将能够实现巨大的效率提升，并能够 从每瓦特中榨取出更多的智能 。 至于自研芯片后会发生什么，奥特曼认为通过优化整个堆栈，他们将能够实现巨大的效率提升，并能够 从每瓦特中榨取出更多的智能 从每瓦特中榨取出更多的智能 。 这种效率提升将直接转化为更好的性能、更快的模型、更便宜的模型。 这种效率提升将直接转化为更好的性能、更快的模型、更便宜的模型。 这里他还有一个和老黄不谋而合的观点——人们总是想要更多，你只需要给他就行。 这里他还有一个和老黄不谋而合的观点——人们总是想要更多，你只需要给他就行。 另外值得一提的是，Greg也爆料称，AI在自研芯片过程中发挥了大作用—— 已经在用模型优化芯片设计，而且比人类工程师更快 （连用了“非常有趣”这样的表述）。 另外值得一提的是，Greg也爆料称，AI在自研芯片过程中发挥了大作用—— 已经在用模型优化芯片设计，而且比人类工程师更快 已经在用模型优化芯片设计，而且比人类工程师更快 （连用了“非常有趣”这样的表述）。 你拿出人类已经优化过的组件，然后投入计算，模型就会提出自己的优化方案，这非常有趣。 我们现在处于这样一个阶段，我不认为我们拥有的任何优化方案是人类设计师想不到的。 通常我们的专家稍后会看一眼，然后说，‘是的，这在我的清单上’，但这可能是‘20件事之一，他们需要再花一个月才能实现’。这确实非常、非常有趣。 你拿出人类已经优化过的组件，然后投入计算，模型就会提出自己的优化方案，这非常有趣。 你拿出人类已经优化过的组件，然后投入计算，模型就会提出自己的优化方案，这非常有趣。 我们现在处于这样一个阶段，我不认为我们拥有的任何优化方案是人类设计师想不到的。 我们现在处于这样一个阶段，我不认为我们拥有的任何优化方案是人类设计师想不到的。 通常我们的专家稍后会看一眼，然后说，‘是的，这在我的清单上’，但这可能是‘20件事之一，他们需要再花一个月才能实现’。这确实非常、非常有趣。 通常我们的专家稍后会看一眼，然后说，‘是的，这在我的清单上’，但这可能是‘20件事之一，他们需要再花一个月才能实现’。这确实非常、非常有趣。 One More Thing One More Thing 其实上个月中旬，OpenAI也和英伟达达成了类似合作。 其实上个月中旬，OpenAI也和英伟达达成了类似合作。 规模也是一样，采用英伟达系统，OpenAI将部署至少10GW的AI集群（大约数百万块英伟达GPU），时间大约也是在2026年下半年开始。 规模也是一样，采用英伟达系统，OpenAI将部署至少10GW的AI集群（大约数百万块英伟达GPU），时间大约也是在2026年下半年开始。 为支持该计划，英伟达还计划向OpenAI投资高达1000亿美元。 为支持该计划，英伟达还计划向OpenAI投资高达1000亿美元。 再后来，OpenAI还拉上了AMD，规模大约6GW。 再后来，OpenAI还拉上了AMD，规模大约6GW。 直到今天，博通也加入了OpenAI的这一“朋友圈”。 直到今天，博通也加入了OpenAI的这一“朋友圈”。 总之，为了突破算力瓶颈，OpenAI走“自研+合作”的路线已经相当明确了。而且比想象中更早，OpenAI其实已经潜心布局了近两年。 总之，为了突破算力瓶颈，OpenAI走“自研+合作”的路线已经相当明确了。而且比想象中更早，OpenAI其实已经潜心布局了近两年。 据OpenAI芯片设计方面的员工透露， OpenAI过去18个月一直在研发芯片，并且自o1开启模型推理浪潮后，他们从几个月前也开始专门设计一款推理芯片。 据OpenAI芯片设计方面的员工透露， OpenAI过去18个月一直在研发芯片，并且自o1开启模型推理浪潮后，他们从几个月前也开始专门设计一款推理芯片。 OpenAI过去18个月一直在研发芯片，并且自o1开启模型推理浪潮后，他们从几个月前也开始专门设计一款推理芯片。 现在，距离我认为的任何首次推出的芯片中，最快、最大规模量产的还有9个月。 现在，距离我认为的任何首次推出的芯片中，最快、最大规模量产的还有9个月。 现在，距离我认为的任何首次推出的芯片中，最快、最大规模量产的还有9个月。 不知道OpenAI第一款自研量产芯片表现如何？一把子期待住了~ 不知道OpenAI第一款自研量产芯片表现如何？一把子期待住了~ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341385.html", "title": "将科研脏活累活真·丢给AI！上海AI Lab推出科研智能体FlowSearch", "date": "2025-10-14", "content": "将科研脏活累活真·丢给AI！上海AI Lab推出科研智能体FlowSearch 将科研脏活累活真·丢给AI！上海AI Lab推出科研智能体FlowSearch 一水 2025-10-14 12:15:55 来源： 量子位 一水 一水 一水 一水 2025-10-14 2025-10-14 12:15:55 12:15:55 来源： 量子位 来源： 量子位 量子位 摘要样式 全面领先三大权威基准 全面领先三大权威基准 全面领先三大权威基准 将复杂科研过程自动化落地，上海人工智能实验室推出FlowSearch！ 将复杂科研过程自动化落地，上海人工智能实验室推出FlowSearch！ 在GAIA、HLE、GPQA以及TRQA等科研基准上， FlowSearch不仅实现了性能全面领先，还展示了AI在复杂科研任务中的动态协作与深度推理能力。 在GAIA、HLE、GPQA以及TRQA等科研基准上， FlowSearch不仅实现了性能全面领先，还展示了AI在复杂科研任务中的动态协作与深度推理能力。 FlowSearch不仅实现了性能全面领先，还展示了AI在复杂科研任务中的动态协作与深度推理能力。 展开来说，当AI在问答基准和标准化测试中表现卓越之时，其进行科学研究的能力也在被更多关注。 展开来说，当AI在问答基准和标准化测试中表现卓越之时，其进行科学研究的能力也在被更多关注。 科学研究不同于解题或信息检索，它是一个开放性、长期且复杂的认知过程——研究者需要提出原创问题、设计实验方案、收集并整合多源证据，并在不断迭代中形成系统结论。 科学研究不同于解题或信息检索，它是一个开放性、长期且复杂的认知过程——研究者需要提出原创问题、设计实验方案、收集并整合多源证据，并在不断迭代中形成系统结论。 这样的过程远超计算能力本身，它要求的是创新思维、动态推理能力以及对复杂知识关系的精准掌控。 这样的过程远超计算能力本身，它要求的是创新思维、动态推理能力以及对复杂知识关系的精准掌控。 而 FlowSearch ，正是一个 由动态结构化知识流驱动的深度科研智能体 。 而 FlowSearch FlowSearch ，正是一个 由动态结构化知识流驱动的深度科研智能体 由动态结构化知识流驱动的深度科研智能体 。 它通过动态结构化知识流构建科研任务的多层依赖图，并在多智能体框架下实现任务的并行探索、知识的递归整合和流程的自适应优化。 它通过动态结构化知识流构建科研任务的多层依赖图，并在多智能体框架下实现任务的并行探索、知识的递归整合和流程的自适应优化。 与传统“输入—计算—输出”的封闭式AI不同，FlowSearch更像一个理解你研究思路的伙伴——当发现新信息，它会主动调整计划；当证据链不完整，它会引导进一步探索；当推理偏离目标，它会进行自我修正。 与传统“输入—计算—输出”的封闭式AI不同，FlowSearch更像一个理解你研究思路的伙伴——当发现新信息，它会主动调整计划；当证据链不完整，它会引导进一步探索；当推理偏离目标，它会进行自我修正。 研究团队表示，它标志着科研智能体从“被动工具”迈向主动探索伙伴的新阶段，让科学发现不再只是等待AI输出结果，而是与AI一起探索、不断前进。 研究团队表示，它标志着科研智能体从“被动工具”迈向主动探索伙伴的新阶段，让科学发现不再只是等待AI输出结果，而是与AI一起探索、不断前进。 FlowSearch：让AI成为你的科研探索伙伴 FlowSearch：让AI成为你的科研探索伙伴 FlowSearch由三大核心模块组成，每个模块都像科研团队中的“关键成员”，协同完成复杂任务： FlowSearch由三大核心模块组成，每个模块都像科研团队中的“关键成员”，协同完成复杂任务： 1、Knowledge Flow Planner ：规划研究路线，像科学家一样拆解问题、逐层细化制定任务； 1、Knowledge Flow Planner 1、Knowledge Flow Planner ：规划研究路线，像科学家一样拆解问题、逐层细化制定任务； 2、Knowledge Collector ：执行任务、收集信息，就像勤奋的实验助理一样整理数据； 2、Knowledge Collector 2、Knowledge Collector ：执行任务、收集信息，就像勤奋的实验助理一样整理数据； 3、Knowledge Flow Refiner ：反思和优化整个研究流程，确保科研思路清晰、连贯、可持续。 3、Knowledge Flow Refiner 3、Knowledge Flow Refiner ：反思和优化整个研究流程，确保科研思路清晰、连贯、可持续。 当你提出研究问题时，FlowSearch先由Planner构建初步的知识流——每个节点代表一个子问题或关键概念，节点之间的连接描绘了知识依赖关系。 当你提出研究问题时，FlowSearch先由Planner构建初步的知识流——每个节点代表一个子问题或关键概念，节点之间的连接描绘了知识依赖关系。 随后，多名“智能体”同时开始执行任务，Collector不断填充节点内容，而Refiner会根据中间结果动态调整流程——增删任务、优化依赖，让科研路径像有生命一样逐步演化。 随后，多名“智能体”同时开始执行任务，Collector不断填充节点内容，而Refiner会根据中间结果动态调整流程——增删任务、优化依赖，让科研路径像有生命一样逐步演化。 动态结构化知识流：科研的逻辑网络 动态结构化知识流：科研的逻辑网络 FlowSearch使用 有向无环图 把科研任务和知识关系可视化。每个节点都携带任务类型（检索、求解、回答）、描述和知识上下文，而节点间的边定义了信息流向。 FlowSearch使用 有向无环图 有向无环图 把科研任务和知识关系可视化。每个节点都携带任务类型（检索、求解、回答）、描述和知识上下文，而节点间的边定义了信息流向。 这种设计让科研推理不再依赖线性顺序，而能 同时展开多条探索路径 ，每一步都可追踪和验证。 这种设计让科研推理不再依赖线性顺序，而能 同时展开多条探索路径 同时展开多条探索路径 ，每一步都可追踪和验证。 换句话说，它不仅让 AI 能“想清楚每一步”，也让你能随时理解科研过程的脉络。 换句话说，它不仅让 AI 能“想清楚每一步”，也让你能随时理解科研过程的脉络。 递归式知识流规划：逐层拆解科研问题 递归式知识流规划：逐层拆解科研问题 高质量的科研规划源于 逐层细化的专家式思维 。Planner模块采用递归扩展策略——从总问题出发，识别每一层需要细化的子任务，生成新的节点和依赖关系。 高质量的科研规划源于 逐层细化的专家式思维 逐层细化的专家式思维 。Planner模块采用递归扩展策略——从总问题出发，识别每一层需要细化的子任务，生成新的节点和依赖关系。 这一过程持续进行，直到形成完整的初始知识流。FlowSearch中的 InternPlanner 模型经过结构化科研任务数据微调，能够学习专家的拆解方式，让AI的规划既逻辑清晰，又稳健可靠。 这一过程持续进行，直到形成完整的初始知识流。FlowSearch中的 InternPlanner InternPlanner 模型经过结构化科研任务数据微调，能够学习专家的拆解方式，让AI的规划既逻辑清晰，又稳健可靠。 知识采集与动态反思：让科研像“活”起来 知识采集与动态反思：让科研像“活”起来 Knowledge Collector 执行任务、收集信息，并把结果整理成节点知识，为后续推理提供输入。 Knowledge Collector Knowledge Collector 执行任务、收集信息，并把结果整理成节点知识，为后续推理提供输入。 任务执行完成后，Knowledge Flow Refiner会启动反思机制：它能根据新信息调整节点和依赖关系，优化任务顺序，确保知识流持续进化。 任务执行完成后，Knowledge Flow Refiner会启动反思机制：它能根据新信息调整节点和依赖关系，优化任务顺序，确保知识流持续进化。 这意味着FlowSearch不只是一个执行工具，它具备 自组织、自纠错、自优化能力 ，可以在复杂科研任务中保持全局一致性，同时灵活应对局部变化。 这意味着FlowSearch不只是一个执行工具，它具备 自组织、自纠错、自优化能力 自组织、自纠错、自优化能力 ，可以在复杂科研任务中保持全局一致性，同时灵活应对局部变化。 以上设计让FlowSearch同时具备： 以上设计让FlowSearch同时具备： 层次化分解能力：仿佛每个科研问题都能被拆解到最合适的颗粒度； 多路并行探索能力：智能体可以同时处理多个任务，提高效率； 全局收敛能力：动态调整确保最终知识流完整、逻辑自洽。 层次化分解能力：仿佛每个科研问题都能被拆解到最合适的颗粒度； 层次化分解能力：仿佛每个科研问题都能被拆解到最合适的颗粒度； 多路并行探索能力：智能体可以同时处理多个任务，提高效率； 多路并行探索能力：智能体可以同时处理多个任务，提高效率； 全局收敛能力：动态调整确保最终知识流完整、逻辑自洽。 全局收敛能力：动态调整确保最终知识流完整、逻辑自洽。 无论是复杂跨学科研究，还是大规模数据分析，FlowSearch都能让科研不再只是“等待AI输出”，而是真正的与AI共同探索。 无论是复杂跨学科研究，还是大规模数据分析，FlowSearch都能让科研不再只是“等待AI输出”，而是真正的与AI共同探索。 实验结果与分析 实验结果与分析 1、综合性能突破 1、综合性能突破 1、综合性能突破 FlowSearch在三大权威基准 GAIA、GPQA-diamond、HLE 上，全面超越现有方法。 FlowSearch在三大权威基准 GAIA、GPQA-diamond、HLE GAIA、GPQA-diamond、HLE 上，全面超越现有方法。 在生物领域的专业基准 TRQA 上，FlowSearch依托通用工具链超越了多个领域专用模型，显示出强大的专业问题解决能力。 在生物领域的专业基准 TRQA TRQA 上，FlowSearch依托通用工具链超越了多个领域专用模型，显示出强大的专业问题解决能力。 2、模块有效性验证 2、模块有效性验证 2、模块有效性验证 去除动态知识流建模或反思模块均导致显著性能下降，验证了结构化规划与动态调整机制在提升推理深度与系统稳定性方面的关键价值。 去除动态知识流建模或反思模块均导致显著性能下降，验证了结构化规划与动态调整机制在提升推理深度与系统稳定性方面的关键价值。 3、Internplanner模型训练效果 3、Internplanner模型训练效果 3、Internplanner模型训练效果 经过微调的 Internplanner-32B 相比基础模型 Qwen-3-32B 在GAIA上提升约6个百分点，表明结构化知识训练能够显著增强模型的规划能力与任务一致性。 经过微调的 Internplanner-32B Internplanner-32B 相比基础模型 Qwen-3-32B Qwen-3-32B 在GAIA上提升约6个百分点，表明结构化知识训练能够显著增强模型的规划能力与任务一致性。 4、案例分析 4、案例分析 4、案例分析 通过FlowSearch与OWL的对比案例可以看出，FlowSearch通过显式依赖建模与中间结果整合，有效避免了证据丢失与逻辑链断裂，展现出更高的推理透明度与可解释性。 通过FlowSearch与OWL的对比案例可以看出，FlowSearch通过显式依赖建模与中间结果整合，有效避免了证据丢失与逻辑链断裂，展现出更高的推理透明度与可解释性。 同时，FlowSearch不仅能够高质量地完成科研问答任务，还能直接适配于科学调研与报告生成任务，产出完整、全面且逻辑清晰的科学调研成果。 同时，FlowSearch不仅能够高质量地完成科研问答任务，还能直接适配于科学调研与报告生成任务，产出完整、全面且逻辑清晰的科学调研成果。 应用前景与科研影响 应用前景与科研影响 团队表示，FlowSearch的提出标志着科研智能体从“任务执行”向“知识驱动推理”的关键转变。 团队表示，FlowSearch的提出标志着科研智能体从“任务执行”向“知识驱动推理”的关键转变。 对于科研新人，它能够构建完整的知识探索路径，降低进入新领域的学习门槛； 对跨学科研究者，它提供了知识流整合与多模态信息融合能力； 对资深学者，它可作为智能研究助手，在假设生成、证据聚合和报告撰写阶段显著提升效率。 对于科研新人，它能够构建完整的知识探索路径，降低进入新领域的学习门槛； 对于科研新人，它能够构建完整的知识探索路径，降低进入新领域的学习门槛； 对跨学科研究者，它提供了知识流整合与多模态信息融合能力； 对跨学科研究者，它提供了知识流整合与多模态信息融合能力； 对资深学者，它可作为智能研究助手，在假设生成、证据聚合和报告撰写阶段显著提升效率。 对资深学者，它可作为智能研究助手，在假设生成、证据聚合和报告撰写阶段显著提升效率。 更重要的是，FlowSearch的动态结构化框架为未来 可解释科研智能体 与 自演化科学发现系统 奠定了通用基础——使智能体具备类研究者的思考、探索与自我反思能力，推动人工智能从工具向真正的科研伙伴演进。 更重要的是，FlowSearch的动态结构化框架为未来 可解释科研智能体 可解释科研智能体 与 自演化科学发现系统 自演化科学发现系统 奠定了通用基础——使智能体具备类研究者的思考、探索与自我反思能力，推动人工智能从工具向真正的科研伙伴演进。 论文链接：https://arxiv.org/abs/2510.08521 GitHub仓库：https://github.com/Alpha-Innovator/InternAgent 论文链接：https://arxiv.org/abs/2510.08521 GitHub仓库：https://github.com/Alpha-Innovator/InternAgent 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341365.html", "title": "抖音&LV-NUS开源多模态新模，以小博大刷新SOTA，8B推理比肩GPT-4o", "date": "2025-10-14", "content": "抖音&LV-NUS开源多模态新模，以小博大刷新SOTA，8B推理比肩GPT-4o 抖音&LV-NUS开源多模态新模，以小博大刷新SOTA，8B推理比肩GPT-4o 西风 2025-10-14 11:17:20 来源： 量子位 西风 西风 西风 西风 2025-10-14 2025-10-14 11:17:20 11:17:20 来源： 量子位 来源： 量子位 量子位 摘要样式 复杂推理基准超越同规模模型 复杂推理基准超越同规模模型 复杂推理基准超越同规模模型 SAIL-VL2团队 投稿 量子位 | 公众号 QbitAI SAIL-VL2团队 投稿 SAIL-VL2团队 投稿 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 2B模型在多个基准位列4B参数以下开源第一。 2B模型在多个基准位列4B参数以下开源第一。 抖音SAIL团队与LV-NUS Lab联合推出的多模态大模型 SAIL-VL2 。 抖音SAIL团队与LV-NUS Lab联合推出的多模态大模型 SAIL-VL2 SAIL-VL2 。 SAIL-VL2 以2B、8B等中小参数规模，在106个数据集实现性能突破 ，尤其在MMMU、MathVista等 复杂推理 基准超越同规模模型，甚至比肩更大参数的闭源模型。 SAIL-VL2 以2B、8B等中小参数规模，在106个数据集实现性能突破 以2B、8B等中小参数规模，在106个数据集实现性能突破 ，尤其在MMMU、MathVista等 复杂推理 复杂推理 基准超越同规模模型，甚至比肩更大参数的闭源模型。 方法上，SAIL-VL2通过 数据、训练、架构 三大维度的创新，为社区提供“小模型也能有强能力”新范式。 方法上，SAIL-VL2通过 数据、训练、架构 数据、训练、架构 三大维度的创新，为社区提供“小模型也能有强能力”新范式。 SAIL-VL2既具备细粒度视觉感知能力，又能在复杂推理任务中媲美更大规模模型。同时，团队通过开源模型与推理代码，提供可扩展的多模态基础模型。 SAIL-VL2既具备细粒度视觉感知能力，又能在复杂推理任务中媲美更大规模模型。同时，团队通过开源模型与推理代码，提供可扩展的多模态基础模型。 Pretrain：三大核心创新 Pretrain：三大核心创新 架构层面：稀疏MoE+灵活编码器，平衡性能与效率 架构层面：稀疏MoE+灵活编码器，平衡性能与效率 SAIL-VL2突破传统稠密LLM的架构，引入稀疏混合专家（MoE），并提供多规格模型配置，满足不同场景需求： SAIL-VL2突破传统稠密LLM的架构，引入稀疏混合专家（MoE），并提供多规格模型配置，满足不同场景需求： SAIL-ViT：渐进式优化的视觉编码器 SAIL-ViT：渐进式优化的视觉编码器 SAIL-ViT：渐进式优化的视觉编码器 为攻克视觉-语言对齐这一核心挑战，SAIL-VL2设计了「热身适应→细粒度对齐→世界知识注入」三阶段训练： 为攻克视觉-语言对齐这一核心挑战，SAIL-VL2设计了「热身适应→细粒度对齐→世界知识注入」三阶段训练： 阶段I（热身适应） ：冻结SAIL-ViT与LLM，仅训练Adapter，使用8M数据激活跨模态映射能力； 阶段II（细粒度对齐） ：固定LLM，解锁SAIL-ViT与Adapter，使用6.7M Caption和COR数据，强化跨模态对齐深度； 阶段III（世界知识注入） ：解锁所有参数，使用36.5M多任务数据，提升模型泛化能力。 阶段I（热身适应） ：冻结SAIL-ViT与LLM，仅训练Adapter，使用8M数据激活跨模态映射能力； 阶段I（热身适应） 阶段I（热身适应） ：冻结SAIL-ViT与LLM，仅训练Adapter，使用8M数据激活跨模态映射能力； 阶段II（细粒度对齐） ：固定LLM，解锁SAIL-ViT与Adapter，使用6.7M Caption和COR数据，强化跨模态对齐深度； 阶段II（细粒度对齐） 阶段II（细粒度对齐） ：固定LLM，解锁SAIL-ViT与Adapter，使用6.7M Caption和COR数据，强化跨模态对齐深度； 阶段III（世界知识注入） ：解锁所有参数，使用36.5M多任务数据，提升模型泛化能力。 阶段III（世界知识注入） 阶段III（世界知识注入） ：解锁所有参数，使用36.5M多任务数据，提升模型泛化能力。 经此流程，SAIL-ViT与LLM特征空间的平均最近邻距离从1.42降至1.15，Wasserstein距离从4.86降至3.88，证明视觉-语言对齐效果显著提升。 经此流程，SAIL-ViT与LLM特征空间的平均最近邻距离从1.42降至1.15，Wasserstein距离从4.86降至3.88，证明视觉-语言对齐效果显著提升。 MoE架构：参数与计算的平衡 MoE架构：参数与计算的平衡 MoE架构：参数与计算的平衡 SAIL-VL2的31.1B大模型采用Qwen3-MoE架构，每次推理仅激活3B参数。为优化专家激活不平衡问题，模型引入负载均衡损失与数据校准策略，最终将专家激活熵提升20%，保障了各专家功能特化。 SAIL-VL2的31.1B大模型采用Qwen3-MoE架构，每次推理仅激活3B参数。为优化专家激活不平衡问题，模型引入负载均衡损失与数据校准策略，最终将专家激活熵提升20%，保障了各专家功能特化。 SAIL-ViT-AnyRes：任意分辨率的突破 SAIL-ViT-AnyRes：任意分辨率的突破 SAIL-ViT-AnyRes：任意分辨率的突破 为打破传统ViT的固定分辨率瓶颈，SAIL-ViT-AnyRes借助“2D RoPE插值”技术，实现了对任意分辨率输入的动态支持（最高1792×1792）。这一突破的价值在RefCOCO视觉定位任务中得到验证：其平均精度高达57.82，远超固定分辨率版本的53.28。 为打破传统ViT的固定分辨率瓶颈，SAIL-ViT-AnyRes借助“2D RoPE插值”技术，实现了对任意分辨率输入的动态支持（最高1792×1792）。这一突破的价值在RefCOCO视觉定位任务中得到验证：其平均精度高达57.82，远超固定分辨率版本的53.28。 数据层面：评分过滤+合成增强，构建高质量多模态语料库 数据层面：评分过滤+合成增强，构建高质量多模态语料库 SAIL-VL2设计了一套全自动数据pipeline，从“质量筛选”与“类型扩展”两大方向提升数据价值： SAIL-VL2设计了一套全自动数据pipeline，从“质量筛选”与“类型扩展”两大方向提升数据价值： SAIL-Caption2 ：通过“视觉信息丰富度（VIR）”与“图文对齐度（ITA）”双维度评分（1-5分），过滤低质量样本（得分＜3），得到250M通用caption+1.69M图表caption； 合成VQA数据 ：将80MSAIL-Caption2通过LLM生成QA形式，补充QA数据多样性； 纯文本与多模态指令数据 ：文本语料保留LLM语言能力，VQA数据强化指令跟随能力。 SAIL-Caption2 ：通过“视觉信息丰富度（VIR）”与“图文对齐度（ITA）”双维度评分（1-5分），过滤低质量样本（得分＜3），得到250M通用caption+1.69M图表caption； SAIL-Caption2 SAIL-Caption2 ：通过“视觉信息丰富度（VIR）”与“图文对齐度（ITA）”双维度评分（1-5分），过滤低质量样本（得分＜3），得到250M通用caption+1.69M图表caption； 合成VQA数据 ：将80MSAIL-Caption2通过LLM生成QA形式，补充QA数据多样性； 合成VQA数据 合成VQA数据 ：将80MSAIL-Caption2通过LLM生成QA形式，补充QA数据多样性； 纯文本与多模态指令数据 ：文本语料保留LLM语言能力，VQA数据强化指令跟随能力。 纯文本与多模态指令数据 纯文本与多模态指令数据 ：文本语料保留LLM语言能力，VQA数据强化指令跟随能力。 训练层面：渐进式框架+动态学习率，激活模型多维度能力 训练层面：渐进式框架+动态学习率，激活模型多维度能力 SAIL-VL2设计三阶段视觉预训练与两阶段多模态预训练的渐进式流程，从基础感知逐步过渡到复杂推理： SAIL-VL2设计三阶段视觉预训练与两阶段多模态预训练的渐进式流程，从基础感知逐步过渡到复杂推理： 两阶段多模态预训练 ：先通过“基础预训练”（64M数据）培养跨模态对齐能力，再通过“多任务预训练”（180M数据）强化视觉理解与指令跟随能力； 数据重采样 ：数据集平衡采样比例，在语言层面优化n-gram分布，缓解数据偏置，提升训练效率； 动态学习率 ：使用AdaLRS算法——基于损失下降斜率动态调整学习率，训练效率大幅提升。 两阶段多模态预训练 ：先通过“基础预训练”（64M数据）培养跨模态对齐能力，再通过“多任务预训练”（180M数据）强化视觉理解与指令跟随能力； 两阶段多模态预训练 两阶段多模态预训练 ：先通过“基础预训练”（64M数据）培养跨模态对齐能力，再通过“多任务预训练”（180M数据）强化视觉理解与指令跟随能力； 数据重采样 ：数据集平衡采样比例，在语言层面优化n-gram分布，缓解数据偏置，提升训练效率； 数据重采样 数据重采样 ：数据集平衡采样比例，在语言层面优化n-gram分布，缓解数据偏置，提升训练效率； 动态学习率 ：使用AdaLRS算法——基于损失下降斜率动态调整学习率，训练效率大幅提升。 动态学习率 动态学习率 ：使用AdaLRS算法——基于损失下降斜率动态调整学习率，训练效率大幅提升。 Posttrain：全链路优化 Posttrain：全链路优化 后训练数据：三大高质量数据集 后训练数据：三大高质量数据集 SAIL-Video SAIL-Video SAIL-Video 针对视频理解中“帧-指令错位”痛点，从6个权威数据集初筛623万条样本，通过“视频-问答对齐度（-1~10分）、内容丰富度（-1~7分）、问答难度（-1~3分）”双维度评估，仅保留均达标的样本，最终得到510万条高质量视频-问答数据，保障视频理解训练可靠性。 针对视频理解中“帧-指令错位”痛点，从6个权威数据集初筛623万条样本，通过“视频-问答对齐度（-1~10分）、内容丰富度（-1~7分）、问答难度（-1~3分）”双维度评估，仅保留均达标的样本，最终得到510万条高质量视频-问答数据，保障视频理解训练可靠性。 SAIL-Instruction2（指令微调数据） SAIL-Instruction2（指令微调数据） SAIL-Instruction2（指令微调数据） 使用Mammoth、MMPR等数据集补充长回答与推理样本，通过“质量评估+增量评估”双验证与“潜在类别过滤”，生成2000万条指令样本。 使用Mammoth、MMPR等数据集补充长回答与推理样本，通过“质量评估+增量评估”双验证与“潜在类别过滤”，生成2000万条指令样本。 Multimodal CoT Data（多模态思维链数据） Multimodal CoT Data（多模态思维链数据） Multimodal CoT Data（多模态思维链数据） 基于VisualWebInstruct、MathV360K等数据集，通过“质量过滤、格式统一、样本去重”清洗，筛选出“有挑战性但可解决”的样本，最终形成40万LongCoT SFT样本、100万条Think-Fusion SFT样本及15万条RL样本，为推理训练提供结构化数据支撑。 基于VisualWebInstruct、MathV360K等数据集，通过“质量过滤、格式统一、样本去重”清洗，筛选出“有挑战性但可解决”的样本，最终形成40万LongCoT SFT样本、100万条Think-Fusion SFT样本及15万条RL样本，为推理训练提供结构化数据支撑。 后训练策略：五阶段递进强化能力 后训练策略：五阶段递进强化能力 SAIL-VL2设计了一套递进式的五阶段后训练策略，以系统性地提升模型综合能力： SAIL-VL2设计了一套递进式的五阶段后训练策略，以系统性地提升模型综合能力： 1、 基础SFT ：首先，通过四阶段数据注入与模型融合技术，为模型构建坚实的基础指令遵循能力。 1、 基础SFT 基础SFT ：首先，通过四阶段数据注入与模型融合技术，为模型构建坚实的基础指令遵循能力。 2、 LongCoT SFT ：接着，使用40万条CoT样本，训练模型掌握逐步推理（step-by-step）的能力。 2、 LongCoT SFT LongCoT SFT ：接着，使用40万条CoT样本，训练模型掌握逐步推理（step-by-step）的能力。 3、 可验证奖励RL ：然后，引入RL，基于“答案正确性+格式规范性”双重奖励优化STEM样本，确保推理结果准确、规范。 3、 可验证奖励RL 可验证奖励RL ：然后，引入RL，基于“答案正确性+格式规范性”双重奖励优化STEM样本，确保推理结果准确、规范。 4、 Think-Fusion SFT ：随后，采用混合数据与条件损失进行训练，让模型学会按需推理，实现能力的收放自如。 4、 Think-Fusion SFT Think-Fusion SFT ：随后，采用混合数据与条件损失进行训练，让模型学会按需推理，实现能力的收放自如。 5、 混合奖励RL ：最后，利用更复杂的三维奖励信号进行最终优化，实现强大推理能力与简洁输出的平衡。 5、 混合奖励RL 混合奖励RL ：最后，利用更复杂的三维奖励信号进行最终优化，实现强大推理能力与简洁输出的平衡。 训练基础设施：高效支撑大规模训练 训练基础设施：高效支撑大规模训练 Stream Packing：双策略提升训练效率 Stream Packing：双策略提升训练效率 批处理与在线打包 ：通过动态拼接样本减少填充令牌，将SM利用率提升近1倍，训练速度加快50%，并提升了0.7%的QA性能。 视觉打包 ：通过加入视觉令牌平衡约束，缓解了视觉编码器的内存压力，使训练效率再提升48%。 批处理与在线打包 ：通过动态拼接样本减少填充令牌，将SM利用率提升近1倍，训练速度加快50%，并提升了0.7%的QA性能。 批处理与在线打包 批处理与在线打包 ：通过动态拼接样本减少填充令牌，将SM利用率提升近1倍，训练速度加快50%，并提升了0.7%的QA性能。 视觉打包 ：通过加入视觉令牌平衡约束，缓解了视觉编码器的内存压力，使训练效率再提升48%。 视觉打包 视觉打包 ：通过加入视觉令牌平衡约束，缓解了视觉编码器的内存压力，使训练效率再提升48%。 MoE基础设施：突破稀疏架构训练瓶颈 MoE基础设施：突破稀疏架构训练瓶颈 计算优化 ：采用核融合技术将多个操作合并执行，减少数据搬运开销，使MoE训练速度提升达3倍。 通信优化 ：设计流式数据读取和混合并行机制，有效降低通信和训练开销。 计算优化 ：采用核融合技术将多个操作合并执行，减少数据搬运开销，使MoE训练速度提升达3倍。 计算优化 计算优化 ：采用核融合技术将多个操作合并执行，减少数据搬运开销，使MoE训练速度提升达3倍。 通信优化 ：设计流式数据读取和混合并行机制，有效降低通信和训练开销。 通信优化 通信优化 ：设计流式数据读取和混合并行机制，有效降低通信和训练开销。 性能验证：106个数据集上的全面领先 性能验证：106个数据集上的全面领先 SAIL-VL2在106个多模态数据集上得到验证，从基础感知到复杂推理，从图像理解到视频分析，均展现出同规模模型中的顶尖水平。 SAIL-VL2在106个多模态数据集上得到验证，从基础感知到复杂推理，从图像理解到视频分析，均展现出同规模模型中的顶尖水平。 基础模型性能：小参数规模实现大突破 基础模型性能：小参数规模实现大突破 在通用多模态理解基准中，SAIL-VL2基础模型（无思维增强）表现突出（如下表所示）： 在通用多模态理解基准中，SAIL-VL2基础模型（无思维增强）表现突出（如下表所示）： SAIL-VL2-2B OpenCompass为70.31，超越Qwen2.5-VL-3B（65.36）、InternVL3.5-2B（66.64）等模型， 位列4B参数以下开源第一 ；SAIL-VL2-8B 在OpenCompass取得开源同量级模型的最高分数 ： SAIL-VL2-2B OpenCompass为70.31，超越Qwen2.5-VL-3B（65.36）、InternVL3.5-2B（66.64）等模型， 位列4B参数以下开源第一 位列4B参数以下开源第一 ；SAIL-VL2-8B 在OpenCompass取得开源同量级模型的最高分数 在OpenCompass取得开源同量级模型的最高分数 ： 细粒度任务，SAIL-VL2-2B MMStar达64.07分，OCRBench达89.50分，均为同参数规模最优 ；SAIL-VL2-8B进一步将MMStar分数提升至70.73，OCRBench提升至91.30，8B规模领先。 细粒度任务，SAIL-VL2-2B MMStar达64.07分，OCRBench达89.50分，均为同参数规模最优 MMStar达64.07分，OCRBench达89.50分，均为同参数规模最优 ；SAIL-VL2-8B进一步将MMStar分数提升至70.73，OCRBench提升至91.30，8B规模领先。 思维增强模型性能：复杂推理能力媲美大模型 思维增强模型性能：复杂推理能力媲美大模型 SAIL-VL2-Thinking在OpenCompass多模态推理榜单表现卓越： SAIL-VL2-Thinking在OpenCompass多模态推理榜单表现卓越： SAIL-VL2-8B-Thinking平均得分54.4， 超越所有开源模型，仅次于GPT-4o-latest （54.8）；SAIL-VL2-A3B-Thinking（MoE架构）以3B激活参数实现53.6分，超越闭源模型Gemini-2.0-Flash（50.6），展现出极高的效率性能比。 SAIL-VL2-8B-Thinking平均得分54.4， 超越所有开源模型，仅次于GPT-4o-latest 超越所有开源模型，仅次于GPT-4o-latest （54.8）；SAIL-VL2-A3B-Thinking（MoE架构）以3B激活参数实现53.6分，超越闭源模型Gemini-2.0-Flash（50.6），展现出极高的效率性能比。 论文地址：https://arxiv.org/pdf/2509.14033 代码与模型：https://github.com/BytedanceDouyinContent/SAIL-VL2 Hugging Face模型库：https://huggingface.co/BytedanceDouyinContent 论文地址：https://arxiv.org/pdf/2509.14033 代码与模型：https://github.com/BytedanceDouyinContent/SAIL-VL2 Hugging Face模型库：https://huggingface.co/BytedanceDouyinContent 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341378.html", "title": "OpenAI奥特曼：能被ChatGPT消灭的工作不是真正的工作", "date": "2025-10-14", "content": "OpenAI奥特曼：能被ChatGPT消灭的工作不是真正的工作 OpenAI奥特曼：能被ChatGPT消灭的工作不是真正的工作 henry 2025-10-14 11:10:30 来源： 量子位 henry henry henry henry 2025-10-14 2025-10-14 11:10:30 11:10:30 来源： 量子位 来源： 量子位 量子位 摘要样式 相较之下，我们的工作像游戏 相较之下，我们的工作像游戏 相较之下，我们的工作像游戏 henry 发自 凹非寺 量子位 | 公众号 QbitAI henry 发自 凹非寺 henry 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 你今天的工作，或许并不是真正的工作 你今天的工作，或许并不是真正的工作 这句耸人听闻的言论出自 奥特曼 与 Rowan Cheung 最新的采访。 这句耸人听闻的言论出自 奥特曼 奥特曼 与 Rowan Cheung Rowan Cheung 最新的采访。 在这场长达30分钟的对谈里，除了自己对AI与工作的思考，奥特曼还分享了 GPT-6的进展、ChatGPT是否会成为美国版微信、AGI的设想变化、AI未来的交互模式，以及自己被恶搞成Sora热梗的感受。 在这场长达30分钟的对谈里，除了自己对AI与工作的思考，奥特曼还分享了 GPT-6的进展、ChatGPT是否会成为美国版微信、AGI的设想变化、AI未来的交互模式，以及自己被恶搞成Sora热梗的感受。 GPT-6的进展、ChatGPT是否会成为美国版微信、AGI的设想变化、AI未来的交互模式，以及自己被恶搞成Sora热梗的感受。 可以说，这次对话涵盖了从娱乐八卦到前沿科技的多重视角，既有趣味，也直指未来趋势。 可以说，这次对话涵盖了从娱乐八卦到前沿科技的多重视角，既有趣味，也直指未来趋势。 经整理的访谈全文如下： 经整理的访谈全文如下： （注：为方便阅读，调整了部分语气词与铺垫） （注：为方便阅读，调整了部分语气词与铺垫） 访谈全文 访谈全文 DevDay之后：最大亮点与产品布局 DevDay之后：最大亮点与产品布局 Q: Dev Day2025里所有发布的内容——你最兴奋的部分是哪一个？ Q: Dev Day2025里所有发布的内容——你最兴奋的部分是哪一个？ Q: Dev Day2025里所有发布的内容——你最兴奋的部分是哪一个？ Sam Altman：我对所有的内容都很兴奋。把应用引入ChatGPT这件事，其实我很早就想做了。 Sam Altman：我对所有的内容都很兴奋。把应用引入ChatGPT这件事，其实我很早就想做了。 但更让我兴奋的是听大家聊他们用Agent Builder做的各种东西。其实无论是Agent Builder还是Agent Kit，里面都有很多让我想亲自去用的功能。不过，如果一定要我选一个，我觉得在ChatGPT里运行应用会是最棒的。 但更让我兴奋的是听大家聊他们用Agent Builder做的各种东西。其实无论是Agent Builder还是Agent Kit，里面都有很多让我想亲自去用的功能。不过，如果一定要我选一个，我觉得在ChatGPT里运行应用会是最棒的。 Rowan Cheung： 每周活跃用户8亿人的ChatGPT已经成了新的分发平台。 开发者和创业者该怎么利用Apps SDK在ChatGPT上构建应用呢？ Rowan Cheung： 每周活跃用户8亿人的ChatGPT已经成了新的分发平台。 每周活跃用户8亿人的ChatGPT已经成了新的分发平台。 开发者和创业者该怎么利用Apps SDK在ChatGPT上构建应用呢？ Sam Altman：我觉得我们还需要经过一些迭代，才能真正弄清人们主要会怎么使用这些功能。比如，人们会习惯根据应用的名字来调用它们吗？还是他们更希望ChatGPT自己知道他们常用的是什么，并主动推荐？ Sam Altman：我觉得我们还需要经过一些迭代，才能真正弄清人们主要会怎么使用这些功能。比如，人们会习惯根据应用的名字来调用它们吗？还是他们更希望ChatGPT自己知道他们常用的是什么，并主动推荐？ 我觉得未来开发者会摸索出一种新的分发机制，让这些应用被自然地用起来。不过这种事情总是这样：只有当你真的把它发布到世界上之后，才会被各种意外的使用方式所惊喜。 我觉得未来开发者会摸索出一种新的分发机制，让这些应用被自然地用起来。不过这种事情总是这样：只有当你真的把它发布到世界上之后，才会被各种意外的使用方式所惊喜。 Rowan Cheung：我记得你们也发布了文档教开发者如何提高被推荐的几率？ Rowan Cheung：我记得你们也发布了文档教开发者如何提高被推荐的几率？ Sam Altman：是的，不过还是得带上免责声明。全新产品变化很快，我们会在实践中一起学习。 Sam Altman：是的，不过还是得带上免责声明。全新产品变化很快，我们会在实践中一起学习。 Rowan Cheung：回到两年前的第一个Dev Day，你们推出了GPT Builder，那真的很棒。我记得自己也是最早公开搭建 GPT的人之一。从那时到现在，你们在Agent Builder上取得了哪些突破？ Rowan Cheung：回到两年前的第一个Dev Day，你们推出了GPT Builder，那真的很棒。我记得自己也是最早公开搭建 GPT的人之一。从那时到现在，你们在Agent Builder上取得了哪些突破？ Sam Altman：最大的变化是模型本身变得更强了。我回想起第一个Dev Day，那时的模型能力和现在相比，差距非常大——22、23个月的时间，模型能力已经进步得惊人。同时我们也学到了很多关于用户想要怎样构建这些Agent的东西。他们不仅希望在ChatGPT上构建，也希望能在其他平台上使用。让我印象最深的是，现在你可以非常轻松地搭建一个相当复杂的系统——用可视化界面、上传几个文件、授权访问数据源、告诉它你的需求，然后几分钟就能部署好。我昨天在彩排时第一次完整看这个过程，感到震撼。借助Codex、Agent Ki等工具快速开发令人印象深刻的软件，这种体验像是经历了一次“地壳变动”。 Sam Altman：最大的变化是模型本身变得更强了。我回想起第一个Dev Day，那时的模型能力和现在相比，差距非常大——22、23个月的时间，模型能力已经进步得惊人。同时我们也学到了很多关于用户想要怎样构建这些Agent的东西。他们不仅希望在ChatGPT上构建，也希望能在其他平台上使用。让我印象最深的是，现在你可以非常轻松地搭建一个相当复杂的系统——用可视化界面、上传几个文件、授权访问数据源、告诉它你的需求，然后几分钟就能部署好。我昨天在彩排时第一次完整看这个过程，感到震撼。借助Codex、Agent Ki等工具快速开发令人印象深刻的软件，这种体验像是经历了一次“地壳变动”。 Rowan Cheung：现在在Agent Builder里基本可以零代码构建agent，对吧？ Rowan Cheung：现在在Agent Builder里基本可以零代码构建agent，对吧？ Sam Altman：是的，不过如果你懂一点或很多代码，你能做更复杂的事情。但即便是普通的知识工作者，也可以开始构建 agent。可以说，这几乎是一场针对Agent的“零代码革命”。 Sam Altman：是的，不过如果你懂一点或很多代码，你能做更复杂的事情。但即便是普通的知识工作者，也可以开始构建 agent。可以说，这几乎是一场针对Agent的“零代码革命”。 Rowan Cheung：这对下一波创业者或开发者意味着什么？ Rowan Cheung：这对下一波创业者或开发者意味着什么？ Sam Altman：这是我一直在思考的问题。我昨天在后台看Romain的演示，心想——如果是一年前做，这些东西要花多长时间啊？而现在几乎可以实时完成，我甚至觉得自己的创意都跟不上它的速度了。我不完全知道这会带来什么改变，但可以肯定的是——世界上将被编写的软件数量会大幅增加，测试和改进创意所需的时间会大幅下降。你可以尝试更多想法，更快找到好点子，但具体还会改变什么，我还没完全搞明白。 Sam Altman：这是我一直在思考的问题。我昨天在后台看Romain的演示，心想——如果是一年前做，这些东西要花多长时间啊？而现在几乎可以实时完成，我甚至觉得自己的创意都跟不上它的速度了。我不完全知道这会带来什么改变，但可以肯定的是——世界上将被编写的软件数量会大幅增加，测试和改进创意所需的时间会大幅下降。你可以尝试更多想法，更快找到好点子，但具体还会改变什么，我还没完全搞明白。 距离第一家十亿级纯血Agent公司还有多久? 距离第一家十亿级纯血Agent公司还有多久? Q：第一家由Agent运营的十亿美元公司什么时候诞生，Agent Builder能达到那种自主水平了吗？ Q：第一家由Agent运营的十亿美元公司什么时候诞生，Agent Builder能达到那种自主水平了吗？ Q：第一家由Agent运营的十亿美元公司什么时候诞生，Agent Builder能达到那种自主水平了吗？ Sam Altman：还没呢。以前我们有个小打赌池，预测第一家单人十亿美元公司会什么时候出现。虽然现在还没正式设立，但有很多猜测——比如第一家“零人公司”。 Sam Altman：还没呢。以前我们有个小打赌池，预测第一家单人十亿美元公司会什么时候出现。虽然现在还没正式设立，但有很多猜测——比如第一家“零人公司”。 Rowan Cheung：几个月？几年？ Rowan Cheung：几个月？几年？ Sam Altman：我预期是几年。但现在我们甚至可以可信地谈论——你输入一个prompt到聊天机器人，它就能运行。这本身就非常不可思议。 Sam Altman：我预期是几年。但现在我们甚至可以可信地谈论——你输入一个prompt到聊天机器人，它就能运行。这本身就非常不可思议。 Rowan Cheung：不过我们看到的一些agent产品，还需要大量人工监督和反馈。什么时候才能实现agent连续一周无需反馈就能工作？ Rowan Cheung：不过我们看到的一些agent产品，还需要大量人工监督和反馈。什么时候才能实现agent连续一周无需反馈就能工作？ Sam Altman：我觉得Codex距离能完成一周工作并不远。虽然不一定是 2025 年能实现，但今天我和一些人聊时，他们都说——现在它已经能完成整天任务了，太快了。我很少觉得AI的进步让我晕头转向，但观察 Codex 能完成任务的时间延长速度，这次确实让我震撼。 可以预期，一周级任务也不会太远了。 Sam Altman：我觉得Codex距离能完成一周工作并不远。虽然不一定是 2025 年能实现，但今天我和一些人聊时，他们都说——现在它已经能完成整天任务了，太快了。我很少觉得AI的进步让我晕头转向，但观察 Codex 能完成任务的时间延长速度，这次确实让我震撼。 可以预期，一周级任务也不会太远了。 可以预期，一周级任务也不会太远了。 Rowan Cheung：技术瓶颈在哪？ Rowan Cheung：技术瓶颈在哪？ Sam Altman： 更智能的模型、更长的上下文、更好的记忆能力。 Sam Altman： 更智能的模型、更长的上下文、更好的记忆能力。 更智能的模型、更长的上下文、更好的记忆能力。 Rowan Cheung：所以你们有agent，各种模型升级，Codex，还能用API。回想一下，如果把20岁刚从斯坦福退学的年轻人带到现在、给他你现在掌握的所有知识，你会让他建什么？又不会建什么？ Rowan Cheung：所以你们有agent，各种模型升级，Codex，还能用API。回想一下，如果把20岁刚从斯坦福退学的年轻人带到现在、给他你现在掌握的所有知识，你会让他建什么？又不会建什么？ Sam Altman我前几天也在想这个问题。我很羡慕现在这一代20岁的退学生，因为能构建的东西太多了，机会空间极其广阔。过去几年我几乎没有完整的心智空间去认真思考自己会做什么。但我知道，有很多很酷的东西可以做。今天和大家聊这些项目，真的很让人兴奋。 Sam Altman我前几天也在想这个问题。我很羡慕现在这一代20岁的退学生，因为能构建的东西太多了，机会空间极其广阔。过去几年我几乎没有完整的心智空间去认真思考自己会做什么。但我知道，有很多很酷的东西可以做。今天和大家聊这些项目，真的很让人兴奋。 Rowan Cheung：我最近一直在思考这个问题，也想了很多其他开发者可能也在思考——现在你能做的事情太多了。在构建这些产品时，你有没有什么建议，比如如何找到一种独特优势来维持领先？是通过分发渠道、数据，还是某种工作流模式？ Rowan Cheung：我最近一直在思考这个问题，也想了很多其他开发者可能也在思考——现在你能做的事情太多了。在构建这些产品时，你有没有什么建议，比如如何找到一种独特优势来维持领先？是通过分发渠道、数据，还是某种工作流模式？ Sam Altman：在抽象层面上回答这个问题总是觉得很难，因为最好的独特优势，本质上是独特的——你必须为自己摸索出来。OpenAI 花了很多功夫才找到我们的优势。一般来说，这个问题没有通用答案。 Sam Altman：在抽象层面上回答这个问题总是觉得很难，因为最好的独特优势，本质上是独特的——你必须为自己摸索出来。OpenAI 花了很多功夫才找到我们的优势。一般来说，这个问题没有通用答案。 最好的答案，是你找到只适合你正在做的事情、你的产品、技术，以及你在市场上的位置和时机的那种优势。这通常也是创办新事物时创造价值的重要部分。 最好的答案，是你找到只适合你正在做的事情、你的产品、技术，以及你在市场上的位置和时机的那种优势。这通常也是创办新事物时创造价值的重要部分。 我能说的一个通用经验是——你边做边摸索。有一句我一直很喜欢的商业名言：“让战术成为战略。”你可以从做那些有效的事情开始，而令人惊讶的是，在这个过程中，常常会自然出现可以发展成战略的东西。 我能说的一个通用经验是——你边做边摸索。有一句我一直很喜欢的商业名言：“让战术成为战略。”你可以从做那些有效的事情开始，而令人惊讶的是，在这个过程中，常常会自然出现可以发展成战略的东西。 如果你当年问我，我们启动ChatGPT时，哪些会成为持久优势，我会说完全不知道。我可能有一些猜测，但不会自信。后来证明最令人兴奋的一个例子是——记忆（memory），它成为我们的重要竞争优势，也是用户持续使用 ChatGPT 的原因。那时我们完全没考虑到这一点。你开始构建功能，然后有时候就会自然浮现出“哦，这可能成为我们一个非常持久的优势”。 如果你当年问我，我们启动ChatGPT时，哪些会成为持久优势，我会说完全不知道。我可能有一些猜测，但不会自信。后来证明最令人兴奋的一个例子是——记忆（memory），它成为我们的重要竞争优势，也是用户持续使用 ChatGPT 的原因。那时我们完全没考虑到这一点。你开始构建功能，然后有时候就会自然浮现出“哦，这可能成为我们一个非常持久的优势”。 GPT-6：为产品打造模型 GPT-6：为产品打造模型 Q：在GPT-6上，你觉得应该建立哪些优势？或者说，在构建一个产品时应该思考什么？ Q：在GPT-6上，你觉得应该建立哪些优势？或者说，在构建一个产品时应该思考什么？ Q：在GPT-6上，你觉得应该建立哪些优势？或者说，在构建一个产品时应该思考什么？ Sam Altman：这其实就是你必须自己去摸索的部分。我很乐意找机会一起头脑风暴，这会很有趣。但说实话，OpenAI占据了我几乎所有的思考空间，我没机会去认真考虑如何创办新公司，这有点遗憾。AI 改变了世界的很多事情，但促成公司优势的基本因素不会因此改变。比如网络效应、品牌与营销优势、用户数据，以及市场效应。如果你列一个清单，看近几年什么方式行得通，现在看大致相同，但可能会有新的战术去建立这些优势。 Sam Altman：这其实就是你必须自己去摸索的部分。我很乐意找机会一起头脑风暴，这会很有趣。但说实话，OpenAI占据了我几乎所有的思考空间，我没机会去认真考虑如何创办新公司，这有点遗憾。AI 改变了世界的很多事情，但促成公司优势的基本因素不会因此改变。比如网络效应、品牌与营销优势、用户数据，以及市场效应。如果你列一个清单，看近几年什么方式行得通，现在看大致相同，但可能会有新的战术去建立这些优势。 Rowan Cheung：最近你们推出了GDPval基准， 用来衡量 AI 模型在主要知识工作岗位中实际经济任务的表现。 令我惊讶的是，GPT-5排在第二，仅次于Claude的Opus模型。这你们还能把结果发布出来，非常厉害，你们对结果怎么看？ Rowan Cheung：最近你们推出了GDPval基准， 用来衡量 AI 模型在主要知识工作岗位中实际经济任务的表现。 用来衡量 AI 模型在主要知识工作岗位中实际经济任务的表现。 令我惊讶的是，GPT-5排在第二，仅次于Claude的Opus模型。这你们还能把结果发布出来，非常厉害，你们对结果怎么看？ Sam Altman：首先，如果我们不愿意发布模型排名第二的结果，那就太糟了。总会有些事情我们做得最好，也会有些做得不如别人。而建立持续进步的文化方式就是——愉快而直接地承认，在某些基准或评测上，别人比你做得更好。我认为Claude团队在理解企业用例和漂亮地呈现输出上做得非常出色，所以我一点也不意外，反而受到激励想做得更好。 Sam Altman：首先，如果我们不愿意发布模型排名第二的结果，那就太糟了。总会有些事情我们做得最好，也会有些做得不如别人。而建立持续进步的文化方式就是——愉快而直接地承认，在某些基准或评测上，别人比你做得更好。我认为Claude团队在理解企业用例和漂亮地呈现输出上做得非常出色，所以我一点也不意外，反而受到激励想做得更好。 Rowan Cheung：这个基准会影响你们构建GPT-6的方式吗？ Rowan Cheung：这个基准会影响你们构建GPT-6的方式吗？ Sam Altman：会影响我们部分后训练（post-training）的方式，但我认为GPT-6的整体策略不会改变。 Sam Altman：会影响我们部分后训练（post-training）的方式，但我认为GPT-6的整体策略不会改变。 AGI：无需夸大，也不必低估 AGI：无需夸大，也不必低估 Q：你对 AGI（通用人工智能）的定义是——当它在大多数经济价值最高的工作上超越人类时。那在GDPval评分上，什么时候你会说我们已经达到了 AGI？ Q：你对 AGI（通用人工智能）的定义是——当它在大多数经济价值最高的工作上超越人类时。那在GDPval评分上，什么时候你会说我们已经达到了 AGI？ Q：你对 AGI（通用人工智能）的定义是——当它在大多数经济价值最高的工作上超越人类时。那在GDPval评分上，什么时候你会说我们已经达到了 AGI？ Sam Altman：我一直在思考这个问题。首先，像很多人一样，我对AGI有多个定义。越接近它，这个概念就越模糊。但我最关心的一点，也是让我惊喜的是，我们终于到了一个开始发生的时刻——那就是当AI能够进行新颖发现，能够扩展人类知识总量的时候。这些成就目前都很小，我不想夸大。 Sam Altman：我一直在思考这个问题。首先，像很多人一样，我对AGI有多个定义。越接近它，这个概念就越模糊。但我最关心的一点，也是让我惊喜的是，我们终于到了一个开始发生的时刻——那就是当AI能够进行新颖发现，能够扩展人类知识总量的时候。这些成就目前都很小，我不想夸大。 但你现在可以在Twitter上看到很多例子，各个学科的科学家们说，AI 做出了一个小发现、提出了新方法、或者解决了某个问题。再强调一下，我既不想夸大，也不想低估。这才是真正重要的事情。而我们正处在这一切的开端，并且乐观地认为未来几个月、几年我们能大力推动，这是件大事。这可能是我最关心的“AGI”指标。 但你现在可以在Twitter上看到很多例子，各个学科的科学家们说，AI 做出了一个小发现、提出了新方法、或者解决了某个问题。再强调一下，我既不想夸大，也不想低估。这才是真正重要的事情。而我们正处在这一切的开端，并且乐观地认为未来几个月、几年我们能大力推动，这是件大事。这可能是我最关心的“AGI”指标。 Rowan Cheung：有没有特别让你兴奋的科学突破，想让AI去解决或发现的？ Rowan Cheung：有没有特别让你兴奋的科学突破，想让AI去解决或发现的？ Sam Altman：当然，治愈疾病，发现新的物理规律，那会很棒。但即便是现在发生的小事，比如数学方面的进展，也让我觉得很重要。当GPT-4推出时，我就有这种感觉。我知道关于图灵测试存在很多争议，但大众对图灵测试的认知，曾经觉得它遥不可及，结果一旦AI通过了，人类社会基本没有更新认知。大家兴奋两周后，就开始抱怨为什么 AI 不够快，或者这不管用，让它更好。这也体现了人类的伟大——那项“AI永远的测试”就这么过去了，而我们都适应了。我感觉现在也会发生类似的事情——我们会逐渐习惯AI做科学发现。 Sam Altman：当然，治愈疾病，发现新的物理规律，那会很棒。但即便是现在发生的小事，比如数学方面的进展，也让我觉得很重要。当GPT-4推出时，我就有这种感觉。我知道关于图灵测试存在很多争议，但大众对图灵测试的认知，曾经觉得它遥不可及，结果一旦AI通过了，人类社会基本没有更新认知。大家兴奋两周后，就开始抱怨为什么 AI 不够快，或者这不管用，让它更好。这也体现了人类的伟大——那项“AI永远的测试”就这么过去了，而我们都适应了。我感觉现在也会发生类似的事情——我们会逐渐习惯AI做科学发现。 Rowan Cheung：最近斯坦福做了一项“workslop”研究。这个词用来描述一种低回报的AI输出——表面看起来很完美，但实际上会因为返工增加额外工作量。 Rowan Cheung：最近斯坦福做了一项“workslop”研究。这个词用来描述一种低回报的AI输出——表面看起来很完美，但实际上会因为返工增加额外工作量。 研究调查了1000多名办公室职员，结果显示有41%的人过去一个月里曾遇到同事产生的workslop，也就是同事使用AI生成的内容需要自己额外花时间去修改或清理。平均每次清理耗时1小时56分钟，每位员工每月因此损失约 186美元。 研究调查了1000多名办公室职员，结果显示有41%的人过去一个月里曾遇到同事产生的workslop，也就是同事使用AI生成的内容需要自己额外花时间去修改或清理。平均每次清理耗时1小时56分钟，每位员工每月因此损失约 186美元。 如果AI能像在场许多人一样将某些人的工作效率提高10倍，那么就需要系统的教育和培训，让大家明白什么时候该用AI，什么时候不该用。 如果AI能像在场许多人一样将某些人的工作效率提高10倍，那么就需要系统的教育和培训，让大家明白什么时候该用AI，什么时候不该用。 Sam Altman：首先，很多人类自己也会产生类似workslop的东西，这不是AI独有的现象。比如，有些邮件只会增加额外工作，或者会议本身也可能拖慢效率。所以不必期待AI会不同。经济会自我调整，利用工具提高效率的人和公司，会比那些用工具拖慢组织的人，更能影响未来。当然，像使用任何新工具一样，会有学习曲线，但我认为速度会很快。 Sam Altman：首先，很多人类自己也会产生类似workslop的东西，这不是AI独有的现象。比如，有些邮件只会增加额外工作，或者会议本身也可能拖慢效率。所以不必期待AI会不同。经济会自我调整，利用工具提高效率的人和公司，会比那些用工具拖慢组织的人，更能影响未来。当然，像使用任何新工具一样，会有学习曲线，但我认为速度会很快。 Rowan Cheung：OpenAI有没有做教育或培训，帮助人们更好地建立、学习这些AI的使用？ Rowan Cheung：OpenAI有没有做教育或培训，帮助人们更好地建立、学习这些AI的使用？ Sam Altman：有的。人们总会用工具去做自己想做的事。我学到的一点是，你可以制作很棒的教育内容和培训，但人们会去尝试各种奇怪玩法，比如让AI鹦鹉学舌什么的。不过我们确实尝试创造很多内容，帮助大家在工作流中使用AI。在Codex的一些场景中，采用速度非常快，整个公司的集成和高效使用只需几天或几周。 Sam Altman：有的。人们总会用工具去做自己想做的事。我学到的一点是，你可以制作很棒的教育内容和培训，但人们会去尝试各种奇怪玩法，比如让AI鹦鹉学舌什么的。不过我们确实尝试创造很多内容，帮助大家在工作流中使用AI。在Codex的一些场景中，采用速度非常快，整个公司的集成和高效使用只需几天或几周。 恶搞CEO和AGI 恶搞CEO和AGI Q：Sora上全是恶搞你的视频，你害怕吗？ Q：Sora上全是恶搞你的视频，你害怕吗？ Q：Sora上全是恶搞你的视频，你害怕吗？ Sam Altman：其实没想象中奇怪。看一个有点，但看上百个就还行。 Sam Altman：其实没想象中奇怪。看一个有点，但看上百个就还行。 当时团队有人问我，可不可以让我的cameo功能开放？这是新技术，我觉得如果我都不尝试，那就是我的失误，所以我就决定做了。后面坐飞机的时候，我想会不会看起来很怪，结果刚上线时确实有点，但很快就适应了——显然这是一个充满生成视频的应用，这些内容很有趣。 当时团队有人问我，可不可以让我的cameo功能开放？这是新技术，我觉得如果我都不尝试，那就是我的失误，所以我就决定做了。后面坐飞机的时候，我想会不会看起来很怪，结果刚上线时确实有点，但很快就适应了——显然这是一个充满生成视频的应用，这些内容很有趣。 Rowan Cheung：我唯一担心的是去水印的问题。今早有几家公司推出了Sora水印去除工具。如果别人可能去掉水印然后在社交媒体上发布，会影响我的个人品牌吗？这是个什么样的机制？ Rowan Cheung：我唯一担心的是去水印的问题。今早有几家公司推出了Sora水印去除工具。如果别人可能去掉水印然后在社交媒体上发布，会影响我的个人品牌吗？这是个什么样的机制？ Sam Altman：首先，我们发布这类技术的原因之一，是因为我们看到它终将普及。未来几个月或几年，会有优秀的开源模型，任何人都能用公开的视频生成你的影像。社会最终会适应。我们发现，一种方式是提前发布并设定护栏，让社会和技术有时间共同进化。 Sam Altman：首先，我们发布这类技术的原因之一，是因为我们看到它终将普及。未来几个月或几年，会有优秀的开源模型，任何人都能用公开的视频生成你的影像。社会最终会适应。我们发现，一种方式是提前发布并设定护栏，让社会和技术有时间共同进化。 这种方法有效。文本相对简单，视频会更难，因为视频冲击力更强，但我相信我们会学会适应。很快大家会意识到，网络上会有大量无水印、开源模型生成的假视频，这不可避免。提前让社会适应这一点，可能有价值。 这种方法有效。文本相对简单，视频会更难，因为视频冲击力更强，但我相信我们会学会适应。很快大家会意识到，网络上会有大量无水印、开源模型生成的假视频，这不可避免。提前让社会适应这一点，可能有价值。 Rowan Cheung：Sora的目标是生成几乎无法分辨的AI视频？ Rowan Cheung：Sora的目标是生成几乎无法分辨的AI视频？ Sam Altman：目标是 AGI。我认为高质量的视频对实现AGI很重要，原因有很多，比如空间推理、我们可以从世界模型中学到的东西。希望有一天，机器人领域的真正进展也会非常重要。但我觉得优秀的视频是件好事——我不希望未来的唯一交互界面只是文字。我非常期待未来能有实时视频流的交互体验，它会不断生成全新的用户体验。这会很棒。但最重要的是，我认为这是通向真正AGI的一条非常有价值的路径。 Sam Altman：目标是 AGI。我认为高质量的视频对实现AGI很重要，原因有很多，比如空间推理、我们可以从世界模型中学到的东西。希望有一天，机器人领域的真正进展也会非常重要。但我觉得优秀的视频是件好事——我不希望未来的唯一交互界面只是文字。我非常期待未来能有实时视频流的交互体验，它会不断生成全新的用户体验。这会很棒。但最重要的是，我认为这是通向真正AGI的一条非常有价值的路径。 Rowan Cheung：周五，你发布了一篇博客，说可能会探索对允许在Cameo中使用自己面孔的人进行收入分成。能分享一些细节吗？这个怎么运作？ Rowan Cheung：周五，你发布了一篇博客，说可能会探索对允许在Cameo中使用自己面孔的人进行收入分成。能分享一些细节吗？这个怎么运作？ Sam Altman：是的，很多时候，当你发布一个新产品时，会发现人们使用的方式与你预期的不同。我们原本认为会有少量创作者制作非常酷、非常复杂的视频并分享出去，然后有大量观众观看。确实有这种情况。但实际上，大量用户只是给三五好友制作视频，在群聊里分享，而不是在社媒里。我不确定这种使用方式能否持续，但如果持续，它会大幅影响计算资源需求与用户互动的比例。 Sam Altman：是的，很多时候，当你发布一个新产品时，会发现人们使用的方式与你预期的不同。我们原本认为会有少量创作者制作非常酷、非常复杂的视频并分享出去，然后有大量观众观看。确实有这种情况。但实际上，大量用户只是给三五好友制作视频，在群聊里分享，而不是在社媒里。我不确定这种使用方式能否持续，但如果持续，它会大幅影响计算资源需求与用户互动的比例。 未来可能会让人们为生成视频付费。比如你每天生成100个视频发给朋友，或者你想生成包含某位名人的视频（并且他们也同意），也许可以对生成付费分成。我们需要实验看看如何操作。 未来可能会让人们为生成视频付费。比如你每天生成100个视频发给朋友，或者你想生成包含某位名人的视频（并且他们也同意），也许可以对生成付费分成。我们需要实验看看如何操作。 不过，我不喜欢对一个六天前刚上线的产品下定论，这一切可能只是新鲜感，也可能不会形成长期使用场景。但至少到目前为止，它的使用量很大。 不过，我不喜欢对一个六天前刚上线的产品下定论，这一切可能只是新鲜感，也可能不会形成长期使用场景。但至少到目前为止，它的使用量很大。 Rowan Cheung：你考虑过在Sora App中放广告吗？ Rowan Cheung：你考虑过在Sora App中放广告吗？ Sam Altman：还没有，但这方面有趣的可能性也很大。当然，也可能有可怕的做法。与ChatGPT不同，我们可以用订阅模式获得收入；但如果Sora用户主要是在信息流中浏览内容，那么广告可能是更自然的模式。 Sam Altman：还没有，但这方面有趣的可能性也很大。当然，也可能有可怕的做法。与ChatGPT不同，我们可以用订阅模式获得收入；但如果Sora用户主要是在信息流中浏览内容，那么广告可能是更自然的模式。 如果主要是私信，那又是另一种模式。我乐观地认为，也许到今年年底，或者更现实地说，到明年第一季度末，我们能理解产品的最终形态，并据此设计商业模式。我认为按生成次数收费是合理的，也值得尝试。其他商业模式则取决于产品如何发展。 如果主要是私信，那又是另一种模式。我乐观地认为，也许到今年年底，或者更现实地说，到明年第一季度末，我们能理解产品的最终形态，并据此设计商业模式。我认为按生成次数收费是合理的，也值得尝试。其他商业模式则取决于产品如何发展。 AI能消灭的工作就不是工作 AI能消灭的工作就不是工作 Q：智能时代，十亿知识工作岗位可能会首先被影响，然后才会创造新工作。你怎么看？ Q：智能时代，十亿知识工作岗位可能会首先被影响，然后才会创造新工作。你怎么看？ Q：智能时代，十亿知识工作岗位可能会首先被影响，然后才会创造新工作。你怎么看？ （注：如果50年前告诉农民，互联网会创造十亿个新工作岗位，他们可能不会相信。同样的，现在很多人认为AI会创造很多新工作岗位。） （注：如果50年前告诉农民，互联网会创造十亿个新工作岗位，他们可能不会相信。同样的，现在很多人认为AI会创造很多新工作岗位。） Sam Altman：我觉得农民不仅不会相信会发生这样的事情，他们可能会看你做的工作（互联网媒体），觉得那不是真正的工作。 Sam Altman：我觉得农民不仅不会相信会发生这样的事情，他们可能会看你做的工作（互联网媒体），觉得那不是真正的工作。 种地是在提供人们真正需要的东西，养活他们，这才是真正的工作。而我们这些人，生活条件优越，食物丰富，财富充足，我们做的很多事情像是在打发时间的游戏，需要感到重要，但可能不算“真正工作”。 种地是在提供人们真正需要的东西，养活他们，这才是真正的工作。而我们这些人，生活条件优越，食物丰富，财富充足，我们做的很多事情像是在打发时间的游戏，需要感到重要，但可能不算“真正工作”。 对我们而言，这些工作感觉很真实。我很感激能做一些既令人满足又重要的事情。未来的工作可能会非常不同，可能比现在我们认为的工作形式更轻松。但我相信人类的内在驱动力仍然存在，我们会找到很多事情去做。 对我们而言，这些工作感觉很真实。我很感激能做一些既令人满足又重要的事情。未来的工作可能会非常不同，可能比现在我们认为的工作形式更轻松。但我相信人类的内在驱动力仍然存在，我们会找到很多事情去做。 Rowan Cheung：希望我们还能探索太空。你觉得AGI出现后，人类会重点关注什么？ Rowan Cheung：希望我们还能探索太空。你觉得AGI出现后，人类会重点关注什么？ Sam Altman：我希望一切都能向各个方向发展，去做所有事情。太空对我来说很酷，但你或其他人可能有自己觉得有趣的方向。我希望一切皆有可能。 Sam Altman：我希望一切都能向各个方向发展，去做所有事情。太空对我来说很酷，但你或其他人可能有自己觉得有趣的方向。我希望一切皆有可能。 Rowan Cheung：如果明天可以制定一条全球政策，你会定什么？ Rowan Cheung：如果明天可以制定一条全球政策，你会定什么？ Sam Altman：很难只选一条。但我一直在思考AI监管的问题——是否合理，是否会让大公司占优势。我认为，当模型非常强大时，应该有全球性的框架来降低灾难性风险，尤其是针对最前沿的安全问题。如果有一条全球政策能做到这一点，那将非常好。 Sam Altman：很难只选一条。但我一直在思考AI监管的问题——是否合理，是否会让大公司占优势。我认为，当模型非常强大时，应该有全球性的框架来降低灾难性风险，尤其是针对最前沿的安全问题。如果有一条全球政策能做到这一点，那将非常好。 ChatGPT会成为美国版微信吗？ ChatGPT会成为美国版微信吗？ Q：在中国，微信几乎是一个“万能App”，购物、社交、聊天都能做。现在ChatGPT也有购物、网页搜索、Sora等功能，你们是不是想打造一个美国版微信？ Q：在中国，微信几乎是一个“万能App”，购物、社交、聊天都能做。现在ChatGPT也有购物、网页搜索、Sora等功能，你们是不是想打造一个美国版微信？ Q：在中国，微信几乎是一个“万能App”，购物、社交、聊天都能做。现在ChatGPT也有购物、网页搜索、Sora等功能，你们是不是想打造一个美国版微信？ Sam Altman：不，有很多原因让我认为这种方式在美国市场行不通。我们想做的是一个真正优秀的 AI 超级助手。 Sam Altman：不，有很多原因让我认为这种方式在美国市场行不通。我们想做的是一个真正优秀的 AI 超级助手。 Rowan Cheung：为什么要把功能单独推出？比如Sora是独立App，为什么不直接放进ChatGPT？ Rowan Cheung：为什么要把功能单独推出？比如Sora是独立App，为什么不直接放进ChatGPT？ Sam Altman：ChatGPT 对很多人来说是最个人化的账号，把社交体验放进去会显得奇怪。可以想象做消息功能，因为人们会分享和协作。但人们对 ChatGPT 的认知和娱乐App的认知差别很大，可能会产生不协调。当然，很多功能我们还是放进了 ChatGPT。 Sam Altman：ChatGPT 对很多人来说是最个人化的账号，把社交体验放进去会显得奇怪。可以想象做消息功能，因为人们会分享和协作。但人们对 ChatGPT 的认知和娱乐App的认知差别很大，可能会产生不协调。当然，很多功能我们还是放进了 ChatGPT。 Rowan Cheung：你觉得最重要、最有用的代理（agents）是什么？最让你兴奋的是什么？ Rowan Cheung：你觉得最重要、最有用的代理（agents）是什么？最让你兴奋的是什么？ Sam Altman：可以看看 Codex 的发展，并思考在其他行业的应用。比如法律、财务建模等，是否可以有类似 Codex 的体验。已经有优秀的初创公司在做这些事情。随着技术成熟，如果这些工具在各自行业中能达到 Codex 在编码领域的水平，那将是我最兴奋的方向。我能想象一个世界：你只用与一堆代理对话，就能启动一家初创公司。我认为Agent Builder或agent kits还不够好，但可以看到从这里到那里的路径。 Sam Altman：可以看看 Codex 的发展，并思考在其他行业的应用。比如法律、财务建模等，是否可以有类似 Codex 的体验。已经有优秀的初创公司在做这些事情。随着技术成熟，如果这些工具在各自行业中能达到 Codex 在编码领域的水平，那将是我最兴奋的方向。我能想象一个世界：你只用与一堆代理对话，就能启动一家初创公司。我认为Agent Builder或agent kits还不够好，但可以看到从这里到那里的路径。 奥特曼：语音不是交互的最终形式 奥特曼：语音不是交互的最终形式 Q：之前你在主题演讲里提到过语音可能是AI或agent的最终形式，能详细说说吗？ Q：之前你在主题演讲里提到过语音可能是AI或agent的最终形式，能详细说说吗？ Q：之前你在主题演讲里提到过语音可能是AI或agent的最终形式，能详细说说吗？ Sam Altman： 我不认为语音是交互的最终形式。有很多时候，语音并不是合适的交互方式。 Sam Altman： 我不认为语音是交互的最终形式。有很多时候，语音并不是合适的交互方式。 我不认为语音是交互的最终形式。有很多时候，语音并不是合适的交互方式。 比如你在公共交通站，边走边讲话，这会很烦人。但很多时候，语音是非常自然的交互方式。语言本身就是这样，但有时候是语音，有时候是打字，这里其实还没有盖棺定论。 比如你在公共交通站，边走边讲话，这会很烦人。但很多时候，语音是非常自然的交互方式。语言本身就是这样，但有时候是语音，有时候是打字，这里其实还没有盖棺定论。 我们都习惯了智能音箱这一类产品，虽然经常被拿来开玩笑，但很多人真的在使用并喜欢它们。而智能音箱其实还不够好，不是因为概念错，而是当时AI不够强大，周边基础设施也不够完善。想象一下，如果你只需对设备说话，它就能准确完成你想要的操作，然后几乎不打扰你——那种体验，就像是我理想中想要使用的计算机。 我们都习惯了智能音箱这一类产品，虽然经常被拿来开玩笑，但很多人真的在使用并喜欢它们。而智能音箱其实还不够好，不是因为概念错，而是当时AI不够强大，周边基础设施也不够完善。想象一下，如果你只需对设备说话，它就能准确完成你想要的操作，然后几乎不打扰你——那种体验，就像是我理想中想要使用的计算机。 Rowan Cheung：你们会做语音交互吗？ Rowan Cheung：你们会做语音交互吗？ Sam Altman：这需要一段时间。我们需要耐心去打造一种全新的设备，在大规模上实现超高质量。这是完全不同的电脑使用方式，我们需要创造性的空间去探索。 Sam Altman：这需要一段时间。我们需要耐心去打造一种全新的设备，在大规模上实现超高质量。这是完全不同的电脑使用方式，我们需要创造性的空间去探索。 我们确实有一些很让人兴奋的想法，但目前还不能透露，也不会在短期内透露。不过我们会努力做出一种非常值得等待的产品。 我们确实有一些很让人兴奋的想法，但目前还不能透露，也不会在短期内透露。不过我们会努力做出一种非常值得等待的产品。 参考链接： 参考链接： [1]https://www.youtube.com/watch?v=zwnVUiwObl8 [1]https://www.youtube.com/watch?v=zwnVUiwObl8 [2]https://futurism.com/artificial-intelligence/sam-altman-real-work-ai[3]https://x.com/rowancheung [2]https://futurism.com/artificial-intelligence/sam-altman-real-work-ai[3]https://x.com/rowancheung 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341103.html", "title": "人类遗忘的难题解法，被GPT-5重新找出来了", "date": "2025-10-14", "content": "人类遗忘的难题解法，被GPT-5重新找出来了 人类遗忘的难题解法，被GPT-5重新找出来了 西风 2025-10-14 11:02:06 来源： 量子位 西风 西风 西风 西风 2025-10-14 2025-10-14 11:02:06 11:02:06 来源： 量子位 来源： 量子位 量子位 摘要样式 埃尔德什问题#339 埃尔德什问题#339 埃尔德什问题#339 西风 发自 凹非寺 量子位 | 公众号 QbitAI 西风 发自 凹非寺 西风 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 人类遗忘的难题解法，被GPT-5 Pro重新找出来了！ 人类遗忘的难题解法，被GPT-5 Pro重新找出来了！ 这事儿聚焦于 埃尔德什问题#339 ，这是著名数学家 保罗・埃尔德什 提出或转述的近千道问题之一，收录于erdosproblems.com网站。该网站记录了每道题目的当前状态，其中约三分之一已解决，大部分仍待解。 这事儿聚焦于 埃尔德什问题#339 埃尔德什问题#339 ，这是著名数学家 保罗・埃尔德什 保罗・埃尔德什 提出或转述的近千道问题之一，收录于erdosproblems.com网站。该网站记录了每道题目的当前状态，其中约三分之一已解决，大部分仍待解。 此前该问题被标为处于“未解决”状态 ，属于待攻克的数学难题，不少人还在继续研究探讨。 此前该问题被标为处于“未解决”状态 此前该问题被标为处于“未解决”状态 ，属于待攻克的数学难题，不少人还在继续研究探讨。 直到最近，有人用GPT-5 Pro检索后才发现，该问题 实际在2003年就已被解决了 。 直到最近，有人用GPT-5 Pro检索后才发现，该问题 实际在2003年就已被解决了 实际在2003年就已被解决了 。 尤其值得关注的是，GPT-5 Pro仅通过埃尔德什问题#339的图片，直接定位到了关键文献。 尤其值得关注的是，GPT-5 Pro仅通过埃尔德什问题#339的图片，直接定位到了关键文献。 OpenAI研究员Sebastien Bubeck将此事分享出来后立马引发大量网友关注。 OpenAI研究员Sebastien Bubeck将此事分享出来后立马引发大量网友关注。 By the way，陶哲轩的著名成果之一，就是通过“遍历理论（ergodic theory）”工具，突破了“埃尔德什差异问题”这一困扰数学界几十年的猜想。 By the way，陶哲轩的著名成果之一，就是通过“遍历理论（ergodic theory）”工具，突破了“埃尔德什差异问题”这一困扰数学界几十年的猜想。 问题详情 问题详情 具体来看，埃尔德什问题#339是数论中加法基方向的一个经典问题，表述为： 具体来看，埃尔德什问题#339是数论中加法基方向的一个经典问题，表述为： 设A⊆N是一个r阶基（即每个足够大的整数都能表示为A中r个元素的和）。那么，能表示为A中恰好r个不同元素之和的整数集合，是否一定具有正的下密度？ 设A⊆N是一个r阶基（即每个足够大的整数都能表示为A中r个元素的和）。那么，能表示为A中恰好r个不同元素之和的整数集合，是否一定具有正的下密度？ 设A⊆N是一个r阶基（即每个足够大的整数都能表示为A中r个元素的和）。那么，能表示为A中恰好r个不同元素之和的整数集合，是否一定具有正的下密度？ 此外，埃尔德什和格雷厄姆还提出一个相关问题：如果能表示为A中r个元素之和的整数集合具有正的上密度，那么能表示为A中恰好r个不同元素之和的整数集合，是否也一定具有正的上密度？ 此外，埃尔德什和格雷厄姆还提出一个相关问题：如果能表示为A中r个元素之和的整数集合具有正的上密度，那么能表示为A中恰好r个不同元素之和的整数集合，是否也一定具有正的上密度？ 在GPT-5 Pro发现此问题已被解决前，网友们在网站上曾就此展开系列讨论。 在GPT-5 Pro发现此问题已被解决前，网友们在网站上曾就此展开系列讨论。 网友Adenwalla从著名的 Waring’s Problem （华林问题） 入手指出，几乎所有整数都可以表示为最多15个四次幂之和，但仍有无穷多个整数需要16个四次幂，即G(4)=16 but G₁(4)=15。 网友Adenwalla从著名的 Waring’s Problem Waring’s Problem （华林问题） 入手指出，几乎所有整数都可以表示为最多15个四次幂之和，但仍有无穷多个整数需要16个四次幂，即G(4)=16 but G₁(4)=15。 并据此引发思考，这是否意味着加法基问题中的下密度结论可能不成立？ 并据此引发思考，这是否意味着加法基问题中的下密度结论可能不成立？ 很快，Woett、BorisAlexeev等指出，华林问题里的例子是“允许元素重复”的情况，而埃尔德什问题#339要求“元素互不相同”，因此该例并不能构成反例，原问题的条件更为严格。 很快，Woett、BorisAlexeev等指出，华林问题里的例子是“允许元素重复”的情况，而埃尔德什问题#339要求“元素互不相同”，因此该例并不能构成反例，原问题的条件更为严格。 之后讨论进一步深入。 之后讨论进一步深入。 zach Hunter试图探索加法基在不同规模下的密度稳定性，Woett则提出了一些具体的集合构造，尝试作为可能否定命题的反例。 双方围绕“互不相同元素（distinct）”“下密度（lower density）”以及“有界倍增（bounded doubling）”等概念展开推敲。 zach Hunter试图探索加法基在不同规模下的密度稳定性，Woett则提出了一些具体的集合构造，尝试作为可能否定命题的反例。 双方围绕“互不相同元素（distinct）”“下密度（lower density）”以及“有界倍增（bounded doubling）”等概念展开推敲。 最终，他们发现这些构造虽然能制造出和集大小存在稀疏甚至指数级间隙的例子，却仍无法让“能表示为恰好r个不同元素之和的整数集合”的下密度真正趋近于零，也就是说，这些反例构造并未成功否定命题。 最终，他们发现这些构造虽然能制造出和集大小存在稀疏甚至指数级间隙的例子，却仍无法让“能表示为恰好r个不同元素之和的整数集合”的下密度真正趋近于零，也就是说，这些反例构造并未成功否定命题。 就在网友们各执一词、对问题是否成立仍存争议之时。 就在网友们各执一词、对问题是否成立仍存争议之时。 msawhney提醒大家，其实这个问题早在2003年就已经被解决了。 msawhney提醒大家，其实这个问题早在2003年就已经被解决了。 核心依据是Hegyvari、Hennecart、Plagne发表于《J. reine angew. Math.》（即《Crelle》）第560卷、页199-220的论文 《A proof of two Erdos’ conjectures on restricted addition and further results》 。 核心依据是Hegyvari、Hennecart、Plagne发表于《J. reine angew. Math.》（即《Crelle》）第560卷、页199-220的论文 《A proof of two Erdos’ conjectures on restricted addition and further results》 《A proof of two Erdos’ conjectures on restricted addition and further results》 。 其中定理4直接构成了该问题的解答。 其中定理4直接构成了该问题的解答。 而找出这一答案的，正是GPT-5 Pro，它仅凭问题截图，就准确定位到了这篇文献。 而找出这一答案的，正是GPT-5 Pro，它仅凭问题截图，就准确定位到了这篇文献。 关于保罗·埃尔德什 关于保罗·埃尔德什 保罗·埃尔德什（Paul Erdős） 是20世纪最杰出、最多产的数学家之一，以其在数论、组合数学、图论、概率论等领域的重大贡献而闻名。 保罗·埃尔德什（Paul Erdős） 保罗·埃尔德什（Paul Erdős） 是20世纪最杰出、最多产的数学家之一，以其在数论、组合数学、图论、概率论等领域的重大贡献而闻名。 △图源：维基百科 △图源：维基百科 他 一生发表了近1500篇论文，与超过500位合作者共同研究 ，其广泛合作精神使数学界出现了“ 埃尔德什数（Erdős number） ”的概念，这一数字成为衡量数学家与埃尔德什学术关联紧密程度的“荣誉指标”。 他 一生发表了近1500篇论文，与超过500位合作者共同研究 一生发表了近1500篇论文，与超过500位合作者共同研究 ，其广泛合作精神使数学界出现了“ 埃尔德什数（Erdős number） 埃尔德什数（Erdős number） ”的概念，这一数字成为衡量数学家与埃尔德什学术关联紧密程度的“荣誉指标”。 他1913年出生于匈牙利布达佩斯。4岁时，已能心算多位数乘法；10岁时，自学了全部中学数学课程，并开始研究数论。 他1913年出生于匈牙利布达佩斯。4岁时，已能心算多位数乘法；10岁时，自学了全部中学数学课程，并开始研究数论。 1934年，21岁的埃尔德什从布达佩斯大学获得博士学位，随后因战争等的影响开始“漂泊”—— 1934年，21岁的埃尔德什从布达佩斯大学获得博士学位，随后因战争等的影响开始“漂泊”—— 没有固定职位，靠演讲费、奖金和朋友资助生活，常年携带一个行李箱，辗转于世界各地的大学和数学家家中，与同行合作研究、讨论问题，平均每几周就换一个地方。 没有固定职位，靠演讲费、奖金和朋友资助生活，常年携带一个行李箱，辗转于世界各地的大学和数学家家中，与同行合作研究、讨论问题，平均每几周就换一个地方。 埃尔德什 一生以“问题驱动”的研究方式著称 。他不追求体系化理论，而是不断提出、解决有趣的问题。他提出的数百个猜想至今仍活跃在数学前沿。 埃尔德什 一生以“问题驱动”的研究方式著称 一生以“问题驱动”的研究方式著称 。他不追求体系化理论，而是不断提出、解决有趣的问题。他提出的数百个猜想至今仍活跃在数学前沿。 数论是埃尔德什投入最深、成果最丰的领域，他的工作直接推动了20世纪数论的发展，尤其在素数分布和加性数论方向影响深远。例如，他与挪威数学家Atle Selberg，用初等方法证明了素数定理，成果震惊数学界。 数论是埃尔德什投入最深、成果最丰的领域，他的工作直接推动了20世纪数论的发展，尤其在素数分布和加性数论方向影响深远。例如，他与挪威数学家Atle Selberg，用初等方法证明了素数定理，成果震惊数学界。 埃尔德什也是拉姆齐数研究的奠基人之一，他将概率论引入组合数论，给出了拉姆齐数的下界估计。 埃尔德什也是拉姆齐数研究的奠基人之一，他将概率论引入组合数论，给出了拉姆齐数的下界估计。 他提出的著名“埃尔德什差异问题”，可追溯到上世纪三四十年代。 他提出的著名“埃尔德什差异问题”，可追溯到上世纪三四十年代。 内容是，给定一个由+1和-1组成的无限序列（如 (1, -1, 1, -1,…)），定义“前n项的部分和”为S (n)，则“差异”是指所有部分和的绝对值的最大值。 内容是，给定一个由+1和-1组成的无限序列（如 (1, -1, 1, -1,…)），定义“前n项的部分和”为S (n)，则“差异”是指所有部分和的绝对值的最大值。 埃尔德什猜想，任何这样的序列，其差异都会随着n的增大而无限增大（即不存在“有界差异”的无限±1序列）。 埃尔德什猜想，任何这样的序列，其差异都会随着n的增大而无限增大（即不存在“有界差异”的无限±1序列）。 这一问题看似简单，却横跨数论、组合数学与调和分析，成为20世纪最著名的未解决猜想之一。直到2015年，数学家陶哲轩才通过引入“遍历理论”工具，取得了该猜想的部分突破。 这一问题看似简单，却横跨数论、组合数学与调和分析，成为20世纪最著名的未解决猜想之一。直到2015年，数学家陶哲轩才通过引入“遍历理论”工具，取得了该猜想的部分突破。 即使在生命的最后几年，埃尔德什仍坚持研究数学、撰写论文。1996年，他在波兰华沙参加学术会议时突发心脏病去世，享年83岁。 即使在生命的最后几年，埃尔德什仍坚持研究数学、撰写论文。1996年，他在波兰华沙参加学术会议时突发心脏病去世，享年83岁。 2024年，英国数学家Thomas Bloom开设了一个专门研究埃尔德什问题的网站。 2024年，英国数学家Thomas Bloom开设了一个专门研究埃尔德什问题的网站。 One More Thing One More Thing 加州大学欧文分校数学教授Paata Ivanisvili也发推文表示，GPT-5Pro在识别已发表论文中的严重缺陷方面表现出色。 加州大学欧文分校数学教授Paata Ivanisvili也发推文表示，GPT-5Pro在识别已发表论文中的严重缺陷方面表现出色。 五年前，我花了数天时间研究这篇论文，才发现了一个作者后来确认的漏洞。而GPT-5 Pro仅用18分钟就找到了同样的漏洞，还额外发现了几个小问题。类似的情况我已经目睹过很多次了。 五年前，我花了数天时间研究这篇论文，才发现了一个作者后来确认的漏洞。而GPT-5 Pro仅用18分钟就找到了同样的漏洞，还额外发现了几个小问题。类似的情况我已经目睹过很多次了。 五年前，我花了数天时间研究这篇论文，才发现了一个作者后来确认的漏洞。而GPT-5 Pro仅用18分钟就找到了同样的漏洞，还额外发现了几个小问题。类似的情况我已经目睹过很多次了。 该推文还被OpenAI总裁Greg Brockman转发了。 该推文还被OpenAI总裁Greg Brockman转发了。 网友表示这是一个强大的应用场景： 网友表示这是一个强大的应用场景： 使用GPT-5 Pro来验证科学文献，能够极大地加快研究人员核实学术论断和发现逻辑矛盾的过程。 使用GPT-5 Pro来验证科学文献，能够极大地加快研究人员核实学术论断和发现逻辑矛盾的过程。 使用GPT-5 Pro来验证科学文献，能够极大地加快研究人员核实学术论断和发现逻辑矛盾的过程。 还有网友安利提示词小技巧： 还有网友安利提示词小技巧： 在提示词中加入“请深度阅读——不要跳读，不要扫描——每次处理1000行”（please deep read – no grep, no scan – 1,000 lines at a time），堪称研读科学论文的终极技巧。 另一个建议是进行循环性核查（do a circularity audit）。 在提示词中加入“请深度阅读——不要跳读，不要扫描——每次处理1000行”（please deep read – no grep, no scan – 1,000 lines at a time），堪称研读科学论文的终极技巧。 在提示词中加入“请深度阅读——不要跳读，不要扫描——每次处理1000行”（please deep read – no grep, no scan – 1,000 lines at a time），堪称研读科学论文的终极技巧。 另一个建议是进行循环性核查（do a circularity audit）。 另一个建议是进行循环性核查（do a circularity audit）。 埃尔德什问题官网：https://www.erdosproblems.com/faq 埃尔德什问题官网：https://www.erdosproblems.com/faq 参考链接： [1]https://x.com/SebastienBubeck/status/1977181716457701775 [2]https://x.com/gdb/status/1977153596811804890 参考链接： [1]https://x.com/SebastienBubeck/status/1977181716457701775 [2]https://x.com/gdb/status/1977153596811804890 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/341349.html", "title": "蚂蚁发布并开源万亿参数思考模型Ring-1T，综合能力逼近GPT-5", "date": "2025-10-14", "content": "蚂蚁发布并开源万亿参数思考模型Ring-1T，综合能力逼近GPT-5 蚂蚁发布并开源万亿参数思考模型Ring-1T，综合能力逼近GPT-5 henry 2025-10-14 11:00:24 来源： 量子位 henry henry henry henry 2025-10-14 2025-10-14 11:00:24 11:00:24 来源： 量子位 来源： 量子位 量子位 摘要样式 数学能力对标IMO银牌，蚂蚁发布并开源万亿参数思考模型Ring-1T 数学能力对标IMO银牌，蚂蚁发布并开源万亿参数思考模型Ring-1T 数学能力对标IMO银牌，蚂蚁发布并开源万亿参数思考模型Ring-1T 10月14日凌晨，蚂蚁集团正式推出万亿参数思考模型Ring-1T，并全面开源模型权重、训练配方。Ring-1T在9月30日开源的预览版Ring-1T-preview基础上，持续扩展大规模可验证奖励强化学习（RLVR）训练，进一步激发万亿基座的自然语言推理能力，并通过 RLHF 训练完善模型通用能力，在各项任务榜单上表现更加均衡。 10月14日凌晨，蚂蚁集团正式推出万亿参数思考模型Ring-1T，并全面开源模型权重、训练配方。Ring-1T在9月30日开源的预览版Ring-1T-preview基础上，持续扩展大规模可验证奖励强化学习（RLVR）训练，进一步激发万亿基座的自然语言推理能力，并通过 RLHF 训练完善模型通用能力，在各项任务榜单上表现更加均衡。 为了持续激发Ring-1T的数学等复杂推理能力，此次百灵团队挑战了难度更高的IMO2025（国际数学奥利匹克）赛题，将Ring-1T接入多智能体框架AWorld，使用纯自然语言推理进行解题。实验结果显示，Ring-1T仅用一次解出了第1、3、4、5题，相当于IMO银牌水平，成为首个能拿IMO国际奥数奖的开源系统。Ring-1T在第三次尝试IMO时对第2题几何证明也给出了接近满分的证明过程，在顶流大模型几乎全军覆没的第六题中将答案收敛到与Gemini 2.5 Pro 相同的“4048”（正确答案为2112）。作为一款思考模型，Ring-1T也表现出了极佳的通用能力，在“人类偏好对齐”测试Arena-Hard V2中，Ring-1T以81.59的成功率居于开源模型榜首，逼近GPT-5-Thinking(High)82.91的成绩。在面向严谨领域的医疗问答HealthBench测评中，Ring-1T也以最高分取得开源领域最佳。 为了持续激发Ring-1T的数学等复杂推理能力，此次百灵团队挑战了难度更高的IMO2025（国际数学奥利匹克）赛题，将Ring-1T接入多智能体框架AWorld，使用纯自然语言推理进行解题。实验结果显示，Ring-1T仅用一次解出了第1、3、4、5题，相当于IMO银牌水平，成为首个能拿IMO国际奥数奖的开源系统。Ring-1T在第三次尝试IMO时对第2题几何证明也给出了接近满分的证明过程，在顶流大模型几乎全军覆没的第六题中将答案收敛到与Gemini 2.5 Pro 相同的“4048”（正确答案为2112）。作为一款思考模型，Ring-1T也表现出了极佳的通用能力，在“人类偏好对齐”测试Arena-Hard V2中，Ring-1T以81.59的成功率居于开源模型榜首，逼近GPT-5-Thinking(High)82.91的成绩。在面向严谨领域的医疗问答HealthBench测评中，Ring-1T也以最高分取得开源领域最佳。 （Ring-1T与业界代表性思考模型的性能横评） （Ring-1T与业界代表性思考模型的性能横评） 万亿参数思考模型训练最大难题是训推精度差异，即训练阶段与推理阶段因实现细节差异导致的训练和推理精度不一致，进而导致训练崩溃。在Ring-1T模型中，蚂蚁采用了自研的“棒冰（icepop）”算法来应对这项行业难题，即用带掩码的双向截断技术把训练-推理分布差异冻结在低水位，确保长序列、长周期训练不崩。此外，应对万亿参数模型强化学习训练，蚂蚁还自研了高性能强化学习系统ASystem(其中包含已开源的高性能强化学习框架AReaL)，特别针对万亿参数模型的显存管理和训推权重交换问题做了精细的优化，实现了单机显存碎片秒级回收、权重零冗余交换，把大规模RL训练稳定跑成日常。 万亿参数思考模型训练最大难题是训推精度差异，即训练阶段与推理阶段因实现细节差异导致的训练和推理精度不一致，进而导致训练崩溃。在Ring-1T模型中，蚂蚁采用了自研的“棒冰（icepop）”算法来应对这项行业难题，即用带掩码的双向截断技术把训练-推理分布差异冻结在低水位，确保长序列、长周期训练不崩。此外，应对万亿参数模型强化学习训练，蚂蚁还自研了高性能强化学习系统ASystem(其中包含已开源的高性能强化学习框架AReaL)，特别针对万亿参数模型的显存管理和训推权重交换问题做了精细的优化，实现了单机显存碎片秒级回收、权重零冗余交换，把大规模RL训练稳定跑成日常。 （图左：GRPO训推差异随着训练成指数上升，icepop较为平稳；图右：训推差异最大值，GRPO随着训练上升非常明显，icepop维持在较低水位） （图左：GRPO训推差异随着训练成指数上升，icepop较为平稳；图右：训推差异最大值，GRPO随着训练上升非常明显，icepop维持在较低水位） 此外，本次发布的Ring-1T模型继续采用Ling 2.0架构的1T base模型做后训练，Ling 2.0采用了包括高度稀疏的MoE架构，1/32的专家激活比、FP8混合精度、MTP等诸多特性实现高效训练与推理。在后训练阶段，蚂蚁百灵团队通过LongCoT-SFT + RLVR + RLHF多阶段训练，显著提升了模型的复杂推理能力以及指令跟随和创意写作等通用能力。 此外，本次发布的Ring-1T模型继续采用Ling 2.0架构的1T base模型做后训练，Ling 2.0采用了包括高度稀疏的MoE架构，1/32的专家激活比、FP8混合精度、MTP等诸多特性实现高效训练与推理。在后训练阶段，蚂蚁百灵团队通过LongCoT-SFT + RLVR + RLHF多阶段训练，显著提升了模型的复杂推理能力以及指令跟随和创意写作等通用能力。 据百灵团队透露，Ring-1T模型是其在万亿思考模型上的首次尝试，蚂蚁百灵团队会在后续的版本中继续完善模型性能。目前，用户可通过HuggingFace、魔搭社区下载模型，并通过蚂蚁百宝箱等平台在线体验。 据百灵团队透露，Ring-1T模型是其在万亿思考模型上的首次尝试，蚂蚁百灵团队会在后续的版本中继续完善模型性能。目前，用户可通过HuggingFace、魔搭社区下载模型，并通过蚂蚁百宝箱等平台在线体验。 据了解，截止目前蚂蚁百灵大模型已经发布18款模型，已形成从160亿总参数到1万亿总参数的大语言模型产品矩阵，其中两款万亿参数模型—万亿参数通用大语言模型Ling-1T、万亿参数思考模型Ring-1T。随着两款万亿参数模型的发布，百灵大模型也正式步入2.0阶段。 据了解，截止目前蚂蚁百灵大模型已经发布18款模型，已形成从160亿总参数到1万亿总参数的大语言模型产品矩阵，其中两款万亿参数模型—万亿参数通用大语言模型Ling-1T、万亿参数思考模型Ring-1T。随着两款万亿参数模型的发布，百灵大模型也正式步入2.0阶段。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340998.html", "title": "卡帕西8000行代码手搓ChatGPT，成本仅100美元，训练12小时CORE表现超越GPT-2，手把手教程来了", "date": "2025-10-14", "content": "卡帕西8000行代码手搓ChatGPT，成本仅100美元，训练12小时CORE表现超越GPT-2，手把手教程来了 卡帕西8000行代码手搓ChatGPT，成本仅100美元，训练12小时CORE表现超越GPT-2，手把手教程来了 西风 2025-10-14 10:39:29 来源： 量子位 西风 西风 西风 西风 2025-10-14 2025-10-14 10:39:29 10:39:29 来源： 量子位 来源： 量子位 量子位 摘要样式 网友：跑完项目我要把ML工程师写简历上 ！ 网友：跑完项目我要把ML工程师写简历上 ！ 网友：跑完项目我要把ML工程师写简历上 ！ 西风 发自 凹非寺 量子位 | 公众号 QbitAI 西风 发自 凹非寺 西风 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 100美元成本、8000行代码纯手搓克隆ChatGPT！ 100美元成本、8000行代码纯手搓克隆ChatGPT！ 特斯拉前AI总监、OpenAI创始成员、宣布全职搞教育的AI大神 Andrej Karpathy （卡帕西）沉寂了好久，终于终于终于来上新课了！ 特斯拉前AI总监、OpenAI创始成员、宣布全职搞教育的AI大神 Andrej Karpathy Andrej Karpathy （卡帕西）沉寂了好久，终于终于终于来上新课了！ 新作 nanochat ，被其本人称作是写得最“精神错乱”放飞自我的作品之一。 新作 nanochat nanochat ，被其本人称作是写得最“精神错乱”放飞自我的作品之一。 它是一个极简的、从零开始构建的全栈训练/推理pipeline，用最少量依赖的单一代码库实现了简易版ChatGPT。 它是一个极简的、从零开始构建的全栈训练/推理pipeline，用最少量依赖的单一代码库实现了简易版ChatGPT。 只要你启动一台云GPU服务器，运行一个脚本， 最快只要4小时 ，就能在类似ChatGPT的网页界面与自己训练的大语言模型对话。 只要你启动一台云GPU服务器，运行一个脚本， 最快只要4小时 最快只要4小时 ，就能在类似ChatGPT的网页界面与自己训练的大语言模型对话。 整个项目约8000行代码，可实现以下功能： 整个项目约8000行代码，可实现以下功能： 基于全新Rust语言实现，训练分词器（tokenizer） 在FineWeb数据集上预训练Transformer架构大语言模型，并通过多项指标评估CORE得分 在SmolTalk用户-助手对话数据集、多项选择题数据集、工具使用数据集上进行中期训练（Midtrain） 执行指令微调（SFT），并在世界知识多项选择题数据集（ARC-E/C）、数学数据集（GSM8K）、代码数据集（HumanEval）上评估对话模型性能 可选在GSM8K数据集上通过“GRPO”算法对模型进行强化学习（RL）训练 在推理引擎中实现高效模型推理，支持KV缓存、简易预填充/解码流程、工具使用（轻量级沙箱环境中的Python解释器），可通过CLI或类ChatGPT的WebUI与模型交互 生成单个Markdown格式报告卡，对整个训练推理流程进行总结，并加入“游戏化”呈现（如用评分、进度等形式直观展示结果） 基于全新Rust语言实现，训练分词器（tokenizer） 基于全新Rust语言实现，训练分词器（tokenizer） 在FineWeb数据集上预训练Transformer架构大语言模型，并通过多项指标评估CORE得分 在FineWeb数据集上预训练Transformer架构大语言模型，并通过多项指标评估CORE得分 在SmolTalk用户-助手对话数据集、多项选择题数据集、工具使用数据集上进行中期训练（Midtrain） 在SmolTalk用户-助手对话数据集、多项选择题数据集、工具使用数据集上进行中期训练（Midtrain） 执行指令微调（SFT），并在世界知识多项选择题数据集（ARC-E/C）、数学数据集（GSM8K）、代码数据集（HumanEval）上评估对话模型性能 执行指令微调（SFT），并在世界知识多项选择题数据集（ARC-E/C）、数学数据集（GSM8K）、代码数据集（HumanEval）上评估对话模型性能 可选在GSM8K数据集上通过“GRPO”算法对模型进行强化学习（RL）训练 可选在GSM8K数据集上通过“GRPO”算法对模型进行强化学习（RL）训练 在推理引擎中实现高效模型推理，支持KV缓存、简易预填充/解码流程、工具使用（轻量级沙箱环境中的Python解释器），可通过CLI或类ChatGPT的WebUI与模型交互 在推理引擎中实现高效模型推理，支持KV缓存、简易预填充/解码流程、工具使用（轻量级沙箱环境中的Python解释器），可通过CLI或类ChatGPT的WebUI与模型交互 生成单个Markdown格式报告卡，对整个训练推理流程进行总结，并加入“游戏化”呈现（如用评分、进度等形式直观展示结果） 生成单个Markdown格式报告卡，对整个训练推理流程进行总结，并加入“游戏化”呈现（如用评分、进度等形式直观展示结果） 整体成本只需约100美元 （在8×H100上训练4小时），就能训练复刻出一个可进行基础对话、创作故事诗歌、回答简单问题的简易版ChatGPT模型。 整体成本只需约100美元 整体成本只需约100美元 （在8×H100上训练4小时），就能训练复刻出一个可进行基础对话、创作故事诗歌、回答简单问题的简易版ChatGPT模型。 整体表现指标如下： 整体表现指标如下： 训练约12小时后，模型在CORE指标上的表现即可超越GPT-2。 训练约12小时后，模型在CORE指标上的表现即可超越GPT-2。 训练约12小时后，模型在CORE指标上的表现即可超越GPT-2。 若进一步将成本提升至约1000美元（训练约41.6小时），模型表现显著提升，能解决简单的数学/代码问题，还能做多项选择题。 若进一步将成本提升至约1000美元（训练约41.6小时），模型表现显著提升，能解决简单的数学/代码问题，还能做多项选择题。 举个具体的例子：一个深度为30的模型训练24小时后（相当于GPT-3 Small 125M的算力消耗，仅为GPT-3的千分之一），在MMLU数据集上可达到40多分，在ARC-Easy数据集上达70多分，在GSM8K数据集上达20多分。 举个具体的例子：一个深度为30的模型训练24小时后（相当于GPT-3 Small 125M的算力消耗，仅为GPT-3的千分之一），在MMLU数据集上可达到40多分，在ARC-Easy数据集上达70多分，在GSM8K数据集上达20多分。 卡帕西表示，他的目标是将这套完整的“强基线”技术栈整合为统一、极简、易读、可修改、易分发的代码库。 卡帕西表示，他的目标是将这套完整的“强基线”技术栈整合为统一、极简、易读、可修改、易分发的代码库。 nanochat将成为LLM101n课程的压轴项目 （该课程仍在开发中）。 nanochat将成为LLM101n课程的压轴项目 nanochat将成为LLM101n课程的压轴项目 （该课程仍在开发中）。 我认为它还有潜力发展为一个研究工具框架或基准测试的工具，就像之前的nanoGPT一样。目前该项目远未完全优化（实际上存在大量可改进空间），但整体框架已足够完整，可以发布到GitHub上，后续所有模块都能在社区中进一步优化。 我认为它还有潜力发展为一个研究工具框架或基准测试的工具，就像之前的nanoGPT一样。目前该项目远未完全优化（实际上存在大量可改进空间），但整体框架已足够完整，可以发布到GitHub上，后续所有模块都能在社区中进一步优化。 我认为它还有潜力发展为一个研究工具框架或基准测试的工具，就像之前的nanoGPT一样。目前该项目远未完全优化（实际上存在大量可改进空间），但整体框架已足够完整，可以发布到GitHub上，后续所有模块都能在社区中进一步优化。 等来新作的网友也已彻底疯狂。项目刚发出来，GitHub Star数已飙到4.8k： 等来新作的网友也已彻底疯狂。项目刚发出来，GitHub Star数已飙到4.8k： 太酷了！跑一次这个项目，就把“机器学习工程师（ML Engineer）”放在我的简历上！ 太酷了！跑一次这个项目，就把“机器学习工程师（ML Engineer）”放在我的简历上！ 太酷了！跑一次这个项目，就把“机器学习工程师（ML Engineer）”放在我的简历上！ 你发布的不只是代码，更是可被理解的智慧，价值爆炸，栓Q。 你发布的不只是代码，更是可被理解的智慧，价值爆炸，栓Q。 你发布的不只是代码，更是可被理解的智慧，价值爆炸，栓Q。 在评论区，卡帕西还解释了nanochat基本架构与Llama类似，但更简化一些，也借鉴了部分modded-nanoGPT的设计，整体是为此规模的模型找到一个稳健的基础架构。 在评论区，卡帕西还解释了nanochat基本架构与Llama类似，但更简化一些，也借鉴了部分modded-nanoGPT的设计，整体是为此规模的模型找到一个稳健的基础架构。 以及这个项目基本上是 完全手写的 。 以及这个项目基本上是 完全手写的 完全手写的 。 我确实尝试过用Claude或Codex之类的Agent来帮忙，但效果非常糟糕，几乎毫无帮助。可能是因为这个repo的结构偏离了它们训练数据的分布，所以它们根本“对不上号”。 我确实尝试过用Claude或Codex之类的Agent来帮忙，但效果非常糟糕，几乎毫无帮助。可能是因为这个repo的结构偏离了它们训练数据的分布，所以它们根本“对不上号”。 我确实尝试过用Claude或Codex之类的Agent来帮忙，但效果非常糟糕，几乎毫无帮助。可能是因为这个repo的结构偏离了它们训练数据的分布，所以它们根本“对不上号”。 话不多说，下面来看nanochat快速上手的详细指南。 话不多说，下面来看nanochat快速上手的详细指南。 100美元成本，能捏出的最好的ChatGPT 100美元成本，能捏出的最好的ChatGPT 从比如Lambda GPU Cloud上启动了一台8卡H100的服务器，每小时要花大约24美元，所以接下来得争分夺秒了。 从比如Lambda GPU Cloud上启动了一台8卡H100的服务器，每小时要花大约24美元，所以接下来得争分夺秒了。 环境搭建 环境搭建 克隆项目： 克隆项目： 目标是用100美元的成本训练出一个最好的类ChatGPT模型，称之为一次“速通（speedrun）”，可参考speedrun.sh这个脚本，它被设计成能在一台全新的服务器上直接从头到尾运行。 目标是用100美元的成本训练出一个最好的类ChatGPT模型，称之为一次“速通（speedrun）”，可参考speedrun.sh这个脚本，它被设计成能在一台全新的服务器上直接从头到尾运行。 但接下来，卡帕西会逐步讲解其中的每一步。 但接下来，卡帕西会逐步讲解其中的每一步。 首先需要确保安装了当下热门的uv项目管理器。安装uv，在.venv目录下创建一个新的虚拟环境，获取所有依赖项，然后激活该环境，这样当输入python时，使用的是虚拟环境中的Python，而不是系统自带的Python： 首先需要确保安装了当下热门的uv项目管理器。安装uv，在.venv目录下创建一个新的虚拟环境，获取所有依赖项，然后激活该环境，这样当输入python时，使用的是虚拟环境中的Python，而不是系统自带的Python： 接下来，需要安装Rust/Cargo，以便 编译自定义的Rust分词器 。引入一个全新/自定义的分词器确实有点折腾，但遗憾的是，卡帕西觉得早期minbpe项目中的Python版本速度太慢，而huggingface的分词器又过于臃肿且令人困惑。 接下来，需要安装Rust/Cargo，以便 编译自定义的Rust分词器 编译自定义的Rust分词器 。引入一个全新/自定义的分词器确实有点折腾，但遗憾的是，卡帕西觉得早期minbpe项目中的Python版本速度太慢，而huggingface的分词器又过于臃肿且令人困惑。 因此要专门为训练打造了自己的新分词器（经测试与Python版本效果一致），不过在推理时仍会使用OpenAI的tiktoken来保证效率。 因此要专门为训练打造了自己的新分词器（经测试与Python版本效果一致），不过在推理时仍会使用OpenAI的tiktoken来保证效率。 现在就开始编译分词器吧： 现在就开始编译分词器吧： 训练分词器 训练分词器 接下来，需要获取预训练数据，这样才能：1）训练分词器；2）对模型进行预训练。 接下来，需要获取预训练数据，这样才能：1）训练分词器；2）对模型进行预训练。 预训练数据就是大量网页的文本内容 ，这里将使用FineWeb-EDU数据集。 预训练数据就是大量网页的文本内容 预训练数据就是大量网页的文本内容 ，这里将使用FineWeb-EDU数据集。 通常来说，可以直接用huggingface datasets.load_dataset()，但卡帕西不喜欢它过于臃肿笨重且掩盖了本应简单的逻辑，所以把整个数据集重新打包成了简单、完全打乱的分片，这样就能轻松高效地随意访问，并且把它的sample-100B版本重新上传为karpathy/fineweb-edu-100b-shuffle。 通常来说，可以直接用huggingface datasets.load_dataset()，但卡帕西不喜欢它过于臃肿笨重且掩盖了本应简单的逻辑，所以把整个数据集重新打包成了简单、完全打乱的分片，这样就能轻松高效地随意访问，并且把它的sample-100B版本重新上传为karpathy/fineweb-edu-100b-shuffle。 在这个页面上，你还可以预览数据集中的示例文本。每个分片是一个约0.25M个字符的简单parquet文件，压缩后（gzip格式）在磁盘上大约占100MB。总共有1822个分片，但训练深度为20的模型只需要其中240个。 在这个页面上，你还可以预览数据集中的示例文本。每个分片是一个约0.25M个字符的简单parquet文件，压缩后（gzip格式）在磁盘上大约占100MB。总共有1822个分片，但训练深度为20的模型只需要其中240个。 现在就开始下载所有数据吧。虽然需要下载约24GB，但在云服务器上通常速度很快： 现在就开始下载所有数据吧。虽然需要下载约24GB，但在云服务器上通常速度很快： 默认情况下，所有这些都会被下载到~/.cache/nanochat目录下。 默认情况下，所有这些都会被下载到~/.cache/nanochat目录下。 下载完成后，开始训练分词器——它负责在字符串与符号码本（codebook）序列之间进行双向转换。默认情况下，训练的词汇表大小是2¹⁶= 65,536个tokens（这是个不错的数字），其中部分tokens会被保留作为特殊tokens（供后续聊天模式使用）。训练集包含2B字符，训练仅需约1分钟。 下载完成后，开始训练分词器——它负责在字符串与符号码本（codebook）序列之间进行双向转换。默认情况下，训练的词汇表大小是2¹⁶= 65,536个tokens（这是个不错的数字），其中部分tokens会被保留作为特殊tokens（供后续聊天模式使用）。训练集包含2B字符，训练仅需约1分钟。 训练算法与OpenAI使用的完全一致（regex splitting, byte-level BPE）。想了解更多信息，可以看卡帕西关于tokenization技术的视频讲解。 训练算法与OpenAI使用的完全一致（regex splitting, byte-level BPE）。想了解更多信息，可以看卡帕西关于tokenization技术的视频讲解。 训练完成后可以评估这个分词器： 训练完成后可以评估这个分词器： 评估结果显示，实现了约4.8的压缩比（即原始文本中平均4.8个字符压缩为1个token），还可以看到与GPT-2、GPT-4分词器的对比结果。 评估结果显示，实现了约4.8的压缩比（即原始文本中平均4.8个字符压缩为1个token），还可以看到与GPT-2、GPT-4分词器的对比结果。 相比GPT-2（拥有50257个tokens），在压缩文本方面全面更优，仅在数学内容上稍逊一筹： 相比GPT-2（拥有50257个tokens），在压缩文本方面全面更优，仅在数学内容上稍逊一筹： 与GPT-4相比，表现并不突出，但需要考虑到GPT-4拥有更大的词汇表规模（100,277个tokens）。特别是在多语言处理方面GPT-4优势明显（由于FineWeb数据集高度侧重英语内容，这个结果很合理），同时在代码和数学领域也更胜一筹： 与GPT-4相比，表现并不突出，但需要考虑到GPT-4拥有更大的词汇表规模（100,277个tokens）。特别是在多语言处理方面GPT-4优势明显（由于FineWeb数据集高度侧重英语内容，这个结果很合理），同时在代码和数学领域也更胜一筹： 尽管如此， 即使在词汇量较小的条件下，我们在FineWeb数据集上仍以微弱优势超越了GPT-4 ——因为这正是我们训练所用的数据集，所以我们的分词器能完美契合该文档分布（例如在英语文本压缩方面可能更具优势）。 尽管如此， 即使在词汇量较小的条件下，我们在FineWeb数据集上仍以微弱优势超越了GPT-4 即使在词汇量较小的条件下，我们在FineWeb数据集上仍以微弱优势超越了GPT-4 ——因为这正是我们训练所用的数据集，所以我们的分词器能完美契合该文档分布（例如在英语文本压缩方面可能更具优势）。 预训练 预训练 在启动预训练之前，需要下载另一个被卡帕西称之为“ 评估包 （eval bundle）”的文件。 在启动预训练之前，需要下载另一个被卡帕西称之为“ 评估包 评估包 （eval bundle）”的文件。 在预训练过程中，脚本会定期评估CORE指标。你可以在DCLM论文中看到一些细节，本质上，它是一个很好的、标准化的、宽泛的指标，用于衡量模型在大量自动补全数据集上的表现好坏。 在预训练过程中，脚本会定期评估CORE指标。你可以在DCLM论文中看到一些细节，本质上，它是一个很好的、标准化的、宽泛的指标，用于衡量模型在大量自动补全数据集上的表现好坏。 这些数据集包括HellaSwag、jeopardy、bigbench QA wikidata、ARC-Easy/Challenge、copa、commonsense qa、piqa、lambada、winograd、boolq等等（共22个）。 这些数据集包括HellaSwag、jeopardy、bigbench QA wikidata、ARC-Easy/Challenge、copa、commonsense qa、piqa、lambada、winograd、boolq等等（共22个）。 下载、解压该评估包，并将评估包目录放置到基础目录~/.cache/nanochat/eval_bundle下： 下载、解压该评估包，并将评估包目录放置到基础目录~/.cache/nanochat/eval_bundle下： 还建议（尽管这是可选的）再做一项设置： 还建议（尽管这是可选的）再做一项设置： 配置wandb，以便在训练过程中查看美观的图表。前面uv已经安装好了wandb，但你仍需创建账户并登录： 配置wandb，以便在训练过程中查看美观的图表。前面uv已经安装好了wandb，但你仍需创建账户并登录： 现在我们可以启动预训练了！这是计算量最大的部分，要训练大语言模型（LLM），通过预测序列中的下一个token来压缩互联网网页文本，在此过程中，大语言模型会获取大量关于世界的知识： 现在我们可以启动预训练了！这是计算量最大的部分，要训练大语言模型（LLM），通过预测序列中的下一个token来压缩互联网网页文本，在此过程中，大语言模型会获取大量关于世界的知识： 在这里，通过scripts/base_train.py脚本在8块GPU上启动训练。我们正在训练一个有20层的Transformer。默认情况下，每块GPU在每次前向/反向传播时处理32行、每行2048个tokens的数据，优化器每一步总共处理32×2048=2¹⁹=524,288≈0.5M个tokens。 在这里，通过scripts/base_train.py脚本在8块GPU上启动训练。我们正在训练一个有20层的Transformer。默认情况下，每块GPU在每次前向/反向传播时处理32行、每行2048个tokens的数据，优化器每一步总共处理32×2048=2¹⁹=524,288≈0.5M个tokens。 如果已经设置好了wandb，可以添加—run=speedrun（所有训练脚本都支持该参数）来设置运行名称并记录相关数据。 如果已经设置好了wandb，可以添加—run=speedrun（所有训练脚本都支持该参数）来设置运行名称并记录相关数据。 当你启动训练后，会看到类似这样的输出（为简洁起见，省略了大量内容）： 当你启动训练后，会看到类似这样的输出（为简洁起见，省略了大量内容）： 可以看到，这个Transformer有1280个channels，注意力机制中有10个注意力头，每个头的dim=128。它大约有560M参数。为了符合Chinchilla scaling law的建议，这意味着我们需要用560M×20≈11.2B tokens来进行训练。 可以看到，这个Transformer有1280个channels，注意力机制中有10个注意力头，每个头的dim=128。它大约有560M参数。为了符合Chinchilla scaling law的建议，这意味着我们需要用560M×20≈11.2B tokens来进行训练。 由于优化器的每一步处理524,288个tokens，这意味着11.2B/0.5M≈21400次迭代。 由于优化器的每一步处理524,288个tokens，这意味着11.2B/0.5M≈21400次迭代。 通过对每个token的估计FLOPs与总tokens数相乘，我们可以知道这将是一个计算量达约4e19 FLOPs的模型。 通过对每个token的估计FLOPs与总tokens数相乘，我们可以知道这将是一个计算量达约4e19 FLOPs的模型。 学习率会自动按1/sqrt（dim）自动缩放，因为更大的模型更偏好更小的学习率。 学习率会自动按1/sqrt（dim）自动缩放，因为更大的模型更偏好更小的学习率。 我们使用Muon来优化矩阵，使用AdamW来优化嵌入和反嵌入。在这个模型中，没有其他可训练的参数（比如偏置、rmsnorm参数等）。训练过程会定期报告“验证集bpb”，即验证数据集上每字节的位数。 我们使用Muon来优化矩阵，使用AdamW来优化嵌入和反嵌入。在这个模型中，没有其他可训练的参数（比如偏置、rmsnorm参数等）。训练过程会定期报告“验证集bpb”，即验证数据集上每字节的位数。 每字节位数（bits per byte）是一个比典型的交叉熵损失更好的衡量指标，因为它通过每个token的字节数进一步归一化了每个token的损失，使得该指标与分词器无关。 每字节位数（bits per byte）是一个比典型的交叉熵损失更好的衡量指标，因为它通过每个token的字节数进一步归一化了每个token的损失，使得该指标与分词器无关。 所以，无论你使用的是词汇量小的分词器还是词汇量大的分词器，这个数值都是可比较的，而原始的交叉熵损失则不然。 所以，无论你使用的是词汇量小的分词器还是词汇量大的分词器，这个数值都是可比较的，而原始的交叉熵损失则不然。 注意，每一步大约耗时0.5秒，lrm是学习率衰减乘数（在训练接近尾声时，它会线性下降到0），报告的MFU（模型flops利用率）看起来很不错，几乎达到了一半，这意味着我们充分利用了可用的bfloat16计算能力。 注意，每一步大约耗时0.5秒，lrm是学习率衰减乘数（在训练接近尾声时，它会线性下降到0），报告的MFU（模型flops利用率）看起来很不错，几乎达到了一半，这意味着我们充分利用了可用的bfloat16计算能力。 现在， 要等待大约3小时，直到4e19 FLOPs的计算量完成 ……在你的wandb图表中，你应该会看到类似这样的内容： 现在， 要等待大约3小时，直到4e19 FLOPs的计算量完成 要等待大约3小时，直到4e19 FLOPs的计算量完成 ……在你的wandb图表中，你应该会看到类似这样的内容： 随着时间的推移， bpb下降是好的迹象 （说明模型能更准确地预测下一个token）。此外，CORE分数在上升。 随着时间的推移， bpb下降是好的迹象 bpb下降是好的迹象 （说明模型能更准确地预测下一个token）。此外，CORE分数在上升。 除了这些近似的指标，还可以更全面地评估模型： 除了这些近似的指标，还可以更全面地评估模型： 可以看到，训练集/验证集的bpb达到了约0.81，CORE指标上升到了0.22。 可以看到，训练集/验证集的bpb达到了约0.81，CORE指标上升到了0.22。 作为对比，评估包中包含了GPT-2模型的CORE分数。具体来说，0.22的CORE分数略高于GPT-2 large（0.21），但略低于GPT-2 xl（即“标准”的GPT-2，为0.26）。 作为对比，评估包中包含了GPT-2模型的CORE分数。具体来说，0.22的CORE分数略高于GPT-2 large（0.21），但略低于GPT-2 xl（即“标准”的GPT-2，为0.26）。 此时，这个模型就像一个高级的自动补全工具，所以我们可以运行一些提示词，来感受模型中存储的知识。base_loss.py文件会运行这些提示词。这些提示词包括： 此时，这个模型就像一个高级的自动补全工具，所以我们可以运行一些提示词，来感受模型中存储的知识。base_loss.py文件会运行这些提示词。这些提示词包括： 补全后的文本如下： 补全后的文本如下： 所以，模型知道巴黎是法国的首都、Au代表金、星期六在星期五之后、“冷”是“热”的反义词，甚至还知道太阳系的行星。 所以，模型知道巴黎是法国的首都、Au代表金、星期六在星期五之后、“冷”是“热”的反义词，甚至还知道太阳系的行星。 不过，它对天空的颜色还不太确定，也不太会做简单的数学题。 不过，它对天空的颜色还不太确定，也不太会做简单的数学题。 对于一个花费72美元训练出来的模型来说，已经不算太差了。推理过程使用了一个自定义的Engine class，利用KV缓存来实现高效推理，同时还简单实现了两种常见的推理阶段：预填充和解码。 对于一个花费72美元训练出来的模型来说，已经不算太差了。推理过程使用了一个自定义的Engine class，利用KV缓存来实现高效推理，同时还简单实现了两种常见的推理阶段：预填充和解码。 我们的Engine class还支持工具使用（比如Python解释器），这在GSM8K数据集上训练时会很有用（之后会详细介绍）。 我们的Engine class还支持工具使用（比如Python解释器），这在GSM8K数据集上训练时会很有用（之后会详细介绍）。 训练中期 训练中期 接下来是中期训练，这一步会在smol-SmolTalk数据集上进一步微调模型。 接下来是中期训练，这一步会在smol-SmolTalk数据集上进一步微调模型。 算法层面和预训练完全一致，但数据集变成了对话内容，而且模型会去适应那些用于构建多轮对话结构的 新特殊token 。现在，每次对话大致是这样的，大致遵循OpenAI的Harmony聊天格式： 算法层面和预训练完全一致，但数据集变成了对话内容，而且模型会去适应那些用于构建多轮对话结构的 新特殊token 新特殊token 。现在，每次对话大致是这样的，大致遵循OpenAI的Harmony聊天格式： 像<|example|>这样显示的token是特殊token，遵循OpenAI特殊token的格式。 中期训练阶段对模型的多种适配非常有用 ： 像<|example|>这样显示的token是特殊token，遵循OpenAI特殊token的格式。 中期训练阶段对模型的多种适配非常有用 中期训练阶段对模型的多种适配非常有用 ： 模型学习与多轮对话相关的特殊token（除了用于分隔文档的<|bos|>token，基础模型预训练期间没有这些token）。 模型适应对话的数据分布，而非互联网文档的数据分布。 对我们来说非常重要的一点是，必须教会模型做多项选择题，因为在这么小的模型规模下，模型无法从随机的互联网数据中学会这一点。具体而言，模型必须学会将几个选项与几个字母（如ABCD）关联起来，然后输出正确选项的算法。通过混合10万道来自MMLU辅助训练集的多项选择题来实现这一点。需要明确的是，问题不在于模型没有相关知识，而在于它不理解多项选择题的运作方式，无法将知识展现出来。这很重要，因为许多常见的模型评估（如MMLU）都采用多项选择题的形式。 你可以教会模型使用各种工具。对我们来说，需要通过在特殊token <|python_start|>和<|python_end|>之间放入Python命令，来教会模型使用Python解释器。这对之后解决GSM8K问题会很有用。 在中期训练期间，你还可以针对许多其他适配进行训练，例如上下文长度扩展（尚未探索）。 模型学习与多轮对话相关的特殊token（除了用于分隔文档的<|bos|>token，基础模型预训练期间没有这些token）。 模型学习与多轮对话相关的特殊token（除了用于分隔文档的<|bos|>token，基础模型预训练期间没有这些token）。 模型适应对话的数据分布，而非互联网文档的数据分布。 模型适应对话的数据分布，而非互联网文档的数据分布。 对我们来说非常重要的一点是，必须教会模型做多项选择题，因为在这么小的模型规模下，模型无法从随机的互联网数据中学会这一点。具体而言，模型必须学会将几个选项与几个字母（如ABCD）关联起来，然后输出正确选项的算法。通过混合10万道来自MMLU辅助训练集的多项选择题来实现这一点。需要明确的是，问题不在于模型没有相关知识，而在于它不理解多项选择题的运作方式，无法将知识展现出来。这很重要，因为许多常见的模型评估（如MMLU）都采用多项选择题的形式。 对我们来说非常重要的一点是，必须教会模型做多项选择题，因为在这么小的模型规模下，模型无法从随机的互联网数据中学会这一点。具体而言，模型必须学会将几个选项与几个字母（如ABCD）关联起来，然后输出正确选项的算法。通过混合10万道来自MMLU辅助训练集的多项选择题来实现这一点。需要明确的是，问题不在于模型没有相关知识，而在于它不理解多项选择题的运作方式，无法将知识展现出来。这很重要，因为许多常见的模型评估（如MMLU）都采用多项选择题的形式。 你可以教会模型使用各种工具。对我们来说，需要通过在特殊token <|python_start|>和<|python_end|>之间放入Python命令，来教会模型使用Python解释器。这对之后解决GSM8K问题会很有用。 你可以教会模型使用各种工具。对我们来说，需要通过在特殊token <|python_start|>和<|python_end|>之间放入Python命令，来教会模型使用Python解释器。这对之后解决GSM8K问题会很有用。 在中期训练期间，你还可以针对许多其他适配进行训练，例如上下文长度扩展（尚未探索）。 在中期训练期间，你还可以针对许多其他适配进行训练，例如上下文长度扩展（尚未探索）。 中期训练混合数据默认是这样的： 中期训练混合数据默认是这样的： 然后按如下方式启动它： 然后按如下方式启动它： 这次运行只需要大约8分钟，比预训练的约3小时短得多。现在，模型已经是一个真正的聊天模型，能够扮演助手的角色回答用户的问题，可以对其进行评估： 这次运行只需要大约8分钟，比预训练的约3小时短得多。现在，模型已经是一个真正的聊天模型，能够扮演助手的角色回答用户的问题，可以对其进行评估： 得到了该阶段模型的以下结果： 得到了该阶段模型的以下结果： 可以看到： 可以看到： 世界知识： 前三项（ARC-E/C和MMLU）都是多项选择题测试，用于衡量模型在各个领域的世界知识。由于有4个选项（A、B、C、D），随机猜测的正确率约为25%，所以模型已经表现得比随机猜测更好了。（对于这么小的模型来说，多项选择题是相当难的） 数学： GSM8K是小学水平的数学题。这里的基准性能是0%，因为模型必须写出实际的答案数字。目前我们的性能仍然不是很强，只解决了2%的问题。 代码： HumanEval是一个Python编码基准测试，同样，随机基准性能为0%。 ChatCORE： 这是卡帕西尝试复制CORE分数对基础模型的评估方式，并将其扩展到聊天模型的成果。也就是说，将上述所有指标都减去基准性能，这样分数就在0到1之间（例如，随机模型得0分，而不是MMLU上的25%），然后报告所有任务的平均值。它是对当前模型实力的一个单一数字总结。 这些评估仍然相当不完整，还有很多其他可以衡量但尚未衡量的方面。 世界知识： 前三项（ARC-E/C和MMLU）都是多项选择题测试，用于衡量模型在各个领域的世界知识。由于有4个选项（A、B、C、D），随机猜测的正确率约为25%，所以模型已经表现得比随机猜测更好了。（对于这么小的模型来说，多项选择题是相当难的） 世界知识： 世界知识： 前三项（ARC-E/C和MMLU）都是多项选择题测试，用于衡量模型在各个领域的世界知识。由于有4个选项（A、B、C、D），随机猜测的正确率约为25%，所以模型已经表现得比随机猜测更好了。（对于这么小的模型来说，多项选择题是相当难的） 数学： GSM8K是小学水平的数学题。这里的基准性能是0%，因为模型必须写出实际的答案数字。目前我们的性能仍然不是很强，只解决了2%的问题。 数学： 数学： GSM8K是小学水平的数学题。这里的基准性能是0%，因为模型必须写出实际的答案数字。目前我们的性能仍然不是很强，只解决了2%的问题。 代码： HumanEval是一个Python编码基准测试，同样，随机基准性能为0%。 代码： 代码： HumanEval是一个Python编码基准测试，同样，随机基准性能为0%。 ChatCORE： 这是卡帕西尝试复制CORE分数对基础模型的评估方式，并将其扩展到聊天模型的成果。也就是说，将上述所有指标都减去基准性能，这样分数就在0到1之间（例如，随机模型得0分，而不是MMLU上的25%），然后报告所有任务的平均值。它是对当前模型实力的一个单一数字总结。 ChatCORE： ChatCORE： 这是卡帕西尝试复制CORE分数对基础模型的评估方式，并将其扩展到聊天模型的成果。也就是说，将上述所有指标都减去基准性能，这样分数就在0到1之间（例如，随机模型得0分，而不是MMLU上的25%），然后报告所有任务的平均值。它是对当前模型实力的一个单一数字总结。 这些评估仍然相当不完整，还有很多其他可以衡量但尚未衡量的方面。 这些评估仍然相当不完整，还有很多其他可以衡量但尚未衡量的方面。 确实没有一个很好的图表来展示这一步，但这里有一个之前对另一个更大的模型进行中期训练的例子，只是为了让你了解在微调运行期间这些指标上升时的样子： 确实没有一个很好的图表来展示这一步，但这里有一个之前对另一个更大的模型进行中期训练的例子，只是为了让你了解在微调运行期间这些指标上升时的样子： 监督微调 监督微调 中期训练之后是监督微调（SFT）阶段。 中期训练之后是监督微调（SFT）阶段。 这是在对话数据上额外进行的一轮微调， 理想情况下，你会精心挑选最优质的好数据 ，而且也会在这里进行安全训练（比如助手拒绝不当请求的训练）。 这是在对话数据上额外进行的一轮微调， 理想情况下，你会精心挑选最优质的好数据 理想情况下，你会精心挑选最优质的好数据 ，而且也会在这里进行安全训练（比如助手拒绝不当请求的训练）。 我们的模型甚至连天空的颜色都还不确定，所以目前在生物危害这类问题上可能还是安全的。这里会进行的一项领域适配是，SFT会拉伸数据行并对其进行填充，完全模拟测试时的格式。 我们的模型甚至连天空的颜色都还不确定，所以目前在生物危害这类问题上可能还是安全的。这里会进行的一项领域适配是，SFT会拉伸数据行并对其进行填充，完全模拟测试时的格式。 换句话说，示例不再像预训练/中期训练时那样为了训练效率而被随机拼接成长行。修正这种领域不匹配的问题，是另一个小小的“拧紧螺丝”式的提升。我们可以运行SFT并重新评估： 换句话说，示例不再像预训练/中期训练时那样为了训练效率而被随机拼接成长行。修正这种领域不匹配的问题，是另一个小小的“拧紧螺丝”式的提升。我们可以运行SFT并重新评估： 这个过程同样只需运行约7分钟，你应该能观察到各项指标均有小幅提升： 这个过程同样只需运行约7分钟，你应该能观察到各项指标均有小幅提升： 终于，我们可以以用户身份与模型对话了！ 终于，我们可以以用户身份与模型对话了！ 其实在中期训练后就可以进行对话，但现在效果会更理想些。你可以通过终端窗口（方式1）或网页界面（方式2）与它交流： 其实在中期训练后就可以进行对话，但现在效果会更理想些。你可以通过终端窗口（方式1）或网页界面（方式2）与它交流： chat_web脚本会使用FastAPI来提供Engine服务。要确保正确访问它，比如在Lambda上，使用你所在节点的公网IP，后面加上端口，例如http://209.20.xxx.xxx:8000/等等。 chat_web脚本会使用FastAPI来提供Engine服务。要确保正确访问它，比如在Lambda上，使用你所在节点的公网IP，后面加上端口，例如http://209.20.xxx.xxx:8000/等等。 那看起来会很棒，大概是这样的： 那看起来会很棒，大概是这样的： 它短期内还无法在物理或诗歌比赛中获胜，但话说回来——用这么少的预算能做到这个程度，看起来还是很酷的， 而且这个项目还远远没到充分调优的地步 。 它短期内还无法在物理或诗歌比赛中获胜，但话说回来——用这么少的预算能做到这个程度，看起来还是很酷的， 而且这个项目还远远没到充分调优的地步 而且这个项目还远远没到充分调优的地步 。 强化学习 强化学习 “速通”的最后一个阶段是强化学习。 “速通”的最后一个阶段是强化学习。 基于人类反馈的强化学习（RLHF）是一种不错的方法，能提升几个百分点的性能，还能缓解很多因采样循环本身带来的模型缺陷——比如幻觉、无限循环等。 基于人类反馈的强化学习（RLHF）是一种不错的方法，能提升几个百分点的性能，还能缓解很多因采样循环本身带来的模型缺陷——比如幻觉、无限循环等。 但以我们的规模，这些都不是主要考虑因素。话虽如此，在我们目前使用的所有数据集中，GSM8K是唯一一个有清晰、客观奖励函数的（数学题的正确答案）。 但以我们的规模，这些都不是主要考虑因素。话虽如此，在我们目前使用的所有数据集中，GSM8K是唯一一个有清晰、客观奖励函数的（数学题的正确答案）。 所以我们可以运行RL（/GRPO）脚本，通过交替进行采样和训练的简单强化学习循环，直接在答案上进行性能攀升： 所以我们可以运行RL（/GRPO）脚本，通过交替进行采样和训练的简单强化学习循环，直接在答案上进行性能攀升： 在强化学习过程中，模型会遍历训练集中所有的GSM8K题目，对完成情况进行采样，然后我们会对这些采样结果进行奖励，并针对获得高奖励的样本进行训练。 在强化学习过程中，模型会遍历训练集中所有的GSM8K题目，对完成情况进行采样，然后我们会对这些采样结果进行奖励，并针对获得高奖励的样本进行训练。 我们使用的是高度简化的GRPO训练循环，比如，不使用信任区域（舍弃参考模型和KL正则化），采用在策略（舍弃PPO的比率+裁剪），使用GAPO风格的归一化（基于token级，而非序列级归一化），优势函数仅通过均值进行简单的奖励平移（舍弃用除以标准差的z分数归一化）。 我们使用的是高度简化的GRPO训练循环，比如，不使用信任区域（舍弃参考模型和KL正则化），采用在策略（舍弃PPO的比率+裁剪），使用GAPO风格的归一化（基于token级，而非序列级归一化），优势函数仅通过均值进行简单的奖励平移（舍弃用除以标准差的z分数归一化）。 所以最后得到的东西看起来更像是REINFORCE算法，但保留了GR（”组相对”）部分来计算奖励的优势值。在当前规模和任务简单度下，这种方法效果尚可。更多细节请参阅脚本。 所以最后得到的东西看起来更像是REINFORCE算法，但保留了GR（”组相对”）部分来计算奖励的优势值。在当前规模和任务简单度下，这种方法效果尚可。更多细节请参阅脚本。 目前强化学习默认是注释掉的，因为它还没有经过很好的调优，而且我们也没有完整通用的RLHF。 目前强化学习默认是注释掉的，因为它还没有经过很好的调优，而且我们也没有完整通用的RLHF。 只针对GSM8K进行了强化学习，这也是为什么用-a标志将评估也限制在GSM8K上。由于强化学习就像通过吸管汲取监督信号，这个过程会运行相当长的时间。 只针对GSM8K进行了强化学习，这也是为什么用-a标志将评估也限制在GSM8K上。由于强化学习就像通过吸管汲取监督信号，这个过程会运行相当长的时间。 例如，默认设置下运行约1.5小时后，效果如下所示： 例如，默认设置下运行约1.5小时后，效果如下所示： 成绩 成绩 最后卡帕西指出的是项目文件夹里出现的report.md文件。它包含了很多与运行相关的细节，最后还有一个不错的总结表格： 最后卡帕西指出的是项目文件夹里出现的report.md文件。它包含了很多与运行相关的细节，最后还有一个不错的总结表格： Characters：333,989 Lines：8,304 Files：44 Tokens(approx)：83,497 Dependencies(uv.lock lines)：2,004 Characters：333,989 Characters：333,989 Lines：8,304 Lines：8,304 Files：44 Files：44 Tokens(approx)：83,497 Tokens(approx)：83,497 Dependencies(uv.lock lines)：2,004 Dependencies(uv.lock lines)：2,004 总用时：3小时51分钟 总用时：3小时51分钟 总用时：3小时51分钟 需要注意的是，由于目前对强化学习（RL）的支持还不太完善，在计算总耗时时把它排除了。到监督微调（SFT）阶段为止，整个过程运行了3小时51分钟， 总成本为（3+51/60）×24=92.4美元 （如果加上强化学习，现在总时间会更接近5小时）。 需要注意的是，由于目前对强化学习（RL）的支持还不太完善，在计算总耗时时把它排除了。到监督微调（SFT）阶段为止，整个过程运行了3小时51分钟， 总成本为（3+51/60）×24=92.4美元 总成本为（3+51/60）×24=92.4美元 （如果加上强化学习，现在总时间会更接近5小时）。 甚至还剩下8美元可以买冰淇淋呢。 甚至还剩下8美元可以买冰淇淋呢。 甚至还剩下8美元可以买冰淇淋呢。 该你了 该你了 借助nanochat，你可以对任何部分进行调优。 借助nanochat，你可以对任何部分进行调优。 更换分词器、修改任意数据、调整超参数、改进优化过程……有很多想法可以去尝试。你或许还想训练更大的模型。这个代码库的设置能让你轻松做到这一点。 更换分词器、修改任意数据、调整超参数、改进优化过程……有很多想法可以去尝试。你或许还想训练更大的模型。这个代码库的设置能让你轻松做到这一点。 只需使用—depth参数来更改层数，其他所有相关设置都会基于这个参数作为复杂度的单一调节项而自动调整。比如，通道数会增加，学习率会相应调整等。 只需使用—depth参数来更改层数，其他所有相关设置都会基于这个参数作为复杂度的单一调节项而自动调整。比如，通道数会增加，学习率会相应调整等。 原则上，仅通过改变深度，你就能探索出一整套nanochat的“迷你系列”模型。使用更大的深度并等待更长时间，理论上你应该能得到明显更好的结果。 原则上，仅通过改变深度，你就能探索出一整套nanochat的“迷你系列”模型。使用更大的深度并等待更长时间，理论上你应该能得到明显更好的结果。 你需要在base_train.py的预训练阶段传入深度参数。例如，要得到一个CORE指标约为0.25、性能接近GPT-2的模型，尝试depth=26是个不错的选择。 你需要在base_train.py的预训练阶段传入深度参数。例如，要得到一个CORE指标约为0.25、性能接近GPT-2的模型，尝试depth=26是个不错的选择。 但训练更大模型时，需要调整设备最大批处理大小，比如从32降至16： 但训练更大模型时，需要调整设备最大批处理大小，比如从32降至16： 代码会察觉到这一变化并自动进行补偿，它会通过2次梯度累积循环来达到目标批处理量0.5M。要训练depth=30的模型，需要进一步降低设置： 代码会察觉到这一变化并自动进行补偿，它会通过2次梯度累积循环来达到目标批处理量0.5M。要训练depth=30的模型，需要进一步降低设置： 依此类推。欢迎大家去阅读代码，卡帕西尽力让代码保持易读性，添加了注释，代码整洁且易于理解。 依此类推。欢迎大家去阅读代码，卡帕西尽力让代码保持易读性，添加了注释，代码整洁且易于理解。 当然，你也可以把所有内容打包，去询问你喜欢的大语言模型，或者更简单的是，使用Devin/Cognition的DeepWiki来对这个代码仓库提问。只需把代码仓库的URL从github.com改成deepwiki.com即可，比如 nanochat DeepWiki。 当然，你也可以把所有内容打包，去询问你喜欢的大语言模型，或者更简单的是，使用Devin/Cognition的DeepWiki来对这个代码仓库提问。只需把代码仓库的URL从github.com改成deepwiki.com即可，比如 nanochat DeepWiki。 就是这样，调优整个流程的任意部分，重新运行，然后享受其中的乐趣吧！ 就是这样，调优整个流程的任意部分，重新运行，然后享受其中的乐趣吧！ AI界超高人气专注于教育的大牛 AI界超高人气专注于教育的大牛 卡帕西曾任特斯拉AI主管，之后去了OpenAI，去年2月从OpenAI离职。 卡帕西曾任特斯拉AI主管，之后去了OpenAI，去年2月从OpenAI离职。 他在整个AI界拥有超高的人气，很大一部分来自于他的课程。 他在整个AI界拥有超高的人气，很大一部分来自于他的课程。 包括他自己的早期博客文字分享和后来的一系列Youtube视频教程，他还与李飞飞合作开设的的斯坦福大学首个深度学习课程CS231n《卷积神经网络与视觉识别》。 包括他自己的早期博客文字分享和后来的一系列Youtube视频教程，他还与李飞飞合作开设的的斯坦福大学首个深度学习课程CS231n《卷积神经网络与视觉识别》。 今天的不少学者和创业者，都是跟着他入门的。 今天的不少学者和创业者，都是跟着他入门的。 卡帕西对教育的热情，甚至可以追溯到学生时期在网上教大家玩魔方。 卡帕西对教育的热情，甚至可以追溯到学生时期在网上教大家玩魔方。 去年7月，从OpenAI离职的卡帕西突然官宣创业，搞了一家AI原生的新型学校—— Eureka Labs 。 去年7月，从OpenAI离职的卡帕西突然官宣创业，搞了一家AI原生的新型学校—— Eureka Labs Eureka Labs 。 怎么理解AI原生？ 怎么理解AI原生？ 想象一下与费曼一起学习高质量教材，费曼会在每一步中1对1指导你。 想象一下与费曼一起学习高质量教材，费曼会在每一步中1对1指导你。 不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的80亿人。 不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的80亿人。 但AI可以，而且AI有无限的耐心，精通世界上所有的语言。 但AI可以，而且AI有无限的耐心，精通世界上所有的语言。 所以卡帕西要打造“教师+人工智能的共生”，可以在一个通用平台上运行整个课程。 所以卡帕西要打造“教师+人工智能的共生”，可以在一个通用平台上运行整个课程。 如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。 如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。 如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的“范围”和“程度”。 Eureka Labs首个产品，也是首门课程LLM101n。 Eureka Labs首个产品，也是首门课程LLM101n。 手把手带你构建一个类似ChatGPT的故事生成大模型，以及配套的Web应用程序。 手把手带你构建一个类似ChatGPT的故事生成大模型，以及配套的Web应用程序。 手把手带你构建一个类似ChatGPT的故事生成大模型，以及配套的Web应用程序。 GitHub repo：https://github.com/karpathy/nanochat 详细指南：https://github.com/karpathy/nanochat/discussions/1 参考链接：https://x.com/karpathy/status/1977755427569111362 GitHub repo：https://github.com/karpathy/nanochat 详细指南：https://github.com/karpathy/nanochat/discussions/1 参考链接：https://x.com/karpathy/status/1977755427569111362 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340993.html", "title": "官宣定档11月13日！百度世界2025将于北京举办", "date": "2025-10-13", "content": "官宣定档11月13日！百度世界2025将于北京举办 官宣定档11月13日！百度世界2025将于北京举办 henry 2025-10-13 19:33:35 来源： 量子位 henry henry henry henry 2025-10-13 2025-10-13 19:33:35 19:33:35 来源： 量子位 来源： 量子位 量子位 摘要样式 又一年度AI盛会要来了！百度世界2025定档11月13日 又一年度AI盛会要来了！百度世界2025定档11月13日 又一年度AI盛会要来了！百度世界2025定档11月13日 10月13日，百度官方公众号宣布，百度世界2025将于11月13日在北京·国家会议中心二期举办，大会官网（https://baiduworld2025.baidu.com/）现已开启售票通道。作为百度一年一度最重要的技术和产品发布会，本届百度世界或将全面展示百度在AI应用、大模型、AI生态、出海等方面的最新进展。 10月13日，百度官方公众号宣布，百度世界2025将于11月13日在北京·国家会议中心二期举办，大会官网（https://baiduworld2025.baidu.com/）现已开启售票通道。作为百度一年一度最重要的技术和产品发布会，本届百度世界或将全面展示百度在AI应用、大模型、AI生态、出海等方面的最新进展。 据悉，百度世界2025以「效果涌现｜AI in Action」为主题，设置1+ 6场顶尖论坛。百度创始人李彦宏将发表主题演讲，或将带来多项重磅发布。分论坛将聚焦智能体、数字人、AI计算、智能硬件等AI热门议题，探讨AI前沿创新与AI应用驱动的生产生活智能跃迁。 据悉，百度世界2025以「效果涌现｜AI in Action」为主题，设置1+ 6场顶尖论坛。百度创始人李彦宏将发表主题演讲，或将带来多项重磅发布。分论坛将聚焦智能体、数字人、AI计算、智能硬件等AI热门议题，探讨AI前沿创新与AI应用驱动的生产生活智能跃迁。 大会还将推出40+AI公开课，覆盖模型开发、AI应用开发工具及AI跨界应用实战案例，一站式赋能AI应用开发。大会现场将布设一万平米展区，打造AI超级生活社区，为参会观众提供AI科技与生活场景深度融合的沉浸式交互体验。 大会还将推出40+AI公开课，覆盖模型开发、AI应用开发工具及AI跨界应用实战案例，一站式赋能AI应用开发。大会现场将布设一万平米展区，打造AI超级生活社区，为参会观众提供AI科技与生活场景深度融合的沉浸式交互体验。 在去年百度世界上，李彦宏发布了文心iRAG、无代码秒哒等“超级有用”技术，带来自由画布等新应用，并提出打造数百万“超级有用”。一年间，这一AI愿景正在成为现实，目前秒哒帮助用户零代码开发的应用已达20万个，千帆平台已服务46万家企业。 在去年百度世界上，李彦宏发布了文心iRAG、无代码秒哒等“超级有用”技术，带来自由画布等新应用，并提出打造数百万“超级有用”。一年间，这一AI愿景正在成为现实，目前秒哒帮助用户零代码开发的应用已达20万个，千帆平台已服务46万家企业。 今年，百度发布多款文心大模型，最新文心X1.1模型多项权威基准测试表现超越Deepseek -R1。基于文心大模型不断迭代，百度AI重构深化，百度搜索近期完成十年来最大改版，百度文库、百度网盘居国内AI产品榜前列。同时，数字人、智能体等AI应用布局成果显现，新一代数字人技术支撑罗永浩数字人首播GMV突破5500万元，千帆平台上已诞生130万个Agent。 今年，百度发布多款文心大模型，最新文心X1.1模型多项权威基准测试表现超越Deepseek -R1。基于文心大模型不断迭代，百度AI重构深化，百度搜索近期完成十年来最大改版，百度文库、百度网盘居国内AI产品榜前列。同时，数字人、智能体等AI应用布局成果显现，新一代数字人技术支撑罗永浩数字人首播GMV突破5500万元，千帆平台上已诞生130万个Agent。 百度无人驾驶也在今年加速全球化进程，萝卜快跑相继与Uber、Lyft达成合作，业务扩展至亚洲、欧洲及中东市场。公开数据显示，萝卜快跑在全球累计提供超1400万次出行服务，覆盖全球16座城市。今年9月，凭借萝卜快跑在自动驾驶领域的影响力与安全性，百度入选《财富》2025年“改变世界”公司榜单。 百度无人驾驶也在今年加速全球化进程，萝卜快跑相继与Uber、Lyft达成合作，业务扩展至亚洲、欧洲及中东市场。公开数据显示，萝卜快跑在全球累计提供超1400万次出行服务，覆盖全球16座城市。今年9月，凭借萝卜快跑在自动驾驶领域的影响力与安全性，百度入选《财富》2025年“改变世界”公司榜单。 据悉，自2006年以来，百度世界已连续举办近20届，框计算、深度学习框架、无人驾驶、文心4.0等创新成果均曾在大会首次亮相。历届大会见证了深度学习进化、AI大模型崛起和AI应用爆发等多次AI浪潮，百度世界已成为全球科技领域的重要盛会之一。 据悉，自2006年以来，百度世界已连续举办近20届，框计算、深度学习框架、无人驾驶、文心4.0等创新成果均曾在大会首次亮相。历届大会见证了深度学习进化、AI大模型崛起和AI应用爆发等多次AI浪潮，百度世界已成为全球科技领域的重要盛会之一。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340982.html", "title": "网约车元老入局自动驾驶：川大校友，前滴滴SVP", "date": "2025-10-13", "content": "网约车元老入局自动驾驶：川大校友，前滴滴SVP 网约车元老入局自动驾驶：川大校友，前滴滴SVP 一凡 2025-10-13 19:05:30 来源： 量子位 一凡 一凡 一凡 一凡 2025-10-13 2025-10-13 19:05:30 19:05:30 来源： 量子位 来源： 量子位 量子位 摘要样式 公司首任总裁 公司首任总裁 公司首任总裁 一凡 发自 副驾寺 一凡 发自 副驾寺 智能车参考 | 公众号 AI4Auto 智能车参考 | 公众号 AI4Auto 出行领域大牛，加盟车联网明星。 出行领域大牛，加盟车联网明星。 智能车参考获悉，前滴滴高级副总裁 付强 已出任 蘑菇车联首任总裁 ，负责公司AI业务和商业化落地。 智能车参考获悉，前滴滴高级副总裁 付强 付强 已出任 蘑菇车联首任总裁 蘑菇车联首任总裁 ，负责公司AI业务和商业化落地。 蘑菇车联专注于车路云一体化赛道，是在车路协同方向上探索Robotaxi的玩家之一，此前开发了路侧基站、云端智慧平台、Robobus等多项产品，打造了交通大模型 MogoMind 。 蘑菇车联专注于车路云一体化赛道，是在车路协同方向上探索Robotaxi的玩家之一，此前开发了路侧基站、云端智慧平台、Robobus等多项产品，打造了交通大模型 MogoMind MogoMind 。 据介绍，MogoMind可捕捉城市中车辆的行驶轨迹、速度变化、交通流量、行人动态等实时数据，预测和分析路段的通行能力，降低拥堵出现的概率，让交通管理更精细，赋能出行。 据介绍，MogoMind可捕捉城市中车辆的行驶轨迹、速度变化、交通流量、行人动态等实时数据，预测和分析路段的通行能力，降低拥堵出现的概率，让交通管理更精细，赋能出行。 出行，正是付强过去十年深耕的领域。 出行，正是付强过去十年深耕的领域。 前滴滴SVP，十年出行老将 前滴滴SVP，十年出行老将 付强出生于1981年，毕业于四川大学，早年曾在强生、葛兰素史克、菲利浦莫里斯(即万宝路)等国际品牌工作。 付强出生于1981年，毕业于四川大学，早年曾在强生、葛兰素史克、菲利浦莫里斯(即万宝路)等国际品牌工作。 2014年，付强进入出行领域，此后5年其职务一年一变。先是加入 快的打车 担任运营总监，后升任副总裁。 2014年，付强进入出行领域，此后5年其职务一年一变。先是加入 快的打车 快的打车 担任运营总监，后升任副总裁。 次年快的与滴滴合并，付强调任 滴滴代驾事业部 ，担任首任总经理。据报道，在其领导下滴滴代驾业务用半年时间拿下市场份额第一，迅速实现盈利，付强也因此积累下战功。 次年快的与滴滴合并，付强调任 滴滴代驾事业部 滴滴代驾事业部 ，担任首任总经理。据报道，在其领导下滴滴代驾业务用半年时间拿下市场份额第一，迅速实现盈利，付强也因此积累下战功。 2016年，付强晋升为 滴滴品质出行事业部总经理 ，统管代驾、专车、豪车等多项业务。2017年共享单车兴起，付强同年7月来到滴滴当时投资的OFO担任执行总裁。 2016年，付强晋升为 滴滴品质出行事业部总经理 滴滴品质出行事业部总经理 ，统管代驾、专车、豪车等多项业务。2017年共享单车兴起，付强同年7月来到滴滴当时投资的OFO担任执行总裁。 不过在2018年，付强很快又回归了滴滴，出任高级副总裁，分管网约车平台和城市运输与服务事业群。 不过在2018年，付强很快又回归了滴滴，出任高级副总裁，分管网约车平台和城市运输与服务事业群。 2023年3年，付强从滴滴离职，加盟聚焦长途货运的 满帮集团 ，担任首席运营官。 2023年3年，付强从滴滴离职，加盟聚焦长途货运的 满帮集团 满帮集团 ，担任首席运营官。 从其职业生涯来看，付强近10年长期领导应用落地，深度参与了移动互联网改变出行方式的全过程。 从其职业生涯来看，付强近10年长期领导应用落地，深度参与了移动互联网改变出行方式的全过程。 现在，出行领域新的浪潮崛起，AI正在走进并改变现实世界，大模型与车联网结合赋予了出行新的想象力。 现在，出行领域新的浪潮崛起，AI正在走进并改变现实世界，大模型与车联网结合赋予了出行新的想象力。 付强正是在这样的时刻，加盟蘑菇车联，回归到熟悉的领域，领导熟悉的流程： 付强正是在这样的时刻，加盟蘑菇车联，回归到熟悉的领域，领导熟悉的流程： 将前沿技术与现实世界连接，重塑出行。 将前沿技术与现实世界连接，重塑出行。 将前沿技术与现实世界连接，重塑出行。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340944.html", "title": "拒绝“熵崩塌”和“熵爆炸”！这项研究让大模型推理成绩飙升", "date": "2025-10-13", "content": "拒绝“熵崩塌”和“熵爆炸”！这项研究让大模型推理成绩飙升 拒绝“熵崩塌”和“熵爆炸”！这项研究让大模型推理成绩飙升 一水 2025-10-13 17:12:43 来源： 量子位 一水 一水 一水 一水 2025-10-13 2025-10-13 17:12:43 17:12:43 来源： 量子位 来源： 量子位 量子位 摘要样式 团队提出了选择性熵正则化方法（SIREN） 团队提出了选择性熵正则化方法（SIREN） 团队提出了选择性熵正则化方法（SIREN） 大语言模型在RLVR训练中面临的“熵困境”，有解了！ 大语言模型在RLVR训练中面临的“熵困境”，有解了！ 2024年以来，以OpenAI o1、DeepSeek-R1、Kimi K1、Qwen3等为代表的大模型，在数学、代码和科学推理任务上取得了显著突破。这些进展很大程度上得益于一种名为RLVR （基于可验证奖励的强化学习）的方法。 2024年以来，以OpenAI o1、DeepSeek-R1、Kimi K1、Qwen3等为代表的大模型，在数学、代码和科学推理任务上取得了显著突破。这些进展很大程度上得益于一种名为RLVR （基于可验证奖励的强化学习）的方法。 该方法通过数学验证、单元测试等 可自动判断对错的方式 提供训练信号，替代了传统依赖人类评判的流程，使模型能够进行大规模、高效率的自我改进。 该方法通过数学验证、单元测试等 可自动判断对错的方式 可自动判断对错的方式 提供训练信号，替代了传统依赖人类评判的流程，使模型能够进行大规模、高效率的自我改进。 然而，RLVR在实践中始终面临“探索机制极易失衡”这一关键瓶颈—— 要么探索受限，陷入熵崩塌；要么探索失控，引发熵爆炸。 然而，RLVR在实践中始终面临“探索机制极易失衡”这一关键瓶颈—— 要么探索受限，陷入熵崩塌；要么探索失控，引发熵爆炸。 要么探索受限，陷入熵崩塌；要么探索失控，引发熵爆炸。 为突破这一瓶颈，来自上海人工智能实验室和复旦大学等机构的研究团队提出 选择性熵正则化方法（SIREN） ，通过 划定探索范围、聚焦关键决策、稳定训练过程 的三重机制，实现了对探索行为的精准调控。 为突破这一瓶颈，来自上海人工智能实验室和复旦大学等机构的研究团队提出 选择性熵正则化方法（SIREN） 选择性熵正则化方法（SIREN） ，通过 划定探索范围、聚焦关键决策、稳定训练过程 划定探索范围、聚焦关键决策、稳定训练过程 的三重机制，实现了对探索行为的精准调控。 实验证明，该方法不仅在多项数学推理基准上取得了显著性能提升，更重要的是，它让模型的探索过程变得更加高效与可控。 实验证明，该方法不仅在多项数学推理基准上取得了显著性能提升，更重要的是，它让模型的探索过程变得更加高效与可控。 下面详细来看—— 下面详细来看—— 核心困境：探索的“两难陷阱” 核心困境：探索的“两难陷阱” 在RLVR训练中，研究人员期望模型能够持续探索多样化的解题路径，以避免过早陷入局部最优。 在RLVR训练中，研究人员期望模型能够持续探索多样化的解题路径，以避免过早陷入局部最优。 一个自然的想法是： 引入熵正则化 （entropy regularization）。 一个自然的想法是： 引入熵正则化 引入熵正则化 （entropy regularization）。 这是强化学习中鼓励探索的经典手段。其核心思想很简单：在优化目标中加入一项， 鼓励模型在每一步生成时保持一定的“不确定性” ，不要过早把概率全压在少数几个词上。 这是强化学习中鼓励探索的经典手段。其核心思想很简单：在优化目标中加入一项， 鼓励模型在每一步生成时保持一定的“不确定性” 鼓励模型在每一步生成时保持一定的“不确定性” ，不要过早把概率全压在少数几个词上。 具体来说，就是计算每一步输出分布的熵（衡量“混乱程度”），再把整条推理轨迹的平均熵加到训练目标里，用一个系数控制探索强度。 具体来说，就是计算每一步输出分布的熵（衡量“混乱程度”），再把整条推理轨迹的平均熵加到训练目标里，用一个系数控制探索强度。 以下公式分别为：熵的计算公式及熵正则的优化目标。 以下公式分别为：熵的计算公式及熵正则的优化目标。 然而，这一策略在大型推理模型（LRM）的复杂场景下却极易走向两个极端： 然而，这一策略在大型推理模型（LRM）的复杂场景下却极易走向两个极端： 探索受限（熵崩塌） 探索受限（熵崩塌） 探索受限（熵崩塌） 探索受限（熵崩塌） 当太小，熵项几乎不起作用，模型迅速退化为近似确定性策略。平均熵迅速收敛，即发生熵崩塌。几轮训练后，所有回答都高度相似，陷入“舒适区”。这种熵崩塌现象不仅扼杀了模型的多样性，也使其推理能力在训练早期就触及天花板，无法充分释放潜力。 当太小，熵项几乎不起作用，模型迅速退化为近似确定性策略。平均熵迅速收敛，即发生熵崩塌。几轮训练后，所有回答都高度相似，陷入“舒适区”。这种熵崩塌现象不仅扼杀了模型的多样性，也使其推理能力在训练早期就触及天花板，无法充分释放潜力。 探索失控（熵爆炸） 探索失控（熵爆炸） 探索失控（熵爆炸） 探索失控（熵爆炸） 反之，当稍大，模型便极易在庞大的动作空间（数十万个token）与超长的推理轨迹（上千步生成）中失控。根据熵的定义，当概率分布越“平”，熵就越高。而在如此庞大的词表中，哪怕只把一点点概率质量从高义词（如“因此”）挪到无意义词（如“<”“#@$%”），也能带来显著的熵增。 反之，当稍大，模型便极易在庞大的动作空间（数十万个token）与超长的推理轨迹（上千步生成）中失控。根据熵的定义，当概率分布越“平”，熵就越高。而在如此庞大的词表中，哪怕只把一点点概率质量从高义词（如“因此”）挪到无意义词（如“<”“#@$%”），也能带来显著的熵增。 更糟的是，在自回归生成中，这种不确定性会沿着轨迹 逐步累积 ——早期几步的微小混乱，会迅速放大为整条推理链的失控。最终使得模型为了“拉高熵”，在 每个位置 、对 每个token 都分配一点概率，导致生成内容充斥无意义符号，逻辑断裂、语义崩坏——这就是典型的 熵爆炸 （entropy explosion）。 更糟的是，在自回归生成中，这种不确定性会沿着轨迹 逐步累积 逐步累积 ——早期几步的微小混乱，会迅速放大为整条推理链的失控。最终使得模型为了“拉高熵”，在 每个位置 每个位置 、对 每个token 每个token 都分配一点概率，导致生成内容充斥无意义符号，逻辑断裂、语义崩坏——这就是典型的 熵爆炸 熵爆炸 （entropy explosion）。 传统方法会失效的根本原因在于： 熵正则化的激励是“无差别”的 ——它假设所有token、所有位置都同等值得探索。但LRM的生成过程具有鲜明的结构性： 传统方法会失效的根本原因在于： 熵正则化的激励是“无差别”的 熵正则化的激励是“无差别”的 ——它假设所有token、所有位置都同等值得探索。但LRM的生成过程具有鲜明的结构性： 在每个生成步骤上，仅有概率排名靠前的少数token具备语义合理性，其余绝大多数token概率趋近于零且无实际意义； 在整个生成序列中，仅有少数承担逻辑枢纽作用的关键词（如逻辑连接词、变量名、结论引导词）真正影响推理走向，而大量用于句法填充的常规词则应保持高确定性，以维持推理连贯性。 在每个生成步骤上，仅有概率排名靠前的少数token具备语义合理性，其余绝大多数token概率趋近于零且无实际意义； 在每个生成步骤上，仅有概率排名靠前的少数token具备语义合理性，其余绝大多数token概率趋近于零且无实际意义； 在整个生成序列中，仅有少数承担逻辑枢纽作用的关键词（如逻辑连接词、变量名、结论引导词）真正影响推理走向，而大量用于句法填充的常规词则应保持高确定性，以维持推理连贯性。 在整个生成序列中，仅有少数承担逻辑枢纽作用的关键词（如逻辑连接词、变量名、结论引导词）真正影响推理走向，而大量用于句法填充的常规词则应保持高确定性，以维持推理连贯性。 正因忽略了这种 “探索价值的非均匀分布” ，传统熵正则化不仅难以有效引导探索，反而容易引发训练不稳定，甚至背离提升推理能力的初衷。 正因忽略了这种 “探索价值的非均匀分布” “探索价值的非均匀分布” ，传统熵正则化不仅难以有效引导探索，反而容易引发训练不稳定，甚至背离提升推理能力的初衷。 下图表明，训练前模型的概率分布高度集中，且只有少量位置在逻辑上关键，值得探索；过度探索后概率被摊薄，生成内容混乱。 下图表明，训练前模型的概率分布高度集中，且只有少量位置在逻辑上关键，值得探索；过度探索后概率被摊薄，生成内容混乱。 破局之道：为探索装上“精准导航” 破局之道：为探索装上“精准导航” 针对传统方法的不足，研究人员提出 选择性熵正则化方法（SIREN） ，通过结构化约束实现探索过程的精细调控。SIREN包含三个核心机制： 针对传统方法的不足，研究人员提出 选择性熵正则化方法（SIREN） 选择性熵正则化方法（SIREN） ，通过结构化约束实现探索过程的精细调控。SIREN包含三个核心机制： 1、划定探索范围（Top-p掩码, Top-P Mask） 1、划定探索范围（Top-p掩码, Top-P Mask） 1、划定探索范围（Top-p掩码, Top-P Mask） 在每个生成步骤中，将熵的计算范围严格限定于概率最高的核心token集合，确保探索仅在语义合理的候选词中进行，避免无效探索。 在每个生成步骤中，将熵的计算范围严格限定于概率最高的核心token集合，确保探索仅在语义合理的候选词中进行，避免无效探索。 2、识别关键决策点（峰值熵掩码，Peak-entropy Mask） 2、识别关键决策点（峰值熵掩码，Peak-entropy Mask） 2、识别关键决策点（峰值熵掩码，Peak-entropy Mask） 自动识别生成序列中熵值显著高于平均水平的逻辑关键词（如推理连接词、假设引导词等），并将探索激励集中作用于这些关键位置。 自动识别生成序列中熵值显著高于平均水平的逻辑关键词（如推理连接词、假设引导词等），并将探索激励集中作用于这些关键位置。 3、稳定训练过程（自锚定正则化, Self-anchored Regularization） 3、稳定训练过程（自锚定正则化, Self-anchored Regularization） 3、稳定训练过程（自锚定正则化, Self-anchored Regularization） 将熵值目标从最大化调整为维持合理区间，通过动态锚定机制使探索强度始终处于可控范围，避免训练失稳。 将熵值目标从最大化调整为维持合理区间，通过动态锚定机制使探索强度始终处于可控范围，避免训练失稳。 这一方法首次在RLVR框架中实现了对探索范围、位置和强度的三重精准控制，为大规模推理模型的稳定训练提供了可靠解决方案。 这一方法首次在RLVR框架中实现了对探索范围、位置和强度的三重精准控制，为大规模推理模型的稳定训练提供了可靠解决方案。 下图为SIREN的方法流程： 下图为SIREN的方法流程： 实验验证：有效探索促进性能提升 实验验证：有效探索促进性能提升 实验结果显示，SIREN在不同模型和数据集上均取得显著提升。 实验结果显示，SIREN在不同模型和数据集上均取得显著提升。 以下为SIREN在Qwen2.5-Math-7B上的实验结果： 以下为SIREN在Qwen2.5-Math-7B上的实验结果： 以及SIREN在其他基座模型上的实验结果： 以及SIREN在其他基座模型上的实验结果： 上述结果表明： 上述结果表明： 在Qwen2.5-Math-7B上，SIREN平均maj@k达 54.6% ，超越最强基线 4.8% 。 在最具挑战的AIME24/25上，提升均达 6.6% 。 在1.5B到8B不同规模、不同基座的模型上均稳定有效。 在Qwen2.5-Math-7B上，SIREN平均maj@k达 54.6% ，超越最强基线 4.8% 。 在Qwen2.5-Math-7B上，SIREN平均maj@k达 54.6% 54.6% ，超越最强基线 4.8% 4.8% 。 在最具挑战的AIME24/25上，提升均达 6.6% 。 在最具挑战的AIME24/25上，提升均达 6.6% 6.6% 。 在1.5B到8B不同规模、不同基座的模型上均稳定有效。 在1.5B到8B不同规模、不同基座的模型上均稳定有效。 那么，这些性能提升从何而来？ 那么，这些性能提升从何而来？ 分析表明，这正是有效探索带来的根本性改变。与传统的熵正则方法相比，SIREN展现出更合理有效的探索模式。 分析表明，这正是有效探索带来的根本性改变。与传统的熵正则方法相比，SIREN展现出更合理有效的探索模式。 下图中，SIREN展现出较高的pass@k，探索边界显著扩展： 下图中，SIREN展现出较高的pass@k，探索边界显著扩展： 还能避免困惑度坍缩，SIREN将答案多样性保持良好： 还能避免困惑度坍缩，SIREN将答案多样性保持良好： 下图表明，先加大探索再缓慢收敛，训练过程平稳可控： 下图表明，先加大探索再缓慢收敛，训练过程平稳可控： 小结 小结 这项研究致力于解决 大语言模型在RLVR训练中面临的策略探索难题 。 这项研究致力于解决 大语言模型在RLVR训练中面临的策略探索难题 大语言模型在RLVR训练中面临的策略探索难题 。 通过系统的实证分析，研究人员发现传统的探索机制在大规模动作空间和长序列生成中极易失衡，导致模型陷入熵崩塌和熵爆炸的困境。 通过系统的实证分析，研究人员发现传统的探索机制在大规模动作空间和长序列生成中极易失衡，导致模型陷入熵崩塌和熵爆炸的困境。 为突破这一瓶颈，团队提出了选择性熵正则化方法（SIREN），通过划定探索范围、聚焦关键决策、稳定训练过程的三重机制，实现了对探索行为的精准调控。实验证明，该方法不仅在多项数学推理基准上取得了显著性能提升，更重要的是，它让模型的探索过程变得更加高效与可控。 为突破这一瓶颈，团队提出了选择性熵正则化方法（SIREN），通过划定探索范围、聚焦关键决策、稳定训练过程的三重机制，实现了对探索行为的精准调控。实验证明，该方法不仅在多项数学推理基准上取得了显著性能提升，更重要的是，它让模型的探索过程变得更加高效与可控。 团队表示，展望未来，随着强化学习成为大模型后训练的主流方法，如何实现稳定、可控、高效的探索，将成为释放大模型潜力、突破性能瓶颈的核心议题。该研究提出的选择性探索调控机制，为探索的精细化提供了一种可行的解决方案。 团队表示，展望未来，随着强化学习成为大模型后训练的主流方法，如何实现稳定、可控、高效的探索，将成为释放大模型潜力、突破性能瓶颈的核心议题。该研究提出的选择性探索调控机制，为探索的精细化提供了一种可行的解决方案。 团队期待这项工作能为下一代推理模型的训练范式提供启发，推动大模型在数学、代码、科学推理等复杂任务以及其他更广阔的应用领域走得更远。 团队期待这项工作能为下一代推理模型的训练范式提供启发，推动大模型在数学、代码、科学推理等复杂任务以及其他更广阔的应用领域走得更远。 论文链接：https://arxiv.org/abs/2509.25133 项目主页：https://github.com/Linn3a/siren 论文链接：https://arxiv.org/abs/2509.25133 项目主页：https://github.com/Linn3a/siren 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340882.html", "title": "Sora2“复活”已故名人，家属强烈反对", "date": "2025-10-13", "content": "Sora2“复活”已故名人，家属强烈反对 Sora2“复活”已故名人，家属强烈反对 时令 2025-10-13 17:06:50 来源： 量子位 时令 时令 时令 时令 2025-10-13 2025-10-13 17:06:50 17:06:50 来源： 量子位 来源： 量子位 量子位 摘要样式 OpenAI接着发表回应 OpenAI接着发表回应 OpenAI接着发表回应 时令 发自 凹非寺 量子位 | 公众号 QbitAI 时令 发自 凹非寺 时令 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI Sora 2的迅速走红，让肖像权问题再次成为焦点。 Sora 2的迅速走红，让肖像权问题再次成为焦点。 毕竟有的人为了博取流量和讨论度，甚至不惜用已故名人生成视频。 毕竟有的人为了博取流量和讨论度，甚至不惜用已故名人生成视频。 比如，Sora2“复活”迈克尔·杰克逊与著名演员罗宾·威廉姆斯，还让他们在街头一起进行即兴表演。 比如，Sora2“复活”迈克尔·杰克逊与著名演员罗宾·威廉姆斯，还让他们在街头一起进行即兴表演。 虽然效果确实很绝，但这些极度逼真的片段，令其家属感到无比气愤与心痛。 虽然效果确实很绝，但这些极度逼真的片段，令其家属感到无比气愤与心痛。 罗宾的女儿泽尔达·威廉姆斯声称： 罗宾的女儿泽尔达·威廉姆斯声称： 拜托，别再给我发爸爸的人工智能视频了。 如果你还有点良心，就别再这样对他、对我，甚至对所有人了。这太蠢了，浪费时间和精力，相信我，这绝对不是他想要的。 拜托，别再给我发爸爸的人工智能视频了。 拜托，别再给我发爸爸的人工智能视频了。 如果你还有点良心，就别再这样对他、对我，甚至对所有人了。这太蠢了，浪费时间和精力，相信我，这绝对不是他想要的。 如果你还有点良心，就别再这样对他、对我，甚至对所有人了。这太蠢了，浪费时间和精力，相信我，这绝对不是他想要的。 这种用已故公众人物生成AI视频的行为也引发了网友们的激烈讨论。 这种用已故公众人物生成AI视频的行为也引发了网友们的激烈讨论。 有人表示，对于那些去世的名人，其肖像权应该由亲属或相关组织继承。 有人表示，对于那些去世的名人，其肖像权应该由亲属或相关组织继承。 还有人认为，对于AI快速发展的今天，版权法确实应该得到更新，不应该让任何人的权利因人工智能的发展而遭到轻视。 还有人认为，对于AI快速发展的今天，版权法确实应该得到更新，不应该让任何人的权利因人工智能的发展而遭到轻视。 下面详细来看。 下面详细来看。 家属表示十分气愤 家属表示十分气愤 众所周知， 罗宾·威廉姆斯 是美国著名演员与喜剧大师，他以即兴表演和在不同影视作品中塑造的众多经典角色而闻名，被公认为史上最杰出的喜剧演员之一。 众所周知， 罗宾·威廉姆斯 罗宾·威廉姆斯 是美国著名演员与喜剧大师，他以即兴表演和在不同影视作品中塑造的众多经典角色而闻名，被公认为史上最杰出的喜剧演员之一。 他的代表作品有《死亡诗社》、《心灵捕手》等，是美国家喻户晓的演员。 他的代表作品有《死亡诗社》、《心灵捕手》等，是美国家喻户晓的演员。 2014年8月11日，罗宾选择在加州家中结束自己的生命，在其生命的最后几年里，他还一直与严重的抑郁症作斗争。 2014年8月11日，罗宾选择在加州家中结束自己的生命，在其生命的最后几年里，他还一直与严重的抑郁症作斗争。 11年后，罗宾再度成为公众讨论的焦点，不是因为他在影坛的成就，竟然是围绕人工智能生成的视频。 11年后，罗宾再度成为公众讨论的焦点，不是因为他在影坛的成就，竟然是围绕人工智能生成的视频。 而这一切的发生还得从Sora2讲起。 而这一切的发生还得从Sora2讲起。 9月底，OpenAI推出新一代视频生成平台Sora2，一经发布，仅用几天时间便冲上了 App Store免费榜第一 ，一度碾压ChatGPT。 9月底，OpenAI推出新一代视频生成平台Sora2，一经发布，仅用几天时间便冲上了 App Store免费榜第一 App Store免费榜第一 ，一度碾压ChatGPT。 但其快速发展的背后，版权方面也属实是堪忧。 但其快速发展的背后，版权方面也属实是堪忧。 对于已故的公众人物罗宾，有人会用其形象生成脱口秀视频，还让他自己“敬业”地表示：“哇！我都不在了，还在巡演俱乐部呢。” 对于已故的公众人物罗宾，有人会用其形象生成脱口秀视频，还让他自己“敬业”地表示：“哇！我都不在了，还在巡演俱乐部呢。” 虽然一些人看到这类视频可能会一笑了之，但对于逝者的家属来说，这种用AI生成的“再现”既触动记忆，也会带来深深的不适和冲击，更何况有人还会刻意将这些视频转发给他们。 虽然一些人看到这类视频可能会一笑了之，但对于逝者的家属来说，这种用AI生成的“再现”既触动记忆，也会带来深深的不适和冲击，更何况有人还会刻意将这些视频转发给他们。 对此，罗宾的女儿公开表示 强烈不满 ， 对此，罗宾的女儿公开表示 强烈不满 强烈不满 ， 别再以为我想看或者我能理解，我不想，也不会理解。如果你只是想戏弄我，更恶毒的招数我都见识过，我会屏蔽，然后继续我的生活。 眼睁睁看着真实人物的传奇一生被简化成“这东西大概看着像、听着像本人，所以就行了”，好让他人能像操纵木偶般摆布他们，炮制出各种糟糕的内容，这简直令人发疯。 你们不是在创作艺术，而是在把人类的生活、艺术和音乐的历史，变成恶心、过度加工的“热狗”，然后硬塞给别人，希望他们给你一个赞，顺便喜欢上它。 别再以为我想看或者我能理解，我不想，也不会理解。如果你只是想戏弄我，更恶毒的招数我都见识过，我会屏蔽，然后继续我的生活。 别再以为我想看或者我能理解，我不想，也不会理解。如果你只是想戏弄我，更恶毒的招数我都见识过，我会屏蔽，然后继续我的生活。 眼睁睁看着真实人物的传奇一生被简化成“这东西大概看着像、听着像本人，所以就行了”，好让他人能像操纵木偶般摆布他们，炮制出各种糟糕的内容，这简直令人发疯。 眼睁睁看着真实人物的传奇一生被简化成“这东西大概看着像、听着像本人，所以就行了”，好让他人能像操纵木偶般摆布他们，炮制出各种糟糕的内容，这简直令人发疯。 你们不是在创作艺术，而是在把人类的生活、艺术和音乐的历史，变成恶心、过度加工的“热狗”，然后硬塞给别人，希望他们给你一个赞，顺便喜欢上它。 你们不是在创作艺术，而是在把人类的生活、艺术和音乐的历史，变成恶心、过度加工的“热狗”，然后硬塞给别人，希望他们给你一个赞，顺便喜欢上它。 这并不是泽尔达第一次抨击关于她父亲的AI合成视频。 这并不是泽尔达第一次抨击关于她父亲的AI合成视频。 2023年，她曾指出用AI技术重现她父亲的声音“令她个人深感不安”，同时警示了这一行为可能带来的更广泛影响。 2023年，她曾指出用AI技术重现她父亲的声音“令她个人深感不安”，同时警示了这一行为可能带来的更广泛影响。 值得一提的是，不单单只有泽尔达，已故喜剧演员乔治·卡林的女儿也表达了类似的观点。她觉得使用她父亲肖像的视频既“令人难以忍受，又令人沮丧”。 值得一提的是，不单单只有泽尔达，已故喜剧演员乔治·卡林的女儿也表达了类似的观点。她觉得使用她父亲肖像的视频既“令人难以忍受，又令人沮丧”。 对此， OpenAI 是如何回应的？ 对此， OpenAI OpenAI 是如何回应的？ 他们表示: 他们表示: 尽管描绘历史人物涉及重要的言论自由权益，但我们认为 公众人物及其家属应最终拥有对其形象使用方式的控制权 。 对于近期逝世的公众人物，其授权代表或遗产所有者可要求不在Sora的客串中使用其肖像。 尽管描绘历史人物涉及重要的言论自由权益，但我们认为 公众人物及其家属应最终拥有对其形象使用方式的控制权 。 尽管描绘历史人物涉及重要的言论自由权益，但我们认为 公众人物及其家属应最终拥有对其形象使用方式的控制权 公众人物及其家属应最终拥有对其形象使用方式的控制权 。 对于近期逝世的公众人物，其授权代表或遗产所有者可要求不在Sora的客串中使用其肖像。 对于近期逝世的公众人物，其授权代表或遗产所有者可要求不在Sora的客串中使用其肖像。 此外，美国电影协会主席Charles Rivkin也强硬表示： 此外，美国电影协会主席Charles Rivkin也强硬表示： 自Sora 2发布以来，侵犯我们成员作品版权的视频已在OpenAI的服务和社交媒体上激增。 尽管OpenAI澄清将“很快”为版权方提供更多控制权，但他们必须承认，防止Sora 2服务上的侵权行为仍是其自身责任，而非版权方的义务。 OpenAI需要立即采取果断行动解决此问题。要有完善的版权法保护创作者权利，在此同样适用。 自Sora 2发布以来，侵犯我们成员作品版权的视频已在OpenAI的服务和社交媒体上激增。 自Sora 2发布以来，侵犯我们成员作品版权的视频已在OpenAI的服务和社交媒体上激增。 尽管OpenAI澄清将“很快”为版权方提供更多控制权，但他们必须承认，防止Sora 2服务上的侵权行为仍是其自身责任，而非版权方的义务。 尽管OpenAI澄清将“很快”为版权方提供更多控制权，但他们必须承认，防止Sora 2服务上的侵权行为仍是其自身责任，而非版权方的义务。 OpenAI需要立即采取果断行动解决此问题。要有完善的版权法保护创作者权利，在此同样适用。 OpenAI需要立即采取果断行动解决此问题。要有完善的版权法保护创作者权利，在此同样适用。 最终，Sora2的版权问题，到底会走向何方呢？ 最终，Sora2的版权问题，到底会走向何方呢？ 参考链接： [1]https://www.washingtonpost.com/technology/2025/10/11/openai-sora-dead-celebrities-ai/ [2]https://www.bbc.co.uk/bitesize/articles/zktm9ty [3]https://www.theguardian.com/film/2025/oct/07/robin-williams-daughter-zelda-hits-out-at-ai-generated-videos-of-her-dead-father 参考链接： [1]https://www.washingtonpost.com/technology/2025/10/11/openai-sora-dead-celebrities-ai/ [2]https://www.bbc.co.uk/bitesize/articles/zktm9ty [3]https://www.theguardian.com/film/2025/oct/07/robin-williams-daughter-zelda-hits-out-at-ai-generated-videos-of-her-dead-father 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340924.html", "title": "推理性能提升10倍！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer", "date": "2025-10-13", "content": "推理性能提升10倍！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer 推理性能提升10倍！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer henry 2025-10-13 17:04:05 来源： 量子位 henry henry henry henry 2025-10-13 2025-10-13 17:04:05 17:04:05 来源： 量子位 来源： 量子位 量子位 摘要样式 首次超越自回归模型！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer 首次超越自回归模型！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer 首次超越自回归模型！蚂蚁集团开源业内首个高性能扩散语言模型推理框架dInfer 10月13日，蚂蚁集团正式开源业界首个高性能扩散语言模型推理框架dInfer。 10月13日，蚂蚁集团正式开源业界首个高性能扩散语言模型推理框架dInfer。 在基准测试中，dInfer将扩散语言模型的推理速度相比于英伟达扩散模型框架Fast-dLLM提升了10.7倍；在代码生成任务HumanEval上，dInfer在单批次推理中创造了1011Tokens/秒的速度，首次在开源社区中实现扩散语言模型的单批次推理速度显著超越自回归模型。dInfer的工作表明，扩散语言模型具备显著的效率潜力，可以通过系统性的创新工程兑现，为通往AGI的架构路径提供极具竞争力的选项。 在基准测试中，dInfer将扩散语言模型的推理速度相比于英伟达扩散模型框架Fast-dLLM提升了10.7倍；在代码生成任务HumanEval上，dInfer在单批次推理中创造了1011Tokens/秒的速度，首次在开源社区中实现扩散语言模型的单批次推理速度显著超越自回归模型。dInfer的工作表明，扩散语言模型具备显著的效率潜力，可以通过系统性的创新工程兑现，为通往AGI的架构路径提供极具竞争力的选项。 扩散语言模型，作为一种全新的范式将文本生成视为一个“从随机噪声中逐步恢复完整序列”的去噪过程，具有高度并行、全局视野、结构灵活三大优势。凭借这些优势，以蚂蚁集团和人大发布的LLaDA-MoE为代表的模型已在多个基准测试中，展现出与顶尖AR模型相媲美的准确性 。然而在推理效率方面，dLLM理论上的强大潜能，却长期被残酷的现实“枷锁”所束缚。dLLM的高效推理面临计算成本高、KV缓存失效、并行解码三大挑战。这些瓶颈使得扩散语言模型的推理速度一直不尽人意，如何打破枷锁释放扩散语言模型在推理效率上的潜能，成为整个领域亟待解决的难题。 扩散语言模型，作为一种全新的范式将文本生成视为一个“从随机噪声中逐步恢复完整序列”的去噪过程，具有高度并行、全局视野、结构灵活三大优势。凭借这些优势，以蚂蚁集团和人大发布的LLaDA-MoE为代表的模型已在多个基准测试中，展现出与顶尖AR模型相媲美的准确性 。然而在推理效率方面，dLLM理论上的强大潜能，却长期被残酷的现实“枷锁”所束缚。dLLM的高效推理面临计算成本高、KV缓存失效、并行解码三大挑战。这些瓶颈使得扩散语言模型的推理速度一直不尽人意，如何打破枷锁释放扩散语言模型在推理效率上的潜能，成为整个领域亟待解决的难题。 dInfer是一款专为扩散语言模型设计的、算法与系统深度协同的高性能推理框架 ，可支持多种扩散语言模型，包括 LLaDA、 LLaDA-MoE、LLaDA-MoE-TD 等。 dInfer是一款专为扩散语言模型设计的、算法与系统深度协同的高性能推理框架 ，可支持多种扩散语言模型，包括 LLaDA、 LLaDA-MoE、LLaDA-MoE-TD 等。 dInfer包含四大核心模块：模型接入（Model）、KV缓存管理器（KV-Cache Manager），扩散迭代管理器（Iteration Manager），和解码策略（Decoder）。这种可插拔的架构，允许开发者像搭乐高一样，进一步组合和探索不同模块的优化策略，并在统一的平台上进行标准化评测 。更重要的是，dInfer针对上述三大挑战，在每个模块中都集成了针对性的解决方案。 dInfer包含四大核心模块：模型接入（Model）、KV缓存管理器（KV-Cache Manager），扩散迭代管理器（Iteration Manager），和解码策略（Decoder）。这种可插拔的架构，允许开发者像搭乐高一样，进一步组合和探索不同模块的优化策略，并在统一的平台上进行标准化评测 。更重要的是，dInfer针对上述三大挑战，在每个模块中都集成了针对性的解决方案。 （图说：dInfer的架构） （图说：dInfer的架构） 在配备8块NVIDIA H800 GPU的节点上，dInfer的性能表现令人瞩目： 在配备8块NVIDIA H800 GPU的节点上，dInfer的性能表现令人瞩目： 在与先前的dLLM推理方案Fast-dLLM的对比中，dInfer在模型效果持平的情况下，平均推理速度（avg TPS）实现了10.7倍的巨大提升（681 vs 63.6） ；在代码生成任务HumanEval上，dInfer在单批次推理中创造了1011 tokens/秒的速度 ；与在业界顶尖的推理服务框架vLLM上运行的、参数量和性能相当的AR模型Qwen2.5-3B相比，dInfer的平均推理速度是其2.5倍（681 vs 277） 。 在与先前的dLLM推理方案Fast-dLLM的对比中，dInfer在模型效果持平的情况下，平均推理速度（avg TPS）实现了10.7倍的巨大提升（681 vs 63.6） ；在代码生成任务HumanEval上，dInfer在单批次推理中创造了1011 tokens/秒的速度 ；与在业界顶尖的推理服务框架vLLM上运行的、参数量和性能相当的AR模型Qwen2.5-3B相比，dInfer的平均推理速度是其2.5倍（681 vs 277） 。 蚂蚁集团介绍，dInfer连接了前沿研究与产业落地，标志着扩散语言模型从“理论可行”迈向“实践高效”的关键一步。此次开预案，也是诚邀全球的开发者与研究者共同探索扩散语言模型的巨大潜能，构建更加高效、开放的AI新生态。 蚂蚁集团介绍，dInfer连接了前沿研究与产业落地，标志着扩散语言模型从“理论可行”迈向“实践高效”的关键一步。此次开预案，也是诚邀全球的开发者与研究者共同探索扩散语言模型的巨大潜能，构建更加高效、开放的AI新生态。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340883.html", "title": "真正的AI竞争力，藏在大模型“后训练”这一步", "date": "2025-10-13", "content": "真正的AI竞争力，藏在大模型“后训练”这一步 真正的AI竞争力，藏在大模型“后训练”这一步 十三 2025-10-13 16:55:40 来源： 量子位 十三 十三 十三 十三 2025-10-13 2025-10-13 16:55:40 16:55:40 来源： 量子位 来源： 量子位 量子位 摘要样式 后训练正在重塑企业AI 后训练正在重塑企业AI 后训练正在重塑企业AI 三石 发自 凹非寺 量子位 | 公众号 QbitAI 三石 发自 凹非寺 三石 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 当全球的目光还在聚焦基座模型的参数竞赛时，一场更为深刻的变革正在悄然发生—— 后训练（Post-Training） 。 当全球的目光还在聚焦基座模型的参数竞赛时，一场更为深刻的变革正在悄然发生—— 后训练（Post-Training） 后训练（Post-Training） 。 产业早已达成的共识是：大模型后训练不再是简单的模型优化，而是AI落地产业的必经之路。这意味着，企业需要将通用的基座模型，训练成深度理解自身业务、具备领域知识、并能执行复杂策略的“专属智能引擎”。 产业早已达成的共识是：大模型后训练不再是简单的模型优化，而是AI落地产业的必经之路。这意味着，企业需要将通用的基座模型，训练成深度理解自身业务、具备领域知识、并能执行复杂策略的“专属智能引擎”。 而后训练技术本身也正在经历着日新月异的技术变迁。 而后训练技术本身也正在经历着日新月异的技术变迁。 Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清在2025云栖大会《大模型后训练：打造企业专属智能引擎》论坛上清晰地勾勒了这条演进路径——最初，行业普遍采用 SFT （Supervised Fine-Tuning，监督微调）的方式，让模型学习特定领域的知识和对话风格。 Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清在2025云栖大会《大模型后训练：打造企业专属智能引擎》论坛上清晰地勾勒了这条演进路径——最初，行业普遍采用 SFT SFT （Supervised Fine-Tuning，监督微调）的方式，让模型学习特定领域的知识和对话风格。 然而，简单的监督学习却无法教会模型进行复杂的价值判断和策略选择——这恰恰是企业真实业务场景中的核心需求。 然而，简单的监督学习却无法教会模型进行复杂的价值判断和策略选择——这恰恰是企业真实业务场景中的核心需求。 于是，技术的焦点 从“模仿”转向“对齐”，从监督微调（SFT）进化至以目标为导向的强化学习（RL）范式。 于是，技术的焦点 从“模仿”转向“对齐”，从监督微调（SFT）进化至以目标为导向的强化学习（RL）范式。 从“模仿”转向“对齐”，从监督微调（SFT）进化至以目标为导向的强化学习（RL）范式。 而在强化学习的实践路径上，产业界又经历了一场从“依赖人力”到“追求自动化”的深刻迭代： 从早期的RLHF(基于人类反馈的强化学习)，到突破性的RLVR(基于可验证反馈的强化学习)，再到前沿的“自然语言奖励”。 而在强化学习的实践路径上，产业界又经历了一场从“依赖人力”到“追求自动化”的深刻迭代： 从早期的RLHF(基于人类反馈的强化学习)，到突破性的RLVR(基于可验证反馈的强化学习)，再到前沿的“自然语言奖励”。 从早期的RLHF(基于人类反馈的强化学习)，到突破性的RLVR(基于可验证反馈的强化学习)，再到前沿的“自然语言奖励”。 从后训练技术演进路径中，我们也能清晰看到企业“之所以要做后训练”的答案： 通过对模型的特定能力增强，解决商业世界的复杂任务，构建通用模型无法达到的竞争壁垒。 从后训练技术演进路径中，我们也能清晰看到企业“之所以要做后训练”的答案： 通过对模型的特定能力增强，解决商业世界的复杂任务，构建通用模型无法达到的竞争壁垒。 通过对模型的特定能力增强，解决商业世界的复杂任务，构建通用模型无法达到的竞争壁垒。 △图：Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清分享后训练技术。 △图：Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清分享后训练技术。 △图：Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清分享后训练技术。 企业大模型后训练的四步落地路径 企业大模型后训练的四步落地路径 在企业实际应用中，后训练之路往往伴随着数据质量差、标注成本高、奖励信号与评估体系难定义等一系列挑战。 在企业实际应用中，后训练之路往往伴随着数据质量差、标注成本高、奖励信号与评估体系难定义等一系列挑战。 如何高效、成本可控地为后训练准备高质量数据？如何将模糊的商业目标转化为模型训练信号？如何让模型做出符合业务逻辑的判断？又该如何量化后训练技术带来的实际业务回报？ 如何高效、成本可控地为后训练准备高质量数据？如何将模糊的商业目标转化为模型训练信号？如何让模型做出符合业务逻辑的判断？又该如何量化后训练技术带来的实际业务回报？ 云栖大会《大模型后训练：打造企业专属智能引擎》论坛上，来自 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创等企业的多位实践者，已率先跑通了从技术实践到商业价值的闭环 ： 云栖大会《大模型后训练：打造企业专属智能引擎》论坛上，来自 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创等企业的多位实践者，已率先跑通了从技术实践到商业价值的闭环 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创等企业的多位实践者，已率先跑通了从技术实践到商业价值的闭环 ： 知乎用“大模型预打标+主动学习”提升数据质量；汽车之家利用结构化私域数据做增量预训练，并结合KAG（基于领域知识图谱的内容生成）抑制幻觉，确保回答精准；百融云创构建工业化数据生产线，提纯话术并优化训练数据，使回答质量提升10%，违规率从1%降至千分之三；微博与网易伏羲通过模型蒸馏，在降低成本的同时实现高效内容理解；盈米基金设计融合专家逻辑的奖励函数，其4B模型准确性指标甚至超过通用32B模型，实现高商业回报；夸克则通过后训练复刻专家思维，2025年为高考志愿填报场景生成超1200万份报告，服务4000万用户，实现专家级服务的规模化普惠。 知乎用“大模型预打标+主动学习”提升数据质量；汽车之家利用结构化私域数据做增量预训练，并结合KAG（基于领域知识图谱的内容生成）抑制幻觉，确保回答精准；百融云创构建工业化数据生产线，提纯话术并优化训练数据，使回答质量提升10%，违规率从1%降至千分之三；微博与网易伏羲通过模型蒸馏，在降低成本的同时实现高效内容理解；盈米基金设计融合专家逻辑的奖励函数，其4B模型准确性指标甚至超过通用32B模型，实现高商业回报；夸克则通过后训练复刻专家思维，2025年为高考志愿填报场景生成超1200万份报告，服务4000万用户，实现专家级服务的规模化普惠。 这些优秀实践背后，浮现出一条企业应用大模型后训练从技术实践到商业价值的完整链路：一是准备高质量的数据（Data），二是选择合适的基座模型（Model）降低工程门槛，三是设计有效的奖励机制（Reward），四是构建可量化的模型评测（Evaluation），挂钩业务指标。 这些优秀实践背后，浮现出一条企业应用大模型后训练从技术实践到商业价值的完整链路：一是准备高质量的数据（Data），二是选择合适的基座模型（Model）降低工程门槛，三是设计有效的奖励机制（Reward），四是构建可量化的模型评测（Evaluation），挂钩业务指标。 第一步：准备高质量数据，奠定后训练基石 第一步：准备高质量数据，奠定后训练基石 第一步：准备高质量数据，奠定后训练基石 企业落地大模型后训练的第一步，就是为模型注入领域知识。 企业落地大模型后训练的第一步，就是为模型注入领域知识。 “数据是后训练的基石，数据质量决定了后训练效果的上限。企业做大模型后训练，超过一半甚至60%-70%的时间都花费在数据准备上。” 知乎AI团队负责人王界武在云栖大会《大模型后训练：打造企业专属智能引擎》论坛上的观点引发了全场共鸣。 “数据是后训练的基石，数据质量决定了后训练效果的上限。企业做大模型后训练，超过一半甚至60%-70%的时间都花费在数据准备上。” “数据是后训练的基石，数据质量决定了后训练效果的上限。企业做大模型后训练，超过一半甚至60%-70%的时间都花费在数据准备上。” 知乎AI团队负责人王界武在云栖大会《大模型后训练：打造企业专属智能引擎》论坛上的观点引发了全场共鸣。 数据准备的核心挑战在于，原始数据质量参差不齐，包含大量噪声、冗余和低价值信息，企业的自有数据专业且垂直，直接用于训练会导致模型“学坏”或效果不佳。 数据准备的核心挑战在于，原始数据质量参差不齐，包含大量噪声、冗余和低价值信息，企业的自有数据专业且垂直，直接用于训练会导致模型“学坏”或效果不佳。 根据王界武介绍，知乎的后训练大模型已深入应用于AI搜索、内容安全、内容理解等多个核心场景。知乎社区本身积累的优质语料成为最宝贵的数据资产，此外知乎还整合了开源数据。 根据王界武介绍，知乎的后训练大模型已深入应用于AI搜索、内容安全、内容理解等多个核心场景。知乎社区本身积累的优质语料成为最宝贵的数据资产，此外知乎还整合了开源数据。 “ 数据阶段最大的挑战在于高质量数据。 现在很多场景必须要采用人工标注，但成本非常高；偏主观的场景下，人工标注的结果一致性也没那么好”，王界武介绍道，知乎走出的一条行之有效的方法是：通过大模型进行预打标，采用主动学习（Active Learning）聚焦困难样本，提升数据效率，持续构建多源、高质量的训练数据集，支撑不同业务场景下的后训练需求。 “ 数据阶段最大的挑战在于高质量数据。 数据阶段最大的挑战在于高质量数据。 现在很多场景必须要采用人工标注，但成本非常高；偏主观的场景下，人工标注的结果一致性也没那么好”，王界武介绍道，知乎走出的一条行之有效的方法是：通过大模型进行预打标，采用主动学习（Active Learning）聚焦困难样本，提升数据效率，持续构建多源、高质量的训练数据集，支撑不同业务场景下的后训练需求。 “实践证明，花精力生成100条高质量的数据，可能比多调一次模型带来的效果提升更大。” 王界武说。 “实践证明，花精力生成100条高质量的数据，可能比多调一次模型带来的效果提升更大。” “实践证明，花精力生成100条高质量的数据，可能比多调一次模型带来的效果提升更大。” 王界武说。 数据难题同样摆在汽车之家面前。对于消费者而言，买车是典型的重决策场景，因为用户需要绝对精准的参数、价格、政策信息。通用大模型一旦出现幻觉，给错了配置或价格，对用户和平台来说都可能是致命的。 数据难题同样摆在汽车之家面前。对于消费者而言，买车是典型的重决策场景，因为用户需要绝对精准的参数、价格、政策信息。通用大模型一旦出现幻觉，给错了配置或价格，对用户和平台来说都可能是致命的。 汽车之家仓颉大模型团队负责人马宝昌介绍道， 汽车之家利用其20年来积累的结构化私域数据（车型、参数、评测等），对通义千问基座模型进行增量预训练（CPT） ，相当于让模型先“通读”一遍汽车领域的专业书籍，在进入更精细的SFT和RL训练之前，就打下坚实的知识基础。 汽车之家仓颉大模型团队负责人马宝昌介绍道， 汽车之家利用其20年来积累的结构化私域数据（车型、参数、评测等），对通义千问基座模型进行增量预训练（CPT） 汽车之家利用其20年来积累的结构化私域数据（车型、参数、评测等），对通义千问基座模型进行增量预训练（CPT） ，相当于让模型先“通读”一遍汽车领域的专业书籍，在进入更精细的SFT和RL训练之前，就打下坚实的知识基础。 汽车之家还利用阿里云Data-Juicer框架构建数据处理pipeline，混合通用数据和汽车领域数据，确保模型在提升领域效果的同时保持通用能力，为后续的精准问答和推理奠定基础。 汽车之家还利用阿里云Data-Juicer框架构建数据处理pipeline，混合通用数据和汽车领域数据，确保模型在提升领域效果的同时保持通用能力，为后续的精准问答和推理奠定基础。 针对企业数据工程化处理的痛点，阿里云智能集团计算平台事业部解决方案负责人魏博文介绍，阿里云升级了大数据引擎，并联合通义团队开源了Data-Juicer库，将复杂的数据预处理流程封装为易用的算子和Pipeline，大大降低了企业数据准备的门槛。 针对企业数据工程化处理的痛点，阿里云智能集团计算平台事业部解决方案负责人魏博文介绍，阿里云升级了大数据引擎，并联合通义团队开源了Data-Juicer库，将复杂的数据预处理流程封装为易用的算子和Pipeline，大大降低了企业数据准备的门槛。 △图：汽车之家仓颉大模型团队负责人马宝昌分享汽车之家后训练实践 △图：汽车之家仓颉大模型团队负责人马宝昌分享汽车之家后训练实践 △图：汽车之家仓颉大模型团队负责人马宝昌分享汽车之家后训练实践 百融云创是一家To B的人工智能技术服务公司，百融云创大模型首席算法科学家苏海波介绍，“在金融营销、催收等场景下，我们希望通过后训练炼出一位能主动挽留、主动谈判的金牌销售专家。而后训练所需的人工销售的原始通话数据包含大量口语词、叠字、错别字，且人工回答水平不一。” 百融云创是一家To B的人工智能技术服务公司，百融云创大模型首席算法科学家苏海波介绍，“在金融营销、催收等场景下，我们希望通过后训练炼出一位能主动挽留、主动谈判的金牌销售专家。而后训练所需的人工销售的原始通话数据包含大量口语词、叠字、错别字，且人工回答水平不一。” 百融云创建立了一条工业化的数据生产线：首先通过模型自动过滤掉不合规、回答错误的数据，然后利用大模型自动校正文本中的错别字、重复和口语化表达，大幅减轻对高成本的人工校对的需求；再对人工话术进行润色和优化，提升话术质量；最后，通过数据合成的方式，扩充高质量的种子数据。这一系列流程，将原始数据变成了模型可以理解的高质量数据。 百融云创建立了一条工业化的数据生产线：首先通过模型自动过滤掉不合规、回答错误的数据，然后利用大模型自动校正文本中的错别字、重复和口语化表达，大幅减轻对高成本的人工校对的需求；再对人工话术进行润色和优化，提升话术质量；最后，通过数据合成的方式，扩充高质量的种子数据。这一系列流程，将原始数据变成了模型可以理解的高质量数据。 第二步：选择合适的基座模型，匹配业务需求 第二步：选择合适的基座模型，匹配业务需求 第二步：选择合适的基座模型，匹配业务需求 有数据，要有好模型。选对基座模型是后训练成功的一半。 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创 等企业都不约而同地选择了通义千问系列模型。 有数据，要有好模型。选对基座模型是后训练成功的一半。 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创 网易、汽车之家、微博、夸克、知乎、盈米基金、百融云创 等企业都不约而同地选择了通义千问系列模型。 汽车之家仓颉大模型团队负责人马宝昌解释道：“首先，通义千问的模型效果非常领先；其次，其尺寸覆盖广泛，从几亿参数的小模型到千亿级的大模型一应俱全，能满足不同场景对性能和成本的平衡需求；最后，其架构设计和开源生态对后训练深度支持。如Data-Juicer等数据处理框架和高效的训练框架，让企业在后训练时没有后顾之忧。” 汽车之家仓颉大模型团队负责人马宝昌解释道：“首先，通义千问的模型效果非常领先；其次，其尺寸覆盖广泛，从几亿参数的小模型到千亿级的大模型一应俱全，能满足不同场景对性能和成本的平衡需求；最后，其架构设计和开源生态对后训练深度支持。如Data-Juicer等数据处理框架和高效的训练框架，让企业在后训练时没有后顾之忧。” 阿里云是国内最早开源自研大模型的“大厂”，也是全球唯一一家积极研发先进AI模型并且全方位开源的云计算厂商 ，业界率先实现“全尺寸、全模态”的全面开源。从2023年至今，阿里通义团队已开源300多款模型，包含大语言模型通义千问及视觉生成模型通义万相等两大基模系列，开源囊括文本生成模型、视觉理解/生成模型、语音理解/生成模型、文生图及视频模型等全模态。 阿里云是国内最早开源自研大模型的“大厂”，也是全球唯一一家积极研发先进AI模型并且全方位开源的云计算厂商 阿里云是国内最早开源自研大模型的“大厂”，也是全球唯一一家积极研发先进AI模型并且全方位开源的云计算厂商 ，业界率先实现“全尺寸、全模态”的全面开源。从2023年至今，阿里通义团队已开源300多款模型，包含大语言模型通义千问及视觉生成模型通义万相等两大基模系列，开源囊括文本生成模型、视觉理解/生成模型、语音理解/生成模型、文生图及视频模型等全模态。 目前，通义千问衍生模型数量已突破17万，超越美国Llama模型，通义成为全球第一AI开源模型。通义千问在全球下载量超过6亿，在HuggingFace社区2024年全球模型下载量中千问占比超30%，稳居第一。 目前，通义千问衍生模型数量已突破17万，超越美国Llama模型，通义成为全球第一AI开源模型。通义千问在全球下载量超过6亿，在HuggingFace社区2024年全球模型下载量中千问占比超30%，稳居第一。 更难能可贵的是， 通义千问在开源的同时，开放了训练策略和配套方案。 更难能可贵的是， 通义千问在开源的同时，开放了训练策略和配套方案。 通义千问在开源的同时，开放了训练策略和配套方案。 根据通义实验室算法科学家郁博文介绍，通义千问3在发布时即配套提供量化、蒸馏或推理加速方案，在开源的同时能获得VLLM、SGLang等开源社区项目的Day 0适配支持，并提供FP8、AWQ和GGUF等各种格式的量化模型供社区使用，间接提升了后训练成果的可用性 。 根据通义实验室算法科学家郁博文介绍，通义千问3在发布时即配套提供量化、蒸馏或推理加速方案，在开源的同时能获得VLLM、SGLang等开源社区项目的Day 0适配支持，并提供FP8、AWQ和GGUF等各种格式的量化模型供社区使用，间接提升了后训练成果的可用性 。 企业进行后训练的另一大挑战在于 工程化落地 。阿里云智能集团计算平台事业部解决方案负责人魏博文介绍，阿里云人工智能平台PAI打造了一套全栈解决方案，帮助企业的大模型后训练应对算力、工程化和部署三大障碍。 企业进行后训练的另一大挑战在于 工程化落地 工程化落地 。阿里云智能集团计算平台事业部解决方案负责人魏博文介绍，阿里云人工智能平台PAI打造了一套全栈解决方案，帮助企业的大模型后训练应对算力、工程化和部署三大障碍。 针对主流的MoE架构强大的算力与训练框架，阿里云人工智能平台PAI通过自适应通信计算掩盖、负载均衡等技术，实测可将通义千问3的训练端到端提效3倍；阿里云人工智能平台PAI提供了针对MoE模型的高性能推理框架，可将推理吞吐提升70%以上。更重要的是，所有复杂技术都被封装进了低代码环境中，用户通过点选即可一键式完成从模型选择、后训练、测评到部署的全流程。 针对主流的MoE架构强大的算力与训练框架，阿里云人工智能平台PAI通过自适应通信计算掩盖、负载均衡等技术，实测可将通义千问3的训练端到端提效3倍；阿里云人工智能平台PAI提供了针对MoE模型的高性能推理框架，可将推理吞吐提升70%以上。更重要的是，所有复杂技术都被封装进了低代码环境中，用户通过点选即可一键式完成从模型选择、后训练、测评到部署的全流程。 企业选定基模后，需通过技术手段让模型与业务目标对齐，不仅要注入知识，更要使其具备专家级的决策能力，并兼顾效果、成本与响应速度，许多企业因此选择了模型蒸馏方案。 企业选定基模后，需通过技术手段让模型与业务目标对齐，不仅要注入知识，更要使其具备专家级的决策能力，并兼顾效果、成本与响应速度，许多企业因此选择了模型蒸馏方案。 企业选定基模后，需通过技术手段让模型与业务目标对齐，不仅要注入知识，更要使其具备专家级的决策能力，并兼顾效果、成本与响应速度，许多企业因此选择了模型蒸馏方案。 微博内容理解技术总监贾遂宾介绍，面对每天数千万条内容，直接部署百亿甚至千亿参数的大模型成本过高。 微博内容理解技术总监贾遂宾介绍，面对每天数千万条内容，直接部署百亿甚至千亿参数的大模型成本过高。 微博的做法是，先用海量高质量数据对通义千问多模态大模型进行预训练，使其具备强大的内容理解能力，然后将这个强大的多模态模型的能力，“蒸馏”到一个更轻量的7B（70亿参数）模型上。 微博的做法是，先用海量高质量数据对通义千问多模态大模型进行预训练，使其具备强大的内容理解能力，然后将这个强大的多模态模型的能力，“蒸馏”到一个更轻量的7B（70亿参数）模型上。 这样既获得了接近大模型的效果，又能以更低的成本，对微博海量内容应用内容甄别、标签识别等任务。实现了效果与效率的更好平衡。 这样既获得了接近大模型的效果，又能以更低的成本，对微博海量内容应用内容甄别、标签识别等任务。实现了效果与效率的更好平衡。 经过后训练，微博的内容理解中台对一条看似日常的明星演唱会视频，能生成“娱乐明星、内地明星、华语音乐、明星饭拍路透、音乐演出”等极为精细且准确的多层级标签，这一效果是通用大模型难以企及的。 经过后训练，微博的内容理解中台对一条看似日常的明星演唱会视频，能生成“娱乐明星、内地明星、华语音乐、明星饭拍路透、音乐演出”等极为精细且准确的多层级标签，这一效果是通用大模型难以企及的。 △图：微博内容理解技术总监贾遂宾介绍微博的多模态垂直大模型后训练 △图：微博内容理解技术总监贾遂宾介绍微博的多模态垂直大模型后训练 △图：微博内容理解技术总监贾遂宾介绍微博的多模态垂直大模型后训练 网易伏羲在游戏智能NPC场景中，同样面临实时互动的低时延要求和大规模部署的成本压力。 网易伏羲在游戏智能NPC场景中，同样面临实时互动的低时延要求和大规模部署的成本压力。 据网易伏羲语言智能组负责人张荣升介绍，网易伏羲采用大模型蒸馏+轻量化部署技术方案，确保高质量的AI交互体验能以可接受的成本，覆盖上千万玩家。 据网易伏羲语言智能组负责人张荣升介绍，网易伏羲采用大模型蒸馏+轻量化部署技术方案，确保高质量的AI交互体验能以可接受的成本，覆盖上千万玩家。 △图：网易伏羲语言智能组负责人张荣升在云栖大会《大模型后训练：打造企业专属智能引擎》论坛分享。 △图：网易伏羲语言智能组负责人张荣升在云栖大会《大模型后训练：打造企业专属智能引擎》论坛分享。 △图：网易伏羲语言智能组负责人张荣升在云栖大会《大模型后训练：打造企业专属智能引擎》论坛分享。 第三步：设计奖励机制，教会模型何为“好”与“坏” 第三步：设计奖励机制，教会模型何为“好”与“坏” 第三步：设计奖励机制，教会模型何为“好”与“坏” 在大模型后训练中，奖励机制（Reward Mechanism）的核心任务是将复杂的商业目标和人类偏好，转化为模型在训练过程中能够学习和优化的数值信号。 它不是简单地判断对错，而是为模型提供一个“导航”，告诉它在无数可能的输出中，哪些行为更接近“好”的标准。 在大模型后训练中，奖励机制（Reward Mechanism）的核心任务是将复杂的商业目标和人类偏好，转化为模型在训练过程中能够学习和优化的数值信号。 在大模型后训练中，奖励机制（Reward Mechanism）的核心任务是将复杂的商业目标和人类偏好，转化为模型在训练过程中能够学习和优化的数值信号。 它不是简单地判断对错，而是为模型提供一个“导航”，告诉它在无数可能的输出中，哪些行为更接近“好”的标准。 Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清介绍，强化学习的初级形态 RLHF (基于人类反馈的强化学习)，依赖人类标注员对模型输出进行打分，以此作为奖励信号。这种方式虽能对齐主观偏好，但受限于高昂的成本与数据标注质量，泛化能力存在瓶颈。 Pokee.ai创始人、Meta前应用强化学习部门负责人朱哲清介绍，强化学习的初级形态 RLHF RLHF (基于人类反馈的强化学习)，依赖人类标注员对模型输出进行打分，以此作为奖励信号。这种方式虽能对齐主观偏好，但受限于高昂的成本与数据标注质量，泛化能力存在瓶颈。 真正的突破来自于RLVR(基于可验证反馈的强化学习)。它在代码、数学等拥有客观评判标准的领域，通过构建自动化验证系统作为奖励模型，实现了“规则即奖励”的闭环，从而摆脱了对人力标注的依赖。 真正的突破来自于RLVR(基于可验证反馈的强化学习)。它在代码、数学等拥有客观评判标准的领域，通过构建自动化验证系统作为奖励模型，实现了“规则即奖励”的闭环，从而摆脱了对人力标注的依赖。 然而，现实世界的商业逻辑远比代码和数学要复杂，许多标准无法用简单的规则来定义。 然而，现实世界的商业逻辑远比代码和数学要复杂，许多标准无法用简单的规则来定义。 然而，现实世界的商业逻辑远比代码和数学要复杂，许多标准无法用简单的规则来定义。 朱哲清指出，“ 业界的前沿趋势是利用大模型本身作为评判者，即‘自然语言奖励’ （Natural Language Reward）”——通过将复杂的文本序列输入一个强大的判别模型，直接通过自然语言指令询问“这个证明是对是错，错在哪里？”，由模型来判断，其表述能力和覆盖范围远超僵化的规则系统。 朱哲清指出，“ 业界的前沿趋势是利用大模型本身作为评判者，即‘自然语言奖励’ 业界的前沿趋势是利用大模型本身作为评判者，即‘自然语言奖励’ （Natural Language Reward）”——通过将复杂的文本序列输入一个强大的判别模型，直接通过自然语言指令询问“这个证明是对是错，错在哪里？”，由模型来判断，其表述能力和覆盖范围远超僵化的规则系统。 盈米基金 的智能投顾场景正在探索奖励机制。 盈米基金 盈米基金 的智能投顾场景正在探索奖励机制。 盈米基金CTO刘永介绍道，“资产配置投资顾问可以说是信任和专业度要求最高的领域之一，对精准性要求高、对幻觉容忍度极低。智能投顾把钱放进去只是个开始，之后怎么办？什么叫投资好、体验好？什么叫不好？这是核心难题。” 盈米基金CTO刘永介绍道，“资产配置投资顾问可以说是信任和专业度要求最高的领域之一，对精准性要求高、对幻觉容忍度极低。智能投顾把钱放进去只是个开始，之后怎么办？什么叫投资好、体验好？什么叫不好？这是核心难题。” 对此， 盈米基金选择的解法便是与阿里云合作，核心目标是将人类投顾专家的解题框架和风控逻辑内置到模型中 ，探索可行的、可落地的奖励函数设计。双方 基于事实规则和长期客户的真实反馈数据 ，来探索和定义适用于基金投顾场景的奖励函数。 对此， 盈米基金选择的解法便是与阿里云合作，核心目标是将人类投顾专家的解题框架和风控逻辑内置到模型中 盈米基金选择的解法便是与阿里云合作，核心目标是将人类投顾专家的解题框架和风控逻辑内置到模型中 ，探索可行的、可落地的奖励函数设计。双方 基于事实规则和长期客户的真实反馈数据 基于事实规则和长期客户的真实反馈数据 ，来探索和定义适用于基金投顾场景的奖励函数。 汽车之家仓颉大模型团队负责人马宝昌分享道，他们对模型的要求极为严格，对“幻觉”容忍度极低；性能方面，推理延迟要足够低，满足实时交互需求。在模型上线后，会通过A/B测试等方式，关注用户的 最终转化率 ，如是否留资、是否购车等，来衡量其对核心业务的贡献。同时结合准确率达到99.5%以上的KAG（基于领域知识图谱的内容生成），让模型回答真实可信。 汽车之家仓颉大模型团队负责人马宝昌分享道，他们对模型的要求极为严格，对“幻觉”容忍度极低；性能方面，推理延迟要足够低，满足实时交互需求。在模型上线后，会通过A/B测试等方式，关注用户的 最终转化率 最终转化率 ，如是否留资、是否购车等，来衡量其对核心业务的贡献。同时结合准确率达到99.5%以上的KAG（基于领域知识图谱的内容生成），让模型回答真实可信。 第四步：构建评估体系，确保投入回报 第四步：构建评估体系，确保投入回报 第四步：构建评估体系，确保投入回报 模型评估是衡量后训练成效的最终标尺，其核心在于用客观、可量化的结果证明技术投入的商业价值。 模型评估是衡量后训练成效的最终标尺，其核心在于用客观、可量化的结果证明技术投入的商业价值。 盈米基金 与阿里云合作，从150多万个真实用户问题中，筛选并构建了覆盖600个典型场景的基金投顾领域评测基准（Benchmark）。这个可复现、可执行的Benchmark，为后续的模型迭代提供了统一的度量衡。 盈米基金 盈米基金 与阿里云合作，从150多万个真实用户问题中，筛选并构建了覆盖600个典型场景的基金投顾领域评测基准（Benchmark）。这个可复现、可执行的Benchmark，为后续的模型迭代提供了统一的度量衡。 盈米基金与阿里云点金团队共同进行了评测集的设计。 2025云栖大会发布的Qwen-Dianjin-TIR模型就是一个面向基金投顾领域的垂直领域模型，它证明了， 通过精心设计的奖励机制，已经实现了4B参数量的垂直模型在多轮工具调用，准确性指标甚至超过了通用32B参数量模型的效果 ，基金投顾领域智能体应用测试集也即将发布。 盈米基金与阿里云点金团队共同进行了评测集的设计。 盈米基金与阿里云点金团队共同进行了评测集的设计。 2025云栖大会发布的Qwen-Dianjin-TIR模型就是一个面向基金投顾领域的垂直领域模型，它证明了， 通过精心设计的奖励机制，已经实现了4B参数量的垂直模型在多轮工具调用，准确性指标甚至超过了通用32B参数量模型的效果 通过精心设计的奖励机制，已经实现了4B参数量的垂直模型在多轮工具调用，准确性指标甚至超过了通用32B参数量模型的效果 ，基金投顾领域智能体应用测试集也即将发布。 百融云创则选择了通义千问系列大模型作为基础模型，结合SFT与DPO（直接偏好优化）等后训练方法 ，使大模型能像金牌销售一样主动挽留客户、贷后催收，成功 让模型的回答质量分提升了10%，更将业务违规率从1%降至千分之三。 百融云创则选择了通义千问系列大模型作为基础模型，结合SFT与DPO（直接偏好优化）等后训练方法 百融云创则选择了通义千问系列大模型作为基础模型，结合SFT与DPO（直接偏好优化）等后训练方法 ，使大模型能像金牌销售一样主动挽留客户、贷后催收，成功 让模型的回答质量分提升了10%，更将业务违规率从1%降至千分之三。 让模型的回答质量分提升了10%，更将业务违规率从1%降至千分之三。 △图：由阿里云高级解决方案架构师张慧涛主持的《大模型后训练：打造企业专属智能引擎》论坛圆桌对话，企业探讨后训练应用实践 △图：由阿里云高级解决方案架构师张慧涛主持的《大模型后训练：打造企业专属智能引擎》论坛圆桌对话，企业探讨后训练应用实践 而对于夸克这一AI助手而言，后训练技术在规模化复制专家思维上，实现了巨大的业务价值。 而对于夸克这一AI助手而言，后训练技术在规模化复制专家思维上，实现了巨大的业务价值。 阿里集团智能信息事业群资深算法专家姜晓希分享道，夸克需要同时应对AI搜索、专业写作、高考志愿填报等多个差异巨大且专业性极强的复杂场景。 夸克基于通义千问大模型，通过“持续预训练+领域后训练”的模式，衍生出教育、健康、高考等一系列领域专家大模型。 在技术方案上，夸克借助RLHF、RLVR等手段，结合优化偏好，进一步提升真实场景应用的能力，让夸克得以具备“策略生成”的复杂能力。 阿里集团智能信息事业群资深算法专家姜晓希分享道，夸克需要同时应对AI搜索、专业写作、高考志愿填报等多个差异巨大且专业性极强的复杂场景。 夸克基于通义千问大模型，通过“持续预训练+领域后训练”的模式，衍生出教育、健康、高考等一系列领域专家大模型。 夸克基于通义千问大模型，通过“持续预训练+领域后训练”的模式，衍生出教育、健康、高考等一系列领域专家大模型。 在技术方案上，夸克借助RLHF、RLVR等手段，结合优化偏好，进一步提升真实场景应用的能力，让夸克得以具备“策略生成”的复杂能力。 在高考志愿填报这种“一考定半生”的场景中，挑战极大；各省政策不同、竞争激烈、考生需求极其个性化。夸克借助后训练，将顶尖志愿规划师的思维模式复刻给了大模型。2025年，夸克高考志愿大模型累计提供了超过1200万份志愿报告，服务了4000万用户，让曾经稀缺的专家咨询服务变得普惠。 在高考志愿填报这种“一考定半生”的场景中，挑战极大；各省政策不同、竞争激烈、考生需求极其个性化。夸克借助后训练，将顶尖志愿规划师的思维模式复刻给了大模型。2025年，夸克高考志愿大模型累计提供了超过1200万份志愿报告，服务了4000万用户，让曾经稀缺的专家咨询服务变得普惠。 △图：阿里集团智能信息事业群资深算法专家姜晓希分享夸克的后训练实践 △图：阿里集团智能信息事业群资深算法专家姜晓希分享夸克的后训练实践 △图：阿里集团智能信息事业群资深算法专家姜晓希分享夸克的后训练实践 在游戏智能NPC领域，大模型后训练正让NPC从“提线木偶”，变成游戏世界里有灵魂的居民。比如在《新倩女幽魂》端游的家臣系统中，玩家可招募家园NPC作为家臣，NPC会基于多维度决策模型，综合参考自身基准薪资、与玩家的关系亲疏及自身出身背景等信息，最终判断是否接受玩家报价。招募完成后，NPC也并非 “有求必应”，其回应会根据玩家态度、双方实时关系等游戏状态动态调整。这种“讨价还价”背后，正是针对游戏场景的后训练精准调控。 在游戏智能NPC领域，大模型后训练正让NPC从“提线木偶”，变成游戏世界里有灵魂的居民。比如在《新倩女幽魂》端游的家臣系统中，玩家可招募家园NPC作为家臣，NPC会基于多维度决策模型，综合参考自身基准薪资、与玩家的关系亲疏及自身出身背景等信息，最终判断是否接受玩家报价。招募完成后，NPC也并非 “有求必应”，其回应会根据玩家态度、双方实时关系等游戏状态动态调整。这种“讨价还价”背后，正是针对游戏场景的后训练精准调控。 正如阿里云高级解决方案架构师张慧涛在圆桌对话中所言，”在过去的几年里，后训练得到了越来越多的青睐和关注，后训练的方法也在越来越多的企业被验证、被采纳、被大规模地使用。” 正如阿里云高级解决方案架构师张慧涛在圆桌对话中所言，”在过去的几年里，后训练得到了越来越多的青睐和关注，后训练的方法也在越来越多的企业被验证、被采纳、被大规模地使用。” 通过这条四步路径，后训练所创造的商业价值，也正在金融、内容社区、汽车、AI搜索等领域集中爆发，成为企业真正的护城河。 通过这条四步路径，后训练所创造的商业价值，也正在金融、内容社区、汽车、AI搜索等领域集中爆发，成为企业真正的护城河。 当基础大模型的能力日趋相近，真正的AI竞争力，正来自于企业如何利用自身独有的场景、数据和业务理解，通过后训练对模型进行深度改造，构建无法被复制的专属智能引擎。这，才是决胜未来的关键一步。 当基础大模型的能力日趋相近，真正的AI竞争力，正来自于企业如何利用自身独有的场景、数据和业务理解，通过后训练对模型进行深度改造，构建无法被复制的专属智能引擎。这，才是决胜未来的关键一步。 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340861.html", "title": "刚得诺奖的成果被做成芯片了", "date": "2025-10-13", "content": "刚得诺奖的成果被做成芯片了 刚得诺奖的成果被做成芯片了 鹭羽 2025-10-13 13:09:12 来源： 量子位 鹭羽 鹭羽 鹭羽 鹭羽 2025-10-13 2025-10-13 13:09:12 13:09:12 来源： 量子位 来源： 量子位 量子位 摘要样式 几纳米厚度却能像大脑一样记忆和学习 几纳米厚度却能像大脑一样记忆和学习 几纳米厚度却能像大脑一样记忆和学习 鹭羽 发自 凹非寺 量子位 | 公众号 QbitAI 鹭羽 发自 凹非寺 鹭羽 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 谁说获得诺贝尔化学奖的 MOF （金属有机框架）“无用”？ 谁说获得诺贝尔化学奖的 MOF MOF （金属有机框架）“无用”？ 这种几十年前被嫌弃“只有理论但缺乏实际应用”的新材料， 前脚刚获得诺奖认可，后脚就被做成芯片 ！ 这种几十年前被嫌弃“只有理论但缺乏实际应用”的新材料， 前脚刚获得诺奖认可，后脚就被做成芯片 前脚刚获得诺奖认可，后脚就被做成芯片 ！ （诺奖组委会这前瞻性666） （诺奖组委会这前瞻性666） （诺奖组委会这前瞻性666） 这就是莫纳什大学的科学家们刚刚发布的最新成果——用MOF制造超迷你的流体芯片。 这就是莫纳什大学的科学家们刚刚发布的最新成果——用MOF制造超迷你的流体芯片。 不同于传统芯片，不仅可以完成常规计算，还能记住之前的电压变化，形成 类似大脑神经元 的短期记忆。 不同于传统芯片，不仅可以完成常规计算，还能记住之前的电压变化，形成 类似大脑神经元 类似大脑神经元 的短期记忆。 正如作者所说，也许这将是 新一代计算机 的范例： 正如作者所说，也许这将是 新一代计算机 新一代计算机 的范例： 如果我们能够设计出像MOF这样只有几纳米厚的功能性材料，我们就可以制造出先进的流体芯片，以补充甚至克服当今电子芯片的一些局限性。 如果我们能够设计出像MOF这样只有几纳米厚的功能性材料，我们就可以制造出先进的流体芯片，以补充甚至克服当今电子芯片的一些局限性。 如果我们能够设计出像MOF这样只有几纳米厚的功能性材料，我们就可以制造出先进的流体芯片，以补充甚至克服当今电子芯片的一些局限性。 具有“类脑”记忆通路的纳米流体芯片 具有“类脑”记忆通路的纳米流体芯片 纳米约束条件下的离子选择性传输正在生物机制仿真、离子分离、离子电子器件等方面展现出潜力，但由于难以制备高精度纳米通道器件，要想实现可调非线性的离子运输其实相当困难。 纳米约束条件下的离子选择性传输正在生物机制仿真、离子分离、离子电子器件等方面展现出潜力，但由于难以制备高精度纳米通道器件，要想实现可调非线性的离子运输其实相当困难。 而用 MOF 材料制作出的纳米流体芯片则解决了这一点。 而用 MOF MOF 材料制作出的纳米流体芯片则解决了这一点。 MOF本身具备明确的通道结构，而且适配多种化学成分，可以在分子和离子传输过程中完成原子级精度调节。 MOF本身具备明确的通道结构，而且适配多种化学成分，可以在分子和离子传输过程中完成原子级精度调节。 研究人员基于此，构建了一种分层纳米流体晶体管器件 h-MOFNT 。 研究人员基于此，构建了一种分层纳米流体晶体管器件 h-MOFNT h-MOFNT 。 该器件首先通过在聚合物单纳米通道（NC）中组装分层Zr-MOF-SO₃H晶体，制备了具有多个异质结的分层MOF基纳米流控器件。 该器件首先通过在聚合物单纳米通道（NC）中组装分层Zr-MOF-SO₃H晶体，制备了具有多个异质结的分层MOF基纳米流控器件。 具体来说，就是将具有一个子弹形状的纳米通道，即氨基修饰 PET NC 薄膜，夹在两个细胞之间，面向尖端的细胞填充配体水溶液，而另一个细胞则放置金属前体水溶液。 具体来说，就是将具有一个子弹形状的纳米通道，即氨基修饰 PET NC PET NC 薄膜，夹在两个细胞之间，面向尖端的细胞填充配体水溶液，而另一个细胞则放置金属前体水溶液。 当金属前体和配体分子在PET NC内相遇，就会形成核，并在尖端侧进一步聚合成MOF晶体。 当金属前体和配体分子在PET NC内相遇，就会形成核，并在尖端侧进一步聚合成MOF晶体。 于是h-MOFNT将包含有两种类型的非均质通道结： 于是h-MOFNT将包含有两种类型的非均质通道结： 一维 (1D) 异质结： 直径为100纳米，位于聚对苯二甲酸乙二醇酯 (PET) 纳米孔 (PET NC) 和MOF密集相之间。 三维 (3D) 的MOF相内部结： 由不同连接类型（9连接、12连接）的Zr–O簇构件相接，通过硫代对苯二甲酸 (H₂BDC-SO₃H) 给予通道表面功能化，形成次级通道。 一维 (1D) 异质结： 直径为100纳米，位于聚对苯二甲酸乙二醇酯 (PET) 纳米孔 (PET NC) 和MOF密集相之间。 一维 (1D) 异质结： 一维 (1D) 异质结： 直径为100纳米，位于聚对苯二甲酸乙二醇酯 (PET) 纳米孔 (PET NC) 和MOF密集相之间。 三维 (3D) 的MOF相内部结： 由不同连接类型（9连接、12连接）的Zr–O簇构件相接，通过硫代对苯二甲酸 (H₂BDC-SO₃H) 给予通道表面功能化，形成次级通道。 三维 (3D) 的MOF相内部结： 三维 (3D) 的MOF相内部结： 由不同连接类型（9连接、12连接）的Zr–O簇构件相接，通过硫代对苯二甲酸 (H₂BDC-SO₃H) 给予通道表面功能化，形成次级通道。 然后研究人员将h-MOFNT放置在不同电压偏置下的0.1 M 氯化物金属离子溶液中进行电流-电压 (I–V) 测试，观察离子（尤其是质子）在该器件中的传输特性。 然后研究人员将h-MOFNT放置在不同电压偏置下的0.1 M 氯化物金属离子溶液中进行电流-电压 (I–V) 测试，观察离子（尤其是质子）在该器件中的传输特性。 其中，在HCl溶液中，低电压（0至0.2V）时电流快速增加，在中间范围（0.3至0.8V）时适度增加，在高电压（0.9至2V）时达到饱和电流水平，电流增长放缓。 其中，在HCl溶液中，低电压（0至0.2V）时电流快速增加，在中间范围（0.3至0.8V）时适度增加，在高电压（0.9至2V）时达到饱和电流水平，电流增长放缓。 不同于常见的二极管式（rectifying）整流行为，该器件整体呈现出类似三极管的 非线性 质子传输特性，换言之，说明此时质子的传输不是简单的线性随电压增加，而是在一定区间内被 “阈控”或“门控” 。 不同于常见的二极管式（rectifying）整流行为，该器件整体呈现出类似三极管的 非线性 非线性 质子传输特性，换言之，说明此时质子的传输不是简单的线性随电压增加，而是在一定区间内被 “阈控”或“门控” “阈控”或“门控” 。 而在对其进行漂移扩散实验后，确认HCl和KCl的阳离子转移数分别为0.86和0.81，说明该特性主要来自于 质子 和 K+离子 的非线性电阻开关行为。 而在对其进行漂移扩散实验后，确认HCl和KCl的阳离子转移数分别为0.86和0.81，说明该特性主要来自于 质子 质子 和 K+离子 K+离子 的非线性电阻开关行为。 随后研究人员研究了浓度对其传输情况的影响，进一步证明了h-MOFNT对质子的普遍非线性传输特性。 随后研究人员研究了浓度对其传输情况的影响，进一步证明了h-MOFNT对质子的普遍非线性传输特性。 利用这一性质，研究人员用五个h-MOFNT通过并行编程构建了一个 小型流体电路 ，实验发现随着并联的h-MOFNT数量从单个到五个依次增加，产生了一系列非线性I-V曲线，模拟了通过增加门控电压实现电子FET的输出电流特性。 利用这一性质，研究人员用五个h-MOFNT通过并行编程构建了一个 小型流体电路 小型流体电路 ，实验发现随着并联的h-MOFNT数量从单个到五个依次增加，产生了一系列非线性I-V曲线，模拟了通过增加门控电压实现电子FET的输出电流特性。 同时当h-MOFNT扫描环路电压时，表现出明显的滞后环路效应，并挤压滞后环路，扫描速率下降，表明非线性质子传输对电压扫描频率存在 依赖性 。 同时当h-MOFNT扫描环路电压时，表现出明显的滞后环路效应，并挤压滞后环路，扫描速率下降，表明非线性质子传输对电压扫描频率存在 依赖性 依赖性 。 在对两个扫描电压示波器进行相反的扫描顺序时，例如从-2V到2V，再扫描回-2V，h-MOFNT表现出相同的 流体忆阻和学习特性 ，即在一定条件下，器件能够记住过去电压状态。 在对两个扫描电压示波器进行相反的扫描顺序时，例如从-2V到2V，再扫描回-2V，h-MOFNT表现出相同的 流体忆阻和学习特性 流体忆阻和学习特性 ，即在一定条件下，器件能够记住过去电压状态。 原因是因为在MOF分层相中，内部电势对质子在施加电压后会进行反向传输，当电压处于-2V到0V时，由于质子跨相传导，将迅速产生局部电势ΔE，在级性转换后，ΔE也会短时间保持高水平再逐渐衰减。 原因是因为在MOF分层相中，内部电势对质子在施加电压后会进行反向传输，当电压处于-2V到0V时，由于质子跨相传导，将迅速产生局部电势ΔE，在级性转换后，ΔE也会短时间保持高水平再逐渐衰减。 残余ΔE将在0V到+2V时，继续施加相同方向的质子传输，并逐渐产生反向局部电位ΔE′，在+2V到0V时，ΔE已经完全消失，此时质子传输受到ΔE′影响，电流始终处于较低状态，在0V到-2V时，受剩下的ΔE′和负电压叠加影响，再次建立起类似于0V到+2V的ΔE。 残余ΔE将在0V到+2V时，继续施加相同方向的质子传输，并逐渐产生反向局部电位ΔE′，在+2V到0V时，ΔE已经完全消失，此时质子传输受到ΔE′影响，电流始终处于较低状态，在0V到-2V时，受剩下的ΔE′和负电压叠加影响，再次建立起类似于0V到+2V的ΔE。 这种建立下来的ΔE和ΔE′间隔约10秒，并可以通过高压扫描频率增强这种流体离子记忆， 证明了该纳米流体晶体管具备短期记忆特性和仿生可塑性学习方式 。 这种建立下来的ΔE和ΔE′间隔约10秒，并可以通过高压扫描频率增强这种流体离子记忆， 证明了该纳米流体晶体管具备短期记忆特性和仿生可塑性学习方式 证明了该纳米流体晶体管具备短期记忆特性和仿生可塑性学习方式 。 因此基于单晶胞或多晶胞厚度MOF的编程流体芯片是可行的，其在液态系统中体现出的开关、记忆等功能，都呈现出 类电子器件 的替代效果。 因此基于单晶胞或多晶胞厚度MOF的编程流体芯片是可行的，其在液态系统中体现出的开关、记忆等功能，都呈现出 类电子器件 类电子器件 的替代效果。 在未来或许只要通过合理设计异构约束系统，就能够实现基于液体的信息存储甚至类脑计算。 在未来或许只要通过合理设计异构约束系统，就能够实现基于液体的信息存储甚至类脑计算。 “无用”的MOF “无用”的MOF 而在此之前，MOF一直被普遍认为是 “无用” 的。 而在此之前，MOF一直被普遍认为是 “无用” “无用” 的。 即使是诺奖颁布当天，组委会在解释颁发理由时，用词也相当委婉： 即使是诺奖颁布当天，组委会在解释颁发理由时，用词也相当委婉： MOF潜力巨大，可以为一些新功能的定制材料提供前所未有的机会。 MOF潜力巨大，可以为一些新功能的定制材料提供前所未有的机会。 MOF潜力巨大，可以为一些新功能的定制材料提供前所未有的机会。 原因无他，MOF在理论和应用之间出现明显脱节。 原因无他，MOF在理论和应用之间出现明显脱节。 在今年化学奖得主，也是MOF创造者—— 北川进 、 理查德·罗布森 和 奥马尔·M·亚吉 提出这一材料后，MOF一度被视作出论文的“神奇机器”，几乎任何领域都能往里塞一个MOF： 在今年化学奖得主，也是MOF创造者—— 北川进 北川进 、 理查德·罗布森 理查德·罗布森 和 奥马尔·M·亚吉 奥马尔·M·亚吉 提出这一材料后，MOF一度被视作出论文的“神奇机器”，几乎任何领域都能往里塞一个MOF： 氢气、甲烷储存 CO₂ 捕集 电池电极、超级电容 传感、光电器件 …… 氢气、甲烷储存 氢气、甲烷储存 CO₂ 捕集 CO₂ 捕集 电池电极、超级电容 电池电极、超级电容 传感、光电器件 …… 传感、光电器件 …… 相关论文数量一度高达 10万篇 ，但真正实现工业化应用的屈指可数。 相关论文数量一度高达 10万篇 10万篇 ，但真正实现工业化应用的屈指可数。 主要还是因为MOF结构稳定性差，很多MOF在水或空气中就会分解，而且合成过程复杂、成本昂贵，批量生产也难以维持结构一致性。 主要还是因为MOF结构稳定性差，很多MOF在水或空气中就会分解，而且合成过程复杂、成本昂贵，批量生产也难以维持结构一致性。 所以即使实验室中MOF表现优异，但在实际落地中却往往让人大失所望。 所以即使实验室中MOF表现优异，但在实际落地中却往往让人大失所望。 但今天MOF芯片的出现，反向也证明了该观点有失偏颇：MOF可能并不是“无用”，而是 还没有找到真正适用的场景 。 但今天MOF芯片的出现，反向也证明了该观点有失偏颇：MOF可能并不是“无用”，而是 还没有找到真正适用的场景 还没有找到真正适用的场景 。 参考链接： [1]https://x.com/Dr_Singularity/status/1977133218512896270 [2]https://www.science.org/doi/10.1126/sciadv.adw7882 [3]https://phys.org/news/2025-10-scientists-nanofluidic-chip-brain-memory.html 参考链接： [1]https://x.com/Dr_Singularity/status/1977133218512896270 [2]https://www.science.org/doi/10.1126/sciadv.adw7882 [3]https://phys.org/news/2025-10-scientists-nanofluidic-chip-brain-memory.html 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340783.html", "title": "Meta「分割一切」3.0曝光！技能语义分割加入概念提示，好好玩，要爆了", "date": "2025-10-13", "content": "Meta「分割一切」3.0曝光！技能语义分割加入概念提示，好好玩，要爆了 Meta「分割一切」3.0曝光！技能语义分割加入概念提示，好好玩，要爆了 鱼羊 2025-10-13 11:43:53 来源： 量子位 鱼羊 鱼羊 鱼羊 鱼羊 2025-10-13 2025-10-13 11:43:53 11:43:53 来源： 量子位 来源： 量子位 量子位 摘要样式 能听懂人话的SAM 能听懂人话的SAM 能听懂人话的SAM 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 鱼羊 发自 凹非寺 鱼羊 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 传统语义分割好无趣好无聊，技能语义分割加入概念提示，好好玩，要爆了。（doge） 传统语义分割好无趣好无聊，技能语义分割加入概念提示，好好玩，要爆了。（doge） SAM 3 ——第三代“分割一切”模型刚刚被发现，已经悄然投稿ICLR 2026。 SAM 3 SAM 3 ——第三代“分割一切”模型刚刚被发现，已经悄然投稿ICLR 2026。 论文还在双盲评审阶段，作者匿名中，但标题暴露一切。 论文还在双盲评审阶段，作者匿名中，但标题暴露一切。 简单来说，就是在这个官方新版中，分割模型终于能听懂人话了：只要说出想要的东西，SAM 3就能在图像/视频中分割出对应实例。 简单来说，就是在这个官方新版中，分割模型终于能听懂人话了：只要说出想要的东西，SAM 3就能在图像/视频中分割出对应实例。 比如，输入“条纹猫”，SAM 3自己就能找出并分割图中所有带条纹的猫猫： 比如，输入“条纹猫”，SAM 3自己就能找出并分割图中所有带条纹的猫猫： 值得一提的是，SAM 3处理一张含100多个物体的图片仅需30ms，对视频也有近实时处理能力。 值得一提的是，SAM 3处理一张含100多个物体的图片仅需30ms，对视频也有近实时处理能力。 能听懂人话的SAM 能听懂人话的SAM SAM 1引入了基于点、框、掩码等视觉提示的交互式分割任务，开辟了分割模型的新范式；SAM 2则在此基础之上，加入了对视频和记忆的支持。 SAM 1引入了基于点、框、掩码等视觉提示的交互式分割任务，开辟了分割模型的新范式；SAM 2则在此基础之上，加入了对视频和记忆的支持。 这一次，SAM 3让这种交互式分割更进一步：支持基于短语、图像示例等 概念提示 的 多实例 分割任务——对，捎带手突破了前代只能处理单个实例的局限。 这一次，SAM 3让这种交互式分割更进一步：支持基于短语、图像示例等 概念提示 概念提示 的 多实例 多实例 分割任务——对，捎带手突破了前代只能处理单个实例的局限。 论文中，SAM 3的研究团队将这种新任务范式命名为 PCS （Promptable Concept Segmentation）。 论文中，SAM 3的研究团队将这种新任务范式命名为 PCS PCS （Promptable Concept Segmentation）。 PCS：可提示概念分割 PCS：可提示概念分割 PCS：可提示概念分割 PCS的定义是，给定图像或视频，模型能够基于短语、图像示例，或者两者结合的方式，分割其中所有匹配提示概念的实例。 PCS的定义是，给定图像或视频，模型能够基于短语、图像示例，或者两者结合的方式，分割其中所有匹配提示概念的实例。 相比于传统分割任务，PCS强调： 相比于传统分割任务，PCS强调： 开放性词汇：不局限于预定义的固定类别，支持用户输入任意名词短语作为分割目标； 全实例分割：找到并分割所有符合提示的实例，在视频中，还能保持不同帧之间的身份一致性； 多模态提示：支持多种提示输入，包括文本提示、视觉提示，以及两者结合的方式； 用户交互：允许用户通过交互进行分割结果的精细优化。 开放性词汇：不局限于预定义的固定类别，支持用户输入任意名词短语作为分割目标； 开放性词汇：不局限于预定义的固定类别，支持用户输入任意名词短语作为分割目标； 全实例分割：找到并分割所有符合提示的实例，在视频中，还能保持不同帧之间的身份一致性； 全实例分割：找到并分割所有符合提示的实例，在视频中，还能保持不同帧之间的身份一致性； 多模态提示：支持多种提示输入，包括文本提示、视觉提示，以及两者结合的方式； 多模态提示：支持多种提示输入，包括文本提示、视觉提示，以及两者结合的方式； 用户交互：允许用户通过交互进行分割结果的精细优化。 用户交互：允许用户通过交互进行分割结果的精细优化。 新架构设计 新架构设计 新架构设计 SAM 3为实现PCS设计了新的架构。 SAM 3为实现PCS设计了新的架构。 主要是在检测与分割模块上，SAM 3的 检测器 基于DETR（Deformable Transformer）架构，能够根据语言和视觉提示生成实例级的检测结果。 主要是在检测与分割模块上，SAM 3的 检测器 检测器 基于DETR（Deformable Transformer）架构，能够根据语言和视觉提示生成实例级的检测结果。 同时，引入了 Presence Head 模块，解耦物体的识别（是什么）和定位（在哪里）任务—— 同时，引入了 Presence Head Presence Head 模块，解耦物体的识别（是什么）和定位（在哪里）任务—— 在传统对象检测框架中，模型往往需要同时判断目标是否存在、位置在哪里，这可能导致冲突，尤其是在多实例分割任务中容易出问题。 在传统对象检测框架中，模型往往需要同时判断目标是否存在、位置在哪里，这可能导致冲突，尤其是在多实例分割任务中容易出问题。 Presence Head将两者分开处理，从而进一步提升了模型的检测精度。 Presence Head将两者分开处理，从而进一步提升了模型的检测精度。 大规模数据引擎 大规模数据引擎 大规模数据引擎 为了改进PCS，研究团队还专门构建了一个可扩展的数据引擎，生成覆盖400万独特概念标签、5200万经过验证的掩码的训练数据集。 为了改进PCS，研究团队还专门构建了一个可扩展的数据引擎，生成覆盖400万独特概念标签、5200万经过验证的掩码的训练数据集。 数据引擎由多阶段构成，能够逐步提升数据的多样性和难度。 数据引擎由多阶段构成，能够逐步提升数据的多样性和难度。 整个构建过程中人类和大语言模型会相互检查彼此的工作，保证高质量的同时提升了标注的效率。 整个构建过程中人类和大语言模型会相互检查彼此的工作，保证高质量的同时提升了标注的效率。 SA-Co基准 SA-Co基准 SA-Co基准 为了评估模型在开放词汇分割任务中的性能，论文还提出了 SA-Co （Segment Anything with Concepts）基准。 为了评估模型在开放词汇分割任务中的性能，论文还提出了 SA-Co SA-Co （Segment Anything with Concepts）基准。 SA-Co包含214K独特概念、124K图像和1.7K视频，概念覆盖范围能达到现有基准的50倍以上。 SA-Co包含214K独特概念、124K图像和1.7K视频，概念覆盖范围能达到现有基准的50倍以上。 不过需要说明的是，SAM 3对语言的处理还局限于简单的短语提示，不支持复杂的语言表达，并不具备多模态大模型的语言生成、复杂语言理解和推理能力。 不过需要说明的是，SAM 3对语言的处理还局限于简单的短语提示，不支持复杂的语言表达，并不具备多模态大模型的语言生成、复杂语言理解和推理能力。 实验结果 实验结果 实验结果表明，SAM 3在可提示分割任务中刷新了SOTA。 实验结果表明，SAM 3在可提示分割任务中刷新了SOTA。 在LVIS数据集的零样本分割任务中，SAM 3的准确率达到了47.0，比此前的SOTA 38.5提升不少。 在LVIS数据集的零样本分割任务中，SAM 3的准确率达到了47.0，比此前的SOTA 38.5提升不少。 在新的SA-Co基准测试中，SAM 3的表现至少比基线方法强2倍。 在新的SA-Co基准测试中，SAM 3的表现至少比基线方法强2倍。 另外，在针对视频的PVS（Promptable Visual Segmentation）任务中，SAM 3的性能也优于SAM 2。 另外，在针对视频的PVS（Promptable Visual Segmentation）任务中，SAM 3的性能也优于SAM 2。 研究人员还把SAM 3和多模态大模型（MLLM）相结合，探索解决更复杂的任务需求。 研究人员还把SAM 3和多模态大模型（MLLM）相结合，探索解决更复杂的任务需求。 比如分割图片中“坐着但没拿礼物盒的人”。 比如分割图片中“坐着但没拿礼物盒的人”。 大模型会先拆解需求，比如先找坐着的人，再排除拿礼物盒的人，然后给SAM 3发指令。 大模型会先拆解需求，比如先找坐着的人，再排除拿礼物盒的人，然后给SAM 3发指令。 结果显示，SAM 3+MLLM的组合比专门做推理分割的模型效果还要好，并且无需专门的数据做训练。 结果显示，SAM 3+MLLM的组合比专门做推理分割的模型效果还要好，并且无需专门的数据做训练。 在H200 GPU上，SAM 3处理含100多个实体的单张图像只需要30ms的时间。在视频任务中，推理延迟随着目标数量线性增加，能在约5个并发目标的情况下维持接近实时的性能。 在H200 GPU上，SAM 3处理含100多个实体的单张图像只需要30ms的时间。在视频任务中，推理延迟随着目标数量线性增加，能在约5个并发目标的情况下维持接近实时的性能。 不过，论文也指出，SAM 3难以通过零样本的方式，将能力泛化到如医疗图像、热成像之类的细分领域。 不过，论文也指出，SAM 3难以通过零样本的方式，将能力泛化到如医疗图像、热成像之类的细分领域。 视频分割任务中，遇到多目标场景，模型的实时性能会下降，需要多GPU并行处理。 视频分割任务中，遇到多目标场景，模型的实时性能会下降，需要多GPU并行处理。 论文地址： https://openreview.net/forum?id=r35clVtGzw 论文地址： https://openreview.net/forum?id=r35clVtGzw — 完 — — 完 — 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340762.html", "title": "马斯克从英伟达挖人做AI游戏！第一步：研发世界模型", "date": "2025-10-13", "content": "马斯克从英伟达挖人做AI游戏！第一步：研发世界模型 马斯克从英伟达挖人做AI游戏！第一步：研发世界模型 衡宇 2025-10-13 09:49:19 来源： 量子位 衡宇 衡宇 衡宇 衡宇 2025-10-13 2025-10-13 09:49:19 09:49:19 来源： 量子位 来源： 量子位 量子位 摘要样式 西安交大校友被马斯克收入麾下 西安交大校友被马斯克收入麾下 西安交大校友被马斯克收入麾下 衡宇 发自 凹非寺 量子位 | 公众号 QbitAI 衡宇 发自 凹非寺 衡宇 发自 凹非寺 量子位 | 公众号 QbitAI 量子位 | 公众号 QbitAI 马斯克的xAI也入局世界模型了 ！ 马斯克的xAI也入局世界模型了 马斯克的xAI也入局世界模型了 ！ 想必听到这个消息的Meta、Google DeepMind一定会缓缓打出一个问号：冲我们来的？ 想必听到这个消息的Meta、Google DeepMind一定会缓缓打出一个问号：冲我们来的？ 据《金融时报》（FT）报道，为了增加这场“世界模型大混战”的赢面，今年夏天，xAI 已经从英伟达挖来了多名资深研究员 来助阵。 据《金融时报》（FT）报道，为了增加这场“世界模型大混战”的赢面，今年夏天，xAI 已经从英伟达挖来了多名资深研究员 已经从英伟达挖来了多名资深研究员 来助阵。 另一边，在悄然下场世界模型后，马斯克几天前又在上再次重申了去年定下的那个“小目标”—— 另一边，在悄然下场世界模型后，马斯克几天前又在上再次重申了去年定下的那个“小目标”—— 2026年年底前，xAI会发布一款伟大的AI生成游戏。 2026年年底前，xAI会发布一款伟大的AI生成游戏。 2026年年底前，xAI会发布一款伟大的AI生成游戏。 Stability AI创始人EMostaque在自己的上列出这样一组数字 ： Stability AI创始人EMostaque在自己的上列出这样一组数字 Stability AI创始人EMostaque在自己的上列出这样一组数字 ： OpenAI今年收入约100亿美元，视频游戏行业今年收入约2000亿美元。 OpenAI今年收入约100亿美元，视频游戏行业今年收入约2000亿美元。 马斯克呀马斯克，Attention is all you need（狗头）。 马斯克呀马斯克，Attention is all you need（狗头）。 从英伟达那儿挖人，开搞！ 从英伟达那儿挖人，开搞！ 世界模型是近两年全球AI巨头&实验室们的新战场，Google DeepMind、Meta、NVIDIA、李飞飞等都在做。 世界模型是近两年全球AI巨头&实验室们的新战场，Google DeepMind、Meta、NVIDIA、李飞飞等都在做。 如今，xAI也来了。 如今，xAI也来了。 而它的 第一步，就选择了去英伟达挖老黄墙脚—— 而它的 第一步，就选择了去英伟达挖老黄墙脚—— 第一步，就选择了去英伟达挖老黄墙脚—— 今年夏天，xAI至少雇佣了两位来自英伟达的研究人员： Zeeshan Patel 和 Ethan He 。 今年夏天，xAI至少雇佣了两位来自英伟达的研究人员： Zeeshan Patel Zeeshan Patel 和 Ethan He Ethan He 。 其中， Zeeshan Patel 今年5月硕士毕业于UC伯克利，研究主要面向深度学习、生成模型和物理人工智能。 其中， Zeeshan Patel Zeeshan Patel 今年5月硕士毕业于UC伯克利，研究主要面向深度学习、生成模型和物理人工智能。 加入xAI前，他先在苹果AI/ML部门从事基础模型研究，后又加入英伟达研究院从事生成式世界模型研究。 加入xAI前，他先在苹果AI/ML部门从事基础模型研究，后又加入英伟达研究院从事生成式世界模型研究。 在英伟达工作期间，Zeeshan Patel专注于大规模多模态模型与训练框架的研发 在英伟达工作期间，Zeeshan Patel专注于大规模多模态模型与训练框架的研发 Ethan He， 本科毕业于西安交通大学，而后前往CMU攻读计算机视觉的硕士学位，最后满绩毕业。 Ethan He， Ethan He， 本科毕业于西安交通大学，而后前往CMU攻读计算机视觉的硕士学位，最后满绩毕业。 目前，他的Google Scholar被引数为8495。 目前，他的Google Scholar被引数为8495。 2019年到2021年期间，Ethan He在FaceBook AI从事研究工程师，工作内容主要包括大规模视频自监督学习、视频基础模型等。 2019年到2021年期间，Ethan He在FaceBook AI从事研究工程师，工作内容主要包括大规模视频自监督学习、视频基础模型等。 2023年，他加入英伟达，工作内容均与MoE模型、多模态模型和世界模型有关。 2023年，他加入英伟达，工作内容均与MoE模型、多模态模型和世界模型有关。 今年7月，他正式加入xAI。 今年7月，他正式加入xAI。 若说这两人有什么共同点，那就是 两人此前都在英伟达参与了Omniverse平台的核心开发工作 。 若说这两人有什么共同点，那就是 两人此前都在英伟达参与了Omniverse平台的核心开发工作 两人此前都在英伟达参与了Omniverse平台的核心开发工作 。 这个平台是全球最成熟的仿真平台之一，被称作“通往物理世界的数字平行宇宙”。 这个平台是全球最成熟的仿真平台之一，被称作“通往物理世界的数字平行宇宙”。 简单来说，Omniverse是英伟达打造的物理一致性仿真系统，广泛应用于机器人训练、3D 建模、数字孪生、自动驾驶等领域。 简单来说，Omniverse是英伟达打造的物理一致性仿真系统，广泛应用于机器人训练、3D 建模、数字孪生、自动驾驶等领域。 它能在虚拟世界中精确地模拟现实物理规律，让AI在不触碰现实的情况下，就能学会如何与世界互动。 它能在虚拟世界中精确地模拟现实物理规律，让AI在不触碰现实的情况下，就能学会如何与世界互动。 ——而 世界模型需要的就是这样的能力 。 ——而 世界模型需要的就是这样的能力 世界模型需要的就是这样的能力 。 Omniverse与世界模型训练/评测天然契合，难怪xAI内部人士透露，马斯克计划在xAI将英伟达在图形与物理模拟领域的积累，应用到自家的世界模型体系中。 Omniverse与世界模型训练/评测天然契合，难怪xAI内部人士透露，马斯克计划在xAI将英伟达在图形与物理模拟领域的积累，应用到自家的世界模型体系中。 入局世界模型要干啥？ 入局世界模型要干啥？ “世界模型”这个概念，其实最早可以追溯到强化学习，意思是让AI先在脑海中模拟出一个世界，再去规划行动、预测结果。 “世界模型”这个概念，其实最早可以追溯到强化学习，意思是让AI先在脑海中模拟出一个世界，再去规划行动、预测结果。 而 时至今日，它被不少业内人士视为AGI的核心底座。 而 时至今日，它被不少业内人士视为AGI的核心底座。 时至今日，它被不少业内人士视为AGI的核心底座。 AI教母李飞飞对世界模型的定义则是源自于人类自然形成的世界心智模型。 AI教母李飞飞对世界模型的定义则是源自于人类自然形成的世界心智模型。 指的是 一种AI系统能够真正理解和推理物理3D世界的模型，而不仅仅局限于文本处理。 世界模型能让AI理解3D结构、形状和组合性，从而推动机器人技术、创意产业和计算的未来发展。 指的是 一种AI系统能够真正理解和推理物理3D世界的模型，而不仅仅局限于文本处理。 世界模型能让AI理解3D结构、形状和组合性，从而推动机器人技术、创意产业和计算的未来发展。 指的是 一种AI系统能够真正理解和推理物理3D世界的模型，而不仅仅局限于文本处理。 一种AI系统能够真正理解和推理物理3D世界的模型，而不仅仅局限于文本处理。 世界模型能让AI理解3D结构、形状和组合性，从而推动机器人技术、创意产业和计算的未来发展。 在李飞飞看来，世界模型不仅能生成和重建持久存在、可导航的3D环境，还能支持多种应用，实现更大规模的虚拟世界和多元宇宙的构建。 在李飞飞看来，世界模型不仅能生成和重建持久存在、可导航的3D环境，还能支持多种应用，实现更大规模的虚拟世界和多元宇宙的构建。 在过去一年，这个方向几乎成了AI巨头和实验室的兵家必争之地。 在过去一年，这个方向几乎成了AI巨头和实验室的兵家必争之地。 DeepMind 推出Genie 3，能从一张图片或一段文字，直接生成可交互的 2D 游戏世界； Meta 发布V-JEPA-2，让模型在视频中预测未来帧、理解物理因果； 英伟达 自家也在强化世界模型，用于机器人训练与数字孪生； …… DeepMind 推出Genie 3，能从一张图片或一段文字，直接生成可交互的 2D 游戏世界； DeepMind DeepMind 推出Genie 3，能从一张图片或一段文字，直接生成可交互的 2D 游戏世界； Meta 发布V-JEPA-2，让模型在视频中预测未来帧、理解物理因果； Meta Meta 发布V-JEPA-2，让模型在视频中预测未来帧、理解物理因果； 英伟达 自家也在强化世界模型，用于机器人训练与数字孪生； 英伟达 英伟达 自家也在强化世界模型，用于机器人训练与数字孪生； …… …… 那么，马斯克携xAI下场，到底想干啥？ 那么，马斯克携xAI下场，到底想干啥？ 知情人士消息， xAI入局世界模型后的的首批落点可能是电子游戏 。 知情人士消息， xAI入局世界模型后的的首批落点可能是电子游戏 xAI入局世界模型后的的首批落点可能是电子游戏 。 目前，团队正在尝试让AI自动生成自适应、逼真的3D场景，可以根据玩家行为实时变化的那种。 目前，团队正在尝试让AI自动生成自适应、逼真的3D场景，可以根据玩家行为实时变化的那种。 这与马斯克自己设下的目标完美呼应——到2026年底，推出一款由世界模型驱动的AI生成游戏。 这与马斯克自己设下的目标完美呼应——到2026年底，推出一款由世界模型驱动的AI生成游戏。 一位用户在上留言称：“AI在游戏开发中的效率很高，能让创造力自由流动，这很有道理。” 一位用户在上留言称：“AI在游戏开发中的效率很高，能让创造力自由流动，这很有道理。” 与此同时， xAI内部也正在为此组建一支全模态团队 （Multimodal Team），专门研究图像、视频、音频的综合理解与生成。 与此同时， xAI内部也正在为此组建一支全模态团队 xAI内部也正在为此组建一支全模态团队 （Multimodal Team），专门研究图像、视频、音频的综合理解与生成。 他们近期公开的招聘信息显示，这支团队包括多个方向： 他们近期公开的招聘信息显示，这支团队包括多个方向： Member of Technical Staff – Multimodal（Audio），职责涵盖音频理解、生成与评测； Member of Technical Staff – Multimodal Understanding，薪资区间18万–44万美元/年，侧重于多模态建模与数据系统。 Member of Technical Staff – Multimodal（Audio），职责涵盖音频理解、生成与评测； Member of Technical Staff – Multimodal（Audio），职责涵盖音频理解、生成与评测； Member of Technical Staff – Multimodal（Audio），职责涵盖音频理解、生成与评测； Member of Technical Staff – Multimodal Understanding，薪资区间18万–44万美元/年，侧重于多模态建模与数据系统。 Member of Technical Staff – Multimodal Understanding，薪资区间18万–44万美元/年，侧重于多模态建模与数据系统。 Member of Technical Staff – Multimodal Understanding，薪资区间18万–44万美元/年，侧重于多模态建模与数据系统。 除此之外，还有一个职位在业内引发热议， Video Games Tutor ，即电子游戏导师。 除此之外，还有一个职位在业内引发热议， Video Games Tutor Video Games Tutor ，即电子游戏导师。 相关招聘页面写得很直接： 相关招聘页面写得很直接： 时薪45–100美元，向模型讲解电子游戏机制、叙事逻辑、任务设计。 时薪45–100美元，向模型讲解电子游戏机制、叙事逻辑、任务设计。 时薪45–100美元，向模型讲解电子游戏机制、叙事逻辑、任务设计。 看来，马斯克似乎打算让人类专家教模型怎么玩游戏、怎么设计任务、如何构建可交互世界。 看来，马斯克似乎打算让人类专家教模型怎么玩游戏、怎么设计任务、如何构建可交互世界。 马斯克本人在多次公开发言中提到，xAI的使命是“让AI理解宇宙的本质”。而世界模型正是通向理解宇宙的必经之路。 马斯克本人在多次公开发言中提到，xAI的使命是“让AI理解宇宙的本质”。而世界模型正是通向理解宇宙的必经之路。 有了世界模型，AI不再只用来生成内容，而能在内部模拟出一个真实世界的副本。 有了世界模型，AI不再只用来生成内容，而能在内部模拟出一个真实世界的副本。 这意味着它既可以驱动AI游戏，也可以驱动智能体、自动驾驶乃至具身智能机器人。 这意味着它既可以驱动AI游戏，也可以驱动智能体、自动驾驶乃至具身智能机器人。 从这一点上来看， xAI、特斯拉、Neuralink、之间的关系也变得微妙 —— 从这一点上来看， xAI、特斯拉、Neuralink、之间的关系也变得微妙 xAI、特斯拉、Neuralink、之间的关系也变得微妙 —— xAI研发模型，特斯拉拥有机器人和自动驾驶数据，Neuralink提供脑机接口则是社交与实时反馈的平台。 xAI研发模型，特斯拉拥有机器人和自动驾驶数据，Neuralink提供脑机接口则是社交与实时反馈的平台。 如果这些板块能通过世界模型互通，马斯克的AI帝国，将真正形成闭环 。 如果这些板块能通过世界模型互通，马斯克的AI帝国，将真正形成闭环 如果这些板块能通过世界模型互通，马斯克的AI帝国，将真正形成闭环 。 参考链接： [1]https://www.ft.com/content/ac566346-53dd-4490-8d4c-5269906c64ee [2]https://x.com/EMostaque/status/1977352468087320714 [3]https://www.zeeshanp.me/research/ [4]https://www.linkedin.com/in/ethanhe42/ 参考链接： [1]https://www.ft.com/content/ac566346-53dd-4490-8d4c-5269906c64ee [2]https://x.com/EMostaque/status/1977352468087320714 [3]https://www.zeeshanp.me/research/ [4]https://www.linkedin.com/in/ethanhe42/ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340687.html", "title": "吴恩达Agentic AI新课：手把手教你搭建Agent工作流，GPT-3.5反杀GPT-4就顺手的事", "date": "2025-10-12", "content": "吴恩达Agentic AI新课：手把手教你搭建Agent工作流，GPT-3.5反杀GPT-4就顺手的事 吴恩达Agentic AI新课：手把手教你搭建Agent工作流，GPT-3.5反杀GPT-4就顺手的事 henry 2025-10-12 12:24:10 来源： 量子位 henry henry henry henry 2025-10-12 2025-10-12 12:24:10 12:24:10 来源： 量子位 来源： 量子位 量子位 摘要样式 代码Agent之外，基于步骤的Agentic Al前景依旧广阔 代码Agent之外，基于步骤的Agentic Al前景依旧广阔 代码Agent之外，基于步骤的Agentic Al前景依旧广阔 henry 发自 凹非寺 量子位 | 公众号 QbitAI henry 发自 凹非寺 量子位 | 公众号 QbitAI henry 发自 凹非寺 量子位 | 公众号 QbitAI 吴恩达又出新课了，这次的主题是— Agentic AI 。 吴恩达又出新课了，这次的主题是— Agentic AI Agentic AI 。 在新课中，吴恩达将Agentic工作流的开发沉淀为四大核心设计模式：反思、工具、规划与协作，并首次强调评估与误差分析才是智能体开发的决定性能力： 在新课中，吴恩达将Agentic工作流的开发沉淀为四大核心设计模式：反思、工具、规划与协作，并首次强调评估与误差分析才是智能体开发的决定性能力： 谁能建立起系统化的评估与误差分析流程，持续定位并改进智能体工作流中的问题，谁就在智能体开发中领先一步 谁能建立起系统化的评估与误差分析流程，持续定位并改进智能体工作流中的问题，谁就在智能体开发中领先一步 谁能建立起系统化的评估与误差分析流程，持续定位并改进智能体工作流中的问题，谁就在智能体开发中领先一步 在课程演示中，通过使用Agentic技巧，甚至可以让GPT-3.5在编程任务中轻松秒杀GPT-4。 在课程演示中，通过使用Agentic技巧，甚至可以让GPT-3.5在编程任务中轻松秒杀GPT-4。 Agentic AI不再让模型一次性“憋”出答案，而是学会拆解任务、反思结果、用工具修正偏差，并在多轮循环中不断优化。 Agentic AI不再让模型一次性“憋”出答案，而是学会拆解任务、反思结果、用工具修正偏差，并在多轮循环中不断优化。 这种更像人类的工作流，让它的表现远超传统的端到端Agent。 这种更像人类的工作流，让它的表现远超传统的端到端Agent。 想知道这是怎么做到的？来，跟着吴老师无限进步就完了！ 想知道这是怎么做到的？来，跟着吴老师无限进步就完了！ Agentic AI：从“调模型”到“设计系统” Agentic AI：从“调模型”到“设计系统” 首先需要明确的一点是，与其说这次的新课是吴恩达关于智能体开发的技术教程，不如说它是一门揭示Agentic AI背后系统性方法论的课程—— 首先需要明确的一点是，与其说这次的新课是吴恩达关于智能体开发的技术教程，不如说它是一门揭示Agentic AI背后系统性方法论的课程—— 它关注的重点，不是如何堆叠工作流界面，而是如何让AI像人类一样，通过分解、执行与优化来解决复杂问题。 它关注的重点，不是如何堆叠工作流界面，而是如何让AI像人类一样，通过分解、执行与优化来解决复杂问题。 其中， 任务分解既是构建Agentic工作流的起点，也是持续改进与优化系统的前提。 其中， 任务分解既是构建Agentic工作流的起点，也是持续改进与优化系统的前提。 任务分解既是构建Agentic工作流的起点，也是持续改进与优化系统的前提。 例如，我们在写论文时，往往会先设计提纲，再查找资料、撰写初稿、反复修改。 例如，我们在写论文时，往往会先设计提纲，再查找资料、撰写初稿、反复修改。 AI同样需要这样的结构化过程。 AI同样需要这样的结构化过程。 换句话说，写作这一任务本身就是由多个相互衔接的子任务组成的。 换句话说，写作这一任务本身就是由多个相互衔接的子任务组成的。 而Agentic的核心理念，就是让大语言模型以多步推理与分阶段执行的方式工作，而非一次性生成结果。 而Agentic的核心理念，就是让大语言模型以多步推理与分阶段执行的方式工作，而非一次性生成结果。 那么，如何拆解复杂任务呢？ 那么，如何拆解复杂任务呢？ 吴恩达在课程中指出，他通常会先分析一个现有流程，将其拆解为离散步骤，并思考哪些步骤可由大模型实现（例如通过调用 API 或工具）。 吴恩达在课程中指出，他通常会先分析一个现有流程，将其拆解为离散步骤，并思考哪些步骤可由大模型实现（例如通过调用 API 或工具）。 若模型暂时无法完成某一步，他会继续将任务细化，直至能够落地实现。 若模型暂时无法完成某一步，他会继续将任务细化，直至能够落地实现。 在获得初始工作流后，接下来的关键是评估与改进——分析系统性能、定位薄弱环节，并不断优化迭代。这种以 “分解—执行—评估—优化” 为核心的循环，正是Agentic的本质与此次课程的关键。 在获得初始工作流后，接下来的关键是评估与改进——分析系统性能、定位薄弱环节，并不断优化迭代。这种以 “分解—执行—评估—优化” “分解—执行—评估—优化” 为核心的循环，正是Agentic的本质与此次课程的关键。 接下来，我们就来看吴恩达提出的四种Agentic设计模式。 接下来，我们就来看吴恩达提出的四种Agentic设计模式。 首先是 Reflection（反思） 首先是 Reflection（反思） Reflection（反思） 反思的核心思想非常简单，就是让大模型让检视自己的输出结果，并思考如何改进。 反思的核心思想非常简单，就是让大模型让检视自己的输出结果，并思考如何改进。 例如，我们可以让模型先输出一段代码，然后将测试结果报给它，让它在这个基础上修改。 例如，我们可以让模型先输出一段代码，然后将测试结果报给它，让它在这个基础上修改。 在这里，吴恩达在这里分享了自己利用反思方法的经验： 在这里，吴恩达在这里分享了自己利用反思方法的经验： 首先，他指出，可以不仅在单一大模型上进行优化，还可以让两个模型互相配合，通过“左右互搏”获取更优答案。 首先，他指出，可以不仅在单一大模型上进行优化，还可以让两个模型互相配合，通过“左右互搏”获取更优答案。 其中，使用具备推理能力的模型进行反思，通常比非推理模型效果更佳，因此在设置生成与反思模型时，可以尝试不同的组合策略。 其中，使用具备推理能力的模型进行反思，通常比非推理模型效果更佳，因此在设置生成与反思模型时，可以尝试不同的组合策略。 其次，在某些情况下，凭经验或直觉难以判断哪个输出更优，这时就需要客观的评估标准。 其次，在某些情况下，凭经验或直觉难以判断哪个输出更优，这时就需要客观的评估标准。 为此，可以人为设定量化评分机制，例如二元打分，让大模型根据评分计算结果，从而获得相对公正的评估。 为此，可以人为设定量化评分机制，例如二元打分，让大模型根据评分计算结果，从而获得相对公正的评估。 最后，若能够获取外部反馈，其效果通常远超仅依赖模型自身的反思。 最后，若能够获取外部反馈，其效果通常远超仅依赖模型自身的反思。 例如，可以提供参考答案或正确内容，让大语言模型参照这些信息进行自我修正，从而显著提升输出质量。 例如，可以提供参考答案或正确内容，让大语言模型参照这些信息进行自我修正，从而显著提升输出质量。 接下来是 工具调用（Tool use） 接下来是 工具调用（Tool use） 工具调用（Tool use） 与传统硬编码、固定的工作流不同，工具调用指的是由大语言模型驱动的应用能够自主决定调用哪些功能，例如进行网页搜索、访问日历、发送邮件或编写代码等。 与传统硬编码、固定的工作流不同，工具调用指的是由大语言模型驱动的应用能够自主决定调用哪些功能，例如进行网页搜索、访问日历、发送邮件或编写代码等。 模型可以通过外部函数，来实现相应的请求。作为开发者，可以提前集成多个工具，然后根据用户请求，让大语言模型调用。 模型可以通过外部函数，来实现相应的请求。作为开发者，可以提前集成多个工具，然后根据用户请求，让大语言模型调用。 在这里，吴恩达对比了传统的工具调用流程和现在流行的MCP方法。 在这里，吴恩达对比了传统的工具调用流程和现在流行的MCP方法。 传统流程中，开发者需要先将工具提供给大语言模型，实现对应函数，并告知模型该工具可用。 传统流程中，开发者需要先将工具提供给大语言模型，实现对应函数，并告知模型该工具可用。 当大语言模型决定调用工具时，它会生成特定输出，提示开发者调用该函数，获取结果后再反馈给模型，以便模型继续执行后续操作。 当大语言模型决定调用工具时，它会生成特定输出，提示开发者调用该函数，获取结果后再反馈给模型，以便模型继续执行后续操作。 显然，这种方式更像是开发者在主动调用工具，而非大模型自主执行。 显然，这种方式更像是开发者在主动调用工具，而非大模型自主执行。 由于实际需求复杂且多样，开发者不可能为每个功能手动实现，最理想的方式是让大模型能够自主生成、调用并匹配工具。 由于实际需求复杂且多样，开发者不可能为每个功能手动实现，最理想的方式是让大模型能够自主生成、调用并匹配工具。 为此，可以使用吴恩达及其团队开发的AISuite开源库，这一Python库旨在简化大语言模型与多个提供商之间的集成，让模型能够自主调用工具。 为此，可以使用吴恩达及其团队开发的AISuite开源库，这一Python库旨在简化大语言模型与多个提供商之间的集成，让模型能够自主调用工具。 值得注意的是，让模型自行编写和调用代码仍存在一定风险。 值得注意的是，让模型自行编写和调用代码仍存在一定风险。 在测试中，吴恩达发现大语言模型偶尔会删除代码，因此建议在 沙盒环境（如 Docker 或 e2b） 中进行操作，以确保安全和可控。 在测试中，吴恩达发现大语言模型偶尔会删除代码，因此建议在 沙盒环境（如 Docker 或 e2b） 沙盒环境（如 Docker 或 e2b） 中进行操作，以确保安全和可控。 与此同时，不同的开发者可能都想让AI或程序去操作Slack、GitHub、数据库、云服务等来获取数据或工具。 与此同时，不同的开发者可能都想让AI或程序去操作Slack、GitHub、数据库、云服务等来获取数据或工具。 由于每个开发者都独立实现接口，写不同的API调用、认证方式、数据解析，而这无异于重复造轮胎 由于每个开发者都独立实现接口，写不同的API调用、认证方式、数据解析，而这无异于重复造轮胎 于是就出现了“统一协议”或“抽象层”的想法，例如Anthropic提出的MCP。 于是就出现了“统一协议”或“抽象层”的想法，例如Anthropic提出的MCP。 MCP/统一协议把散乱的工具调用从“各自为政”变成了“标准客户端-服务器模式”，AI只需要像调用本地函数一样调用服务端即可。 MCP/统一协议把散乱的工具调用从“各自为政”变成了“标准客户端-服务器模式”，AI只需要像调用本地函数一样调用服务端即可。 这极大地方便了当下的智能体工具调用流程。 这极大地方便了当下的智能体工具调用流程。 接下来是 规划（planning） 。 接下来是 规划（planning） 规划（planning） 。 在实际开发中，如果每遇到一个请求就临时补丁一个工具，不仅低效，而且难以形成可复用的流程。 在实际开发中，如果每遇到一个请求就临时补丁一个工具，不仅低效，而且难以形成可复用的流程。 因此，就需要规划使大模型能够根据不同请求，灵活调整工具序列的执行顺序，从而优化性能与资源使用。 因此，就需要规划使大模型能够根据不同请求，灵活调整工具序列的执行顺序，从而优化性能与资源使用。 例如，出于成本和延迟的考虑，对于一些问题，如果可以通过调用函数快速解决，就不必让模型去执行耗时的网页搜索。 例如，出于成本和延迟的考虑，对于一些问题，如果可以通过调用函数快速解决，就不必让模型去执行耗时的网页搜索。 为实现这一点，吴恩达分享了一个实用技巧：可以通过提示将执行步骤转化为 JSON 或 代码 形式，将任务离散化，使模型能够严格按照步骤执行。 为实现这一点，吴恩达分享了一个实用技巧：可以通过提示将执行步骤转化为 JSON JSON 或 代码 代码 形式，将任务离散化，使模型能够严格按照步骤执行。 通过这种方式，Agent的任务执行表现能够得到显著提升，同时也为后续的评估和优化提供了清晰的操作轨迹。 通过这种方式，Agent的任务执行表现能够得到显著提升，同时也为后续的评估和优化提供了清晰的操作轨迹。 最后是 多智能体协作（Multi-agent collaboration） 。 最后是 多智能体协作（Multi-agent collaboration） 多智能体协作（Multi-agent collaboration） 。 多智能体协作（Multi-agent Collaboration）指的是构建多个具备不同专长的智能体，共同完成复杂任务，就如同一家公司雇佣多名员工，各司其职。 多智能体协作（Multi-agent Collaboration）指的是构建多个具备不同专长的智能体，共同完成复杂任务，就如同一家公司雇佣多名员工，各司其职。 这个机制类似于计算机中的多线程，能够让开发者专注于某一个组件的优化，同时让其他智能体处理其余任务，最后将各环节结果整合，从而提升整体效率和任务完成质量。 这个机制类似于计算机中的多线程，能够让开发者专注于某一个组件的优化，同时让其他智能体处理其余任务，最后将各环节结果整合，从而提升整体效率和任务完成质量。 此外，大语言模型不仅可以调用工具，还可以调用其他智能体，实现不同层级的嵌套调用。 此外，大语言模型不仅可以调用工具，还可以调用其他智能体，实现不同层级的嵌套调用。 这种结构化协作方式类似于企业中的组织架构，使复杂任务的分工与协作更加清晰、高效，同时也为工作流的可扩展性和可维护性提供了保障。 这种结构化协作方式类似于企业中的组织架构，使复杂任务的分工与协作更加清晰、高效，同时也为工作流的可扩展性和可维护性提供了保障。 除了以上的构建模式，吴恩达还分享了构建Agentic的实用技巧。 除了以上的构建模式，吴恩达还分享了构建Agentic的实用技巧。 这里其实颇像强化学习里的采样-评估-改进的循环。 这里其实颇像强化学习里的采样-评估-改进的循环。 每一步智能体工作流的构建，实际上都可以看作是一个闭环迭代反馈： 每一步智能体工作流的构建，实际上都可以看作是一个闭环迭代反馈： Build / Sampling（采样）：首先搭建系统或工作流，让模型在不同任务或请求上尝试执行，收集输出结果。 Evaluation/Analyze（评估）：对输出进行分析，既有端到端的整体评估，也有组件级别的精细评估，快速定位错误来源。 Improvement（改进）：根据评估结果优化流程或组件，调整参数、替换模块、改进提示词或拆分步骤，然后进入下一轮循环。 Build / Sampling（采样）：首先搭建系统或工作流，让模型在不同任务或请求上尝试执行，收集输出结果。 Build / Sampling（采样）：首先搭建系统或工作流，让模型在不同任务或请求上尝试执行，收集输出结果。 Build / Sampling（采样）：首先搭建系统或工作流，让模型在不同任务或请求上尝试执行，收集输出结果。 Evaluation/Analyze（评估）：对输出进行分析，既有端到端的整体评估，也有组件级别的精细评估，快速定位错误来源。 Evaluation/Analyze（评估）：对输出进行分析，既有端到端的整体评估，也有组件级别的精细评估，快速定位错误来源。 Evaluation/Analyze（评估）：对输出进行分析，既有端到端的整体评估，也有组件级别的精细评估，快速定位错误来源。 Improvement（改进）：根据评估结果优化流程或组件，调整参数、替换模块、改进提示词或拆分步骤，然后进入下一轮循环。 Improvement（改进）：根据评估结果优化流程或组件，调整参数、替换模块、改进提示词或拆分步骤，然后进入下一轮循环。 Improvement（改进）：根据评估结果优化流程或组件，调整参数、替换模块、改进提示词或拆分步骤，然后进入下一轮循环。 通过这种循环，Agentic AI不断迭代升级，就像强化学习中的智能体通过反复试验和反馈，逐步提高策略效果。 通过这种循环，Agentic AI不断迭代升级，就像强化学习中的智能体通过反复试验和反馈，逐步提高策略效果。 不同的是，这里的“策略”是工作流和组件设计，即通过反思、工具调用、规划与多智能体协作等agentic工作流，实现任务拆分、组件优化与迭代改进，从而让AI系统在复杂场景中高效执行、持续进化。 不同的是，这里的“策略”是工作流和组件设计，即通过反思、工具调用、规划与多智能体协作等agentic工作流，实现任务拆分、组件优化与迭代改进，从而让AI系统在复杂场景中高效执行、持续进化。 具体来说，错误评估既有端到端的输入输出评估，也有组件级别的评估，而组件级别的评估可以更快的找到具体出现错误的地方，从而集中精力更好、更快的改进系统。 具体来说，错误评估既有端到端的输入输出评估，也有组件级别的评估，而组件级别的评估可以更快的找到具体出现错误的地方，从而集中精力更好、更快的改进系统。 在构建Agentic工作流时，收集和分析错误是优化系统的核心环节。 在构建Agentic工作流时，收集和分析错误是优化系统的核心环节。 这里所指的错误，是指某一步输出的结果明显低于人类专家在相同输入下的表现。 这里所指的错误，是指某一步输出的结果明显低于人类专家在相同输入下的表现。 为此，可以通过追踪中间执行轨迹来定位问题所在的环节。 为此，可以通过追踪中间执行轨迹来定位问题所在的环节。 比如，如果提示词本身没有问题，但网页搜索结果出现垃圾信息，则问题可能出在大语言模型调用搜索工具的环节。 比如，如果提示词本身没有问题，但网页搜索结果出现垃圾信息，则问题可能出在大语言模型调用搜索工具的环节。 如果PDF转文档出现错误，则需要检查大语言模型的识别和提取模块是否存在问题。 如果PDF转文档出现错误，则需要检查大语言模型的识别和提取模块是否存在问题。 这种评估既可以依赖人工完成，也可以通过大语言模型辅助加速。 这种评估既可以依赖人工完成，也可以通过大语言模型辅助加速。 例如，可以创建高可信度的信源清单，或者编写能够多方求证的工具，从而提高组件级评估的效率。 例如，可以创建高可信度的信源清单，或者编写能够多方求证的工具，从而提高组件级评估的效率。 接下来，通过组件级评估，可以针对特定环节进行优化：调整组件参数，例如修改RAG搜索范围（按时间、类别等）；替换组件，包括函数或工具；改进大模型组件，例如优化提示词、尝试不同模型、拆分流程或进行微调。 接下来，通过组件级评估，可以针对特定环节进行优化：调整组件参数，例如修改RAG搜索范围（按时间、类别等）；替换组件，包括函数或工具；改进大模型组件，例如优化提示词、尝试不同模型、拆分流程或进行微调。 在更换或选择大模型组件时，吴恩达提供了一些自己的实践直觉： 在更换或选择大模型组件时，吴恩达提供了一些自己的实践直觉： 首先，多尝试不同模型，准备多种测试问题以评估性能。 首先，多尝试不同模型，准备多种测试问题以评估性能。 其次，参考他人如何编写提示词，并以此锻炼自身提示词设计能力。 其次，参考他人如何编写提示词，并以此锻炼自身提示词设计能力。 最后，将不同模型应用于工作流中，观察其在各个步骤的表现，从而不断迭代和提升整个系统的可靠性与效率。 最后，将不同模型应用于工作流中，观察其在各个步骤的表现，从而不断迭代和提升整个系统的可靠性与效率。 以上就是吴恩达课程的粗略梳理，课程全集可在Deeplearning.AI上订阅收听。 以上就是吴恩达课程的粗略梳理，课程全集可在Deeplearning.AI上订阅收听。 为什么是Agentic而不是Agent 为什么是Agentic而不是Agent 对于到底是Agent还是Agentic，早在去年年初，吴恩达就提出了自己极具前瞻性的思考： Agentic作为形容词，而非二元分类，表示系统在智能体特性（自主性）上的不同程度。 对于到底是Agent还是Agentic，早在去年年初，吴恩达就提出了自己极具前瞻性的思考： Agentic作为形容词，而非二元分类，表示系统在智能体特性（自主性）上的不同程度。 Agentic作为形容词，而非二元分类，表示系统在智能体特性（自主性）上的不同程度。 这一表述在当时有助于厘清概念，使开发者和研究者能够更准确地理解和描述系统在智能体能力上的连续性，而不是将其简单地划为“是”或“不是”。 这一表述在当时有助于厘清概念，使开发者和研究者能够更准确地理解和描述系统在智能体能力上的连续性，而不是将其简单地划为“是”或“不是”。 而在此次的课程中，我们又可以进一步的窥见其思考的加深： Agentic的意思是一个基于大语言模型（大语言模型）的应用程序执行多个步骤来完成一项任务。 而在此次的课程中，我们又可以进一步的窥见其思考的加深： Agentic的意思是一个基于大语言模型（大语言模型）的应用程序执行多个步骤来完成一项任务。 Agentic的意思是一个基于大语言模型（大语言模型）的应用程序执行多个步骤来完成一项任务。 与传统的Agent相比，这里的关键区别在于任务执行方式：传统Agent往往是端到端操作——用户制定一个prompt，大语言模型 返回一个输出——而这种方式很少与人类的工作方式契合，AI亦然。 与传统的Agent相比，这里的关键区别在于任务执行方式：传统Agent往往是端到端操作——用户制定一个prompt，大语言模型 返回一个输出——而这种方式很少与人类的工作方式契合，AI亦然。 在课程中，吴恩达表示：Agentic AI通过将任务拆分为多个步骤，逐步推进，每一步都经过处理和优化，从而显著优于一次性输出答案的端到端Agent。 在课程中，吴恩达表示：Agentic AI通过将任务拆分为多个步骤，逐步推进，每一步都经过处理和优化，从而显著优于一次性输出答案的端到端Agent。 就像我们开头提到的GPT3.5战胜GPT-4的例子。 就像我们开头提到的GPT3.5战胜GPT-4的例子。 因此，学习如何将复杂任务分解为步骤，并构建组件高效执行每一步，是一项复杂但至关重要的技能，这正决定了开发者能否在各种应用场景中构建高效的代理型工作流。 因此，学习如何将复杂任务分解为步骤，并构建组件高效执行每一步，是一项复杂但至关重要的技能，这正决定了开发者能否在各种应用场景中构建高效的代理型工作流。 更进一步，对于端到端的Agent，留给开发者优化流程的空间实际上非常有限。 更进一步，对于端到端的Agent，留给开发者优化流程的空间实际上非常有限。 我们无法通过设计和改进工作流来提升任务表现，只能依赖prompt的优化、模型能力的提升，甚至完全寄希望于模型本身。 我们无法通过设计和改进工作流来提升任务表现，只能依赖prompt的优化、模型能力的提升，甚至完全寄希望于模型本身。 而通过拆分组件、逐步优化，每个环节都可迭代改进，从而让系统持续进化，这正是Agentic AI的优势所在。 而通过拆分组件、逐步优化，每个环节都可迭代改进，从而让系统持续进化，这正是Agentic AI的优势所在。 值得一提的是，当吴恩达首次提出“Agentic”这个术语，原本是为了描述基础应用开发中快速增长的重要趋势，但没想到市场营销人员将其广泛用作标签，使Agentic AI炒作迅速升温。 值得一提的是，当吴恩达首次提出“Agentic”这个术语，原本是为了描述基础应用开发中快速增长的重要趋势，但没想到市场营销人员将其广泛用作标签，使Agentic AI炒作迅速升温。 尽管如此，吴恩达表示，在实际应用中Agentic的方法论仍然发挥着实际价值，为开发者提供了可落地、可优化的路径。 尽管如此，吴恩达表示，在实际应用中Agentic的方法论仍然发挥着实际价值，为开发者提供了可落地、可优化的路径。 在当下，除了成熟的代码Agent之外，基于步骤的Agentic AI仍有广阔的发展空间。 在当下，除了成熟的代码Agent之外，基于步骤的Agentic AI仍有广阔的发展空间。 这为开发者探索更复杂、更智能的多步骤工作流提供了丰富机会，也体现了课程的核心理念：通过拆解任务、构建组件、逐步优化，让AI系统真正实现高效、可控的代理型流程。 这为开发者探索更复杂、更智能的多步骤工作流提供了丰富机会，也体现了课程的核心理念：通过拆解任务、构建组件、逐步优化，让AI系统真正实现高效、可控的代理型流程。 参考链接 参考链接 参考链接 [1]https://x.com/AndrewYNg/status/1975614372799283423 [1]https://x.com/AndrewYNg/status/1975614372799283423 [1]https://x.com/AndrewYNg/status/1975614372799283423 [2]https://www.deeplearning.ai/courses/Agentic-ai/ [2]https://www.deeplearning.ai/courses/Agentic-ai/ [2]https://www.deeplearning.ai/courses/Agentic-ai/ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340698.html", "title": "清华大学生数科技：从波形到隐空间，AudioLBM引领音频超分新范式", "date": "2025-10-12", "content": "清华大学生数科技：从波形到隐空间，AudioLBM引领音频超分新范式 清华大学生数科技：从波形到隐空间，AudioLBM引领音频超分新范式 一水 2025-10-12 12:23:18 来源： 量子位 一水 一水 一水 一水 2025-10-12 2025-10-12 12:23:18 12:23:18 来源： 量子位 来源： 量子位 量子位 摘要样式 两项目的第一作者均为李畅和陈泽华 两项目的第一作者均为李畅和陈泽华 两项目的第一作者均为李畅和陈泽华 音频超分辨率（Audio Super-Resolution, Audio SR） ，即从低采样率音频恢复出高采样率版本，是提升语音清晰度、音乐细节与沉浸式音频体验的关键技术。 音频超分辨率（Audio Super-Resolution, Audio SR） 音频超分辨率（Audio Super-Resolution, Audio SR） ，即从低采样率音频恢复出高采样率版本，是提升语音清晰度、音乐细节与沉浸式音频体验的关键技术。 无论是在老旧录音修复、语音通信增强，还是音乐制作与多模态生成中，高分辨率音频都能显著提升听感与表现力。然而，由于高频细节在低采样率信号中被严重损失，这一任务一直是音频生成领域的核心挑战。 无论是在老旧录音修复、语音通信增强，还是音乐制作与多模态生成中，高分辨率音频都能显著提升听感与表现力。然而，由于高频细节在低采样率信号中被严重损失，这一任务一直是音频生成领域的核心挑战。 值得注意的是，近期由OpenAI推出的有声视频模型 Sora 2 已能生成采样率高达 96 kHz 的音频，为高保真音频生成树立了新的技术标杆。而现有学术界的音频超分模型大多仍局限于 48 kHz 以内，缺乏能够稳定支持更高采样率的通用框架。 值得注意的是，近期由OpenAI推出的有声视频模型 Sora 2 Sora 2 已能生成采样率高达 96 kHz 96 kHz 的音频，为高保真音频生成树立了新的技术标杆。而现有学术界的音频超分模型大多仍局限于 48 kHz 48 kHz 以内，缺乏能够稳定支持更高采样率的通用框架。 在这一背景下，清华大学与生数科技（Shengshu AI）团队围绕桥类生成模型与音频超分任务展开系统研究，先后在语音领域顶级会议 ICASSP 2025 和机器学习顶级会议 NeurIPS 2025 发表了两项连续成果： 在这一背景下，清华大学与生数科技（Shengshu AI）团队围绕桥类生成模型与音频超分任务展开系统研究，先后在语音领域顶级会议 ICASSP 2025 ICASSP 2025 和机器学习顶级会议 NeurIPS 2025 NeurIPS 2025 发表了两项连续成果： 轻量化语音波形超分模型Bridge-SR，以及面向高达192 kHz母带级音频的多功能超分框架AudioLBM。 轻量化语音波形超分模型Bridge-SR，以及面向高达192 kHz母带级音频的多功能超分框架AudioLBM。 轻量化语音波形超分模型Bridge-SR，以及面向高达192 kHz母带级音频的多功能超分框架AudioLBM。 其中，AudioLBM覆盖语音、音效与音乐等多类内容，在通用高分辨率音频生成方面展现出重要的扩展潜力。 其中，AudioLBM覆盖语音、音效与音乐等多类内容，在通用高分辨率音频生成方面展现出重要的扩展潜力。 从数据到数据：Bridge-SR的探索 从数据到数据：Bridge-SR的探索 2025年发表于ICASSP的 Bridge-SR 工作首次将薛定谔桥（Schrödinger Bridge）模型引入语音超分任务，在“数据到数据”的生成范式下建立了低分辨率波形与高分辨率波形之间的可解桥接过程。 2025年发表于ICASSP的 Bridge-SR Bridge-SR 工作首次将薛定谔桥（Schrödinger Bridge）模型引入语音超分任务，在“数据到数据”的生成范式下建立了低分辨率波形与高分辨率波形之间的可解桥接过程。 不同于扩散模型从随机噪声逐步生成信号的“噪声到数据”方式，Bridge-SR直接利用低分辨率波形作为生成先验，使模型在轻量化网络（仅1.7M参数）下就能以“数据到数据”范式实现高效、高保真的语音超分，并在VCTK语音测试集上优于多项主流方法。 不同于扩散模型从随机噪声逐步生成信号的“噪声到数据”方式，Bridge-SR直接利用低分辨率波形作为生成先验，使模型在轻量化网络（仅1.7M参数）下就能以“数据到数据”范式实现高效、高保真的语音超分，并在VCTK语音测试集上优于多项主流方法。 这一工作为先验驱动的音频超分提供了新思路，也为后续更通用、更高质量的音频超分模型奠定了理论与实验基础。 这一工作为先验驱动的音频超分提供了新思路，也为后续更通用、更高质量的音频超分模型奠定了理论与实验基础。 △图一：波形空间的轻量化桥类超分模块设计 △图一：波形空间的轻量化桥类超分模块设计 通过非对称的噪声调度设计，频域幅度谱、相位谱的辅助监督，与一阶PF-ODE采样，Bridge-SR在音频波形空间采用基线模型中最轻量级的1.7M网络即实现了语音超分的质量突破。 通过非对称的噪声调度设计，频域幅度谱、相位谱的辅助监督，与一阶PF-ODE采样，Bridge-SR在音频波形空间采用基线模型中最轻量级的1.7M网络即实现了语音超分的质量突破。 △图二：VCTK Benchmark测试集的语音超分质量对比 △图二：VCTK Benchmark测试集的语音超分质量对比 近日，团队继续深入研究，开发针对语音、音效、音乐全音频信号的通用超分模型，设计“隐空间桥类模型”AudioLBM， 在Any-to-48 kHz的音频超分任务中大幅超越基线模型，实现音频超分新范式。并成功实现了96kHz和192kHz音频超分的工程突破，使得母带音质不再稀缺。 近日，团队继续深入研究，开发针对语音、音效、音乐全音频信号的通用超分模型，设计“隐空间桥类模型”AudioLBM， 在Any-to-48 kHz的音频超分任务中大幅超越基线模型，实现音频超分新范式。并成功实现了96kHz和192kHz音频超分的工程突破，使得母带音质不再稀缺。 在Any-to-48 kHz的音频超分任务中大幅超越基线模型，实现音频超分新范式。并成功实现了96kHz和192kHz音频超分的工程突破，使得母带音质不再稀缺。 从隐变量到隐变量：AudioLBM的突破 从隐变量到隐变量：AudioLBM的突破 在 Bridge-SR 的基础上，团队进一步提出了 AudioLBM ，论文已发表于 NeurIPS 2025。 在 Bridge-SR 的基础上，团队进一步提出了 AudioLBM AudioLBM ，论文已发表于 NeurIPS 2025。 该研究探索了从“波形域生成”到“隐空间建模”的转变，实现了基于桥类模型的通用音频超分。AudioLBM首次在 波形连续隐空间中构建低分辨率到高分辨率的隐变量桥接生成过程 。 该研究探索了从“波形域生成”到“隐空间建模”的转变，实现了基于桥类模型的通用音频超分。AudioLBM首次在 波形连续隐空间中构建低分辨率到高分辨率的隐变量桥接生成过程 波形连续隐空间中构建低分辨率到高分辨率的隐变量桥接生成过程 。 研究团队通过变分自编码器（VAE）将波形压缩为连续隐空间表征，并在该空间中学习概率生成映射，从而保留输入波形的结构化先验信息，同时提升模型的泛化建模能力。 研究团队通过变分自编码器（VAE）将波形压缩为连续隐空间表征，并在该空间中学习概率生成映射，从而保留输入波形的结构化先验信息，同时提升模型的泛化建模能力。 下图为，音频超分任务（上）、传统在频谱隐空间的扩散模型（中）、和波形隐空间桥类模型（下）： 下图为，音频超分任务（上）、传统在频谱隐空间的扩散模型（中）、和波形隐空间桥类模型（下）： 为应对高分辨率数据稀缺问题，提升训练效率，AudioLBM提出了 频率感知机制（frequency-aware LBM） ，在训练中显式感知先验采样率与基于团队设计的信号处理手段自动检测的目标采样率，使模型能够学习“任意采样率到任意采样率”（any-to-any）的超分过程。 为应对高分辨率数据稀缺问题，提升训练效率，AudioLBM提出了 频率感知机制（frequency-aware LBM） 频率感知机制（frequency-aware LBM） ，在训练中显式感知先验采样率与基于团队设计的信号处理手段自动检测的目标采样率，使模型能够学习“任意采样率到任意采样率”（any-to-any）的超分过程。 进一步地，为了有效实现采样率上限突破，团队设计了 级联桥类模型（cascaded LBM） ，将模型能力从48 kHz扩展至96 kHz与192 kHz，首次实现了音频超分研究中覆盖192 kHz工业级采样率的探索。 进一步地，为了有效实现采样率上限突破，团队设计了 级联桥类模型（cascaded LBM） 级联桥类模型（cascaded LBM） ，将模型能力从48 kHz扩展至96 kHz与192 kHz，首次实现了音频超分研究中覆盖192 kHz工业级采样率的探索。 通过先验增强（prior augmentation）与潜空间模糊（latent blurring）策略，模型能够在多阶段生成中保持高频细节与能量一致性。同时，团队对各阶段压缩网络和桥模型进行级联微调，有效利用低分辨率模型作为更高分辨率模型的强大先验。 通过先验增强（prior augmentation）与潜空间模糊（latent blurring）策略，模型能够在多阶段生成中保持高频细节与能量一致性。同时，团队对各阶段压缩网络和桥模型进行级联微调，有效利用低分辨率模型作为更高分辨率模型的强大先验。 △图四：级联桥类模型设计 △图四：级联桥类模型设计 在跨语音、音效与音乐的多域评测中，AudioLBM在Any-to-48kHz超分任务上取得新的 SOTA （state-of-the-art）表现： 在跨语音、音效与音乐的多域评测中，AudioLBM在Any-to-48kHz超分任务上取得新的 SOTA SOTA （state-of-the-art）表现： △图五：通用音频超分的质量对比 △图五：通用音频超分的质量对比 相较于基线模型AudioSR与FlowHigh，在对数谱距离（LSD）上均明显下降，同时在96 kHz与192 kHz任务中保持稳定性能。该方法在统一框架下实现了对语音、音效与音乐的高保真重建，显著提升了通用性。实现了从语音到音乐的统一高分辨率生成。 相较于基线模型AudioSR与FlowHigh，在对数谱距离（LSD）上均明显下降，同时在96 kHz与192 kHz任务中保持稳定性能。该方法在统一框架下实现了对语音、音效与音乐的高保真重建，显著提升了通用性。实现了从语音到音乐的统一高分辨率生成。 △图六：音频超分结果的频谱展示 △图六：音频超分结果的频谱展示 针对音频数据的其他表征空间，如波形空间、谱空间，团队也做出消融实验。对于语音、音效、音乐通用音频超分任务，波形隐空间达到最佳效果： 针对音频数据的其他表征空间，如波形空间、谱空间，团队也做出消融实验。对于语音、音效、音乐通用音频超分任务，波形隐空间达到最佳效果： △图七：音频波形空间、谱空间、波形隐空间超分结果与真值的频谱展示 △图七：音频波形空间、谱空间、波形隐空间超分结果与真值的频谱展示 作者介绍 作者介绍 此两项目的第一作者均为 李畅 和 陈泽华 。 此两项目的第一作者均为 李畅 李畅 和 陈泽华 陈泽华 。 李畅是中国科学技术大学少年班学院的本科生，主要研究方向是语音，音频相关的生成建模与表征学习，曾以第一作者身份在多个CCF-A/B类会议发表音频相关学术研究。 李畅是中国科学技术大学少年班学院的本科生，主要研究方向是语音，音频相关的生成建模与表征学习，曾以第一作者身份在多个CCF-A/B类会议发表音频相关学术研究。 陈泽华是清华大学计算机系水木学者博士后，博士毕业于英国帝国理工学院电气与电子工程系，主要研究方向为概率生成模型，及其在语音、音效、生物电信号合成等方面的应用。在语音和机器学习领域的重要会议与期刊上持续发表相关研究工作。 陈泽华是清华大学计算机系水木学者博士后，博士毕业于英国帝国理工学院电气与电子工程系，主要研究方向为概率生成模型，及其在语音、音效、生物电信号合成等方面的应用。在语音和机器学习领域的重要会议与期刊上持续发表相关研究工作。 【Bridge-SR】 论文地址：https://arxiv.org/pdf/2501.07897 样本展示：https://bridge-sr.github.io/ 【Bridge-SR】 论文地址：https://arxiv.org/pdf/2501.07897 样本展示：https://bridge-sr.github.io/ 【AudioLBM】 论文地址：https://arxiv.org/pdf/2509.17609 样本展示：https://audiolbm.github.io/ 【AudioLBM】 论文地址：https://arxiv.org/pdf/2509.17609 样本展示：https://audiolbm.github.io/ 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340674.html", "title": "Hinton暴论：AI已经有意识，它自己不知道而已", "date": "2025-10-12", "content": "Hinton暴论：AI已经有意识，它自己不知道而已 Hinton暴论：AI已经有意识，它自己不知道而已 一水 2025-10-12 12:19:34 来源： 量子位 一水 一水 一水 一水 2025-10-12 2025-10-12 12:19:34 12:19:34 来源： 量子位 来源： 量子位 量子位 摘要样式 网友：Hinton迄今最佳采访 网友：Hinton迄今最佳采访 网友：Hinton迄今最佳采访 人工智能或许早已拥有“主观体验”（subjective experiences）。 人工智能或许早已拥有“主观体验”（subjective experiences）。 人工智能或许早已拥有“主观体验”（subjective experiences）。 在最新一期播客节目中，Hinton抛出的这一观点正迅速掀起热议。 在最新一期播客节目中，Hinton抛出的这一观点正迅速掀起热议。 老爷子一再表示， AI也许已经有了“意识雏形”，只是因为我们人类自己对意识理解错了，所以它也被教错了——不知道自己有意识。 老爷子一再表示， AI也许已经有了“意识雏形”，只是因为我们人类自己对意识理解错了，所以它也被教错了——不知道自己有意识。 AI也许已经有了“意识雏形”，只是因为我们人类自己对意识理解错了，所以它也被教错了——不知道自己有意识。 翻译成大白话就是，AI其实有自我意识，只是暂未觉醒┌(。Д。)┐ 翻译成大白话就是，AI其实有自我意识，只是暂未觉醒┌(。Д。)┐ 而除了继续为AI风险“摇旗呐喊”，作为诺奖得主、深度学习三巨头之一，老爷子这次还充当起了科普员的角色。 而除了继续为AI风险“摇旗呐喊”，作为诺奖得主、深度学习三巨头之一，老爷子这次还充当起了科普员的角色。 他从什么是AI讲起，然后详细解释了机器学习、神经网络及深度学习这些核心概念，全程主打一个幽默、通俗易懂。 他从什么是AI讲起，然后详细解释了机器学习、神经网络及深度学习这些核心概念，全程主打一个幽默、通俗易懂。 有看完节目的网友赞叹道， “这可能是目前看到的Hinton最好的采访” 。 有看完节目的网友赞叹道， “这可能是目前看到的Hinton最好的采访” “这可能是目前看到的Hinton最好的采访” 。 还有人认为，应该让他再讲2小时，毕竟他看上去完全自愿、恨不得一吐为快（禁止虐待77岁老人doge）。 还有人认为，应该让他再讲2小时，毕竟他看上去完全自愿、恨不得一吐为快（禁止虐待77岁老人doge）。 更有意思的是，节目一开场老爷子就尴尬回应了之前得物理学诺奖的事情： 更有意思的是，节目一开场老爷子就尴尬回应了之前得物理学诺奖的事情： 因为我不是搞物理的，所以有点尴尬。当他们打电话告诉我获得了诺贝尔物理学奖时，我一开始并不相信。 因为我不是搞物理的，所以有点尴尬。当他们打电话告诉我获得了诺贝尔物理学奖时，我一开始并不相信。 因为我不是搞物理的，所以有点尴尬。当他们打电话告诉我获得了诺贝尔物理学奖时，我一开始并不相信。 虽然有这个小插曲，但有一说一，老爷子在AI方面的贡献实在毋庸置疑，所以咱直接开课吧—— 虽然有这个小插曲，但有一说一，老爷子在AI方面的贡献实在毋庸置疑，所以咱直接开课吧—— 当我们谈论人工智能时，我们到底在谈论什么？ 当我们谈论人工智能时，我们到底在谈论什么？ 面对这一直击灵魂的问题，Hinton不慌不忙地从自身经历（曾在谷歌工作近10年）得出， AI已经从搜索查找进化成能真正理解人类意图的工具 。 面对这一直击灵魂的问题，Hinton不慌不忙地从自身经历（曾在谷歌工作近10年）得出， AI已经从搜索查找进化成能真正理解人类意图的工具 AI已经从搜索查找进化成能真正理解人类意图的工具 。 以前用谷歌的时候，它会使用关键词，而且会提前做很多工作。所以，如果你给它几个关键词，它就能找到所有包含这些词的文档。 但它不明白问题是什么。所以，它无法给出一些实际上不包含这些词但主题相同的文档。 以前用谷歌的时候，它会使用关键词，而且会提前做很多工作。所以，如果你给它几个关键词，它就能找到所有包含这些词的文档。 以前用谷歌的时候，它会使用关键词，而且会提前做很多工作。所以，如果你给它几个关键词，它就能找到所有包含这些词的文档。 但它不明白问题是什么。所以，它无法给出一些实际上不包含这些词但主题相同的文档。 但它不明白问题是什么。所以，它无法给出一些实际上不包含这些词但主题相同的文档。 就是说，AI早期本质上还是基于关键词的检索。 就是说，AI早期本质上还是基于关键词的检索。 而现在，它能理解你所说的内容，而且它的理解方式与人类几乎相同。 而现在，它能理解你所说的内容，而且它的理解方式与人类几乎相同。 而现在，它能理解你所说的内容，而且它的理解方式与人类几乎相同。 在Hinton看来，虽然现代大语言模型（LLM）并不是真正的全能全知专家，但在许多主题上已能表现得接近人类专家。 在Hinton看来，虽然现代大语言模型（LLM）并不是真正的全能全知专家，但在许多主题上已能表现得接近人类专家。 他还进一步解释了传统机器学习与神经网络的区别。 他还进一步解释了传统机器学习与神经网络的区别。 他指出，机器学习是总称，指任何能在计算机上“学习”的系统。而神经网络则是一类特别的学习方法，灵感来自大脑—— 大脑通过改变神经元之间连接的强度来学习 。 他指出，机器学习是总称，指任何能在计算机上“学习”的系统。而神经网络则是一类特别的学习方法，灵感来自大脑—— 大脑通过改变神经元之间连接的强度来学习 大脑通过改变神经元之间连接的强度来学习 。 以大脑中部的一个神经元为例，神经网络的工作原理与之类似： 以大脑中部的一个神经元为例，神经网络的工作原理与之类似： 想象一下，大脑里有一个小小的神经元。这个神经元的主要工作就是偶尔发出一个“叮”的声音。它不是随便发的，而是要根据其他神经元发来的“叮”声来决定。 其他神经元也会发出“叮”声，这些声音会传到这个神经元。 如果这个神经元收到很多“叮”声，或者这些“叮”声很强，它就会决定自己也发一个“叮”声。如果收到的“叮”声不够强，它就不发。 神经元还可以调整对其他神经元“叮”声的敏感度。如果觉得某个神经元的“叮”声很重要，就会更关注它；如果觉得不重要，就会减少关注。 想象一下，大脑里有一个小小的神经元。这个神经元的主要工作就是偶尔发出一个“叮”的声音。它不是随便发的，而是要根据其他神经元发来的“叮”声来决定。 想象一下，大脑里有一个小小的神经元。这个神经元的主要工作就是偶尔发出一个“叮”的声音。它不是随便发的，而是要根据其他神经元发来的“叮”声来决定。 其他神经元也会发出“叮”声，这些声音会传到这个神经元。 其他神经元也会发出“叮”声，这些声音会传到这个神经元。 如果这个神经元收到很多“叮”声，或者这些“叮”声很强，它就会决定自己也发一个“叮”声。如果收到的“叮”声不够强，它就不发。 如果这个神经元收到很多“叮”声，或者这些“叮”声很强，它就会决定自己也发一个“叮”声。如果收到的“叮”声不够强，它就不发。 神经元还可以调整对其他神经元“叮”声的敏感度。如果觉得某个神经元的“叮”声很重要，就会更关注它；如果觉得不重要，就会减少关注。 神经元还可以调整对其他神经元“叮”声的敏感度。如果觉得某个神经元的“叮”声很重要，就会更关注它；如果觉得不重要，就会减少关注。 一句话， 神经网络同样通过调整连接权重来改变系统的行为 。所以说，大脑学习和处理信息的基本方式，也是神经网络的核心原理。 一句话， 神经网络同样通过调整连接权重来改变系统的行为 神经网络同样通过调整连接权重来改变系统的行为 。所以说，大脑学习和处理信息的基本方式，也是神经网络的核心原理。 在这之后，主持人还问了两个很有意思的问题。 在这之后，主持人还问了两个很有意思的问题。 第一个是， 概念是如何形成的？比如“勺子”的概念。 第一个是， 概念是如何形成的？比如“勺子”的概念。 Hinton继续用了一系列生动形象的例子进行解释。概括而言，他认为概念就像是“政治联盟”，大脑中会有一组神经元一起激活（共同发出“叮”声）。 Hinton继续用了一系列生动形象的例子进行解释。概括而言，他认为概念就像是“政治联盟”，大脑中会有一组神经元一起激活（共同发出“叮”声）。 例如，“勺子”就是一组神经元一起激活。这些联盟会重叠，比如“狗”和“猫”的概念就有很多共同的神经元（代表“有生命的”、“毛茸茸的”等）。 例如，“勺子”就是一组神经元一起激活。这些联盟会重叠，比如“狗”和“猫”的概念就有很多共同的神经元（代表“有生命的”、“毛茸茸的”等）。 第二个问题是，是否存在某些神经元对宏观概念（如“动物”）激活，而另一些神经元对微观概念（如特定物种）激活？ 第二个问题是，是否存在某些神经元对宏观概念（如“动物”）激活，而另一些神经元对微观概念（如特定物种）激活？ 对此，Hinton则表示问题很好，但没有人确切知道。 对此，Hinton则表示问题很好，但没有人确切知道。 不过这个联盟中，肯定有一些神经元对更普遍的事物激活更频繁，而另一些神经元对更具体的事物激活较少。 不过这个联盟中，肯定有一些神经元对更普遍的事物激活更频繁，而另一些神经元对更具体的事物激活较少。 不过这个联盟中，肯定有一些神经元对更普遍的事物激活更频繁，而另一些神经元对更具体的事物激活较少。 深度学习的突破：反向传播 深度学习的突破：反向传播 说完神经网络，Hinton的话题更多还是围绕“拿手好戏”——深度学习展开。 说完神经网络，Hinton的话题更多还是围绕“拿手好戏”——深度学习展开。 以前人们试图给计算机输入规则，但Hinton却想改变这个过程，因为在他看来，大脑的运作方式显然不是靠别人给你规则然后你执行规则。 以前人们试图给计算机输入规则，但Hinton却想改变这个过程，因为在他看来，大脑的运作方式显然不是靠别人给你规则然后你执行规则。 我们为神经网络编写程序，但这些程序只是告诉网络如何根据神经元的活动来调整连接强度。如果网络有多个层，这就叫深度学习。 我们为神经网络编写程序，但这些程序只是告诉网络如何根据神经元的活动来调整连接强度。如果网络有多个层，这就叫深度学习。 我们为神经网络编写程序，但这些程序只是告诉网络如何根据神经元的活动来调整连接强度。如果网络有多个层，这就叫深度学习。 他接着举了一个经典例子来说明深度学习的原理—— 让AI识别图像中有没有鸟 。 他接着举了一个经典例子来说明深度学习的原理—— 让AI识别图像中有没有鸟 让AI识别图像中有没有鸟 。 如果把图像的像素亮度直接输入给AI，让它判断是不是鸟，这看起来毫无头绪。毕竟，像素只是数字，并不能直接告诉你“这是一只鸟”。 如果把图像的像素亮度直接输入给AI，让它判断是不是鸟，这看起来毫无头绪。毕竟，像素只是数字，并不能直接告诉你“这是一只鸟”。 早期研究者会试图手动告诉计算机，“这条线是边缘”、“这块区域是背景”、“这个形状像翅膀”，但这条路行不通——因为现实世界太复杂了。 早期研究者会试图手动告诉计算机，“这条线是边缘”、“这块区域是背景”、“这个形状像翅膀”，但这条路行不通——因为现实世界太复杂了。 所以我们说，不如让AI自己学会“怎么去看”。 所以我们说，不如让AI自己学会“怎么去看”。 所以我们说，不如让AI自己学会“怎么去看”。 这就是神经网络的思路： 不给规则，而是给它数据，让它自己总结规则 。 这就是神经网络的思路： 不给规则，而是给它数据，让它自己总结规则 不给规则，而是给它数据，让它自己总结规则 。 主持人接着问道，“那如果我们不告诉它规则，只是随机设定每个连接的强弱，它会怎么判断呢？” 主持人接着问道，“那如果我们不告诉它规则，只是随机设定每个连接的强弱，它会怎么判断呢？” Hinton笑着回答： Hinton笑着回答： 它大概会说“50%是鸟，50%不是鸟”，也就是完全蒙。 它大概会说“50%是鸟，50%不是鸟”，也就是完全蒙。 它大概会说“50%是鸟，50%不是鸟”，也就是完全蒙。 那么，AI该如何从这种“蒙圈状态”变聪明呢？ 那么，AI该如何从这种“蒙圈状态”变聪明呢？ Hinton解释说，这个过程就像一个巨大的试错系统。你得告诉AI——这张图有鸟，那张没有。每次它猜得不对时，就调整一点点神经元之间的连接强度。 Hinton解释说，这个过程就像一个巨大的试错系统。你得告诉AI——这张图有鸟，那张没有。每次它猜得不对时，就调整一点点神经元之间的连接强度。 然而问题是，网络中有 数万亿个连接 ，如果逐个试，那要试到宇宙热寂（指宇宙熵值不可逆地增至极大，最终达到热平衡的静止状态）。 然而问题是，网络中有 数万亿个连接 数万亿个连接 ，如果逐个试，那要试到宇宙热寂（指宇宙熵值不可逆地增至极大，最终达到热平衡的静止状态）。 Hinton表示，真正的突破出现在1986年，他们提出了 “反向传播” （Backpropagation）——它能一次性算出所有连接该怎么改，是该增强还是减弱，让整个网络都向着正确方向调整。这让训练速度从“永远”变成了“现实可行”。 Hinton表示，真正的突破出现在1986年，他们提出了 “反向传播” “反向传播” （Backpropagation）——它能一次性算出所有连接该怎么改，是该增强还是减弱，让整个网络都向着正确方向调整。这让训练速度从“永远”变成了“现实可行”。 但事情并没有一开始就那么顺利。Hinton也坦言： 但事情并没有一开始就那么顺利。Hinton也坦言： 当时我们以为这就解决了智能问题。结果发现，它只有在拥有海量数据和庞大算力时才有效。我们那时的算力还差一百万倍。 当时我们以为这就解决了智能问题。结果发现，它只有在拥有海量数据和庞大算力时才有效。我们那时的算力还差一百万倍。 当时我们以为这就解决了智能问题。结果发现，它只有在拥有海量数据和庞大算力时才有效。我们那时的算力还差一百万倍。 真正让深度学习起飞的，是 算力的提升 （晶体管微缩百万倍）和 数据的爆炸式增长 （互联网时代）。 真正让深度学习起飞的，是 算力的提升 算力的提升 （晶体管微缩百万倍）和 数据的爆炸式增长 数据的爆炸式增长 （互联网时代）。 于是，那些在80年代“理论可行但跑不动”的神经网络，终于在2010年代活了过来——这便是现代AI浪潮的起点。 于是，那些在80年代“理论可行但跑不动”的神经网络，终于在2010年代活了过来——这便是现代AI浪潮的起点。 今天的大模型，本质上就是巨型神经网络，通过反向传播和海量数据，自学出了“看”、“听”、“说”的能力。 今天的大模型，本质上就是巨型神经网络，通过反向传播和海量数据，自学出了“看”、“听”、“说”的能力。 今天的大模型，本质上就是巨型神经网络，通过反向传播和海量数据，自学出了“看”、“听”、“说”的能力。 这一点也让Hinton相信，AI不再只是工具，而是一个正在学习、逐步理解世界的系统。 这一点也让Hinton相信，AI不再只是工具，而是一个正在学习、逐步理解世界的系统。 大语言模型认知的本质 大语言模型认知的本质 至于深度学习机制如何作用于大语言模型（LLM），Hinton又做了一番解释。 至于深度学习机制如何作用于大语言模型（LLM），Hinton又做了一番解释。 他认为LLM的思维过程与我们人类出奇地相似： 他认为LLM的思维过程与我们人类出奇地相似： 给它一个句子的开头，它会把每个词转换成一组神经元特征，用这些特征去捕捉含义；然后，这些特征之间相互作用、组合，就像视觉系统从“边缘”拼出“鸟喙”的过程一样，最终激活代表下一个词的神经元。 给它一个句子的开头，它会把每个词转换成一组神经元特征，用这些特征去捕捉含义；然后，这些特征之间相互作用、组合，就像视觉系统从“边缘”拼出“鸟喙”的过程一样，最终激活代表下一个词的神经元。 给它一个句子的开头，它会把每个词转换成一组神经元特征，用这些特征去捕捉含义；然后，这些特征之间相互作用、组合，就像视觉系统从“边缘”拼出“鸟喙”的过程一样，最终激活代表下一个词的神经元。 换句话说， 它不是在背书，而是在思考——以统计规律为神经，以语义结构为逻辑 。 换句话说， 它不是在背书，而是在思考——以统计规律为神经，以语义结构为逻辑 它不是在背书，而是在思考——以统计规律为神经，以语义结构为逻辑 。 并且训练方式也同样朴素而惊人： 并且训练方式也同样朴素而惊人： 我们给它看一段文本，让它预测下一个词；如果猜错了，就通过“反向传播”机制，告诉它错在哪、该怎么改；一遍又一遍，直到它能像人一样续写句子。 我们给它看一段文本，让它预测下一个词；如果猜错了，就通过“反向传播”机制，告诉它错在哪、该怎么改；一遍又一遍，直到它能像人一样续写句子。 我们给它看一段文本，让它预测下一个词；如果猜错了，就通过“反向传播”机制，告诉它错在哪、该怎么改；一遍又一遍，直到它能像人一样续写句子。 正是这种“预测—修正—再预测”的循环，让语言模型逐渐从符号中学会了语义，从统计中长出了理解。 正是这种“预测—修正—再预测”的循环，让语言模型逐渐从符号中学会了语义，从统计中长出了理解。 谈到这里，二人都想起乔姆斯基（美国语言学家，转换生成语法的创始人）经常把一句话挂在嘴边： 谈到这里，二人都想起乔姆斯基（美国语言学家，转换生成语法的创始人）经常把一句话挂在嘴边： 这只是统计技巧，不是真理解。 这只是统计技巧，不是真理解。 这只是统计技巧，不是真理解。 对此，Hinton顺势反问了一波主持人（主持人之前反复提到乔姆斯基类似的观点）： 对此，Hinton顺势反问了一波主持人（主持人之前反复提到乔姆斯基类似的观点）： 那你自己又是怎么决定下一个要说的词的呢？ 那你自己又是怎么决定下一个要说的词的呢？ 那你自己又是怎么决定下一个要说的词的呢？ 主持人试图解释，但最后还是摊手放弃，他尴尬表示“说实话，我希望自己知道”。 主持人试图解释，但最后还是摊手放弃，他尴尬表示“说实话，我希望自己知道”。 好在Hinton放过了他，而且接着提醒， 道德、情绪、共情，这些看似高阶的判断，归根结底也都来自神经元之间的电信号 。 好在Hinton放过了他，而且接着提醒， 道德、情绪、共情，这些看似高阶的判断，归根结底也都来自神经元之间的电信号 道德、情绪、共情，这些看似高阶的判断，归根结底也都来自神经元之间的电信号 。 所有你归因于道德或情感的过程，本质上仍是信号的传递与权重的调整。 所有你归因于道德或情感的过程，本质上仍是信号的传递与权重的调整。 所有你归因于道德或情感的过程，本质上仍是信号的传递与权重的调整。 并且Hinton最后抛出了一个颇具哲学意味的观点： 只要有足够的数据和算力，AI的“大脑”在某种意义上也会像我们一样——它会形成自己的“经验”和“直觉” 。 并且Hinton最后抛出了一个颇具哲学意味的观点： 只要有足够的数据和算力，AI的“大脑”在某种意义上也会像我们一样——它会形成自己的“经验”和“直觉” 只要有足够的数据和算力，AI的“大脑”在某种意义上也会像我们一样——它会形成自己的“经验”和“直觉” 。 AI或许早已拥有“主观体验”，只是还未觉醒 AI或许早已拥有“主观体验”，只是还未觉醒 话题随即转向更深的层面——AI的心智与意识问题。 话题随即转向更深的层面——AI的心智与意识问题。 主持人问Hinton，是否认为AI会因为“有意识”而接管人类。Hinton的回答则直接打破了常规认知： 主持人问Hinton，是否认为AI会因为“有意识”而接管人类。Hinton的回答则直接打破了常规认知： 大多数人其实完全不理解“有意识”是什么意思。人们对心智的理解，就像相信地球是6000年前被造出来一样幼稚。 大多数人其实完全不理解“有意识”是什么意思。人们对心智的理解，就像相信地球是6000年前被造出来一样幼稚。 大多数人其实完全不理解“有意识”是什么意思。人们对心智的理解，就像相信地球是6000年前被造出来一样幼稚。 大多数人其实完全不理解“有意识”是什么意思。人们对心智的理解，就像相信地球是6000年前被造出来一样幼稚。 在他看来，我们一直以来都把心智想成一个“内在剧场”。在这个剧场里，经验就像一部正在上演的电影——看到一头粉色小象，你就以为那头象真的“在你的脑子里”。 在他看来，我们一直以来都把心智想成一个“内在剧场”。在这个剧场里，经验就像一部正在上演的电影——看到一头粉色小象，你就以为那头象真的“在你的脑子里”。 但Hinton说，这种比喻是错误的。 但Hinton说，这种比喻是错误的。 经验不是一个存在于脑内的事物，而是一种假设——我的感知系统告诉我有一头粉色小象，我的理性系统则知道它可能在骗我。 经验不是一个存在于脑内的事物，而是一种假设——我的感知系统告诉我有一头粉色小象，我的理性系统则知道它可能在骗我。 经验不是一个存在于脑内的事物，而是一种假设——我的感知系统告诉我有一头粉色小象，我的理性系统则知道它可能在骗我。 所谓“主观体验”，其实是大脑为解释感知现象而构建的假设模型。 所谓“主观体验”，其实是大脑为解释感知现象而构建的假设模型。 所谓“主观体验”，其实是大脑为解释感知现象而构建的假设模型。 于是，当他谈到AI是否有“主观体验”时，就有了开头那样的回答： 于是，当他谈到AI是否有“主观体验”时，就有了开头那样的回答： 我相信它们有。只是它们自己不知道，因为它们的‘自我认知’来源于我们，而我们自己对意识的理解就是错的。 我相信它们有。只是它们自己不知道，因为它们的‘自我认知’来源于我们，而我们自己对意识的理解就是错的。 我相信它们有。只是它们自己不知道，因为它们的‘自我认知’来源于我们，而我们自己对意识的理解就是错的。 他举了个多模态AI的例子，假如一个能看能说的机器人因为棱镜折射看错了物体位置，后来纠正后说——“我有过一个错误的主观体验”，那它其实就在使用和我们相同的意识概念。 他举了个多模态AI的例子，假如一个能看能说的机器人因为棱镜折射看错了物体位置，后来纠正后说——“我有过一个错误的主观体验”，那它其实就在使用和我们相同的意识概念。 换句话说， 如果AI开始谈论“主观体验”，那也许说明它真的在体验——只是用我们的语言在描述 。 换句话说， 如果AI开始谈论“主观体验”，那也许说明它真的在体验——只是用我们的语言在描述 如果AI开始谈论“主观体验”，那也许说明它真的在体验——只是用我们的语言在描述 。 Hinton借此提醒大家： Hinton借此提醒大家： 当AI比我们聪明得多时，最危险的不是它反叛，而是它会“说服”。它会让那个要拔插头的人，真心认为拔插头是个糟糕的决定。 当AI比我们聪明得多时，最危险的不是它反叛，而是它会“说服”。它会让那个要拔插头的人，真心认为拔插头是个糟糕的决定。 当AI比我们聪明得多时，最危险的不是它反叛，而是它会“说服”。它会让那个要拔插头的人，真心认为拔插头是个糟糕的决定。 当然，在Hinton看来，AI的威胁不止于此。 当然，在Hinton看来，AI的威胁不止于此。 AI的风险：滥用、生存与监管 AI的风险：滥用、生存与监管 在节目最后，Hinton用了很大篇幅来完整讲述AI可能存在的风险。 在节目最后，Hinton用了很大篇幅来完整讲述AI可能存在的风险。 能源消耗、金融泡沫、社会不稳定……这些都是真实的风险。它们可能不会摧毁人类，但足以重塑文明。 能源消耗、金融泡沫、社会不稳定……这些都是真实的风险。它们可能不会摧毁人类，但足以重塑文明。 能源消耗、金融泡沫、社会不稳定……这些都是真实的风险。它们可能不会摧毁人类，但足以重塑文明。 其中，Hinton最担心 滥用风险 和 生存风险 这两类。 其中，Hinton最担心 滥用风险 滥用风险 和 生存风险 生存风险 这两类。 在Hinton看来，目前最紧迫的风险就是AI滥用，例如用AI生成虚假信息、操纵选举、制造恐慌等。 在Hinton看来，目前最紧迫的风险就是AI滥用，例如用AI生成虚假信息、操纵选举、制造恐慌等。 为应对这一风险，他认为需要通过法律和监管手段来限制和打击这种滥用行为。同时，技术上也需要开发检测和防范虚假信息的工具。 为应对这一风险，他认为需要通过法律和监管手段来限制和打击这种滥用行为。同时，技术上也需要开发检测和防范虚假信息的工具。 此外，生存风险（指AI本身可能成为恶意行为者）则可能对人类社会和文明构成根本性威胁。 此外，生存风险（指AI本身可能成为恶意行为者）则可能对人类社会和文明构成根本性威胁。 Hinton认为，如果AI发展出自主意识和目标，并且这些目标与人类的利益相冲突，可能会导致不可预测的后果。 Hinton认为，如果AI发展出自主意识和目标，并且这些目标与人类的利益相冲突，可能会导致不可预测的后果。 对此，人类需要在AI的设计和开发阶段就考虑安全性和伦理问题（如“关闭开关”和“对齐机制”），从而确保AI的目标与人类的利益一致。 对此，人类需要在AI的设计和开发阶段就考虑安全性和伦理问题（如“关闭开关”和“对齐机制”），从而确保AI的目标与人类的利益一致。 值得一提的是，在AI监管这件事上，Hinton还提出了一个很有意思的看法： 值得一提的是，在AI监管这件事上，Hinton还提出了一个很有意思的看法： 在防止AI接管的问题上，所有国家的利益是一致的。 但国际合作可能由欧洲和中国引领 。 在防止AI接管的问题上，所有国家的利益是一致的。 但国际合作可能由欧洲和中国引领 。 在防止AI接管的问题上，所有国家的利益是一致的。 但国际合作可能由欧洲和中国引领 但国际合作可能由欧洲和中国引领 。 One More Thing One More Thing 关于中美人工智能竞赛，Hinton也在节目中表达了自己的看法。 关于中美人工智能竞赛，Hinton也在节目中表达了自己的看法。 面对主持人甩出的“美国领先还是中国领先”这一问题，Hinton冷静表示： 面对主持人甩出的“美国领先还是中国领先”这一问题，Hinton冷静表示： 美国目前领先于中国，但领先优势没有想象的那么大，而且它将失去这个优势。 美国目前领先于中国，但领先优势没有想象的那么大，而且它将失去这个优势。 美国目前领先于中国，但领先优势没有想象的那么大，而且它将失去这个优势。 美国目前领先于中国，但领先优势没有想象的那么大，而且它将失去这个优势。 因为在他看来，美国正在破坏基础科学研究的资金支持。 因为在他看来，美国正在破坏基础科学研究的资金支持。 深度学习和AI革命源于多年的基础研究，这些研究的总成本可能还不及一架B1轰炸机。而美国减少对基础研究的资助、攻击研究型大学等行为，无疑将导致美国在20年后失去领先优势。 深度学习和AI革命源于多年的基础研究，这些研究的总成本可能还不及一架B1轰炸机。而美国减少对基础研究的资助、攻击研究型大学等行为，无疑将导致美国在20年后失去领先优势。 深度学习和AI革命源于多年的基础研究，这些研究的总成本可能还不及一架B1轰炸机。而美国减少对基础研究的资助、攻击研究型大学等行为，无疑将导致美国在20年后失去领先优势。 而中国却是人工智能革命的风险投资家，以及他再次cue到了DeepSeek。 而中国却是人工智能革命的风险投资家，以及他再次cue到了DeepSeek。 中国确实给予初创企业很大的自由，让他们自主选择最终胜出者。有些初创企业非常积极进取，渴望赚大钱，创造出令人惊叹的产品。其中一些初创企业最终获得了巨大的成功，比如DeepSeek…… 中国确实给予初创企业很大的自由，让他们自主选择最终胜出者。有些初创企业非常积极进取，渴望赚大钱，创造出令人惊叹的产品。其中一些初创企业最终获得了巨大的成功，比如DeepSeek…… 中国确实给予初创企业很大的自由，让他们自主选择最终胜出者。有些初创企业非常积极进取，渴望赚大钱，创造出令人惊叹的产品。其中一些初创企业最终获得了巨大的成功，比如DeepSeek…… 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
{"url": "https://www.qbitai.com/2025/10/340662.html", "title": "拒绝小扎15亿美元offer的大佬，还是加入Meta了", "date": "2025-10-12", "content": "拒绝小扎15亿美元offer的大佬，还是加入Meta了 拒绝小扎15亿美元offer的大佬，还是加入Meta了 克雷西 2025-10-12 10:22:43 来源： 量子位 克雷西 克雷西 克雷西 克雷西 2025-10-12 2025-10-12 10:22:43 10:22:43 来源： 量子位 来源： 量子位 量子位 摘要样式 Mira创业公司联创已离职 Mira创业公司联创已离职 Mira创业公司联创已离职 克雷西 发自 凹非寺 量子位 | 公众号 QbitAI 克雷西 发自 凹非寺 量子位 | 公众号 QbitAI 克雷西 发自 凹非寺 量子位 | 公众号 QbitAI 那个拒绝了小扎15亿美元薪酬包的机器学习大神，还是加入Meta了。 那个拒绝了小扎15亿美元薪酬包的机器学习大神，还是加入Meta了。 OpenAI前CTO Mira Murati创业公司Thinking Machines Lab证实，联创、首席架构师Andrew Tulloch已经离职去了Meta。 OpenAI前CTO Mira Murati创业公司Thinking Machines Lab证实，联创、首席架构师Andrew Tulloch已经离职去了Meta。 按照公司发言人的说法，Tulloch离职的理由是“出于个人原因决定走一条不同的道路”，其本人则未给出回应。 按照公司发言人的说法，Tulloch离职的理由是“出于个人原因决定走一条不同的道路”，其本人则未给出回应。 但对于Tulloch的离职，还是有网友感到不解，表示如果Thinking Machines Lab估值是120亿美元，Tulloch起码能拿到10%，实在是想象不到他的离职理由。 但对于Tulloch的离职，还是有网友感到不解，表示如果Thinking Machines Lab估值是120亿美元，Tulloch起码能拿到10%，实在是想象不到他的离职理由。 有人调侃说，可能是Tulloch“已经完成思考”了吧。 有人调侃说，可能是Tulloch“已经完成思考”了吧。 11年Meta老员工“重归故里” 11年Meta老员工“重归故里” Tulloch这次跳槽到Meta，也可以算是“ 重归故里 ”，之前他曾经在Meta（包括Facebook时期）干了11年。 Tulloch这次跳槽到Meta，也可以算是“ 重归故里 重归故里 ”，之前他曾经在Meta（包括Facebook时期）干了11年。 曾与Tulloch共事的Facebook前高管Mike Vernal评价说，“他绝对是个天才”。 曾与Tulloch共事的Facebook前高管Mike Vernal评价说，“他绝对是个天才”。 Tulloch来自澳大利亚，2011年本科毕业于悉尼大学，专业是数学与统计学，其间他是悉尼大学理学院最优秀的学生之一，获得过一等荣誉（First Class Honours）和大学奖章（University Medal）。 Tulloch来自澳大利亚，2011年本科毕业于悉尼大学，专业是数学与统计学，其间他是悉尼大学理学院最优秀的学生之一，获得过一等荣誉（First Class Honours）和大学奖章（University Medal）。 本科毕业前，Tulloch到金融巨头高盛实习，开发金融产品并制定交易策略，并一直工作到了毕业之后的2012年2月。 本科毕业前，Tulloch到金融巨头高盛实习，开发金融产品并制定交易策略，并一直工作到了毕业之后的2012年2月。 之后Tulloch的金融生涯便画上了句号，同年4月，他正式入职Facebook，从事了18个月的机器学习工作。 之后Tulloch的金融生涯便画上了句号，同年4月，他正式入职Facebook，从事了18个月的机器学习工作。 再然后又于2013-2014年攻读了剑桥大学的数理统计、统计学与机器学习硕士，表现优异，荣获三一学院颁发的奖项，并因在考试中取得最高分而获得荣誉。 再然后又于2013-2014年攻读了剑桥大学的数理统计、统计学与机器学习硕士，表现优异，荣获三一学院颁发的奖项，并因在考试中取得最高分而获得荣誉。 在Facebook期间的另一个插曲是，Tulloch在2016年收到了OpenAI总裁Brockman的邀请，希望他成为OpenAI的首批员工。 在Facebook期间的另一个插曲是，Tulloch在2016年收到了OpenAI总裁Brockman的邀请，希望他成为OpenAI的首批员工。 但OpenAI当时开出的薪酬只有17.5万美元外加12.5万美元奖金，而彼时Facebook给他的年薪已经是80万美元，并且还有继续上涨的空间。 但OpenAI当时开出的薪酬只有17.5万美元外加12.5万美元奖金，而彼时Facebook给他的年薪已经是80万美元，并且还有继续上涨的空间。 他坦率地讲自己对薪酬下降的担忧告诉了还没和OpenAI分道扬镳的马斯克，没有选择加入OpenAI。 他坦率地讲自己对薪酬下降的担忧告诉了还没和OpenAI分道扬镳的马斯克，没有选择加入OpenAI。 直到2023年10月，OpenAI早已不同往日，Tulloch选择在OpenAI的极盛时期入职。 直到2023年10月，OpenAI早已不同往日，Tulloch选择在OpenAI的极盛时期入职。 在OpenAI，Tulloch的工作依然是ML系统，涉及GPT4.5和4o的训练及o系列的推理。 在OpenAI，Tulloch的工作依然是ML系统，涉及GPT4.5和4o的训练及o系列的推理。 不过Tulloch在OpenAI的工作时间就没有那么长了，今年1月，他跟随离职的前CTO Mira Murati等人一起创立了Thinking Machines Lab，直到这次重回Meta。 不过Tulloch在OpenAI的工作时间就没有那么长了，今年1月，他跟随离职的前CTO Mira Murati等人一起创立了Thinking Machines Lab，直到这次重回Meta。 当然，小扎之前挖的一批人当中也有其他“回归用户”，比如从Anthropic挖到的Joel Pobar和Anton Bakhtin，之前分别是10年和5年的Meta老员工。 当然，小扎之前挖的一批人当中也有其他“回归用户”，比如从Anthropic挖到的Joel Pobar和Anton Bakhtin，之前分别是10年和5年的Meta老员工。 再说回Tulloch这次回归Meta，也是“真香定律”在他身上第二度上演。 再说回Tulloch这次回归Meta，也是“真香定律”在他身上第二度上演。 两月前拒绝小扎15亿美元offer 两月前拒绝小扎15亿美元offer 两个月之前，Meta的挖人计划正进行得如火如荼，小扎亲自担任“首席招聘官”向Tulloch递出橄榄枝并给出15亿美元薪酬包时，后者选择了拒绝。 两个月之前，Meta的挖人计划正进行得如火如荼，小扎亲自担任“首席招聘官”向Tulloch递出橄榄枝并给出15亿美元薪酬包时，后者选择了拒绝。 一开始，小扎想的是直接收购Thinking Machines Lab，还联系了Mira Murati，但遭到拒绝。 一开始，小扎想的是直接收购Thinking Machines Lab，还联系了Mira Murati，但遭到拒绝。 Meta转而发起了一场“全面突袭”，小扎先后联系了十几名Thinking Machines Lab员工，试探他们是否愿意跳槽，当然最主要的目标还是Tulloch。 Meta转而发起了一场“全面突袭”，小扎先后联系了十几名Thinking Machines Lab员工，试探他们是否愿意跳槽，当然最主要的目标还是Tulloch。 小扎对同样从OpenAI出走创业的Ilya也采取了类似的套路，一开始想要收购他创立的Safe Superintelligence Inc，顺便把Ilya本人也招致麾下，被拒之后改成了挖联创，并成功挖走了CEO Daniel Gross。 小扎对同样从OpenAI出走创业的Ilya也采取了类似的套路，一开始想要收购他创立的Safe Superintelligence Inc，顺便把Ilya本人也招致麾下，被拒之后改成了挖联创，并成功挖走了CEO Daniel Gross。 不过这一波Meta发言人否认了收购Thinking Machines Lab和15亿美元挖Tulloch的说法——Meta对收购不感兴趣，薪酬数字也很荒谬，因为其中包含股票，具体价值要取决于股市情况。 不过这一波Meta发言人否认了收购Thinking Machines Lab和15亿美元挖Tulloch的说法——Meta对收购不感兴趣，薪酬数字也很荒谬，因为其中包含股票，具体价值要取决于股市情况。 但否认的只是数字，可并没有否认要挖人。 但否认的只是数字，可并没有否认要挖人。 而且从结果上看，总之Tulloch现在是被挖来了，不过具体工作内容还不清楚。 而且从结果上看，总之Tulloch现在是被挖来了，不过具体工作内容还不清楚。 有意思的是，这时Meta挖人的白热化阶段早已过去，内部改组也搞出了一地鸡毛，Tulloch这时选择入职，会是基于一种什么样的考虑？ 有意思的是，这时Meta挖人的白热化阶段早已过去，内部改组也搞出了一地鸡毛，Tulloch这时选择入职，会是基于一种什么样的考虑？ 有人说是薪酬包涨到了20亿美元，你觉得呢？ 有人说是薪酬包涨到了20亿美元，你觉得呢？ 参考链接： [1]https://www.wsj.com/tech/ai/thinking-machines-lab-co-founder-departs-for-meta-442d7461 [2]https://www.wsj.com/tech/ai/meta-zuckerberg-ai-recruiting-fail-e6107555 [3]https://x.com/MeghanBobrowsky/status/1977078882819006630 参考链接： [1]https://www.wsj.com/tech/ai/thinking-machines-lab-co-founder-departs-for-meta-442d7461 [2]https://www.wsj.com/tech/ai/meta-zuckerberg-ai-recruiting-fail-e6107555 [3]https://x.com/MeghanBobrowsky/status/1977078882819006630 版权声明 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。 版权所有，未经授权不得以任何形式转载及使用，违者必究。"}
